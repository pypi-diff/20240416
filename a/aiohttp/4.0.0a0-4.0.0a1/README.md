# Comparing `tmp/aiohttp-4.0.0a0.tar.gz` & `tmp/aiohttp-4.0.0a1.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "dist\aiohttp-4.0.0a0.tar", last modified: Wed Jan  9 01:05:08 2019, max compression
+gzip compressed data, was "dist/aiohttp-4.0.0a1.tar", last modified: Wed Oct  9 11:27:45 2019, max compression
```

## Comparing `aiohttp-4.0.0a0.tar` & `aiohttp-4.0.0a1.tar`

### file list

```diff
@@ -1,301 +1,245 @@
-drwxrwxrwx   0        0        0        0 2019-01-09 01:05:08.000000 aiohttp-4.0.0a0/
--rw-rw-rw-   0        0        0     1323 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/.appveyor.yml
--rw-rw-rw-   0        0        0      113 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/.cherry_picker.toml
--rw-rw-rw-   0        0        0      346 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/.editorconfig
--rw-rw-rw-   0        0        0       69 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/.gitattributes
-drwxrwxrwx   0        0        0        0 2019-01-09 01:05:08.000000 aiohttp-4.0.0a0/.github/
--rw-rw-rw-   0        0        0      572 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/.github/CODEOWNERS
--rw-rw-rw-   0        0        0      755 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/.github/ISSUE_TEMPLATE.md
--rw-rw-rw-   0        0        0      229 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/.github/main.workflow
--rw-rw-rw-   0        0        0     1336 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/.github/PULL_REQUEST_TEMPLATE.md
--rw-rw-rw-   0        0        0      651 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/.gitignore
--rw-rw-rw-   0        0        0      125 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/.gitmodules
--rw-rw-rw-   0        0        0       82 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/.pyup.yml
--rw-rw-rw-   0        0        0       67 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/.readthedocs.yml
--rw-rw-rw-   0        0        0     8876 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/.travis.yml
-drwxrwxrwx   0        0        0        0 2019-01-09 01:05:08.000000 aiohttp-4.0.0a0/aiohttp/
--rw-rw-rw-   0        0        0     5392 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/abc.py
--rw-rw-rw-   0        0        0     2644 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/base_protocol.py
--rw-rw-rw-   0        0        0    42268 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/client.py
--rw-rw-rw-   0        0        0     7547 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/client_exceptions.py
--rw-rw-rw-   0        0        0     8001 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/client_proto.py
--rw-rw-rw-   0        0        0    35719 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/client_reqrep.py
--rw-rw-rw-   0        0        0    10694 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/client_ws.py
--rw-rw-rw-   0        0        0    39556 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/connector.py
--rw-rw-rw-   0        0        0    11268 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/cookiejar.py
--rw-rw-rw-   0        0        0     5807 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/formdata.py
--rw-rw-rw-   0        0        0     1781 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/frozenlist.py
--rw-rw-rw-   0        0        0     1431 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/frozenlist.pyi
--rw-rw-rw-   0        0        0     3449 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/hdrs.py
--rw-rw-rw-   0        0        0    22633 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/helpers.py
--rw-rw-rw-   0        0        0     1385 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/http.py
--rw-rw-rw-   0        0        0     2358 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/http_exceptions.py
--rw-rw-rw-   0        0        0    27912 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/http_parser.py
--rw-rw-rw-   0        0        0    24594 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/http_websocket.py
--rw-rw-rw-   0        0        0     5239 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/http_writer.py
--rw-rw-rw-   0        0        0     1234 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/locks.py
--rw-rw-rw-   0        0        0      325 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/log.py
--rw-rw-rw-   0        0        0    32277 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/multipart.py
--rw-rw-rw-   0        0        0    14027 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/payload.py
--rw-rw-rw-   0        0        0     2103 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/payload_streamer.py
--rw-rw-rw-   0        0        0        6 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/py.typed
--rw-rw-rw-   0        0        0    10332 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/pytest_plugin.py
--rw-rw-rw-   0        0        0     3626 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/resolver.py
--rw-rw-rw-   0        0        0      948 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/signals.py
--rw-rw-rw-   0        0        0      325 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/signals.pyi
--rw-rw-rw-   0        0        0    20085 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/streams.py
--rw-rw-rw-   0        0        0     1631 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/tcp_helpers.py
--rw-rw-rw-   0        0        0    20525 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/test_utils.py
--rw-rw-rw-   0        0        0    12662 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/tracing.py
--rw-rw-rw-   0        0        0     1259 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/typedefs.py
--rw-rw-rw-   0        0        0    15086 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/web.py
--rw-rw-rw-   0        0        0    17212 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/web_app.py
--rw-rw-rw-   0        0        0    10079 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/web_exceptions.py
--rw-rw-rw-   0        0        0    12712 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/web_fileresponse.py
--rw-rw-rw-   0        0        0     8269 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/web_log.py
--rw-rw-rw-   0        0        0     4188 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/web_middlewares.py
--rw-rw-rw-   0        0        0    21394 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/web_protocol.py
--rw-rw-rw-   0        0        0    25234 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/web_request.py
--rw-rw-rw-   0        0        0    25511 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/web_response.py
--rw-rw-rw-   0        0        0     6077 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/aiohttp/web_routedef.py
--rw-rw-rw-   0        0        0    10088 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/aiohttp/web_runner.py
--rw-rw-rw-   0        0        0     2165 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/aiohttp/web_server.py
--rw-rw-rw-   0        0        0    38788 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/aiohttp/web_urldispatcher.py
--rw-rw-rw-   0        0        0    17082 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/aiohttp/web_ws.py
--rw-rw-rw-   0        0        0     8178 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/aiohttp/worker.py
--rw-rw-rw-   0        0        0     3959 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/_cparser.pxd
--rw-rw-rw-   0        0        0   189932 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/_find_header.c
--rw-rw-rw-   0        0        0      170 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/_find_header.h
--rw-rw-rw-   0        0        0       68 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/_find_header.pxd
--rw-rw-rw-   0        0        0   287339 2019-01-09 01:04:04.000000 aiohttp-4.0.0a0/aiohttp/_frozenlist.c
--rw-rw-rw-   0        0        0     2605 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/_frozenlist.pyx
--rw-rw-rw-   0        0        0     2027 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/_headers.pxi
--rw-rw-rw-   0        0        0   207049 2019-01-09 01:04:04.000000 aiohttp-4.0.0a0/aiohttp/_helpers.c
--rw-rw-rw-   0        0        0      204 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/_helpers.pyi
--rw-rw-rw-   0        0        0     1049 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/_helpers.pyx
--rw-rw-rw-   0        0        0   994100 2019-01-09 01:04:05.000000 aiohttp-4.0.0a0/aiohttp/_http_parser.c
--rw-rw-rw-   0        0        0    28672 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/_http_parser.pyx
--rw-rw-rw-   0        0        0   205822 2019-01-09 01:04:05.000000 aiohttp-4.0.0a0/aiohttp/_http_writer.c
--rw-rw-rw-   0        0        0     4193 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/_http_writer.pyx
--rw-rw-rw-   0        0        0   135136 2019-01-09 01:04:05.000000 aiohttp-4.0.0a0/aiohttp/_websocket.c
--rw-rw-rw-   0        0        0     1559 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/_websocket.pyx
--rw-rw-rw-   0        0        0     4950 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/aiohttp/__init__.py
-drwxrwxrwx   0        0        0        0 2019-01-09 01:05:08.000000 aiohttp-4.0.0a0/aiohttp.egg-info/
--rw-rw-rw-   0        0        0        1 2019-01-09 01:05:07.000000 aiohttp-4.0.0a0/aiohttp.egg-info/dependency_links.txt
--rw-rw-rw-   0        0        0    18930 2019-01-09 01:05:07.000000 aiohttp-4.0.0a0/aiohttp.egg-info/PKG-INFO
--rw-rw-rw-   0        0        0      194 2019-01-09 01:05:07.000000 aiohttp-4.0.0a0/aiohttp.egg-info/requires.txt
--rw-rw-rw-   0        0        0     6522 2019-01-09 01:05:07.000000 aiohttp-4.0.0a0/aiohttp.egg-info/SOURCES.txt
--rw-rw-rw-   0        0        0        8 2019-01-09 01:05:07.000000 aiohttp-4.0.0a0/aiohttp.egg-info/top_level.txt
-drwxrwxrwx   0        0        0        0 2019-01-09 01:05:08.000000 aiohttp-4.0.0a0/CHANGES/
--rw-rw-rw-   0        0        0       12 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/CHANGES/.gitignore
--rw-rw-rw-   0        0        0      826 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/CHANGES/.TEMPLATE.rst
--rw-rw-rw-   0        0        0      238 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/CHANGES/3035.bugfix
--rw-rw-rw-   0        0        0      201 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/CHANGES/3313.feature
--rw-rw-rw-   0        0        0      123 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/CHANGES/3463.removal
--rw-rw-rw-   0        0        0       52 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/CHANGES/3464.bugfix
--rw-rw-rw-   0        0        0       25 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/CHANGES/3468.bugfix
--rw-rw-rw-   0        0        0      136 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/CHANGES/3471.bugfix
--rw-rw-rw-   0        0        0       90 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/CHANGES/3477.bugfix
--rw-rw-rw-   0        0        0      111 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/CHANGES/3480.bugfix
--rw-rw-rw-   0        0        0      119 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/CHANGES/3482.bugfix
--rw-rw-rw-   0        0        0       75 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/CHANGES/3483.feature
--rw-rw-rw-   0        0        0       85 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/CHANGES/3484.bugfix
--rw-rw-rw-   0        0        0       93 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/CHANGES/3487.misc
--rw-rw-rw-   0        0        0       53 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/CHANGES/3490.doc
--rw-rw-rw-   0        0        0       83 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/CHANGES/3497.bugfix
--rw-rw-rw-   0        0        0     9161 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/CHANGES.rst
--rw-rw-rw-   0        0        0      421 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/codecov.yml
--rw-rw-rw-   0        0        0     3221 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/CODE_OF_CONDUCT.md
--rw-rw-rw-   0        0        0      897 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/CONTRIBUTING.rst
--rw-rw-rw-   0        0        0     3770 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/CONTRIBUTORS.txt
-drwxrwxrwx   0        0        0        0 2019-01-09 01:05:08.000000 aiohttp-4.0.0a0/docs/
--rw-rw-rw-   0        0        0     5076 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/abc.rst
--rw-rw-rw-   0        0        0     4069 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/aiohttp-icon.svg
--rw-rw-rw-   0        0        0     4068 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/aiohttp-plain.svg
--rw-rw-rw-   0        0        0      978 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/built_with.rst
--rw-rw-rw-   0        0        0       79 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/changes.rst
--rw-rw-rw-   0        0        0      293 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/client.rst
--rw-rw-rw-   0        0        0    19515 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/client_advanced.rst
--rw-rw-rw-   0        0        0    14002 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/client_quickstart.rst
--rw-rw-rw-   0        0        0    63426 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/client_reference.rst
--rw-rw-rw-   0        0        0    10982 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/conf.py
--rw-rw-rw-   0        0        0     8585 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/contributing.rst
--rw-rw-rw-   0        0        0     9224 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/deployment.rst
--rw-rw-rw-   0        0        0       98 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/essays.rst
--rw-rw-rw-   0        0        0      392 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/external.rst
--rw-rw-rw-   0        0        0    14086 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/faq.rst
--rw-rw-rw-   0        0        0     4286 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/favicon.ico
--rw-rw-rw-   0        0        0     3419 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/glossary.rst
--rw-rw-rw-   0        0        0     4687 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/index.rst
--rw-rw-rw-   0        0        0     5435 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/logging.rst
--rwxrwxrwx   0        0        0     6703 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/make.bat
--rw-rw-rw-   0        0        0     6875 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/Makefile
--rw-rw-rw-   0        0        0     7176 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/migration_to_2xx.rst
--rw-rw-rw-   0        0        0      249 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/misc.rst
--rw-rw-rw-   0        0        0    11895 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/multipart.rst
--rw-rw-rw-   0        0        0     4979 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/multipart_reference.rst
--rw-rw-rw-   0        0        0     2861 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/new_router.rst
--rw-rw-rw-   0        0        0   256817 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/old-logo.png
--rw-rw-rw-   0        0        0    50150 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/old-logo.svg
--rw-rw-rw-   0        0        0     1733 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/powered_by.rst
--rw-rw-rw-   0        0        0     1156 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/signals.rst
--rw-rw-rw-   0        0        0     2653 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/spelling_wordlist.txt
--rw-rw-rw-   0        0        0     4742 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/streams.rst
--rw-rw-rw-   0        0        0     1252 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/structures.rst
--rw-rw-rw-   0        0        0    23934 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/testing.rst
--rw-rw-rw-   0        0        0     8405 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/third_party.rst
--rw-rw-rw-   0        0        0    12042 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/tracing_reference.rst
--rw-rw-rw-   0        0        0      263 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/utilities.rst
--rw-rw-rw-   0        0        0      381 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/web.rst
--rw-rw-rw-   0        0        0     4416 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/websocket_utilities.rst
--rw-rw-rw-   0        0        0    33902 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/web_advanced.rst
--rw-rw-rw-   0        0        0     2703 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/web_lowlevel.rst
--rw-rw-rw-   0        0        0    22801 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/web_quickstart.rst
--rw-rw-rw-   0        0        0    90641 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/web_reference.rst
--rw-rw-rw-   0        0        0     4405 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/whats_new_1_1.rst
--rw-rw-rw-   0        0        0     2444 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/whats_new_3_0.rst
-drwxrwxrwx   0        0        0        0 2019-01-09 01:05:08.000000 aiohttp-4.0.0a0/docs/_static/
--rw-rw-rw-   0        0        0     4519 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/docs/_static/aiohttp-icon-128x128.png
-drwxrwxrwx   0        0        0        0 2019-01-09 01:05:08.000000 aiohttp-4.0.0a0/examples/
--rw-rw-rw-   0        0        0     1813 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/background_tasks.py
--rw-rw-rw-   0        0        0      552 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/client_auth.py
--rw-rw-rw-   0        0        0      448 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/client_json.py
--rw-rw-rw-   0        0        0     2109 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/client_ws.py
--rw-rw-rw-   0        0        0     1408 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/cli_app.py
--rw-rw-rw-   0        0        0      937 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/curl.py
--rw-rw-rw-   0        0        0     3833 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/fake_server.py
-drwxrwxrwx   0        0        0        0 2019-01-09 01:05:08.000000 aiohttp-4.0.0a0/examples/legacy/
--rw-rw-rw-   0        0        0     3129 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/legacy/crawl.py
--rw-rw-rw-   0        0        0     5355 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/legacy/srv.py
--rw-rw-rw-   0        0        0     4904 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/legacy/tcp_protocol_parser.py
--rw-rw-rw-   0        0        0      548 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/lowlevel_srv.py
--rw-rw-rw-   0        0        0     1103 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/server.crt
--rw-rw-rw-   0        0        0      952 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/server.csr
--rw-rw-rw-   0        0        0     1675 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/server.key
--rw-rw-rw-   0        0        0      752 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/server_simple.py
--rw-rw-rw-   0        0        0      158 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/static_files.py
--rw-rw-rw-   0        0        0     2363 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/websocket.html
--rw-rw-rw-   0        0        0     1396 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/web_classview.py
--rw-rw-rw-   0        0        0      880 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/web_cookies.py
--rw-rw-rw-   0        0        0      608 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/web_rewrite_headers_middleware.py
--rw-rw-rw-   0        0        0     1370 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/web_srv.py
--rw-rw-rw-   0        0        0     1345 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/web_srv_route_deco.py
--rw-rw-rw-   0        0        0     1408 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/web_srv_route_table.py
--rw-rw-rw-   0        0        0     1417 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/examples/web_ws.py
--rw-rw-rw-   0        0        0   113378 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/HISTORY.rst
--rw-rw-rw-   0        0        0    11332 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/LICENSE.txt
--rw-rw-rw-   0        0        0     2935 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/Makefile
--rw-rw-rw-   0        0        0      394 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/MANIFEST.in
--rw-rw-rw-   0        0        0    18930 2019-01-09 01:05:08.000000 aiohttp-4.0.0a0/PKG-INFO
--rw-rw-rw-   0        0        0      246 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/pyproject.toml
--rw-rw-rw-   0        0        0      223 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/pytest.ci.ini
--rw-rw-rw-   0        0        0      184 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/pytest.ini
--rw-rw-rw-   0        0        0     4859 2019-01-09 01:03:41.000000 aiohttp-4.0.0a0/README.rst
-drwxrwxrwx   0        0        0        0 2019-01-09 01:05:08.000000 aiohttp-4.0.0a0/requirements/
--rw-rw-rw-   0        0        0      664 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/requirements/ci-wheel.txt
--rw-rw-rw-   0        0        0      152 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/requirements/ci.txt
--rw-rw-rw-   0        0        0       15 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/requirements/cython.txt
--rw-rw-rw-   0        0        0       71 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/requirements/dev.txt
--rw-rw-rw-   0        0        0       89 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/requirements/doc-spelling.txt
--rw-rw-rw-   0        0        0      109 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/requirements/doc.txt
--rw-rw-rw-   0        0        0       27 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/requirements/flake.txt
--rw-rw-rw-   0        0        0       18 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/requirements/towncrier.txt
--rw-rw-rw-   0        0        0       43 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/requirements/wheel.txt
--rw-rw-rw-   0        0        0     1353 2019-01-09 01:05:08.000000 aiohttp-4.0.0a0/setup.cfg
--rw-rw-rw-   0        0        0     5598 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/setup.py
-drwxrwxrwx   0        0        0        0 2019-01-09 01:05:08.000000 aiohttp-4.0.0a0/tests/
--rw-rw-rw-   0        0        0     6640 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/aiohttp.jpg
--rw-rw-rw-   0        0        0    54997 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/aiohttp.png
-drwxrwxrwx   0        0        0        0 2019-01-09 01:05:08.000000 aiohttp-4.0.0a0/tests/autobahn/
--rw-rw-rw-   0        0        0     1351 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/autobahn/client.py
--rw-rw-rw-   0        0        0      276 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/autobahn/fuzzingclient.json
--rw-rw-rw-   0        0        0      217 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/autobahn/fuzzingserver.json
--rw-rw-rw-   0        0        0     1402 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/autobahn/server.py
--rw-rw-rw-   0        0        0     1889 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/conftest.py
--rw-rw-rw-   0        0        0       13 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/data.unknown_mime_type
--rw-rw-rw-   0        0        0       44 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/hello.txt.gz
--rw-rw-rw-   0        0        0     4416 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_base_protocol.py
--rw-rw-rw-   0        0        0     1311 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_classbasedview.py
--rw-rw-rw-   0        0        0     3420 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_client_connection.py
--rw-rw-rw-   0        0        0     1753 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_client_exceptions.py
--rw-rw-rw-   0        0        0     2521 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_client_fingerprint.py
--rw-rw-rw-   0        0        0    79774 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_client_functional.py
--rw-rw-rw-   0        0        0     3997 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_client_proto.py
--rw-rw-rw-   0        0        0    40307 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_client_request.py
--rw-rw-rw-   0        0        0    39361 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_client_response.py
--rw-rw-rw-   0        0        0    24244 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_client_session.py
--rw-rw-rw-   0        0        0    25799 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_client_ws.py
--rw-rw-rw-   0        0        0    21405 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_client_ws_functional.py
--rw-rw-rw-   0        0        0    64470 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_connector.py
--rw-rw-rw-   0        0        0    21005 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_cookiejar.py
--rw-rw-rw-   0        0        0     4185 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_flowcontrol_streams.py
--rw-rw-rw-   0        0        0     2349 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_formdata.py
--rw-rw-rw-   0        0        0     6159 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_frozenlist.py
--rw-rw-rw-   0        0        0    16621 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_helpers.py
--rw-rw-rw-   0        0        0      506 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_http_exceptions.py
--rw-rw-rw-   0        0        0    31010 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_http_parser.py
--rw-rw-rw-   0        0        0     5893 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_http_writer.py
--rw-rw-rw-   0        0        0     1299 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_locks.py
--rw-rw-rw-   0        0        0     1164 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_loop.py
--rw-rw-rw-   0        0        0    43298 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_multipart.py
--rw-rw-rw-   0        0        0    27327 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_multipart_helpers.py
--rw-rw-rw-   0        0        0     3606 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_payload.py
--rw-rw-rw-   0        0        0    23819 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_proxy.py
--rw-rw-rw-   0        0        0    20935 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_proxy_functional.py
--rw-rw-rw-   0        0        0     6614 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_pytest_plugin.py
--rw-rw-rw-   0        0        0     7737 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_resolver.py
--rw-rw-rw-   0        0        0     6871 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_route_def.py
--rw-rw-rw-   0        0        0    22878 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_run_app.py
--rw-rw-rw-   0        0        0     3717 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_signals.py
--rw-rw-rw-   0        0        0    37353 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_streams.py
--rw-rw-rw-   0        0        0     4793 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_tcp_helpers.py
--rw-rw-rw-   0        0        0     9634 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_test_utils.py
--rw-rw-rw-   0        0        0     4932 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_tracing.py
--rw-rw-rw-   0        0        0    39579 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_urldispatch.py
--rw-rw-rw-   0        0        0     8538 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_websocket_handshake.py
--rw-rw-rw-   0        0        0    15907 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_websocket_parser.py
--rw-rw-rw-   0        0        0     3452 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_websocket_writer.py
--rw-rw-rw-   0        0        0    14916 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_web_app.py
--rw-rw-rw-   0        0        0     4311 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_web_cli.py
--rw-rw-rw-   0        0        0     5696 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_web_exceptions.py
--rw-rw-rw-   0        0        0    56561 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_web_functional.py
--rw-rw-rw-   0        0        0     5574 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_web_log.py
--rw-rw-rw-   0        0        0    15275 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_web_middleware.py
--rw-rw-rw-   0        0        0    21747 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_web_protocol.py
--rw-rw-rw-   0        0        0    21568 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_web_request.py
--rw-rw-rw-   0        0        0     1518 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_web_request_handler.py
--rw-rw-rw-   0        0        0    33866 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_web_response.py
--rw-rw-rw-   0        0        0     3288 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_web_runner.py
--rw-rw-rw-   0        0        0     3251 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_web_sendfile.py
--rw-rw-rw-   0        0        0    24644 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_web_sendfile_functional.py
--rw-rw-rw-   0        0        0     5264 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_web_server.py
--rw-rw-rw-   0        0        0    13978 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_web_urldispatcher.py
--rw-rw-rw-   0        0        0    13914 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_web_websocket.py
--rw-rw-rw-   0        0        0    20146 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_web_websocket_functional.py
--rw-rw-rw-   0        0        0     8070 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tests/test_worker.py
-drwxrwxrwx   0        0        0        0 2019-01-09 01:05:08.000000 aiohttp-4.0.0a0/tools/
--rw-rw-rw-   0        0        0     1827 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tools/build-wheels.sh
--rwxrwxrwx   0        0        0      838 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tools/build.cmd
--rw-rw-rw-   0        0        0     1224 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tools/check_changes.py
--rw-rw-rw-   0        0        0       45 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tools/drop_merged_branches.sh
--rw-rw-rw-   0        0        0     3531 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tools/gen.py
--rw-rw-rw-   0        0        0     1151 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tools/run_docker.sh
--rw-rw-rw-   0        0        0     1077 2019-01-09 01:03:42.000000 aiohttp-4.0.0a0/tox.ini
-drwxrwxrwx   0        0        0        0 2019-01-09 01:05:08.000000 aiohttp-4.0.0a0/vendor/
-drwxrwxrwx   0        0        0        0 2019-01-09 01:05:08.000000 aiohttp-4.0.0a0/vendor/http-parser/
--rw-rw-rw-   0        0        0       46 2019-01-09 01:03:45.000000 aiohttp-4.0.0a0/vendor/http-parser/.git
--rw-rw-rw-   0        0        0      255 2019-01-09 01:03:46.000000 aiohttp-4.0.0a0/vendor/http-parser/.gitignore
--rw-rw-rw-   0        0        0      480 2019-01-09 01:03:46.000000 aiohttp-4.0.0a0/vendor/http-parser/.mailmap
--rw-rw-rw-   0        0        0      132 2019-01-09 01:03:46.000000 aiohttp-4.0.0a0/vendor/http-parser/.travis.yml
--rw-rw-rw-   0        0        0     2502 2019-01-09 01:03:46.000000 aiohttp-4.0.0a0/vendor/http-parser/AUTHORS
--rw-rw-rw-   0        0        0     3786 2019-01-09 01:03:46.000000 aiohttp-4.0.0a0/vendor/http-parser/bench.c
-drwxrwxrwx   0        0        0        0 2019-01-09 01:05:08.000000 aiohttp-4.0.0a0/vendor/http-parser/contrib/
--rw-rw-rw-   0        0        0     4188 2019-01-09 01:03:46.000000 aiohttp-4.0.0a0/vendor/http-parser/contrib/parsertrace.c
--rw-rw-rw-   0        0        0     1151 2019-01-09 01:03:46.000000 aiohttp-4.0.0a0/vendor/http-parser/contrib/url_parser.c
--rw-rw-rw-   0        0        0    71309 2019-01-09 01:03:46.000000 aiohttp-4.0.0a0/vendor/http-parser/http_parser.c
--rw-rw-rw-   0        0        0     2855 2019-01-09 01:03:46.000000 aiohttp-4.0.0a0/vendor/http-parser/http_parser.gyp
--rw-rw-rw-   0        0        0    18864 2019-01-09 01:03:46.000000 aiohttp-4.0.0a0/vendor/http-parser/http_parser.h
--rw-rw-rw-   0        0        0     1077 2019-01-09 01:03:46.000000 aiohttp-4.0.0a0/vendor/http-parser/LICENSE-MIT
--rw-rw-rw-   0        0        0     5284 2019-01-09 01:03:46.000000 aiohttp-4.0.0a0/vendor/http-parser/Makefile
--rw-rw-rw-   0        0        0     9343 2019-01-09 01:03:46.000000 aiohttp-4.0.0a0/vendor/http-parser/README.md
--rw-rw-rw-   0        0        0   119813 2019-01-09 01:03:46.000000 aiohttp-4.0.0a0/vendor/http-parser/test.c
+drwxr-xr-x   0 vsts      (1001) docker     (117)        0 2019-10-09 11:27:45.000000 aiohttp-4.0.0a1/
+-rw-r--r--   0 vsts      (1001) docker     (117)    15824 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/CHANGES.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)     4199 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/CONTRIBUTORS.txt
+-rw-r--r--   0 vsts      (1001) docker     (117)    11332 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/LICENSE.txt
+-rw-r--r--   0 vsts      (1001) docker     (117)      394 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/MANIFEST.in
+-rw-r--r--   0 vsts      (1001) docker     (117)     3252 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/Makefile
+-rw-r--r--   0 vsts      (1001) docker     (117)    26510 2019-10-09 11:27:45.000000 aiohttp-4.0.0a1/PKG-INFO
+-rw-r--r--   0 vsts      (1001) docker     (117)     4894 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/README.rst
+drwxr-xr-x   0 vsts      (1001) docker     (117)        0 2019-10-09 11:27:45.000000 aiohttp-4.0.0a1/aiohttp/
+-rw-r--r--   0 vsts      (1001) docker     (117)     8127 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/__init__.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     3959 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/_cparser.pxd
+-rw-r--r--   0 vsts      (1001) docker     (117)   189932 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/_find_header.c
+-rw-r--r--   0 vsts      (1001) docker     (117)      170 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/_find_header.h
+-rw-r--r--   0 vsts      (1001) docker     (117)       68 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/_find_header.pxd
+-rw-r--r--   0 vsts      (1001) docker     (117)   288942 2019-10-09 11:27:43.000000 aiohttp-4.0.0a1/aiohttp/_frozenlist.c
+-rw-r--r--   0 vsts      (1001) docker     (117)     2605 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/_frozenlist.pyx
+-rw-r--r--   0 vsts      (1001) docker     (117)     2027 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/_headers.pxi
+-rw-r--r--   0 vsts      (1001) docker     (117)   208656 2019-10-09 11:27:43.000000 aiohttp-4.0.0a1/aiohttp/_helpers.c
+-rw-r--r--   0 vsts      (1001) docker     (117)      204 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/_helpers.pyi
+-rw-r--r--   0 vsts      (1001) docker     (117)     1049 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/_helpers.pyx
+-rw-r--r--   0 vsts      (1001) docker     (117)   999796 2019-10-09 11:27:44.000000 aiohttp-4.0.0a1/aiohttp/_http_parser.c
+-rw-r--r--   0 vsts      (1001) docker     (117)    28794 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/_http_parser.pyx
+-rw-r--r--   0 vsts      (1001) docker     (117)   211618 2019-10-09 11:27:42.000000 aiohttp-4.0.0a1/aiohttp/_http_writer.c
+-rw-r--r--   0 vsts      (1001) docker     (117)     4201 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/_http_writer.pyx
+-rw-r--r--   0 vsts      (1001) docker     (117)   136604 2019-10-09 11:27:42.000000 aiohttp-4.0.0a1/aiohttp/_websocket.c
+-rw-r--r--   0 vsts      (1001) docker     (117)     1559 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/_websocket.pyx
+-rw-r--r--   0 vsts      (1001) docker     (117)     5500 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/abc.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     2663 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/base_protocol.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    41973 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/client.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     7525 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/client_exceptions.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     8273 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/client_proto.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    33659 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/client_reqrep.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    10952 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/client_ws.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    41980 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/connector.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    11930 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/cookiejar.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     5807 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/formdata.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     1781 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/frozenlist.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     1449 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/frozenlist.pyi
+-rw-r--r--   0 vsts      (1001) docker     (117)     3449 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/hdrs.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    23105 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/helpers.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     2133 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/http.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     2663 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/http_exceptions.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    28807 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/http_parser.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    24797 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/http_websocket.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     5239 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/http_writer.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     1234 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/locks.py
+-rw-r--r--   0 vsts      (1001) docker     (117)      325 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/log.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    34789 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/multipart.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    14027 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/payload.py
+-rw-r--r--   0 vsts      (1001) docker     (117)        6 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/py.typed
+-rw-r--r--   0 vsts      (1001) docker     (117)     9553 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/pytest_plugin.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     2464 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/resolver.py
+-rw-r--r--   0 vsts      (1001) docker     (117)      948 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/signals.py
+-rw-r--r--   0 vsts      (1001) docker     (117)      324 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/signals.pyi
+-rw-r--r--   0 vsts      (1001) docker     (117)    19809 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/streams.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     1631 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/tcp_helpers.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    19675 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/test_utils.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    13353 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/tracing.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     1324 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/typedefs.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    19460 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/web.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    12245 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/web_app.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    12195 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/web_exceptions.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    12772 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/web_fileresponse.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     8354 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/web_log.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     4361 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/web_middlewares.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    24114 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/web_protocol.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    25415 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/web_request.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    25087 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/web_response.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     6099 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/web_routedef.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    12503 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/web_runner.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     2398 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/web_server.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    38265 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/web_urldispatcher.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    17483 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/web_ws.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     7870 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/aiohttp/worker.py
+drwxr-xr-x   0 vsts      (1001) docker     (117)        0 2019-10-09 11:27:45.000000 aiohttp-4.0.0a1/aiohttp.egg-info/
+-rw-r--r--   0 vsts      (1001) docker     (117)    26510 2019-10-09 11:27:45.000000 aiohttp-4.0.0a1/aiohttp.egg-info/PKG-INFO
+-rw-r--r--   0 vsts      (1001) docker     (117)     5494 2019-10-09 11:27:45.000000 aiohttp-4.0.0a1/aiohttp.egg-info/SOURCES.txt
+-rw-r--r--   0 vsts      (1001) docker     (117)        1 2019-10-09 11:27:45.000000 aiohttp-4.0.0a1/aiohttp.egg-info/dependency_links.txt
+-rw-r--r--   0 vsts      (1001) docker     (117)      197 2019-10-09 11:27:45.000000 aiohttp-4.0.0a1/aiohttp.egg-info/requires.txt
+-rw-r--r--   0 vsts      (1001) docker     (117)        8 2019-10-09 11:27:45.000000 aiohttp-4.0.0a1/aiohttp.egg-info/top_level.txt
+drwxr-xr-x   0 vsts      (1001) docker     (117)        0 2019-10-09 11:27:45.000000 aiohttp-4.0.0a1/docs/
+-rw-r--r--   0 vsts      (1001) docker     (117)     6875 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/Makefile
+drwxr-xr-x   0 vsts      (1001) docker     (117)        0 2019-10-09 11:27:45.000000 aiohttp-4.0.0a1/docs/_static/
+-rw-r--r--   0 vsts      (1001) docker     (117)     4519 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/_static/aiohttp-icon-128x128.png
+-rw-r--r--   0 vsts      (1001) docker     (117)     5052 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/abc.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)     4069 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/aiohttp-icon.svg
+-rw-r--r--   0 vsts      (1001) docker     (117)     4068 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/aiohttp-plain.svg
+-rw-r--r--   0 vsts      (1001) docker     (117)     1063 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/built_with.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)       79 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/changes.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)      300 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/client.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)    21836 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/client_advanced.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)    13795 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/client_quickstart.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)    63625 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/client_reference.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)    10982 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/conf.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     8585 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/contributing.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)     9224 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/deployment.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)       98 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/essays.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)      392 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/external.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)    13041 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/faq.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)     4286 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/favicon.ico
+-rw-r--r--   0 vsts      (1001) docker     (117)     3419 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/glossary.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)     5040 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/index.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)     6545 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/logging.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)     6703 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/make.bat
+-rw-r--r--   0 vsts      (1001) docker     (117)     7176 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/migration_to_2xx.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)      249 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/misc.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)    11906 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/multipart.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)     4981 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/multipart_reference.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)     2861 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/new_router.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)   256817 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/old-logo.png
+-rw-r--r--   0 vsts      (1001) docker     (117)    50150 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/old-logo.svg
+-rw-r--r--   0 vsts      (1001) docker     (117)     1733 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/powered_by.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)     1156 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/signals.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)     2701 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/spelling_wordlist.txt
+-rw-r--r--   0 vsts      (1001) docker     (117)     4722 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/streams.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)     1231 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/structures.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)    23806 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/testing.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)     9213 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/third_party.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)    12042 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/tracing_reference.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)      262 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/utilities.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)      416 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/web.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)    31335 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/web_advanced.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)    14038 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/web_exceptions.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)     2703 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/web_lowlevel.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)    19546 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/web_quickstart.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)    89346 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/web_reference.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)     4415 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/websocket_utilities.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)     4405 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/whats_new_1_1.rst
+-rw-r--r--   0 vsts      (1001) docker     (117)     2444 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/docs/whats_new_3_0.rst
+drwxr-xr-x   0 vsts      (1001) docker     (117)        0 2019-10-09 11:27:45.000000 aiohttp-4.0.0a1/examples/
+-rwxr-xr-x   0 vsts      (1001) docker     (117)     1813 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/background_tasks.py
+-rwxr-xr-x   0 vsts      (1001) docker     (117)     1408 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/cli_app.py
+-rwxr-xr-x   0 vsts      (1001) docker     (117)      521 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/client_auth.py
+-rwxr-xr-x   0 vsts      (1001) docker     (117)      431 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/client_json.py
+-rwxr-xr-x   0 vsts      (1001) docker     (117)     2109 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/client_ws.py
+-rwxr-xr-x   0 vsts      (1001) docker     (117)      937 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/curl.py
+-rwxr-xr-x   0 vsts      (1001) docker     (117)     3683 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/fake_server.py
+drwxr-xr-x   0 vsts      (1001) docker     (117)        0 2019-10-09 11:27:45.000000 aiohttp-4.0.0a1/examples/legacy/
+-rwxr-xr-x   0 vsts      (1001) docker     (117)     2938 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/legacy/crawl.py
+-rwxr-xr-x   0 vsts      (1001) docker     (117)     5355 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/legacy/srv.py
+-rwxr-xr-x   0 vsts      (1001) docker     (117)     4904 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/legacy/tcp_protocol_parser.py
+-rw-r--r--   0 vsts      (1001) docker     (117)      548 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/lowlevel_srv.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     1103 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/server.crt
+-rw-r--r--   0 vsts      (1001) docker     (117)      952 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/server.csr
+-rw-r--r--   0 vsts      (1001) docker     (117)     1675 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/server.key
+-rw-r--r--   0 vsts      (1001) docker     (117)      752 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/server_simple.py
+-rwxr-xr-x   0 vsts      (1001) docker     (117)      158 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/static_files.py
+-rwxr-xr-x   0 vsts      (1001) docker     (117)     1396 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/web_classview.py
+-rwxr-xr-x   0 vsts      (1001) docker     (117)      867 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/web_cookies.py
+-rwxr-xr-x   0 vsts      (1001) docker     (117)      592 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/web_rewrite_headers_middleware.py
+-rwxr-xr-x   0 vsts      (1001) docker     (117)     1370 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/web_srv.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     1345 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/web_srv_route_deco.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     1408 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/web_srv_route_table.py
+-rwxr-xr-x   0 vsts      (1001) docker     (117)     1417 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/web_ws.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     2363 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/examples/websocket.html
+-rw-r--r--   0 vsts      (1001) docker     (117)     1290 2019-10-09 11:27:45.000000 aiohttp-4.0.0a1/setup.cfg
+-rw-r--r--   0 vsts      (1001) docker     (117)     4312 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/setup.py
+drwxr-xr-x   0 vsts      (1001) docker     (117)        0 2019-10-09 11:27:45.000000 aiohttp-4.0.0a1/tests/
+-rw-r--r--   0 vsts      (1001) docker     (117)     6640 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/aiohttp.jpg
+-rw-r--r--   0 vsts      (1001) docker     (117)    54997 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/aiohttp.png
+drwxr-xr-x   0 vsts      (1001) docker     (117)        0 2019-10-09 11:27:45.000000 aiohttp-4.0.0a1/tests/autobahn/
+-rw-r--r--   0 vsts      (1001) docker     (117)     1351 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/autobahn/client.py
+-rw-r--r--   0 vsts      (1001) docker     (117)      276 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/autobahn/fuzzingclient.json
+-rw-r--r--   0 vsts      (1001) docker     (117)      217 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/autobahn/fuzzingserver.json
+-rw-r--r--   0 vsts      (1001) docker     (117)     1402 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/autobahn/server.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     5527 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/conftest.py
+-rw-r--r--   0 vsts      (1001) docker     (117)       13 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/data.unknown_mime_type
+-rw-r--r--   0 vsts      (1001) docker     (117)       44 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/hello.txt.gz
+-rw-r--r--   0 vsts      (1001) docker     (117)     4416 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_base_protocol.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     1311 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_classbasedview.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     3344 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_client_connection.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    10702 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_client_exceptions.py
+-rw-r--r--   0 vsts      (1001) docker     (117)      838 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_client_fingerprint.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    85670 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_client_functional.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     3997 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_client_proto.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    35284 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_client_request.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    39564 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_client_response.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    23267 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_client_session.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    25438 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_client_ws.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    23407 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_client_ws_functional.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    67400 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_connector.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    23150 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_cookiejar.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     4185 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_flowcontrol_streams.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     2349 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_formdata.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     6159 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_frozenlist.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    18201 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_helpers.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     5499 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_http_exceptions.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    31012 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_http_parser.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     5893 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_http_writer.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     1299 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_locks.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     1164 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_loop.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    48734 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_multipart.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    27327 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_multipart_helpers.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     2956 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_payload.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    23777 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_proxy.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    20725 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_proxy_functional.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     5708 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_pytest_plugin.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     5372 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_resolver.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     6871 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_route_def.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    22866 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_run_app.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     3717 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_signals.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    39732 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_streams.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     4793 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_tcp_helpers.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     9191 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_test_utils.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     4964 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_tracing.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    40988 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_urldispatch.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    11321 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_web_app.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     4311 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_web_cli.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    10930 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_web_exceptions.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    55142 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_web_functional.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     8564 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_web_log.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    12492 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_web_middleware.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    22329 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_web_protocol.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    24291 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_web_request.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     1518 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_web_request_handler.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    32496 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_web_response.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     5253 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_web_runner.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     3791 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_web_sendfile.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    24528 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_web_sendfile_functional.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     5857 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_web_server.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    12400 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_web_urldispatcher.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    11207 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_web_websocket.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    21392 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_web_websocket_functional.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     8631 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_websocket_handshake.py
+-rw-r--r--   0 vsts      (1001) docker     (117)    16122 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_websocket_parser.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     3506 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_websocket_writer.py
+-rw-r--r--   0 vsts      (1001) docker     (117)     8015 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/tests/test_worker.py
+drwxr-xr-x   0 vsts      (1001) docker     (117)        0 2019-10-09 11:27:45.000000 aiohttp-4.0.0a1/vendor/
+drwxr-xr-x   0 vsts      (1001) docker     (117)        0 2019-10-09 11:27:45.000000 aiohttp-4.0.0a1/vendor/http-parser/
+-rw-r--r--   0 vsts      (1001) docker     (117)       46 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/vendor/http-parser/.git
+-rw-r--r--   0 vsts      (1001) docker     (117)      255 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/vendor/http-parser/.gitignore
+-rw-r--r--   0 vsts      (1001) docker     (117)      480 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/vendor/http-parser/.mailmap
+-rw-r--r--   0 vsts      (1001) docker     (117)      132 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/vendor/http-parser/.travis.yml
+-rw-r--r--   0 vsts      (1001) docker     (117)     2502 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/vendor/http-parser/AUTHORS
+-rw-r--r--   0 vsts      (1001) docker     (117)     1077 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/vendor/http-parser/LICENSE-MIT
+-rw-r--r--   0 vsts      (1001) docker     (117)     5284 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/vendor/http-parser/Makefile
+-rw-r--r--   0 vsts      (1001) docker     (117)     9343 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/vendor/http-parser/README.md
+-rw-r--r--   0 vsts      (1001) docker     (117)     3786 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/vendor/http-parser/bench.c
+drwxr-xr-x   0 vsts      (1001) docker     (117)        0 2019-10-09 11:27:45.000000 aiohttp-4.0.0a1/vendor/http-parser/contrib/
+-rw-r--r--   0 vsts      (1001) docker     (117)     4188 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/vendor/http-parser/contrib/parsertrace.c
+-rw-r--r--   0 vsts      (1001) docker     (117)     1151 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/vendor/http-parser/contrib/url_parser.c
+-rw-r--r--   0 vsts      (1001) docker     (117)    71309 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/vendor/http-parser/http_parser.c
+-rw-r--r--   0 vsts      (1001) docker     (117)     2855 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/vendor/http-parser/http_parser.gyp
+-rw-r--r--   0 vsts      (1001) docker     (117)    18864 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/vendor/http-parser/http_parser.h
+-rw-r--r--   0 vsts      (1001) docker     (117)   119813 2019-10-09 11:27:32.000000 aiohttp-4.0.0a1/vendor/http-parser/test.c
```

### Comparing `aiohttp-4.0.0a0/aiohttp/abc.py` & `aiohttp-4.0.0a1/aiohttp/abc.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-import asyncio
 import logging
 from abc import ABC, abstractmethod
 from collections.abc import Sized
 from http.cookies import BaseCookie, Morsel  # noqa
 from typing import (
     TYPE_CHECKING,
     Any,
@@ -15,15 +14,14 @@
     Optional,
     Tuple,
 )
 
 from multidict import CIMultiDict  # noqa
 from yarl import URL
 
-from .helpers import get_running_loop
 from .typedefs import LooseCookies
 
 if TYPE_CHECKING:  # pragma: no cover
     from .web_request import BaseRequest, Request
     from .web_response import StreamResponse
     from .web_app import Application
     from .web_exceptions import HTTPException
@@ -137,18 +135,14 @@
 else:
     IterableBase = Iterable
 
 
 class AbstractCookieJar(Sized, IterableBase):
     """Abstract Cookie Jar."""
 
-    def __init__(self, *,
-                 loop: Optional[asyncio.AbstractEventLoop]=None) -> None:
-        self._loop = get_running_loop(loop)
-
     @abstractmethod
     def clear(self) -> None:
         """Clear all cookies."""
 
     @abstractmethod
     def update_cookies(self,
                        cookies: LooseCookies,
@@ -202,7 +196,18 @@
 
     @abstractmethod
     def log(self,
             request: BaseRequest,
             response: StreamResponse,
             time: float) -> None:
         """Emit log to logger."""
+
+
+class AbstractAsyncAccessLogger(ABC):
+    """Abstract asynchronous writer to access log."""
+
+    @abstractmethod
+    async def log(self,
+                  request: BaseRequest,
+                  response: StreamResponse,
+                  request_start: float) -> None:
+        """Emit log to logger."""
```

### Comparing `aiohttp-4.0.0a0/aiohttp/base_protocol.py` & `aiohttp-4.0.0a1/aiohttp/base_protocol.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 from typing import Optional, cast
 
 from .tcp_helpers import tcp_nodelay
 
 
 class BaseProtocol(asyncio.Protocol):
     __slots__ = ('_loop', '_paused', '_drain_waiter',
-                 '_connection_lost', 'transport')
+                 '_connection_lost', '_reading_paused', 'transport')
 
     def __init__(self, loop: asyncio.AbstractEventLoop) -> None:
         self._loop = loop  # type: asyncio.AbstractEventLoop
         self._paused = False
         self._drain_waiter = None  # type: Optional[asyncio.Future[None]]
         self._connection_lost = False
         self._reading_paused = False
```

### Comparing `aiohttp-4.0.0a0/aiohttp/client.py` & `aiohttp-4.0.0a1/aiohttp/client.py`

 * *Files 10% similar despite different names*

```diff
@@ -7,14 +7,16 @@
 import os
 import sys
 import traceback
 import warnings
 from types import SimpleNamespace, TracebackType
 from typing import (  # noqa
     Any,
+    Awaitable,
+    Callable,
     Coroutine,
     Generator,
     Generic,
     Iterable,
     List,
     Mapping,
     Optional,
@@ -23,48 +25,60 @@
     Type,
     TypeVar,
     Union,
 )
 
 import attr
 from multidict import CIMultiDict, MultiDict, MultiDictProxy, istr
+from typing_extensions import final
 from yarl import URL
 
 from . import hdrs, http, payload
 from .abc import AbstractCookieJar
+from .client_exceptions import ClientConnectionError as ClientConnectionError
 from .client_exceptions import (
-    ClientConnectionError,
-    ClientConnectorCertificateError,
-    ClientConnectorError,
-    ClientConnectorSSLError,
-    ClientError,
-    ClientHttpProxyError,
-    ClientOSError,
-    ClientPayloadError,
-    ClientProxyConnectionError,
-    ClientResponseError,
-    ClientSSLError,
-    ContentTypeError,
-    InvalidURL,
-    ServerConnectionError,
-    ServerDisconnectedError,
-    ServerFingerprintMismatch,
-    ServerTimeoutError,
-    TooManyRedirects,
-    WSServerHandshakeError,
+    ClientConnectorCertificateError as ClientConnectorCertificateError,
 )
-from .client_reqrep import (
-    ClientRequest,
-    ClientResponse,
-    Fingerprint,
-    RequestInfo,
-    _merge_ssl_params,
+from .client_exceptions import ClientConnectorError as ClientConnectorError
+from .client_exceptions import (
+    ClientConnectorSSLError as ClientConnectorSSLError,
+)
+from .client_exceptions import ClientError as ClientError
+from .client_exceptions import ClientHttpProxyError as ClientHttpProxyError
+from .client_exceptions import ClientOSError as ClientOSError
+from .client_exceptions import ClientPayloadError as ClientPayloadError
+from .client_exceptions import (
+    ClientProxyConnectionError as ClientProxyConnectionError,
+)
+from .client_exceptions import ClientResponseError as ClientResponseError
+from .client_exceptions import ClientSSLError as ClientSSLError
+from .client_exceptions import ContentTypeError as ContentTypeError
+from .client_exceptions import InvalidURL as InvalidURL
+from .client_exceptions import ServerConnectionError as ServerConnectionError
+from .client_exceptions import (
+    ServerDisconnectedError as ServerDisconnectedError,
+)
+from .client_exceptions import (
+    ServerFingerprintMismatch as ServerFingerprintMismatch,
 )
-from .client_ws import ClientWebSocketResponse
-from .connector import BaseConnector, TCPConnector, UnixConnector
+from .client_exceptions import ServerTimeoutError as ServerTimeoutError
+from .client_exceptions import TooManyRedirects as TooManyRedirects
+from .client_exceptions import WSServerHandshakeError as WSServerHandshakeError
+from .client_reqrep import SSL_ALLOWED_TYPES as SSL_ALLOWED_TYPES
+from .client_reqrep import ClientRequest as ClientRequest
+from .client_reqrep import ClientResponse as ClientResponse
+from .client_reqrep import Fingerprint as Fingerprint
+from .client_reqrep import RequestInfo as RequestInfo
+from .client_ws import DEFAULT_WS_CLIENT_TIMEOUT
+from .client_ws import ClientWebSocketResponse as ClientWebSocketResponse
+from .client_ws import ClientWSTimeout
+from .connector import BaseConnector as BaseConnector
+from .connector import NamedPipeConnector as NamedPipeConnector
+from .connector import TCPConnector as TCPConnector
+from .connector import UnixConnector as UnixConnector
 from .cookiejar import CookieJar
 from .helpers import (
     PY_36,
     BasicAuth,
     CeilTimeout,
     TimeoutHandle,
     get_running_loop,
@@ -109,14 +123,15 @@
     'ClientResponse',
     'Fingerprint',
     'RequestInfo',
     # connector
     'BaseConnector',
     'TCPConnector',
     'UnixConnector',
+    'NamedPipeConnector',
     # client_ws
     'ClientWebSocketResponse',
     # client
     'ClientSession',
     'ClientTimeout',
     'request')
 
@@ -125,18 +140,18 @@
     from ssl import SSLContext
 except ImportError:  # pragma: no cover
     SSLContext = object  # type: ignore
 
 
 @attr.s(frozen=True, slots=True)
 class ClientTimeout:
-    total = attr.ib(type=float, default=None)
-    connect = attr.ib(type=float, default=None)
-    sock_read = attr.ib(type=float, default=None)
-    sock_connect = attr.ib(type=float, default=None)
+    total = attr.ib(type=Optional[float], default=None)
+    connect = attr.ib(type=Optional[float], default=None)
+    sock_read = attr.ib(type=Optional[float], default=None)
+    sock_connect = attr.ib(type=Optional[float], default=None)
 
     # pool_queue_timeout = attr.ib(type=float, default=None)
     # dns_resolution_timeout = attr.ib(type=float, default=None)
     # socket_connect_timeout = attr.ib(type=float, default=None)
     # connection_acquiring_timeout = attr.ib(type=float, default=None)
     # new_connection_timeout = attr.ib(type=float, default=None)
     # http_header_timeout = attr.ib(type=float, default=None)
@@ -150,14 +165,15 @@
 
 # 5 Minute default read timeout
 DEFAULT_TIMEOUT = ClientTimeout(total=5*60)
 
 _RetType = TypeVar('_RetType')
 
 
+@final
 class ClientSession:
     """First-class interface for making HTTP requests."""
 
     __slots__ = (
         '_source_traceback', '_connector',
         '_loop', '_cookie_jar',
         '_connector_owner', '_default_auth',
@@ -165,43 +181,36 @@
         '_requote_redirect_url',
         '_timeout', '_raise_for_status', '_auto_decompress',
         '_trust_env', '_default_headers', '_skip_auto_headers',
         '_request_class', '_response_class',
         '_ws_response_class', '_trace_configs')
 
     def __init__(self, *, connector: Optional[BaseConnector]=None,
-                 loop: Optional[asyncio.AbstractEventLoop]=None,
                  cookies: Optional[LooseCookies]=None,
                  headers: Optional[LooseHeaders]=None,
                  skip_auto_headers: Optional[Iterable[str]]=None,
                  auth: Optional[BasicAuth]=None,
                  json_serialize: JSONEncoder=json.dumps,
                  request_class: Type[ClientRequest]=ClientRequest,
                  response_class: Type[ClientResponse]=ClientResponse,
                  ws_response_class: Type[ClientWebSocketResponse]=ClientWebSocketResponse,  # noqa
                  version: HttpVersion=http.HttpVersion11,
                  cookie_jar: Optional[AbstractCookieJar]=None,
                  connector_owner: bool=True,
-                 raise_for_status: bool=False,
-                 read_timeout: Union[float, object]=sentinel,
-                 conn_timeout: Optional[float]=None,
+                 raise_for_status: Union[bool, Callable[[ClientResponse], Awaitable[None]]]=False,  # noqa
                  timeout: Union[object, ClientTimeout]=sentinel,
                  auto_decompress: bool=True,
                  trust_env: bool=False,
                  requote_redirect_url: bool=True,
                  trace_configs: Optional[List[TraceConfig]]=None) -> None:
 
-        if loop is None:
-            if connector is not None:
-                loop = connector._loop
-
-        loop = get_running_loop(loop)
+        loop = get_running_loop()
 
         if connector is None:
-            connector = TCPConnector(loop=loop)
+            connector = TCPConnector()
 
         # Initialize these three attrs before raising any exception,
         # they are used in __del__
         self._connector = connector  # type: Optional[BaseConnector]
         self._loop = loop
         if loop.get_debug():
             self._source_traceback = traceback.extract_stack(sys._getframe(1))  # type: Optional[traceback.StackSummary]  # noqa
@@ -209,60 +218,39 @@
             self._source_traceback = None
 
         if connector._loop is not loop:
             raise RuntimeError(
                 "Session and connector have to use same event loop")
 
         if cookie_jar is None:
-            cookie_jar = CookieJar(loop=loop)
+            cookie_jar = CookieJar()
         self._cookie_jar = cookie_jar
 
         if cookies is not None:
             self._cookie_jar.update_cookies(cookies)
 
         self._connector_owner = connector_owner
         self._default_auth = auth
         self._version = version
         self._json_serialize = json_serialize
         if timeout is sentinel:
             self._timeout = DEFAULT_TIMEOUT
-            if read_timeout is not sentinel:
-                warnings.warn("read_timeout is deprecated, "
-                              "use timeout argument instead",
-                              DeprecationWarning,
-                              stacklevel=2)
-                self._timeout = attr.evolve(self._timeout, total=read_timeout)
-            if conn_timeout is not None:
-                self._timeout = attr.evolve(self._timeout,
-                                            connect=conn_timeout)
-                warnings.warn("conn_timeout is deprecated, "
-                              "use timeout argument instead",
-                              DeprecationWarning,
-                              stacklevel=2)
         else:
             self._timeout = timeout  # type: ignore
-            if read_timeout is not sentinel:
-                raise ValueError("read_timeout and timeout parameters "
-                                 "conflict, please setup "
-                                 "timeout.read")
-            if conn_timeout is not None:
-                raise ValueError("conn_timeout and timeout parameters "
-                                 "conflict, please setup "
-                                 "timeout.connect")
         self._raise_for_status = raise_for_status
         self._auto_decompress = auto_decompress
         self._trust_env = trust_env
         self._requote_redirect_url = requote_redirect_url
 
         # Convert to list of tuples
         if headers:
-            headers = CIMultiDict(headers)
+            real_headers = CIMultiDict(headers)  # type: CIMultiDict[str]
         else:
-            headers = CIMultiDict()
-        self._default_headers = headers
+            real_headers = CIMultiDict()
+        self._default_headers = real_headers   # type: CIMultiDict[str]
         if skip_auto_headers is not None:
             self._skip_auto_headers = frozenset([istr(i)
                                                  for i in skip_auto_headers])
         else:
             self._skip_auto_headers = frozenset()
 
         self._request_class = request_class
@@ -270,18 +258,16 @@
         self._ws_response_class = ws_response_class
 
         self._trace_configs = trace_configs or []
         for trace_config in self._trace_configs:
             trace_config.freeze()
 
     def __init_subclass__(cls: Type['ClientSession']) -> None:
-        warnings.warn("Inheritance class {} from ClientSession "
-                      "is discouraged".format(cls.__name__),
-                      DeprecationWarning,
-                      stacklevel=2)
+        raise TypeError("Inheritance class {} from ClientSession "
+                        "is forbidden".format(cls.__name__))
 
     def __del__(self, _warnings: Any=warnings) -> None:
         if not self.closed:
             if PY_36:
                 kwargs = {'source': self}
             else:
                 kwargs = {}
@@ -313,46 +299,41 @@
             skip_auto_headers: Optional[Iterable[str]]=None,
             auth: Optional[BasicAuth]=None,
             allow_redirects: bool=True,
             max_redirects: int=10,
             compress: Optional[str]=None,
             chunked: Optional[bool]=None,
             expect100: bool=False,
-            raise_for_status: Optional[bool]=None,
+            raise_for_status: Union[None, bool, Callable[[ClientResponse], Awaitable[None]]]=None,  # noqa
             read_until_eof: bool=True,
             proxy: Optional[StrOrURL]=None,
             proxy_auth: Optional[BasicAuth]=None,
             timeout: Union[ClientTimeout, object]=sentinel,
-            verify_ssl: Optional[bool]=None,
-            fingerprint: Optional[bytes]=None,
-            ssl_context: Optional[SSLContext]=None,
             ssl: Optional[Union[SSLContext, bool, Fingerprint]]=None,
             proxy_headers: Optional[LooseHeaders]=None,
             trace_request_ctx: Optional[SimpleNamespace]=None
     ) -> ClientResponse:
 
         # NOTE: timeout clamps existing connect and read timeouts.  We cannot
         # set the default to None because we need to detect if the user wants
         # to use the existing timeouts by setting timeout to None.
 
         if self.closed:
             raise RuntimeError('Session is closed')
 
-        ssl = _merge_ssl_params(ssl, verify_ssl, ssl_context, fingerprint)
+        if not isinstance(ssl, SSL_ALLOWED_TYPES):
+            raise TypeError("ssl should be SSLContext, bool, Fingerprint, "
+                            "or None, got {!r} instead.".format(ssl))
 
         if data is not None and json is not None:
             raise ValueError(
                 'data and json parameters can not be used at the same time')
         elif json is not None:
             data = payload.JsonPayload(json, dumps=self._json_serialize)
 
-        if not isinstance(chunked, bool) and chunked is not None:
-            warnings.warn(
-                'Chunk size is deprecated #1615', DeprecationWarning)
-
         redirects = 0
         history = []
         version = self._version
 
         # Merge with default headers and transform to CIMultiDict
         headers = self._prepare_headers(headers)
         proxy_headers = self._prepare_headers(proxy_headers)
@@ -420,38 +401,36 @@
                     if (headers is not None and
                             auth is not None and
                             hdrs.AUTHORIZATION in headers):
                         raise ValueError("Cannot combine AUTHORIZATION header "
                                          "with AUTH argument or credentials "
                                          "encoded in URL")
 
-                    session_cookies = self._cookie_jar.filter_cookies(url)
+                    all_cookies = self._cookie_jar.filter_cookies(url)
 
                     if cookies is not None:
                         tmp_cookie_jar = CookieJar()
                         tmp_cookie_jar.update_cookies(cookies)
                         req_cookies = tmp_cookie_jar.filter_cookies(url)
-                        if session_cookies and req_cookies:
-                            session_cookies.load(req_cookies)
-
-                    cookies = session_cookies
+                        if req_cookies:
+                            all_cookies.load(req_cookies)
 
                     if proxy is not None:
                         proxy = URL(proxy)
                     elif self._trust_env:
                         for scheme, proxy_info in proxies_from_env().items():
                             if scheme == url.scheme:
                                 proxy = proxy_info.proxy
                                 proxy_auth = proxy_info.proxy_auth
                                 break
 
                     req = self._request_class(
                         method, url, params=params, headers=headers,
                         skip_auto_headers=skip_headers, data=data,
-                        cookies=cookies, auth=auth, version=version,
+                        cookies=all_cookies, auth=auth, version=version,
                         compress=compress, chunked=chunked,
                         expect100=expect100, loop=self._loop,
                         response_class=self._response_class,
                         proxy=proxy, proxy_auth=proxy_auth, timer=timer,
                         session=self,
                         ssl=ssl, proxy_headers=proxy_headers, traces=traces)
 
@@ -563,15 +542,20 @@
                         continue
 
                     break
 
             # check response status
             if raise_for_status is None:
                 raise_for_status = self._raise_for_status
-            if raise_for_status:
+
+            if raise_for_status is None:
+                pass
+            elif callable(raise_for_status):
+                await raise_for_status(resp)
+            elif raise_for_status:
                 resp.raise_for_status()
 
             # register connection
             if handle is not None:
                 if resp.connection is not None:
                     resp.connection.add_callback(handle.cancel)
                 else:
@@ -605,28 +589,25 @@
             raise
 
     def ws_connect(
             self,
             url: StrOrURL, *,
             method: str=hdrs.METH_GET,
             protocols: Iterable[str]=(),
-            timeout: float=10.0,
+            timeout: Union[ClientWSTimeout, float]=sentinel,
             receive_timeout: Optional[float]=None,
             autoclose: bool=True,
             autoping: bool=True,
             heartbeat: Optional[float]=None,
             auth: Optional[BasicAuth]=None,
             origin: Optional[str]=None,
             headers: Optional[LooseHeaders]=None,
             proxy: Optional[StrOrURL]=None,
             proxy_auth: Optional[BasicAuth]=None,
             ssl: Union[SSLContext, bool, None, Fingerprint]=None,
-            verify_ssl: Optional[bool]=None,
-            fingerprint: Optional[bytes]=None,
-            ssl_context: Optional[SSLContext]=None,
             proxy_headers: Optional[LooseHeaders]=None,
             compress: int=0,
             max_msg_size: int=4*1024*1024) -> '_WSRequestContextManager':
         """Initiate websocket connection."""
         return _WSRequestContextManager(
             self._ws_connect(url,
                              method=method,
@@ -638,44 +619,57 @@
                              heartbeat=heartbeat,
                              auth=auth,
                              origin=origin,
                              headers=headers,
                              proxy=proxy,
                              proxy_auth=proxy_auth,
                              ssl=ssl,
-                             verify_ssl=verify_ssl,
-                             fingerprint=fingerprint,
-                             ssl_context=ssl_context,
                              proxy_headers=proxy_headers,
                              compress=compress,
                              max_msg_size=max_msg_size))
 
     async def _ws_connect(
             self,
             url: StrOrURL, *,
             method: str=hdrs.METH_GET,
             protocols: Iterable[str]=(),
-            timeout: float=10.0,
+            timeout: Union[ClientWSTimeout, float]=sentinel,
             receive_timeout: Optional[float]=None,
             autoclose: bool=True,
             autoping: bool=True,
             heartbeat: Optional[float]=None,
             auth: Optional[BasicAuth]=None,
             origin: Optional[str]=None,
             headers: Optional[LooseHeaders]=None,
             proxy: Optional[StrOrURL]=None,
             proxy_auth: Optional[BasicAuth]=None,
             ssl: Union[SSLContext, bool, None, Fingerprint]=None,
-            verify_ssl: Optional[bool]=None,
-            fingerprint: Optional[bytes]=None,
-            ssl_context: Optional[SSLContext]=None,
             proxy_headers: Optional[LooseHeaders]=None,
             compress: int=0,
             max_msg_size: int=4*1024*1024
     ) -> ClientWebSocketResponse:
+        if timeout is not sentinel:
+            if isinstance(timeout, ClientWSTimeout):
+                ws_timeout = timeout
+            else:
+                warnings.warn("parameter 'timeout' of type 'float' "
+                              "is deprecated, please use "
+                              "'timeout=ClientWSTimeout(ws_close=...)'",
+                              DeprecationWarning,
+                              stacklevel=2)
+                ws_timeout = ClientWSTimeout(ws_close=timeout)
+        else:
+            ws_timeout = DEFAULT_WS_CLIENT_TIMEOUT
+        if receive_timeout is not None:
+            warnings.warn("float parameter 'receive_timeout' "
+                          "is deprecated, please use parameter "
+                          "'timeout=ClientWSTimeout(ws_receive=...)'",
+                          DeprecationWarning,
+                          stacklevel=2)
+            ws_timeout = attr.evolve(ws_timeout, ws_receive=receive_timeout)
 
         if headers is None:
             real_headers = CIMultiDict()  # type: CIMultiDict[str]
         else:
             real_headers = CIMultiDict(headers)
 
         default_headers = {
@@ -694,15 +688,17 @@
             real_headers[hdrs.SEC_WEBSOCKET_PROTOCOL] = ','.join(protocols)
         if origin is not None:
             real_headers[hdrs.ORIGIN] = origin
         if compress:
             extstr = ws_ext_gen(compress=compress)
             real_headers[hdrs.SEC_WEBSOCKET_EXTENSIONS] = extstr
 
-        ssl = _merge_ssl_params(ssl, verify_ssl, ssl_context, fingerprint)
+        if not isinstance(ssl, SSL_ALLOWED_TYPES):
+            raise TypeError("ssl should be SSLContext, bool, Fingerprint, "
+                            "or None, got {!r} instead.".format(ssl))
 
         # send request
         resp = await self.request(method, url,
                                   headers=real_headers,
                                   read_until_eof=False,
                                   auth=auth,
                                   proxy=proxy,
@@ -794,19 +790,18 @@
             resp.close()
             raise
         else:
             return self._ws_response_class(reader,
                                            writer,
                                            protocol,
                                            resp,
-                                           timeout,
+                                           ws_timeout,
                                            autoclose,
                                            autoping,
                                            self._loop,
-                                           receive_timeout=receive_timeout,
                                            heartbeat=heartbeat,
                                            compress=compress,
                                            client_notakeover=notakeover)
 
     def _prepare_headers(
             self,
             headers: Optional[LooseHeaders]) -> 'CIMultiDict[str]':
@@ -914,48 +909,21 @@
         return self._version
 
     @property
     def requote_redirect_url(self) -> bool:
         """Do URL requoting on redirection handling."""
         return self._requote_redirect_url
 
-    @requote_redirect_url.setter
-    def requote_redirect_url(self, val: bool) -> None:
-        """Do URL requoting on redirection handling."""
-        warnings.warn("session.requote_redirect_url modification "
-                      "is deprecated #2778",
-                      DeprecationWarning,
-                      stacklevel=2)
-        self._requote_redirect_url = val
-
-    @property
-    def loop(self) -> asyncio.AbstractEventLoop:
-        """Session's loop."""
-        warnings.warn("client.loop property is deprecated",
-                      DeprecationWarning,
-                      stacklevel=2)
-        return self._loop
-
     def detach(self) -> None:
         """Detach connector from session without closing the former.
 
         Session is switched to closed state anyway.
         """
         self._connector = None
 
-    def __enter__(self) -> None:
-        raise TypeError("Use async with instead")
-
-    def __exit__(self,
-                 exc_type: Optional[Type[BaseException]],
-                 exc_val: Optional[BaseException],
-                 exc_tb: Optional[TracebackType]) -> None:
-        # __exit__ should exist in pair with __enter__ but never executed
-        pass  # pragma: no cover
-
     async def __aenter__(self) -> 'ClientSession':
         return self
 
     async def __aexit__(self,
                         exc_type: Optional[Type[BaseException]],
                         exc_val: Optional[BaseException],
                         exc_tb: Optional[TracebackType]) -> None:
@@ -1026,16 +994,21 @@
                  coro: Coroutine['asyncio.Future[Any]', None, ClientResponse],
                  session: ClientSession) -> None:
         self._coro = coro
         self._resp = None  # type: Optional[ClientResponse]
         self._session = session
 
     async def __aenter__(self) -> ClientResponse:
-        self._resp = await self._coro
-        return self._resp
+        try:
+            self._resp = await self._coro
+        except BaseException:
+            await self._session.close()
+            raise
+        else:
+            return self._resp
 
     async def __aexit__(self,
                         exc_type: Optional[Type[BaseException]],
                         exc: Optional[BaseException],
                         tb: Optional[TracebackType]) -> None:
         assert self._resp is not None
         self._resp.close()
@@ -1059,16 +1032,15 @@
         raise_for_status: Optional[bool]=None,
         read_until_eof: bool=True,
         proxy: Optional[StrOrURL]=None,
         proxy_auth: Optional[BasicAuth]=None,
         timeout: Union[ClientTimeout, object]=sentinel,
         cookies: Optional[LooseCookies]=None,
         version: HttpVersion=http.HttpVersion11,
-        connector: Optional[BaseConnector]=None,
-        loop: Optional[asyncio.AbstractEventLoop]=None
+        connector: Optional[BaseConnector]=None
 ) -> _SessionRequestContextManager:
     """Constructs and sends a request. Returns response object.
     method - HTTP method
     url - request url
     params - (optional) Dictionary or bytes to be sent in the query
       string of the new request
     data - (optional) Dictionary, bytes, or file-like object to
@@ -1099,18 +1071,18 @@
       >>> resp
       <ClientResponse(python.org/) [200]>
       >>> data = await resp.read()
     """
     connector_owner = False
     if connector is None:
         connector_owner = True
-        connector = TCPConnector(loop=loop, force_close=True)
+        connector = TCPConnector(force_close=True)
 
     session = ClientSession(
-        loop=loop, cookies=cookies, version=version, timeout=timeout,
+        cookies=cookies, version=version, timeout=timeout,
         connector=connector, connector_owner=connector_owner)
 
     return _SessionRequestContextManager(
         session._request(method, url,
                          params=params,
                          data=data,
                          json=json,
```

### Comparing `aiohttp-4.0.0a0/aiohttp/client_exceptions.py` & `aiohttp-4.0.0a1/aiohttp/client_exceptions.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 """HTTP related errors."""
 
 import asyncio
-import warnings
 from typing import TYPE_CHECKING, Any, Optional, Tuple, Union
 
 from .typedefs import _CIMultiDict
 
 try:
     import ssl
     SSLContext = ssl.SSLContext
@@ -46,52 +45,40 @@
     """Connection error during reading response.
 
     request_info: instance of RequestInfo
     """
 
     def __init__(self, request_info: RequestInfo,
                  history: Tuple[ClientResponse, ...], *,
-                 code: Optional[int]=None,
                  status: Optional[int]=None,
                  message: str='',
                  headers: Optional[_CIMultiDict]=None) -> None:
         self.request_info = request_info
-        if code is not None:
-            if status is not None:
-                raise ValueError(
-                    "Both code and status arguments are provided; "
-                    "code is deprecated, use status instead")
-            warnings.warn("code argument is deprecated, use status instead",
-                          DeprecationWarning,
-                          stacklevel=2)
         if status is not None:
             self.status = status
-        elif code is not None:
-            self.status = code
         else:
             self.status = 0
         self.message = message
         self.headers = headers
         self.history = history
+        self.args = (request_info, history)
 
-        super().__init__("%s, message='%s'" % (self.status, message))
+    def __str__(self) -> str:
+        return ("%s, message=%r, url=%r" %
+                (self.status, self.message, self.request_info.real_url))
 
-    @property
-    def code(self) -> int:
-        warnings.warn("code property is deprecated, use status instead",
-                      DeprecationWarning,
-                      stacklevel=2)
-        return self.status
-
-    @code.setter
-    def code(self, value: int) -> None:
-        warnings.warn("code property is deprecated, use status instead",
-                      DeprecationWarning,
-                      stacklevel=2)
-        self.status = value
+    def __repr__(self) -> str:
+        args = "%r, %r" % (self.request_info, self.history)
+        if self.status != 0:
+            args += ", status=%r" % (self.status,)
+        if self.message != '':
+            args += ", message=%r" % (self.message,)
+        if self.headers is not None:
+            args += ", headers=%r" % (self.headers,)
+        return "%s(%s)" % (type(self).__name__, args)
 
 
 class ContentTypeError(ClientResponseError):
     """ContentType found is not valid."""
 
 
 class WSServerHandshakeError(ClientResponseError):
@@ -126,14 +113,15 @@
         connection to proxy can not be established.
     """
     def __init__(self, connection_key: ConnectionKey,
                  os_error: OSError) -> None:
         self._conn_key = connection_key
         self._os_error = os_error
         super().__init__(os_error.errno, os_error.strerror)
+        self.args = (connection_key, os_error)
 
     @property
     def os_error(self) -> OSError:
         return self._os_error
 
     @property
     def host(self) -> str:
@@ -144,16 +132,20 @@
         return self._conn_key.port
 
     @property
     def ssl(self) -> Union[SSLContext, None, bool, 'Fingerprint']:
         return self._conn_key.ssl
 
     def __str__(self) -> str:
-        return ('Cannot connect to host {0.host}:{0.port} ssl:{0.ssl} [{1}]'
-                .format(self, self.strerror))
+        return ('Cannot connect to host {0.host}:{0.port} ssl:{1} [{2}]'
+                .format(self, self.ssl if self.ssl is not None else 'default',
+                        self.strerror))
+
+    # OSError.__reduce__ does too much black magick
+    __reduce__ = BaseException.__reduce__
 
 
 class ClientProxyConnectionError(ClientConnectorError):
     """Proxy connection error.
 
     Raised in :class:`aiohttp.connector.TCPConnector` if
         connection to proxy can not be established.
@@ -165,14 +157,18 @@
 
 
 class ServerDisconnectedError(ServerConnectionError):
     """Server disconnected."""
 
     def __init__(self, message: Optional[str]=None) -> None:
         self.message = message
+        if message is None:
+            self.args = ()
+        else:
+            self.args = (message,)
 
 
 class ServerTimeoutError(ServerConnectionError, asyncio.TimeoutError):
     """Server timeout error."""
 
 
 class ServerFingerprintMismatch(ServerConnectionError):
@@ -180,17 +176,18 @@
 
     def __init__(self, expected: bytes, got: bytes,
                  host: str, port: int) -> None:
         self.expected = expected
         self.got = got
         self.host = host
         self.port = port
+        self.args = (expected, got, host, port)
 
     def __repr__(self) -> str:
-        return '<{} expected={} got={} host={} port={}>'.format(
+        return '<{} expected={!r} got={!r} host={!r} port={!r}>'.format(
             self.__class__.__name__, self.expected, self.got,
             self.host, self.port)
 
 
 class ClientPayloadError(ClientError):
     """Response payload error."""
 
@@ -241,14 +238,15 @@
 class ClientConnectorCertificateError(*cert_errors_bases):  # type: ignore
     """Response certificate error."""
 
     def __init__(self, connection_key:
                  ConnectionKey, certificate_error: Exception) -> None:
         self._conn_key = connection_key
         self._certificate_error = certificate_error
+        self.args = (connection_key, certificate_error)
 
     @property
     def certificate_error(self) -> Exception:
         return self._certificate_error
 
     @property
     def host(self) -> str:
```

### Comparing `aiohttp-4.0.0a0/aiohttp/client_proto.py` & `aiohttp-4.0.0a1/aiohttp/client_proto.py`

 * *Files 12% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 from .base_protocol import BaseProtocol
 from .client_exceptions import (
     ClientOSError,
     ClientPayloadError,
     ServerDisconnectedError,
     ServerTimeoutError,
 )
-from .helpers import BaseTimerContext
+from .helpers import BaseTimerContext, set_exception, set_result
 from .http import HttpResponseParser, RawResponseMessage
 from .streams import EMPTY_PAYLOAD, DataQueue, StreamReader
 
 
 class ResponseHandler(BaseProtocol,
                       DataQueue[Tuple[RawResponseMessage, StreamReader]]):
     """Helper class to adapt between Protocol and StreamReader."""
@@ -34,14 +34,16 @@
         self._tail = b''
         self._upgraded = False
         self._parser = None  # type: Optional[HttpResponseParser]
 
         self._read_timeout = None  # type: Optional[float]
         self._read_timeout_handle = None  # type: Optional[asyncio.TimerHandle]
 
+        self.closed = self._loop.create_future()  # type: asyncio.Future[None]
+
     @property
     def upgraded(self) -> bool:
         return self._upgraded
 
     @property
     def should_close(self) -> bool:
         if (self._payload is not None and
@@ -66,14 +68,19 @@
 
     def is_connected(self) -> bool:
         return self.transport is not None
 
     def connection_lost(self, exc: Optional[BaseException]) -> None:
         self._drop_timeout()
 
+        if exc is not None:
+            set_exception(self.closed, exc)
+        else:
+            set_result(self.closed, None)
+
         if self._payload_parser is not None:
             with suppress(Exception):
                 self._payload_parser.feed_eof()
 
         uncompleted = None
         if self._parser is not None:
             try:
@@ -172,14 +179,16 @@
     def _on_read_timeout(self) -> None:
         exc = ServerTimeoutError("Timeout on reading data from socket")
         self.set_exception(exc)
         if self._payload is not None:
             self._payload.set_exception(exc)
 
     def data_received(self, data: bytes) -> None:
+        self._reschedule_timeout()
+
         if not data:
             return
 
         # custom payload parser
         if self._payload_parser is not None:
             eof, tail = self._payload_parser.feed_data(data)
             if eof:
```

### Comparing `aiohttp-4.0.0a0/aiohttp/client_reqrep.py` & `aiohttp-4.0.0a1/aiohttp/client_reqrep.py`

 * *Files 2% similar despite different names*

```diff
@@ -39,14 +39,15 @@
 from .formdata import FormData
 from .helpers import (  # noqa
     PY_36,
     BaseTimerContext,
     BasicAuth,
     HeadersMixin,
     TimerNoop,
+    is_expected_content_type,
     noop,
     reify,
     set_result,
 )
 from .http import SERVER_SOFTWARE, HttpVersion10, HttpVersion11, StreamWriter
 from .log import client_logger
 from .streams import StreamReader  # noqa
@@ -76,17 +77,14 @@
 
 if TYPE_CHECKING:  # pragma: no cover
     from .client import ClientSession  # noqa
     from .connector import Connection  # noqa
     from .tracing import Trace  # noqa
 
 
-json_re = re.compile(r'^application/(?:[\w.+-]+?\+)?json')
-
-
 @attr.s(frozen=True, slots=True)
 class ContentDisposition:
     type = attr.ib(type=str)  # type: Optional[str]
     parameters = attr.ib(type=MappingProxyType)  # type: MappingProxyType[str, str]  # noqa
     filename = attr.ib(type=str)  # type: Optional[str]
 
 
@@ -138,74 +136,27 @@
 
 if ssl is not None:
     SSL_ALLOWED_TYPES = (ssl.SSLContext, bool, Fingerprint, type(None))
 else:  # pragma: no cover
     SSL_ALLOWED_TYPES = type(None)
 
 
-def _merge_ssl_params(
-        ssl: Union['SSLContext', bool, Fingerprint, None],
-        verify_ssl: Optional[bool],
-        ssl_context: Optional['SSLContext'],
-        fingerprint: Optional[bytes]
-) -> Union['SSLContext', bool, Fingerprint, None]:
-    if verify_ssl is not None and not verify_ssl:
-        warnings.warn("verify_ssl is deprecated, use ssl=False instead",
-                      DeprecationWarning,
-                      stacklevel=3)
-        if ssl is not None:
-            raise ValueError("verify_ssl, ssl_context, fingerprint and ssl "
-                             "parameters are mutually exclusive")
-        else:
-            ssl = False
-    if ssl_context is not None:
-        warnings.warn("ssl_context is deprecated, use ssl=context instead",
-                      DeprecationWarning,
-                      stacklevel=3)
-        if ssl is not None:
-            raise ValueError("verify_ssl, ssl_context, fingerprint and ssl "
-                             "parameters are mutually exclusive")
-        else:
-            ssl = ssl_context
-    if fingerprint is not None:
-        warnings.warn("fingerprint is deprecated, "
-                      "use ssl=Fingerprint(fingerprint) instead",
-                      DeprecationWarning,
-                      stacklevel=3)
-        if ssl is not None:
-            raise ValueError("verify_ssl, ssl_context, fingerprint and ssl "
-                             "parameters are mutually exclusive")
-        else:
-            ssl = Fingerprint(fingerprint)
-    if not isinstance(ssl, SSL_ALLOWED_TYPES):
-        raise TypeError("ssl should be SSLContext, bool, Fingerprint or None, "
-                        "got {!r} instead.".format(ssl))
-    return ssl
-
-
 @attr.s(slots=True, frozen=True)
 class ConnectionKey:
     # the key should contain an information about used proxy / TLS
     # to prevent reusing wrong connections from a pool
     host = attr.ib(type=str)
     port = attr.ib(type=int)  # type: Optional[int]
     is_ssl = attr.ib(type=bool)
     ssl = attr.ib()  # type: Union[SSLContext, None, bool, Fingerprint]
     proxy = attr.ib()  # type: Optional[URL]
     proxy_auth = attr.ib()  # type: Optional[BasicAuth]
     proxy_headers_hash = attr.ib(type=int)  # type: Optional[int] # noqa # hash(CIMultiDict)
 
 
-def _is_expected_content_type(response_content_type: str,
-                              expected_content_type: str) -> bool:
-    if expected_content_type == 'application/json':
-        return json_re.match(response_content_type) is not None
-    return expected_content_type in response_content_type
-
-
 class ClientRequest:
     GET_METHODS = {
         hdrs.METH_GET,
         hdrs.METH_HEAD,
         hdrs.METH_OPTIONS,
         hdrs.METH_TRACE,
     }
@@ -216,15 +167,14 @@
         hdrs.ACCEPT: '*/*',
         hdrs.ACCEPT_ENCODING: 'gzip, deflate',
     }
 
     body = b''
     auth = None
     response = None
-    response_class = None
 
     _writer = None  # async task for streaming data
     _continue = None  # waiter future for '100 Continue' response
 
     # N.B.
     # Adding __del__ method with self._writer closing doesn't make sense
     # because _writer is instance method, thus it keeps a reference to self.
@@ -237,27 +187,24 @@
                  data: Any=None,
                  cookies: Optional[LooseCookies]=None,
                  auth: Optional[BasicAuth]=None,
                  version: http.HttpVersion=http.HttpVersion11,
                  compress: Optional[str]=None,
                  chunked: Optional[bool]=None,
                  expect100: bool=False,
-                 loop: Optional[asyncio.AbstractEventLoop]=None,
+                 loop: asyncio.AbstractEventLoop,
                  response_class: Optional[Type['ClientResponse']]=None,
                  proxy: Optional[URL]=None,
                  proxy_auth: Optional[BasicAuth]=None,
                  timer: Optional[BaseTimerContext]=None,
                  session: Optional['ClientSession']=None,
                  ssl: Union[SSLContext, bool, Fingerprint, None]=None,
                  proxy_headers: Optional[LooseHeaders]=None,
                  traces: Optional[List['Trace']]=None):
 
-        if loop is None:
-            loop = asyncio.get_event_loop()
-
         assert isinstance(url, URL), url
         assert isinstance(proxy, (URL, type(None))), proxy
         # FIXME: session is None in tests only, need to fix tests
         # assert session is not None
         self._session = cast('ClientSession', session)
         if params:
             q = MultiDict(url.query)
@@ -363,15 +310,15 @@
         """Update request headers."""
         self.headers = CIMultiDict()  # type: CIMultiDict[str]
 
         # add host
         netloc = cast(str, self.url.raw_host)
         if helpers.is_ipv6_address(netloc):
             netloc = '[{}]'.format(netloc)
-        if not self.url.is_default_port():
+        if self.url.port is not None and not self.url.is_default_port():
             netloc += ':' + str(self.url.port)
         self.headers[hdrs.HOST] = netloc
 
         if headers:
             if isinstance(headers, (dict, MultiDictProxy, MultiDict)):
                 headers = headers.items()  # type: ignore
 
@@ -409,15 +356,15 @@
             iter_cookies = cookies.items()
         else:
             iter_cookies = cookies  # type: ignore
         for name, value in iter_cookies:
             if isinstance(value, Morsel):
                 # Preserve coded_value
                 mrsl_val = value.get(value.key, Morsel())
-                mrsl_val.set(value.key, value.value, value.coded_value)  # type: ignore  # noqa
+                mrsl_val.set(value.key, value.value, value.coded_value)
                 c[name] = mrsl_val
             else:
                 c[name] = value  # type: ignore
 
         self.headers[hdrs.COOKIE] = c.output(header='', sep=';').strip()
 
     def update_content_encoding(self, data: Any) -> None:
@@ -576,15 +523,19 @@
 
     async def send(self, conn: 'Connection') -> 'ClientResponse':
         # Specify request target:
         # - CONNECT request must send authority form URI
         # - not CONNECT proxy must send absolute form URI
         # - most common is origin form URI
         if self.method == hdrs.METH_CONNECT:
-            path = '{}:{}'.format(self.url.raw_host, self.url.port)
+            connect_host = self.url.raw_host
+            assert connect_host is not None
+            if helpers.is_ipv6_address(connect_host):
+                connect_host = '[{}]'.format(connect_host)
+            path = '{}:{}'.format(connect_host, self.url.port)
         elif self.proxy and not self.is_ssl():
             path = str(self.url)
         else:
             path = self.url.raw_path
             if self.url.raw_query_string:
                 path += '?' + self.url.raw_query_string
 
@@ -680,14 +631,15 @@
                  continue100: Optional['asyncio.Future[bool]'],
                  timer: BaseTimerContext,
                  request_info: RequestInfo,
                  traces: List['Trace'],
                  loop: asyncio.AbstractEventLoop,
                  session: 'ClientSession') -> None:
         assert isinstance(url, URL)
+        super().__init__()
 
         self.method = method
         self.cookies = SimpleCookie()
 
         self._real_url = url
         self._url = url.with_fragment(None)
         self._body = None  # type: Optional[bytes]
@@ -706,20 +658,14 @@
             self._source_traceback = traceback.extract_stack(sys._getframe(1))
 
     @reify
     def url(self) -> URL:
         return self._url
 
     @reify
-    def url_obj(self) -> URL:
-        warnings.warn(
-            "Deprecated, use .url #1654", DeprecationWarning, stacklevel=2)
-        return self._url
-
-    @reify
     def real_url(self) -> URL:
         return self._real_url
 
     @reify
     def host(self) -> str:
         assert self._url.host is not None
         return self._url.host
@@ -785,15 +731,15 @@
 
     @property
     def connection(self) -> Optional['Connection']:
         return self._connection
 
     @reify
     def history(self) -> Tuple['ClientResponse', ...]:
-        """A sequence of of responses, if redirects occurred."""
+        """A sequence of responses, if redirects occurred."""
         return self._history
 
     @reify
     def links(self) -> 'MultiDictProxy[MultiDictProxy[Union[str, URL]]]':
         links_str = ", ".join(self.headers.getall("link", []))
 
         if not links_str:
@@ -928,15 +874,16 @@
             self._connection = None
 
         self._cleanup_writer()
         return noop()
 
     def raise_for_status(self) -> None:
         if 400 <= self.status:
-            assert self.reason  # always not None for started response
+            # reason should always be not None for a started response
+            assert self.reason is not None
             self.release()
             raise ClientResponseError(
                 self.request_info,
                 self.history,
                 status=self.status,
                 message=self.reason,
                 headers=self.headers)
@@ -1014,15 +961,15 @@
                    content_type: Optional[str]='application/json') -> Any:
         """Read and decodes JSON response."""
         if self._body is None:
             await self.read()
 
         if content_type:
             ctype = self.headers.get(hdrs.CONTENT_TYPE, '').lower()
-            if not _is_expected_content_type(ctype, content_type):
+            if not is_expected_content_type(ctype, content_type):
                 raise ContentTypeError(
                     self.request_info,
                     self.history,
                     message=('Attempt to decode JSON with '
                              'unexpected mimetype: %s' % ctype),
                     headers=self.headers)
```

### Comparing `aiohttp-4.0.0a0/aiohttp/client_ws.py` & `aiohttp-4.0.0a1/aiohttp/client_ws.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 """WebSocket client for asyncio."""
 
 import asyncio
 from typing import Any, Optional
 
 import async_timeout
+import attr
 
 from .client_exceptions import ClientError
 from .client_reqrep import ClientResponse
 from .helpers import call_later, set_result
 from .http import (
     WS_CLOSED_MESSAGE,
     WS_CLOSING_MESSAGE,
@@ -21,41 +22,48 @@
     DEFAULT_JSON_DECODER,
     DEFAULT_JSON_ENCODER,
     JSONDecoder,
     JSONEncoder,
 )
 
 
+@attr.s(frozen=True, slots=True)
+class ClientWSTimeout:
+    ws_receive = attr.ib(type=Optional[float], default=None)
+    ws_close = attr.ib(type=Optional[float], default=None)
+
+
+DEFAULT_WS_CLIENT_TIMEOUT = ClientWSTimeout(ws_receive=None, ws_close=10.0)
+
+
 class ClientWebSocketResponse:
 
     def __init__(self,
                  reader: 'FlowControlDataQueue[WSMessage]',
                  writer: WebSocketWriter,
                  protocol: Optional[str],
                  response: ClientResponse,
-                 timeout: float,
+                 timeout: ClientWSTimeout,
                  autoclose: bool,
                  autoping: bool,
                  loop: asyncio.AbstractEventLoop,
                  *,
-                 receive_timeout: Optional[float]=None,
                  heartbeat: Optional[float]=None,
                  compress: int=0,
                  client_notakeover: bool=False) -> None:
         self._response = response
         self._conn = response.connection
 
         self._writer = writer
         self._reader = reader
         self._protocol = protocol
         self._closed = False
         self._closing = False
         self._close_code = None  # type: Optional[int]
-        self._timeout = timeout
-        self._receive_timeout = receive_timeout
+        self._timeout = timeout  # type: ClientWSTimeout
         self._autoclose = autoclose
         self._autoping = autoping
         self._heartbeat = heartbeat
         self._heartbeat_cb = None
         if heartbeat is not None:
             self._pong_heartbeat = heartbeat / 2.0
         self._pong_response_cb = None
@@ -183,15 +191,16 @@
 
             if self._closing:
                 self._response.close()
                 return True
 
             while True:
                 try:
-                    with async_timeout.timeout(self._timeout, loop=self._loop):
+                    with async_timeout.timeout(self._timeout.ws_close,
+                                               loop=self._loop):
                         msg = await self._reader.read()
                 except asyncio.CancelledError:
                     self._close_code = 1006
                     self._response.close()
                     raise
                 except Exception as exc:
                     self._close_code = 1006
@@ -218,15 +227,15 @@
                 await self.close()
                 return WS_CLOSED_MESSAGE
 
             try:
                 self._waiting = self._loop.create_future()
                 try:
                     with async_timeout.timeout(
-                            timeout or self._receive_timeout,
+                            timeout or self._timeout.ws_receive,
                             loop=self._loop):
                         msg = await self._reader.read()
                     self._reset_heartbeat()
                 finally:
                     waiter = self._waiting
                     self._waiting = None
                     set_result(waiter, True)
```

### Comparing `aiohttp-4.0.0a0/aiohttp/connector.py` & `aiohttp-4.0.0a1/aiohttp/connector.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,10 @@
 import asyncio
 import functools
+import logging
 import random
 import sys
 import traceback
 import warnings
 from collections import defaultdict, deque
 from contextlib import suppress
 from http.cookies import SimpleCookie
@@ -39,62 +40,44 @@
     ClientHttpProxyError,
     ClientProxyConnectionError,
     ServerFingerprintMismatch,
     cert_errors,
     ssl_errors,
 )
 from .client_proto import ResponseHandler
-from .client_reqrep import ClientRequest, Fingerprint, _merge_ssl_params
+from .client_reqrep import SSL_ALLOWED_TYPES, ClientRequest, Fingerprint
 from .helpers import (
     PY_36,
     CeilTimeout,
     get_running_loop,
     is_ip_address,
-    noop2,
     sentinel,
 )
 from .http import RESPONSES
 from .locks import EventResultOrError
 from .resolver import DefaultResolver
 
 try:
     import ssl
     SSLContext = ssl.SSLContext
 except ImportError:  # pragma: no cover
     ssl = None  # type: ignore
     SSLContext = object  # type: ignore
 
 
-__all__ = ('BaseConnector', 'TCPConnector', 'UnixConnector')
+__all__ = ('BaseConnector', 'TCPConnector', 'UnixConnector',
+           'NamedPipeConnector')
 
 
 if TYPE_CHECKING:  # pragma: no cover
     from .client import ClientTimeout  # noqa
     from .client_reqrep import ConnectionKey  # noqa
     from .tracing import Trace  # noqa
 
 
-class _DeprecationWaiter:
-    __slots__ = ('_awaitable', '_awaited')
-
-    def __init__(self, awaitable: Awaitable[Any]) -> None:
-        self._awaitable = awaitable
-        self._awaited = False
-
-    def __await__(self) -> Any:
-        self._awaited = True
-        return self._awaitable.__await__()
-
-    def __del__(self) -> None:
-        if not self._awaited:
-            warnings.warn("Connector.close() is a coroutine, "
-                          "please use await connector.close()",
-                          DeprecationWarning)
-
-
 class Connection:
 
     _source_traceback = None
     _transport = None
 
     def __init__(self, connector: 'BaseConnector',
                  key: 'ConnectionKey',
@@ -130,21 +113,14 @@
             context = {'client_connection': self,
                        'message': 'Unclosed connection'}
             if self._source_traceback is not None:
                 context['source_traceback'] = self._source_traceback
             self._loop.call_exception_handler(context)
 
     @property
-    def loop(self) -> asyncio.AbstractEventLoop:
-        warnings.warn("connector.loop property is deprecated",
-                      DeprecationWarning,
-                      stacklevel=2)
-        return self._loop
-
-    @property
     def transport(self) -> Optional[asyncio.Transport]:
         if self._protocol is None:
             return None
         return self._protocol.transport
 
     @property
     def protocol(self) -> Optional[ResponseHandler]:
@@ -181,14 +157,18 @@
     @property
     def closed(self) -> bool:
         return self._protocol is None or not self._protocol.is_connected()
 
 
 class _TransportPlaceholder:
     """ placeholder for BaseConnector.connect function """
+    def __init__(self, loop: asyncio.AbstractEventLoop) -> None:
+        fut = loop.create_future()
+        fut.set_result(None)
+        self.closed = fut  # type: asyncio.Future[Optional[Exception]]  # noqa
 
     def close(self) -> None:
         pass
 
 
 class BaseConnector:
     """Base connector class.
@@ -209,27 +189,26 @@
     # abort transport after 2 seconds (cleanup broken connections)
     _cleanup_closed_period = 2.0
 
     def __init__(self, *,
                  keepalive_timeout: Union[object, None, float]=sentinel,
                  force_close: bool=False,
                  limit: int=100, limit_per_host: int=0,
-                 enable_cleanup_closed: bool=False,
-                 loop: Optional[asyncio.AbstractEventLoop]=None) -> None:
+                 enable_cleanup_closed: bool=False) -> None:
 
         if force_close:
             if keepalive_timeout is not None and \
                keepalive_timeout is not sentinel:
                 raise ValueError('keepalive_timeout cannot '
                                  'be set if force_close is True')
         else:
             if keepalive_timeout is sentinel:
                 keepalive_timeout = 15.0
 
-        loop = get_running_loop(loop)
+        loop = get_running_loop()
 
         self._closed = False
         if loop.get_debug():
             self._source_traceback = traceback.extract_stack(sys._getframe(1))
 
         self._conns = {}  # type: Dict[ConnectionKey, List[Tuple[ResponseHandler, float]]]  # noqa
         self._limit = limit
@@ -260,15 +239,15 @@
         if self._closed:
             return
         if not self._conns:
             return
 
         conns = [repr(c) for c in self._conns.values()]
 
-        self._close()
+        self._close_immediately()
 
         if PY_36:
             kwargs = {'source': self}
         else:
             kwargs = {}
         _warnings.warn("Unclosed connector {!r}".format(self),
                        ResourceWarning,
@@ -276,23 +255,14 @@
         context = {'connector': self,
                    'connections': conns,
                    'message': 'Unclosed connector'}
         if self._source_traceback is not None:
             context['source_traceback'] = self._source_traceback
         self._loop.call_exception_handler(context)
 
-    def __enter__(self) -> 'BaseConnector':
-        warnings.warn('"witn Connector():" is deprecated, '
-                      'use "async with Connector():" instead',
-                      DeprecationWarning)
-        return self
-
-    def __exit__(self, *exc: Any) -> None:
-        self.close()
-
     async def __aenter__(self) -> 'BaseConnector':
         return self
 
     async def __aexit__(self,
                         exc_type: Optional[Type[BaseException]]=None,
                         exc_value: Optional[BaseException]=None,
                         exc_traceback: Optional[TracebackType]=None
@@ -382,48 +352,62 @@
         self._cleanup_closed_transports = []
 
         if not self._cleanup_closed_disabled:
             self._cleanup_closed_handle = helpers.weakref_handle(
                 self, '_cleanup_closed',
                 self._cleanup_closed_period, self._loop)
 
-    def close(self) -> Awaitable[None]:
+    async def close(self) -> None:
         """Close all opened transports."""
-        self._close()
-        return _DeprecationWaiter(noop2())
+        waiters = self._close_immediately()
+        if waiters:
+            results = await asyncio.gather(*waiters,
+                                           loop=self._loop,
+                                           return_exceptions=True)
+            for res in results:
+                if isinstance(res, Exception):
+                    err_msg = "Error while closing connector: " + repr(res)
+                    logging.error(err_msg)
+
+    def _close_immediately(self) -> List['asyncio.Future[None]']:
+        waiters = []  # type: List['asyncio.Future[None]']
 
-    def _close(self) -> None:
         if self._closed:
-            return
+            return waiters
 
         self._closed = True
 
         try:
             if self._loop.is_closed():
-                return
+                return waiters
 
             # cancel cleanup task
             if self._cleanup_handle:
                 self._cleanup_handle.cancel()
 
             # cancel cleanup close task
             if self._cleanup_closed_handle:
                 self._cleanup_closed_handle.cancel()
 
             for data in self._conns.values():
                 for proto, t0 in data:
                     proto.close()
+                    waiters.append(proto.closed)
 
             for proto in self._acquired:
                 proto.close()
+                waiters.append(proto.closed)
 
+            # TODO (A.Yushovskiy, 24-May-2019) collect transp. closing futures
             for transport in self._cleanup_closed_transports:
                 if transport is not None:
                     transport.abort()
 
+            return waiters
+
         finally:
             self._conns.clear()
             self._acquired.clear()
             self._waiters.clear()
             self._cleanup_handle = None
             self._cleanup_closed_transports.clear()
             self._cleanup_closed_handle = None
@@ -506,15 +490,16 @@
 
             if traces:
                 for trace in traces:
                     await trace.send_connection_queued_end()
 
         proto = self._get(key)
         if proto is None:
-            placeholder = cast(ResponseHandler, _TransportPlaceholder())
+            placeholder = cast(ResponseHandler,
+                               _TransportPlaceholder(self._loop))
             self._acquired.add(placeholder)
             self._acquired_per_host[key].add(placeholder)
 
             if traces:
                 for trace in traces:
                     await trace.send_connection_create_start()
 
@@ -706,51 +691,47 @@
     limit - The total number of simultaneous connections.
     limit_per_host - Number of simultaneous connections to one host.
     enable_cleanup_closed - Enables clean-up closed ssl transports.
                             Disabled by default.
     loop - Optional event loop.
     """
 
-    def __init__(self, *, verify_ssl: bool=True,
-                 fingerprint: Optional[bytes]=None,
+    def __init__(self, *,
                  use_dns_cache: bool=True, ttl_dns_cache: int=10,
                  family: int=0,
-                 ssl_context: Optional[SSLContext]=None,
                  ssl: Union[None, bool, Fingerprint, SSLContext]=None,
-                 local_addr: Optional[str]=None,
+                 local_addr: Optional[Tuple[str, int]]=None,
                  resolver: Optional[AbstractResolver]=None,
                  keepalive_timeout: Union[None, float, object]=sentinel,
                  force_close: bool=False,
                  limit: int=100, limit_per_host: int=0,
-                 enable_cleanup_closed: bool=False,
-                 loop: Optional[asyncio.AbstractEventLoop]=None):
+                 enable_cleanup_closed: bool=False) -> None:
         super().__init__(keepalive_timeout=keepalive_timeout,
                          force_close=force_close,
                          limit=limit, limit_per_host=limit_per_host,
-                         enable_cleanup_closed=enable_cleanup_closed,
-                         loop=loop)
+                         enable_cleanup_closed=enable_cleanup_closed)
 
-        self._ssl = _merge_ssl_params(ssl, verify_ssl, ssl_context,
-                                      fingerprint)
+        if not isinstance(ssl, SSL_ALLOWED_TYPES):
+            raise TypeError("ssl should be SSLContext, bool, Fingerprint, "
+                            "or None, got {!r} instead.".format(ssl))
+        self._ssl = ssl
         if resolver is None:
-            resolver = DefaultResolver(loop=self._loop)
+            resolver = DefaultResolver()
         self._resolver = resolver
 
         self._use_dns_cache = use_dns_cache
         self._cached_hosts = _DNSCacheTable(ttl=ttl_dns_cache)
         self._throttle_dns_events = {}  # type: Dict[Tuple[str, int], EventResultOrError]  # noqa
         self._family = family
         self._local_addr = local_addr
 
-    def close(self) -> Awaitable[None]:
-        """Close all ongoing DNS calls."""
+    def _close_immediately(self) -> List['asyncio.Future[None]']:
         for ev in self._throttle_dns_events.values():
             ev.cancel()
-
-        return super().close()
+        return super()._close_immediately()
 
     @property
     def family(self) -> int:
         """Socket family like AF_INET."""
         return self._family
 
     @property
@@ -793,32 +774,36 @@
 
             return res
 
         key = (host, port)
 
         if (key in self._cached_hosts) and \
                 (not self._cached_hosts.expired(key)):
+            # get result early, before any await (#4014)
+            result = self._cached_hosts.next_addrs(key)
 
             if traces:
                 for trace in traces:
                     await trace.send_dns_cache_hit(host)
-
-            return self._cached_hosts.next_addrs(key)
+            return result
 
         if key in self._throttle_dns_events:
+            # get event early, before any await (#4014)
+            event = self._throttle_dns_events[key]
             if traces:
                 for trace in traces:
                     await trace.send_dns_cache_hit(host)
-            await self._throttle_dns_events[key].wait()
+            await event.wait()
         else:
+            # update dict early, before any await (#4014)
+            self._throttle_dns_events[key] = \
+                EventResultOrError(self._loop)
             if traces:
                 for trace in traces:
                     await trace.send_dns_cache_miss(host)
-            self._throttle_dns_events[key] = \
-                EventResultOrError(self._loop)
             try:
 
                 if traces:
                     for trace in traces:
                         await trace.send_dns_resolvehost_start(host)
 
                 addrs = await \
@@ -860,15 +845,24 @@
     def _make_ssl_context(verified: bool) -> SSLContext:
         if verified:
             return ssl.create_default_context()
         else:
             sslcontext = ssl.SSLContext(ssl.PROTOCOL_SSLv23)
             sslcontext.options |= ssl.OP_NO_SSLv2
             sslcontext.options |= ssl.OP_NO_SSLv3
-            sslcontext.options |= ssl.OP_NO_COMPRESSION
+            try:
+                sslcontext.options |= ssl.OP_NO_COMPRESSION
+            except AttributeError as attr_err:
+                warnings.warn(
+                    '{!s}: The Python interpreter is compiled '
+                    'against OpenSSL < 1.0.0. Ref: '
+                    'https://docs.python.org/3/library/ssl.html'
+                    '#ssl.OP_NO_COMPRESSION'.
+                    format(attr_err),
+                )
             sslcontext.set_default_verify_paths()
             return sslcontext
 
     def _get_ssl_context(self, req: 'ClientRequest') -> Optional[SSLContext]:
         """Logic to get the correct SSL context
 
         0. if req.ssl is false, return None
@@ -915,17 +909,15 @@
             self, *args: Any,
             req: 'ClientRequest',
             timeout: 'ClientTimeout',
             client_error: Type[Exception]=ClientConnectorError,
             **kwargs: Any) -> Tuple[asyncio.Transport, ResponseHandler]:
         try:
             with CeilTimeout(timeout.sock_connect):
-                return cast(
-                    Tuple[asyncio.Transport, ResponseHandler],
-                    await self._loop.create_connection(*args, **kwargs))
+                return await self._loop.create_connection(*args, **kwargs)  # type: ignore  # noqa
         except cert_errors as exc:
             raise ClientConnectorCertificateError(
                 req.connection_key, exc) from exc
         except ssl_errors as exc:
             raise ClientConnectorSSLError(req.connection_key, exc) from exc
         except OSError as exc:
             raise client_error(req.connection_key, exc) from exc
@@ -983,17 +975,16 @@
                     transp.close()
                     if not self._cleanup_closed_disabled:
                         self._cleanup_closed_transports.append(transp)
                     last_exc = exc
                     continue
 
             return transp, proto
-        else:
-            assert last_exc is not None
-            raise last_exc
+        assert last_exc is not None
+        raise last_exc
 
     async def _create_proxy_connection(
             self,
             req: 'ClientRequest',
             traces: List['Trace'],
             timeout: 'ClientTimeout'
     ) -> Tuple[asyncio.Transport, ResponseHandler]:
@@ -1099,19 +1090,18 @@
     limit - The total number of simultaneous connections.
     limit_per_host - Number of simultaneous connections to one host.
     loop - Optional event loop.
     """
 
     def __init__(self, path: str, force_close: bool=False,
                  keepalive_timeout: Union[object, float, None]=sentinel,
-                 limit: int=100, limit_per_host: int=0,
-                 loop: Optional[asyncio.AbstractEventLoop]=None) -> None:
+                 limit: int=100, limit_per_host: int=0) -> None:
         super().__init__(force_close=force_close,
                          keepalive_timeout=keepalive_timeout,
-                         limit=limit, limit_per_host=limit_per_host, loop=loop)
+                         limit=limit, limit_per_host=limit_per_host)
         self._path = path
 
     @property
     def path(self) -> str:
         """Path to unix socket."""
         return self._path
 
@@ -1122,7 +1112,59 @@
             with CeilTimeout(timeout.sock_connect):
                 _, proto = await self._loop.create_unix_connection(
                     self._factory, self._path)
         except OSError as exc:
             raise ClientConnectorError(req.connection_key, exc) from exc
 
         return cast(ResponseHandler, proto)
+
+
+class NamedPipeConnector(BaseConnector):
+    """Named pipe connector.
+
+    Only supported by the proactor event loop.
+    See also: https://docs.python.org/3.7/library/asyncio-eventloop.html
+
+    path - Windows named pipe path.
+    keepalive_timeout - (optional) Keep-alive timeout.
+    force_close - Set to True to force close and do reconnect
+        after each request (and between redirects).
+    limit - The total number of simultaneous connections.
+    limit_per_host - Number of simultaneous connections to one host.
+    loop - Optional event loop.
+    """
+
+    def __init__(self, path: str, force_close: bool=False,
+                 keepalive_timeout: Union[object, float, None]=sentinel,
+                 limit: int=100, limit_per_host: int=0) -> None:
+        super().__init__(force_close=force_close,
+                         keepalive_timeout=keepalive_timeout,
+                         limit=limit, limit_per_host=limit_per_host)
+        if not isinstance(self._loop, asyncio.ProactorEventLoop):  # type: ignore # noqa
+            raise RuntimeError("Named Pipes only available in proactor "
+                               "loop under windows")
+        self._path = path
+
+    @property
+    def path(self) -> str:
+        """Path to the named pipe."""
+        return self._path
+
+    async def _create_connection(self, req: 'ClientRequest',
+                                 traces: List['Trace'],
+                                 timeout: 'ClientTimeout') -> ResponseHandler:
+        try:
+            with CeilTimeout(timeout.sock_connect):
+                _, proto = await self._loop.create_pipe_connection(  # type: ignore # noqa
+                    self._factory, self._path
+                )
+                # the drain is required so that the connection_made is called
+                # and transport is set otherwise it is not set before the
+                # `assert conn.transport is not None`
+                # in client.py's _request method
+                await asyncio.sleep(0)
+                # other option is to manually set transport like
+                # `proto.transport = trans`
+        except OSError as exc:
+            raise ClientConnectorError(req.connection_key, exc) from exc
+
+        return cast(ResponseHandler, proto)
```

### Comparing `aiohttp-4.0.0a0/aiohttp/cookiejar.py` & `aiohttp-4.0.0a1/aiohttp/cookiejar.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,15 @@
-import asyncio
 import datetime
 import os  # noqa
 import pathlib
 import pickle
 import re
+import warnings
 from collections import defaultdict
 from http.cookies import BaseCookie, Morsel, SimpleCookie  # noqa
-from math import ceil
 from typing import (  # noqa
     DefaultDict,
     Dict,
     Iterable,
     Iterator,
     Mapping,
     Optional,
@@ -19,15 +18,15 @@
     Union,
     cast,
 )
 
 from yarl import URL
 
 from .abc import AbstractCookieJar
-from .helpers import is_ip_address
+from .helpers import get_running_loop, is_ip_address, next_whole_second
 from .typedefs import LooseCookies, PathLike
 
 __all__ = ('CookieJar', 'DummyCookieJar')
 
 
 CookieItem = Union[str, 'Morsel[str]']
 
@@ -44,51 +43,51 @@
     DATE_DAY_OF_MONTH_RE = re.compile(r"(\d{1,2})")
 
     DATE_MONTH_RE = re.compile("(jan)|(feb)|(mar)|(apr)|(may)|(jun)|(jul)|"
                                "(aug)|(sep)|(oct)|(nov)|(dec)", re.I)
 
     DATE_YEAR_RE = re.compile(r"(\d{2,4})")
 
-    MAX_TIME = 2051215261.0  # so far in future (2035-01-01)
+    MAX_TIME = datetime.datetime.max.replace(
+        tzinfo=datetime.timezone.utc)
 
-    def __init__(self, *, unsafe: bool=False,
-                 loop: Optional[asyncio.AbstractEventLoop]=None) -> None:
-        super().__init__(loop=loop)
+    def __init__(self, *, unsafe: bool=False) -> None:
+        self._loop = get_running_loop()
         self._cookies = defaultdict(SimpleCookie)  #type: DefaultDict[str, SimpleCookie]  # noqa
         self._host_only_cookies = set()  # type: Set[Tuple[str, str]]
         self._unsafe = unsafe
-        self._next_expiration = ceil(self._loop.time())
-        self._expirations = {}  # type: Dict[Tuple[str, str], int]
+        self._next_expiration = next_whole_second()
+        self._expirations = {}  # type: Dict[Tuple[str, str], datetime.datetime]  # noqa: E501
 
     def save(self, file_path: PathLike) -> None:
         file_path = pathlib.Path(file_path)
         with file_path.open(mode='wb') as f:
             pickle.dump(self._cookies, f, pickle.HIGHEST_PROTOCOL)
 
     def load(self, file_path: PathLike) -> None:
         file_path = pathlib.Path(file_path)
         with file_path.open(mode='rb') as f:
             self._cookies = pickle.load(f)
 
     def clear(self) -> None:
         self._cookies.clear()
         self._host_only_cookies.clear()
-        self._next_expiration = ceil(self._loop.time())
+        self._next_expiration = next_whole_second()
         self._expirations.clear()
 
     def __iter__(self) -> 'Iterator[Morsel[str]]':
         self._do_expiration()
         for val in self._cookies.values():
             yield from val.values()
 
     def __len__(self) -> int:
         return sum(1 for i in self)
 
     def _do_expiration(self) -> None:
-        now = self._loop.time()
+        now = datetime.datetime.now(datetime.timezone.utc)
         if self._next_expiration > now:
             return
         if not self._expirations:
             return
         next_expiration = self.MAX_TIME
         to_del = []
         cookies = self._cookies
@@ -99,20 +98,24 @@
                 to_del.append((domain, name))
                 self._host_only_cookies.discard((domain, name))
             else:
                 next_expiration = min(next_expiration, when)
         for key in to_del:
             del expirations[key]
 
-        self._next_expiration = ceil(next_expiration)
-
-    def _expire_cookie(self, when: float, domain: str, name: str) -> None:
-        iwhen = int(when)
-        self._next_expiration = min(self._next_expiration, iwhen)
-        self._expirations[(domain, name)] = iwhen
+        try:
+            self._next_expiration = (next_expiration.replace(microsecond=0) +
+                                     datetime.timedelta(seconds=1))
+        except OverflowError:
+            self._next_expiration = self.MAX_TIME
+
+    def _expire_cookie(self, when: datetime.datetime, domain: str, name: str
+                       ) -> None:
+        self._next_expiration = min(self._next_expiration, when)
+        self._expirations[(domain, name)] = when
 
     def update_cookies(self,
                        cookies: LooseCookies,
                        response_url: URL=URL()) -> None:
         """Update cookies."""
         hostname = response_url.raw_host
 
@@ -162,37 +165,47 @@
                     path = "/" + path[1:path.rfind("/")]
                 cookie["path"] = path
 
             max_age = cookie["max-age"]
             if max_age:
                 try:
                     delta_seconds = int(max_age)
-                    self._expire_cookie(self._loop.time() + delta_seconds,
+                    try:
+                        max_age_expiration = (
+                            datetime.datetime.now(datetime.timezone.utc) +
+                            datetime.timedelta(seconds=delta_seconds))
+                    except OverflowError:
+                        max_age_expiration = self.MAX_TIME
+                    self._expire_cookie(max_age_expiration,
                                         domain, name)
                 except ValueError:
                     cookie["max-age"] = ""
 
             else:
                 expires = cookie["expires"]
                 if expires:
                     expire_time = self._parse_date(expires)
                     if expire_time:
-                        self._expire_cookie(expire_time.timestamp(),
+                        self._expire_cookie(expire_time,
                                             domain, name)
                     else:
                         cookie["expires"] = ""
 
             self._cookies[domain][name] = cookie
 
         self._do_expiration()
 
     def filter_cookies(self, request_url: URL=URL()) -> 'BaseCookie[str]':
         """Returns this jar's cookies filtered by their attributes."""
         self._do_expiration()
-        request_url = URL(request_url)
+        if not isinstance(request_url, URL):
+            warnings.warn("The method accepts yarl.URL instances only, got {}"
+                          .format(type(request_url)),
+                          DeprecationWarning)
+            request_url = URL(request_url)
         filtered = SimpleCookie()
         hostname = request_url.raw_host or ""
         is_not_secure = request_url.scheme not in ("https", "wss")
 
         for cookie in self:
             name = cookie.key
             domain = cookie["domain"]
@@ -295,14 +308,15 @@
                     day = int(day_match.group())
                     continue
 
             if not found_month:
                 month_match = cls.DATE_MONTH_RE.match(token)
                 if month_match:
                     found_month = True
+                    assert month_match.lastindex is not None
                     month = month_match.lastindex
                     continue
 
             if not found_year:
                 year_match = cls.DATE_YEAR_RE.match(token)
                 if year_match:
                     found_year = True
@@ -330,18 +344,14 @@
 class DummyCookieJar(AbstractCookieJar):
     """Implements a dummy cookie storage.
 
     It can be used with the ClientSession when no cookie processing is needed.
 
     """
 
-    def __init__(self, *,
-                 loop: Optional[asyncio.AbstractEventLoop]=None) -> None:
-        super().__init__(loop=loop)
-
     def __iter__(self) -> 'Iterator[Morsel[str]]':
         while False:
             yield None
 
     def __len__(self) -> int:
         return 0
```

### Comparing `aiohttp-4.0.0a0/aiohttp/formdata.py` & `aiohttp-4.0.0a1/aiohttp/formdata.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/aiohttp/frozenlist.py` & `aiohttp-4.0.0a1/aiohttp/frozenlist.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/aiohttp/frozenlist.pyi` & `aiohttp-4.0.0a1/aiohttp/frozenlist.pyi`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,26 @@
-from typing import (Generic, Iterable, Iterator, List, MutableSequence,
-                    Optional, TypeVar, Union, overload)
+from typing import (
+    Generic,
+    Iterable,
+    Iterator,
+    List,
+    MutableSequence,
+    Optional,
+    TypeVar,
+    Union,
+    overload,
+)
 
 _T = TypeVar('_T')
 _Arg = Union[List[_T], Iterable[_T]]
 
 
 class FrozenList(MutableSequence[_T], Generic[_T]):
 
-    def __init__(self, items: Optional[_Arg[_T]]=None) -> None: ...
+    def __init__(self, items: Optional[_Arg[_T]]=...) -> None: ...
 
     @property
     def frozen(self) -> bool: ...
 
     def freeze(self) -> None: ...
 
     @overload
```

### Comparing `aiohttp-4.0.0a0/aiohttp/hdrs.py` & `aiohttp-4.0.0a1/aiohttp/hdrs.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/aiohttp/helpers.py` & `aiohttp-4.0.0a1/aiohttp/helpers.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,30 +1,31 @@
 """Various helper functions"""
 
 import asyncio
 import base64
 import binascii
 import cgi
+import datetime
 import functools
 import inspect
 import netrc
 import os
 import platform
 import re
 import sys
 import time
-import warnings
 import weakref
 from collections import namedtuple
 from contextlib import suppress
 from math import ceil
 from pathlib import Path
 from types import TracebackType
 from typing import (  # noqa
     Any,
+    Awaitable,
     Callable,
     Dict,
     Iterable,
     Iterator,
     List,
     Mapping,
     Optional,
@@ -38,39 +39,41 @@
 )
 from urllib.parse import quote
 from urllib.request import getproxies
 
 import async_timeout
 import attr
 from multidict import MultiDict, MultiDictProxy
+from typing_extensions import final
 from yarl import URL
 
 from . import hdrs
-from .log import client_logger, internal_logger
+from .log import client_logger
 from .typedefs import PathLike  # noqa
 
 __all__ = ('BasicAuth', 'ChainMapProxy')
 
 PY_36 = sys.version_info >= (3, 6)
 PY_37 = sys.version_info >= (3, 7)
+PY_38 = sys.version_info >= (3, 8)
 
 if not PY_37:
     import idna_ssl
     idna_ssl.patch_match_hostname()
 
 try:
     from typing import ContextManager
 except ImportError:
     from typing_extensions import ContextManager
 
 
 def all_tasks(
         loop: Optional[asyncio.AbstractEventLoop] = None
 ) -> Set['asyncio.Task[Any]']:
-    tasks = list(asyncio.Task.all_tasks(loop))  # type: ignore
+    tasks = list(asyncio.Task.all_tasks(loop))
     return {t for t in tasks if not t.done()}
 
 
 if PY_37:
     all_tasks = getattr(asyncio, 'all_tasks')  # noqa
 
 
@@ -97,25 +100,22 @@
 coroutines = asyncio.coroutines
 old_debug = coroutines._DEBUG  # type: ignore
 
 # prevent "coroutine noop was never awaited" warning.
 coroutines._DEBUG = False  # type: ignore
 
 
-@asyncio.coroutine
-def noop(*args, **kwargs):  # type: ignore
-    return  # type: ignore
-
-
-async def noop2(*args: Any, **kwargs: Any) -> None:
+async def noop(*args: Any, **kwargs: Any) -> None:
     return
 
 
 coroutines._DEBUG = old_debug  # type: ignore
 
+json_re = re.compile(r'^application/(?:[\w.+-]+?\+)?json')
+
 
 class BasicAuth(namedtuple('BasicAuth', ['login', 'password', 'encoding'])):
     """Http basic authentication helper."""
 
     def __new__(cls, login: str,
                 password: str='',
                 encoding: str='latin1') -> 'BasicAuth':
@@ -249,33 +249,35 @@
                 *logins, password = auth_from_netrc
                 login = logins[0] if logins[0] else logins[-1]
                 auth = BasicAuth(cast(str, login), cast(str, password))
         ret[proto] = ProxyInfo(proxy, auth)
     return ret
 
 
-def current_task(loop: Optional[asyncio.AbstractEventLoop]=None) -> asyncio.Task:  # type: ignore  # noqa  # Return type is intentionally Generic here
+def current_task(
+        loop: Optional[asyncio.AbstractEventLoop]=None
+) -> 'asyncio.Task[Any]':
     if PY_37:
         return asyncio.current_task(loop=loop)  # type: ignore
     else:
-        return asyncio.Task.current_task(loop=loop)  # type: ignore
+        return asyncio.Task.current_task(loop=loop)
 
 
-def get_running_loop(
-    loop: Optional[asyncio.AbstractEventLoop]=None
-) -> asyncio.AbstractEventLoop:
-    if loop is None:
+if sys.version_info >= (3, 7):
+    create_task = asyncio.create_task
+else:
+    def create_task(coro: Awaitable[_T]) -> 'asyncio.Task[_T]':
         loop = asyncio.get_event_loop()
+        return loop.create_task(coro)
+
+
+def get_running_loop() -> asyncio.AbstractEventLoop:
+    loop = asyncio.get_event_loop()
     if not loop.is_running():
-        warnings.warn("The object should be created from async function",
-                      DeprecationWarning, stacklevel=3)
-        if loop.get_debug():
-            internal_logger.warning(
-                "The object should be created from async function",
-                stack_info=True)
+        raise RuntimeError("The object should be created from async function")
     return loop
 
 
 def isasyncgenfunction(obj: Any) -> bool:
     func = getattr(inspect, 'isasyncgenfunction', None)
     if func is not None:
         return func(obj)
@@ -365,14 +367,21 @@
             if key == 'filename':
                 lparams.append(('filename*', "utf-8''" + qval))
         sparams = '; '.join('='.join(pair) for pair in lparams)
         value = '; '.join((value, sparams))
     return value
 
 
+def is_expected_content_type(response_content_type: str,
+                             expected_content_type: str) -> bool:
+    if expected_content_type == 'application/json':
+        return json_re.match(response_content_type) is not None
+    return expected_content_type in response_content_type
+
+
 class reify:
     """Use as a class method decorator.  It operates almost exactly like
     the Python `@property` decorator, but it puts the result of the
     method it decorates into the instance dict after the first call,
     effectively replacing the function it decorates with an instance
     variable.  It is, in Python parlance, a data descriptor.
 
@@ -424,15 +433,15 @@
 _ipv6_regex = re.compile(_ipv6_pattern, flags=re.IGNORECASE)
 _ipv4_regexb = re.compile(_ipv4_pattern.encode('ascii'))
 _ipv6_regexb = re.compile(_ipv6_pattern.encode('ascii'), flags=re.IGNORECASE)
 
 
 def _is_ip_address(
         regex: Pattern[str], regexb: Pattern[bytes],
-        host: Optional[Union[str, bytes]])-> bool:
+        host: Optional[Union[str, bytes]]) -> bool:
     if host is None:
         return False
     if isinstance(host, str):
         return bool(regex.match(host))
     elif isinstance(host, (bytes, bytearray, memoryview)):
         return bool(regexb.match(host))
     else:
@@ -445,16 +454,25 @@
 
 
 def is_ip_address(
         host: Optional[Union[str, bytes, bytearray, memoryview]]) -> bool:
     return is_ipv4_address(host) or is_ipv6_address(host)
 
 
-_cached_current_datetime = None
-_cached_formatted_datetime = None
+def next_whole_second() -> datetime.datetime:
+    """Return current time rounded up to the next whole second."""
+    return (
+        datetime.datetime.now(
+            datetime.timezone.utc).replace(microsecond=0) +
+        datetime.timedelta(seconds=0)
+    )
+
+
+_cached_current_datetime = None  # type: Optional[int]
+_cached_formatted_datetime = ""
 
 
 def rfc822_formatted_time() -> str:
     global _cached_current_datetime
     global _cached_formatted_datetime
 
     now = int(time.time())
@@ -463,20 +481,20 @@
         # always English!
         # Tuples are constants stored in codeobject!
         _weekdayname = ("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")
         _monthname = ("",  # Dummy so we can use 1-based month numbers
                       "Jan", "Feb", "Mar", "Apr", "May", "Jun",
                       "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")
 
-        year, month, day, hh, mm, ss, wd, y, z = time.gmtime(now)  # type: ignore  # noqa
+        year, month, day, hh, mm, ss, wd, *tail = time.gmtime(now)
         _cached_formatted_datetime = "%s, %02d %3s %4d %02d:%02d:%02d GMT" % (
             _weekdayname[wd], day, _monthname[month], year, hh, mm, ss
         )
         _cached_current_datetime = now
-    return _cached_formatted_datetime  # type: ignore
+    return _cached_formatted_datetime
 
 
 def _weakref_handle(info):  # type: ignore
     ref, name = info
     ob = ref()
     if ob is not None:
         with suppress(Exception):
@@ -604,20 +622,20 @@
             self._cancel_handler = self._loop.call_at(
                 ceil(self._loop.time() + self._timeout), self._cancel_task)
         return self
 
 
 class HeadersMixin:
 
-    ATTRS = frozenset([
-        '_content_type', '_content_dict', '_stored_content_type'])
+    __slots__ = ('_content_type', '_content_dict', '_stored_content_type')
 
-    _content_type = None  # type: Optional[str]
-    _content_dict = None  # type: Optional[Dict[str, str]]
-    _stored_content_type = sentinel
+    def __init__(self) -> None:
+        self._content_type = None  # type: Optional[str]
+        self._content_dict = None  # type: Optional[Dict[str, str]]
+        self._stored_content_type = sentinel
 
     def _parse_content_type(self, raw: str) -> None:
         self._stored_content_type = raw
         if raw is None:
             # default value according to RFC 2616
             self._content_type = 'application/octet-stream'
             self._content_dict = {}
@@ -657,14 +675,15 @@
 
 
 def set_exception(fut: 'asyncio.Future[_T]', exc: BaseException) -> None:
     if not fut.done():
         fut.set_exception(exc)
 
 
+@final
 class ChainMapProxy(Mapping[str, Any]):
     __slots__ = ('_maps',)
 
     def __init__(self, maps: Iterable[Mapping[str, Any]]) -> None:
         self._maps = tuple(maps)
 
     def __init_subclass__(cls) -> None:
```

### Comparing `aiohttp-4.0.0a0/aiohttp/http_exceptions.py` & `aiohttp-4.0.0a1/aiohttp/http_exceptions.py`

 * *Files 12% similar despite different names*

```diff
@@ -27,25 +27,30 @@
                  message: str='',
                  headers: Optional[_CIMultiDict]=None) -> None:
         if code is not None:
             self.code = code
         self.headers = headers
         self.message = message
 
-        super().__init__("%s, message='%s'" % (self.code, message))
+    def __str__(self) -> str:
+        return "%s, message=%r" % (self.code, self.message)
+
+    def __repr__(self) -> str:
+        return "<%s: %s>" % (self.__class__.__name__, self)
 
 
 class BadHttpMessage(HttpProcessingError):
 
     code = 400
     message = 'Bad Request'
 
     def __init__(self, message: str, *,
                  headers: Optional[_CIMultiDict]=None) -> None:
         super().__init__(message=message, headers=headers)
+        self.args = (message,)
 
 
 class HttpBadRequest(BadHttpMessage):
 
     code = 400
     message = 'Bad Request'
 
@@ -70,29 +75,34 @@
 
     def __init__(self, line: str,
                  limit: str='Unknown',
                  actual_size: str='Unknown') -> None:
         super().__init__(
             "Got more than %s bytes (%s) when reading %s." % (
                 limit, actual_size, line))
+        self.args = (line, limit, actual_size)
 
 
 class InvalidHeader(BadHttpMessage):
 
     def __init__(self, hdr: Union[bytes, str]) -> None:
         if isinstance(hdr, bytes):
             hdr = hdr.decode('utf-8', 'surrogateescape')
         super().__init__('Invalid HTTP Header: {}'.format(hdr))
         self.hdr = hdr
+        self.args = (hdr,)
 
 
 class BadStatusLine(BadHttpMessage):
 
     def __init__(self, line: str='') -> None:
-        if not line:
+        if not isinstance(line, str):
             line = repr(line)
-        self.args = line,
+        self.args = (line,)
         self.line = line
 
+    __str__ = Exception.__str__
+    __repr__ = Exception.__repr__
+
 
 class InvalidURLError(BadHttpMessage):
     pass
```

### Comparing `aiohttp-4.0.0a0/aiohttp/http_parser.py` & `aiohttp-4.0.0a1/aiohttp/http_parser.py`

 * *Files 2% similar despite different names*

```diff
@@ -162,16 +162,16 @@
             raw_headers.append((bname, bvalue))
 
         return (CIMultiDictProxy(headers), tuple(raw_headers))
 
 
 class HttpParser(abc.ABC):
 
-    def __init__(self, protocol: Optional[BaseProtocol]=None,
-                 loop: Optional[asyncio.AbstractEventLoop]=None,
+    def __init__(self, protocol: BaseProtocol,
+                 loop: asyncio.AbstractEventLoop,
                  max_line_size: int=8190,
                  max_headers: int=32768,
                  max_field_size: int=8190,
                  timer: Optional[BaseTimerContext]=None,
                  code: Optional[int]=None,
                  method: Optional[str]=None,
                  readall: bool=False,
@@ -407,14 +407,21 @@
         # chunking
         te = headers.get(hdrs.TRANSFER_ENCODING)
         if te and 'chunked' in te.lower():
             chunked = True
 
         return (headers, raw_headers, close_conn, encoding, upgrade, chunked)
 
+    def set_upgraded(self, val: bool) -> None:
+        """Set connection upgraded (to websocket) mode.
+
+        :param bool val: new state.
+        """
+        self._upgraded = val
+
 
 class HttpRequestParser(HttpParser):
     """Read request status line. Exception .http_exceptions.BadStatusLine
     could be raised in case of any errors in status line.
     Returns RawRequestMessage.
     """
 
@@ -694,16 +701,34 @@
         self.encoding = encoding
         self._started_decoding = False
 
         if encoding == 'br':
             if not HAS_BROTLI:  # pragma: no cover
                 raise ContentEncodingError(
                     'Can not decode content-encoding: brotli (br). '
-                    'Please install `brotlipy`')
-            self.decompressor = brotli.Decompressor()
+                    'Please install `Brotli`')
+
+            class BrotliDecoder:
+                # Supports both 'brotlipy' and 'Brotli' packages
+                # since they share an import name. The top branches
+                # are for 'brotlipy' and bottom branches for 'Brotli'
+                def __init__(self) -> None:
+                    self._obj = brotli.Decompressor()
+
+                def decompress(self, data: bytes) -> bytes:
+                    if hasattr(self._obj, "decompress"):
+                        return self._obj.decompress(data)
+                    return self._obj.process(data)
+
+                def flush(self) -> bytes:
+                    if hasattr(self._obj, "flush"):
+                        return self._obj.flush()
+                    return b""
+
+            self.decompressor = BrotliDecoder()  # type: Any
         else:
             zlib_mode = (16 + zlib.MAX_WBITS
                          if encoding == 'gzip' else -zlib.MAX_WBITS)
             self.decompressor = zlib.decompressobj(wbits=zlib_mode)
 
     def set_exception(self, exc: BaseException) -> None:
         self.out.set_exception(exc)
```

### Comparing `aiohttp-4.0.0a0/aiohttp/http_websocket.py` & `aiohttp-4.0.0a1/aiohttp/http_websocket.py`

 * *Files 2% similar despite different names*

```diff
@@ -9,15 +9,14 @@
 import zlib
 from enum import IntEnum
 from struct import Struct
 from typing import Any, Callable, List, Optional, Tuple, Union
 
 from .base_protocol import BaseProtocol
 from .helpers import NO_EXTENSIONS
-from .log import ws_logger
 from .streams import DataQueue
 
 __all__ = ('WS_CLOSED_MESSAGE', 'WS_CLOSING_MESSAGE', 'WS_KEY',
            'WebSocketReader', 'WebSocketWriter', 'WSMessage',
            'WebSocketError', 'WSMsgType', 'WSCloseCode')
 
 
@@ -48,23 +47,14 @@
     CLOSE = 0x8
 
     # aiohttp specific types
     CLOSING = 0x100
     CLOSED = 0x101
     ERROR = 0x102
 
-    text = TEXT
-    binary = BINARY
-    ping = PING
-    pong = PONG
-    close = CLOSE
-    closing = CLOSING
-    closed = CLOSED
-    error = ERROR
-
 
 WS_KEY = b'258EAFA5-E914-47DA-95CA-C5AB0DC85B11'
 
 
 UNPACK_LEN2 = Struct('!H').unpack_from
 UNPACK_LEN3 = Struct('!Q').unpack_from
 UNPACK_CLOSE_CODE = Struct('!H').unpack
@@ -78,16 +68,16 @@
 
 _WSMessageBase = collections.namedtuple('_WSMessageBase',
                                         ['type', 'data', 'extra'])
 
 
 class WSMessage(_WSMessageBase):
 
-    def json(self, *,  # type: ignore
-             loads: Callable[[Any], Any]=json.loads) -> None:
+    def json(self, *,
+             loads: Callable[[Any], Any]=json.loads) -> Any:
         """Return parsed JSON data.
 
         .. versionadded:: 0.22
         """
         return loads(self.data)
 
 
@@ -96,15 +86,18 @@
 
 
 class WebSocketError(Exception):
     """WebSocket protocol parser error."""
 
     def __init__(self, code: int, message: str) -> None:
         self.code = code
-        super().__init__(message)
+        super().__init__(code, message)
+
+    def __str__(self) -> str:
+        return self.args[1]
 
 
 class WSHandshakeError(Exception):
     """WebSocket protocol handshake error."""
 
 
 native_byteorder = sys.byteorder
@@ -361,17 +354,20 @@
                         self._partial.extend(_WS_DEFLATE_TRAILING)
                         payload_merged = self._decompressobj.decompress(
                             self._partial, self._max_msg_size)
                         if self._decompressobj.unconsumed_tail:
                             left = len(self._decompressobj.unconsumed_tail)
                             raise WebSocketError(
                                 WSCloseCode.MESSAGE_TOO_BIG,
-                                "Decompressed message size exceeds limit {}".
-                                format(self._max_msg_size + left,
-                                       self._max_msg_size))
+                                "Decompressed message size {} exceeds limit {}"
+                                .format(
+                                    self._max_msg_size + left,
+                                    self._max_msg_size
+                                )
+                            )
                     else:
                         payload_merged = bytes(self._partial)
 
                     self._partial.clear()
 
                     if opcode == WSMsgType.TEXT:
                         try:
@@ -557,16 +553,16 @@
         self._limit = limit
         self._output_size = 0
         self._compressobj = None  # type: Any  # actually compressobj
 
     async def _send_frame(self, message: bytes, opcode: int,
                           compress: Optional[int]=None) -> None:
         """Send a frame over the websocket with message as its payload."""
-        if self._closing:
-            ws_logger.warning('websocket connection is closing.')
+        if self._closing and not (opcode & WSMsgType.CLOSE):
+            raise ConnectionResetError('Cannot write to closing transport')
 
         rsv = 0
 
         # Only compress larger packets (disabled)
         # Does small packet needs to be compressed?
         # if self.compress and opcode < 8 and len(message) > 124:
         if (compress or self.compress) and opcode < 8:
@@ -600,29 +596,34 @@
         else:
             header = PACK_LEN3(0x80 | rsv | opcode, 127 | mask_bit, msg_length)
         if use_mask:
             mask = self.randrange(0, 0xffffffff)
             mask = mask.to_bytes(4, 'big')
             message = bytearray(message)
             _websocket_mask(mask, message)
-            self.transport.write(header + mask + message)
+            self._write(header + mask + message)
             self._output_size += len(header) + len(mask) + len(message)
         else:
             if len(message) > MSG_SIZE:
-                self.transport.write(header)
-                self.transport.write(message)
+                self._write(header)
+                self._write(message)
             else:
-                self.transport.write(header + message)
+                self._write(header + message)
 
             self._output_size += len(header) + len(message)
 
         if self._output_size > self._limit:
             self._output_size = 0
             await self.protocol._drain_helper()
 
+    def _write(self, data: bytes) -> None:
+        if self.transport is None or self.transport.is_closing():
+            raise ConnectionResetError('Cannot write to closing transport')
+        self.transport.write(data)
+
     async def pong(self, message: bytes=b'') -> None:
         """Send pong message."""
         if isinstance(message, str):
             message = message.encode('utf-8')
         await self._send_frame(message, WSMsgType.PONG)
 
     async def ping(self, message: bytes=b'') -> None:
```

### Comparing `aiohttp-4.0.0a0/aiohttp/http_writer.py` & `aiohttp-4.0.0a1/aiohttp/http_writer.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/aiohttp/locks.py` & `aiohttp-4.0.0a1/aiohttp/locks.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/aiohttp/multipart.py` & `aiohttp-4.0.0a1/aiohttp/multipart.py`

 * *Files 3% similar despite different names*

```diff
@@ -15,15 +15,14 @@
     List,
     Mapping,
     Optional,
     Sequence,
     Tuple,
     Type,
     Union,
-    cast,
 )
 from urllib.parse import parse_qsl, unquote, urlencode
 
 from multidict import CIMultiDict, CIMultiDictProxy, MultiMapping  # noqa
 
 from .hdrs import (
     CONTENT_DISPOSITION,
@@ -191,39 +190,46 @@
             encoding, _, value = value.split("'", 2)
             encoding = encoding or 'utf-8'
             return unquote(value, encoding, 'strict')
         return value
 
 
 class MultipartResponseWrapper:
-    """Wrapper around the MultipartBodyReader.
+    """Wrapper around the MultipartReader.
 
     It takes care about
     underlying connection and close it when it needs in.
     """
 
-    def __init__(self, resp: 'ClientResponse', stream: Any) -> None:
-        # TODO: add strong annotation to stream
+    def __init__(
+        self,
+        resp: 'ClientResponse',
+        stream: 'MultipartReader',
+    ) -> None:
         self.resp = resp
         self.stream = stream
 
     def __aiter__(self) -> 'MultipartResponseWrapper':
         return self
 
-    async def __anext__(self) -> Any:
+    async def __anext__(
+        self,
+    ) -> Union['MultipartReader', 'BodyPartReader']:
         part = await self.next()
         if part is None:
             raise StopAsyncIteration  # NOQA
         return part
 
     def at_eof(self) -> bool:
         """Returns True when all response data had been read."""
         return self.resp.content.at_eof()
 
-    async def next(self) -> Any:
+    async def next(
+        self,
+    ) -> Optional[Union['MultipartReader', 'BodyPartReader']]:
         """Emits next multipart reader object."""
         item = await self.stream.next()
         if self.stream.at_eof():
             await self.release()
         return item
 
     async def release(self) -> None:
@@ -233,46 +239,52 @@
 
 
 class BodyPartReader:
     """Multipart reader for single body part."""
 
     chunk_size = 8192
 
-    def __init__(self, boundary: bytes,
-                 headers: Mapping[str, Optional[str]],
-                 content: StreamReader) -> None:
+    def __init__(
+        self,
+        boundary: bytes,
+        headers: 'CIMultiDictProxy[str]',
+        content: StreamReader,
+        *,
+        _newline: bytes = b'\r\n'
+    ) -> None:
         self.headers = headers
         self._boundary = boundary
+        self._newline = _newline
         self._content = content
         self._at_eof = False
         length = self.headers.get(CONTENT_LENGTH, None)
         self._length = int(length) if length is not None else None
         self._read_bytes = 0
         # TODO: typeing.Deque is not supported by Python 3.5
         self._unread = deque()  # type: Any
         self._prev_chunk = None  # type: Optional[bytes]
         self._content_eof = 0
         self._cache = {}  # type: Dict[str, Any]
 
     def __aiter__(self) -> 'BodyPartReader':
         return self
 
-    async def __anext__(self) -> Any:
+    async def __anext__(self) -> bytes:
         part = await self.next()
         if part is None:
             raise StopAsyncIteration  # NOQA
         return part
 
-    async def next(self) -> Any:
+    async def next(self) -> Optional[bytes]:
         item = await self.read()
         if not item:
             return None
         return item
 
-    async def read(self, *, decode: bool=False) -> Any:
+    async def read(self, *, decode: bool=False) -> bytes:
         """Reads body part data.
 
         decode: Decodes data following by encoding
                 method from Content-Encoding header. If it missed
                 data remains untouched
         """
         if self._at_eof:
@@ -292,20 +304,45 @@
         if self._at_eof:
             return b''
         if self._length:
             chunk = await self._read_chunk_from_length(size)
         else:
             chunk = await self._read_chunk_from_stream(size)
 
+        # For the case of base64 data, we must read a fragment of size with a
+        # remainder of 0 by dividing by 4 for string without symbols \n or \r
+        encoding = self.headers.get(CONTENT_TRANSFER_ENCODING)
+        if encoding and encoding.lower() == 'base64':
+            stripped_chunk = b''.join(chunk.split())
+            remainder = len(stripped_chunk) % 4
+
+            while remainder != 0 and not self.at_eof():
+                over_chunk_size = 4 - remainder
+                over_chunk = b''
+
+                if self._prev_chunk:
+                    over_chunk = self._prev_chunk[:over_chunk_size]
+                    self._prev_chunk = self._prev_chunk[len(over_chunk):]
+
+                if len(over_chunk) != over_chunk_size:
+                    over_chunk += await self._content.read(4 - len(over_chunk))
+
+                if not over_chunk:
+                    self._at_eof = True
+
+                stripped_chunk += b''.join(over_chunk.split())
+                chunk += over_chunk
+                remainder = len(stripped_chunk) % 4
+
         self._read_bytes += len(chunk)
         if self._read_bytes == self._length:
             self._at_eof = True
         if self._at_eof:
-            clrf = await self._content.readline()
-            assert b'\r\n' == clrf, \
+            newline = await self._content.readline()
+            assert newline == self._newline, \
                 'reader did not read all the data or it is malformed'
         return chunk
 
     async def _read_chunk_from_length(self, size: int) -> bytes:
         # Reads body part content chunk of the specified size.
         # The body part must has Content-Length header with proper value.
         assert self._length is not None, \
@@ -324,30 +361,35 @@
             self._prev_chunk = await self._content.read(size)
 
         chunk = await self._content.read(size)
         self._content_eof += int(self._content.at_eof())
         assert self._content_eof < 3, "Reading after EOF"
         assert self._prev_chunk is not None
         window = self._prev_chunk + chunk
-        sub = b'\r\n' + self._boundary
+
+        intermeditate_boundary = self._newline + self._boundary
+
         if first_chunk:
-            idx = window.find(sub)
+            pos = 0
         else:
-            idx = window.find(sub, max(0, len(self._prev_chunk) - len(sub)))
+            pos = max(0, len(self._prev_chunk) - len(intermeditate_boundary))
+
+        idx = window.find(intermeditate_boundary, pos)
         if idx >= 0:
             # pushing boundary back to content
             with warnings.catch_warnings():
                 warnings.filterwarnings("ignore",
                                         category=DeprecationWarning)
                 self._content.unread_data(window[idx:])
             if size > idx:
                 self._prev_chunk = self._prev_chunk[:idx]
             chunk = window[len(self._prev_chunk):idx]
             if not chunk:
                 self._at_eof = True
+
         result = self._prev_chunk
         self._prev_chunk = chunk
         return result
 
     async def readline(self) -> bytes:
         """Reads body part by line by line."""
         if self._at_eof:
@@ -368,15 +410,16 @@
             if sline == boundary or sline == last_boundary:
                 self._at_eof = True
                 self._unread.append(line)
                 return b''
         else:
             next_line = await self._content.readline()
             if next_line.startswith(self._boundary):
-                line = line[:-2]  # strip CRLF but only once
+                # strip newline but only once
+                line = line[:-len(self._newline)]
             self._unread.append(next_line)
 
         return line
 
     async def release(self) -> None:
         """Like read(), but reads all the data to the void."""
         if self._at_eof:
@@ -388,15 +431,17 @@
         """Like read(), but assumes that body part contains text data."""
         data = await self.read(decode=True)
         # see https://www.w3.org/TR/html5/forms.html#multipart/form-data-encoding-algorithm # NOQA
         # and https://dvcs.w3.org/hg/xhr/raw-file/tip/Overview.html#dom-xmlhttprequest-send # NOQA
         encoding = encoding or self.get_charset(default='utf-8')
         return data.decode(encoding)
 
-    async def json(self, *, encoding: Optional[str]=None) -> Any:
+    async def json(self,
+                   *,
+                   encoding: Optional[str]=None) -> Optional[Dict[str, Any]]:
         """Like read(), but assumes that body parts contains JSON data."""
         data = await self.read(decode=True)
         if not data:
             return None
         encoding = encoding or self.get_charset(default='utf-8')
         return json.loads(data.decode(encoding))
 
@@ -427,27 +472,27 @@
         if CONTENT_TRANSFER_ENCODING in self.headers:
             data = self._decode_content_transfer(data)
         if CONTENT_ENCODING in self.headers:
             return self._decode_content(data)
         return data
 
     def _decode_content(self, data: bytes) -> bytes:
-        encoding = cast(str, self.headers[CONTENT_ENCODING]).lower()
+        encoding = self.headers.get(CONTENT_ENCODING, '').lower()
 
         if encoding == 'deflate':
             return zlib.decompress(data, -zlib.MAX_WBITS)
         elif encoding == 'gzip':
             return zlib.decompress(data, 16 + zlib.MAX_WBITS)
         elif encoding == 'identity':
             return data
         else:
             raise RuntimeError('unknown content encoding: {}'.format(encoding))
 
     def _decode_content_transfer(self, data: bytes) -> bytes:
-        encoding = cast(str, self.headers[CONTENT_TRANSFER_ENCODING]).lower()
+        encoding = self.headers.get(CONTENT_TRANSFER_ENCODING, '').lower()
 
         if encoding == 'base64':
             return base64.b64decode(data)
         elif encoding == 'quoted-printable':
             return binascii.a2b_qp(data)
         elif encoding in ('binary', '8bit', '7bit'):
             return data
@@ -512,93 +557,115 @@
     response_wrapper_cls = MultipartResponseWrapper
     #: Multipart reader class, used to handle multipart/* body parts.
     #: None points to type(self)
     multipart_reader_cls = None
     #: Body part reader class for non multipart/* content types.
     part_reader_cls = BodyPartReader
 
-    def __init__(self, headers: Mapping[str, str],
-                 content: StreamReader) -> None:
+    def __init__(
+        self,
+        headers: Mapping[str, str],
+        content: StreamReader,
+        *,
+        _newline: bytes = b'\r\n'
+    ) -> None:
         self.headers = headers
         self._boundary = ('--' + self._get_boundary()).encode()
+        self._newline = _newline
         self._content = content
-        self._last_part = None
+        self._last_part = None  # type: Optional[Union['MultipartReader', BodyPartReader]]  # noqa
         self._at_eof = False
         self._at_bof = True
         self._unread = []  # type: List[bytes]
 
     def __aiter__(self) -> 'MultipartReader':
         return self
 
-    async def __anext__(self) -> Any:
+    async def __anext__(
+        self,
+    ) -> Union['MultipartReader', BodyPartReader]:
         part = await self.next()
         if part is None:
             raise StopAsyncIteration  # NOQA
         return part
 
     @classmethod
-    def from_response(cls, response: 'ClientResponse') -> Any:
+    def from_response(
+        cls,
+        response: 'ClientResponse',
+    ) -> MultipartResponseWrapper:
         """Constructs reader instance from HTTP response.
 
         :param response: :class:`~aiohttp.client.ClientResponse` instance
         """
         obj = cls.response_wrapper_cls(response, cls(response.headers,
                                                      response.content))
         return obj
 
     def at_eof(self) -> bool:
         """Returns True if the final boundary was reached or
         False otherwise.
         """
         return self._at_eof
 
-    async def next(self) -> Any:
+    async def next(
+        self,
+    ) -> Optional[Union['MultipartReader', BodyPartReader]]:
         """Emits the next multipart body part."""
         # So, if we're at BOF, we need to skip till the boundary.
         if self._at_eof:
-            return
+            return None
         await self._maybe_release_last_part()
         if self._at_bof:
             await self._read_until_first_boundary()
             self._at_bof = False
         else:
             await self._read_boundary()
         if self._at_eof:  # we just read the last boundary, nothing to do there
-            return
+            return None
         self._last_part = await self.fetch_next_part()
         return self._last_part
 
     async def release(self) -> None:
         """Reads all the body parts to the void till the final boundary."""
         while not self._at_eof:
             item = await self.next()
             if item is None:
                 break
             await item.release()
 
-    async def fetch_next_part(self) -> Any:
+    async def fetch_next_part(
+        self,
+    ) -> Union['MultipartReader', BodyPartReader]:
         """Returns the next body part reader."""
         headers = await self._read_headers()
         return self._get_part_reader(headers)
 
-    def _get_part_reader(self, headers: 'CIMultiDictProxy[str]') -> Any:
+    def _get_part_reader(
+        self,
+        headers: 'CIMultiDictProxy[str]',
+    ) -> Union['MultipartReader', BodyPartReader]:
         """Dispatches the response by the `Content-Type` header, returning
         suitable reader instance.
 
         :param dict headers: Response headers
         """
         ctype = headers.get(CONTENT_TYPE, '')
         mimetype = parse_mimetype(ctype)
 
         if mimetype.type == 'multipart':
             if self.multipart_reader_cls is None:
                 return type(self)(headers, self._content)
-            return self.multipart_reader_cls(headers, self._content)
+            return self.multipart_reader_cls(
+                headers, self._content, _newline=self._newline
+            )
         else:
-            return self.part_reader_cls(self._boundary, headers, self._content)
+            return self.part_reader_cls(
+                self._boundary, headers, self._content, _newline=self._newline
+            )
 
     def _get_boundary(self) -> str:
         mimetype = parse_mimetype(self.headers[CONTENT_TYPE])
 
         assert mimetype.type == 'multipart', (
             'multipart/* content type expected'
         )
@@ -621,18 +688,30 @@
 
     async def _read_until_first_boundary(self) -> None:
         while True:
             chunk = await self._readline()
             if chunk == b'':
                 raise ValueError("Could not find starting boundary %r"
                                  % (self._boundary))
+            newline = None
+            end_boundary = self._boundary + b'--'
+            if chunk.startswith(end_boundary):
+                _, newline = chunk.split(end_boundary, 1)
+            elif chunk.startswith(self._boundary):
+                _, newline = chunk.split(self._boundary, 1)
+            if newline is not None:
+                assert newline in (b'\r\n', b'\n'), (newline,
+                                                     chunk,
+                                                     self._boundary)
+                self._newline = newline
+
             chunk = chunk.rstrip()
             if chunk == self._boundary:
                 return
-            elif chunk == self._boundary + b'--':
+            elif chunk == end_boundary:
                 self._at_eof = True
                 return
 
     async def _read_boundary(self) -> None:
         chunk = (await self._readline()).rstrip()
         if chunk == self._boundary:
             pass
@@ -714,14 +793,17 @@
 
     def __iter__(self) -> Iterator[_Part]:
         return iter(self._parts)
 
     def __len__(self) -> int:
         return len(self._parts)
 
+    def __bool__(self) -> bool:
+        return True
+
     _valid_tchar_regex = re.compile(br"\A[!#$%&'*+\-.^_`|~\w]+\Z")
     _invalid_qdtext_char_regex = re.compile(br"[\x00-\x08\x0A-\x1F\x7F]")
 
     @property
     def _boundary_value(self) -> str:
         """Wrap boundary parameter value in quotes, if necessary.
 
@@ -756,15 +838,15 @@
     @property
     def boundary(self) -> str:
         return self._boundary.decode('ascii')
 
     def append(
             self,
             obj: Any,
-            headers: Optional['MultiMapping[str]']=None
+            headers: Optional[MultiMapping[str]]=None
     ) -> Payload:
         if headers is None:
             headers = CIMultiDict()
 
         if isinstance(obj, Payload):
             obj.headers.update(headers)
             return self.append_payload(obj)
@@ -775,23 +857,28 @@
                 raise TypeError('Cannot create payload from %r' % obj)
             else:
                 return self.append_payload(payload)
 
     def append_payload(self, payload: Payload) -> Payload:
         """Adds a new body part to multipart writer."""
         # compression
-        encoding = payload.headers.get(CONTENT_ENCODING, '').lower()  # type: Optional[str]  # noqa
+        encoding = payload.headers.get(
+            CONTENT_ENCODING,
+            '',
+        ).lower()  # type: Optional[str]
         if encoding and encoding not in ('deflate', 'gzip', 'identity'):
             raise RuntimeError('unknown content encoding: {}'.format(encoding))
         if encoding == 'identity':
             encoding = None
 
         # te encoding
         te_encoding = payload.headers.get(
-            CONTENT_TRANSFER_ENCODING, '').lower()  # type: Optional[str]  # noqa
+            CONTENT_TRANSFER_ENCODING,
+            '',
+        ).lower()  # type: Optional[str]
         if te_encoding not in ('', 'base64', 'quoted-printable', 'binary'):
             raise RuntimeError('unknown content transfer encoding: {}'
                                ''.format(te_encoding))
         if te_encoding == 'binary':
             te_encoding = None
 
         # size
@@ -801,27 +888,27 @@
 
         self._parts.append((payload, encoding, te_encoding))  # type: ignore
         return payload
 
     def append_json(
             self,
             obj: Any,
-            headers: Optional['MultiMapping[str]']=None
+            headers: Optional[MultiMapping[str]]=None
     ) -> Payload:
         """Helper to append JSON part."""
         if headers is None:
             headers = CIMultiDict()
 
         return self.append_payload(JsonPayload(obj, headers=headers))
 
     def append_form(
             self,
             obj: Union[Sequence[Tuple[str, str]],
                        Mapping[str, str]],
-            headers: Optional['MultiMapping[str]']=None
+            headers: Optional[MultiMapping[str]]=None
     ) -> Payload:
         """Helper to append form urlencoded part."""
         assert isinstance(obj, (Sequence, Mapping))
 
         if headers is None:
             headers = CIMultiDict()
 
@@ -832,17 +919,14 @@
         return self.append_payload(
             StringPayload(data, headers=headers,
                           content_type='application/x-www-form-urlencoded'))
 
     @property
     def size(self) -> Optional[int]:
         """Size of the payload."""
-        if not self._parts:
-            return 0
-
         total = 0
         for part, encoding, te_encoding in self._parts:
             if encoding or te_encoding or part.size is None:
                 return None
 
             total += int(
                 2 + len(self._boundary) + 2 +  # b'--'+self._boundary+b'\r\n'
@@ -852,17 +936,14 @@
 
         total += 2 + len(self._boundary) + 4  # b'--'+self._boundary+b'--\r\n'
         return total
 
     async def write(self, writer: Any,
                     close_boundary: bool=True) -> None:
         """Write body."""
-        if not self._parts:
-            return
-
         for part, encoding, te_encoding in self._parts:
             await writer.write(b'--' + self._boundary + b'\r\n')
             await writer.write(part._binary_headers)
 
             if encoding or te_encoding:
                 w = MultipartPayloadWriter(writer)
                 if encoding:
```

### Comparing `aiohttp-4.0.0a0/aiohttp/payload.py` & `aiohttp-4.0.0a1/aiohttp/payload.py`

 * *Files 0% similar despite different names*

```diff
@@ -203,15 +203,15 @@
 class BytesPayload(Payload):
 
     def __init__(self,
                  value: ByteString,
                  *args: Any,
                  **kwargs: Any) -> None:
         if not isinstance(value, (bytes, bytearray, memoryview)):
-            raise TypeError("value argument must be byte-ish, not (!r)"
+            raise TypeError("value argument must be byte-ish, not {!r}"
                             .format(type(value)))
 
         if 'content_type' not in kwargs:
             kwargs['content_type'] = 'application/octet-stream'
 
         super().__init__(value, *args, **kwargs)
```

### Comparing `aiohttp-4.0.0a0/aiohttp/pytest_plugin.py` & `aiohttp-4.0.0a1/aiohttp/pytest_plugin.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 import asyncio
 import contextlib
 import warnings
-from collections.abc import Callable
 
 import pytest
 
-from aiohttp.helpers import isasyncgenfunction
+from aiohttp.helpers import PY_37, isasyncgenfunction
 from aiohttp.web import Application
 
 from .test_utils import (
     BaseTestServer,
     RawTestServer,
     TestClient,
     TestServer,
@@ -157,15 +156,16 @@
 
 def pytest_pyfunc_call(pyfuncitem):  # type: ignore
     """
     Run coroutines in an event loop instead of a normal function call.
     """
     fast = pyfuncitem.config.getoption("--aiohttp-fast")
     if asyncio.iscoroutinefunction(pyfuncitem.function):
-        existing_loop = pyfuncitem.funcargs.get('loop', None)
+        existing_loop = pyfuncitem.funcargs.get('proactor_loop')\
+            or pyfuncitem.funcargs.get('loop', None)
         with _runtime_warning_context():
             with _passthrough_loop_context(existing_loop, fast=fast) as _loop:
                 testargs = {arg: pyfuncitem.funcargs[arg]
                             for arg in pyfuncitem._fixtureinfo.argnames}
                 _loop.run_until_complete(pyfuncitem.obj(**testargs))
 
         return True
@@ -213,18 +213,25 @@
         if loop_debug:
             _loop.set_debug(True)  # pragma: no cover
         asyncio.set_event_loop(_loop)
         yield _loop
 
 
 @pytest.fixture
-def unused_port(aiohttp_unused_port):  # type: ignore # pragma: no cover
-    warnings.warn("Deprecated, use aiohttp_unused_port fixture instead",
-                  DeprecationWarning)
-    return aiohttp_unused_port
+def proactor_loop():  # type: ignore
+    if not PY_37:
+        policy = asyncio.get_event_loop_policy()
+        policy._loop_factory = asyncio.ProactorEventLoop  # type: ignore
+    else:
+        policy = asyncio.WindowsProactorEventLoopPolicy()  # type: ignore
+        asyncio.set_event_loop_policy(policy)
+
+    with loop_context(policy.new_event_loop) as _loop:
+        asyncio.set_event_loop(_loop)
+        yield _loop
 
 
 @pytest.fixture
 def aiohttp_unused_port():  # type: ignore
     """Return a port that is unused on the current host."""
     return _unused_port
 
@@ -235,103 +242,74 @@
 
     aiohttp_server(app, **kwargs)
     """
     servers = []
 
     async def go(app, *, port=None, **kwargs):  # type: ignore
         server = TestServer(app, port=port)
-        await server.start_server(loop=loop, **kwargs)
+        await server.start_server(**kwargs)
         servers.append(server)
         return server
 
     yield go
 
     async def finalize():  # type: ignore
         while servers:
             await servers.pop().close()
 
     loop.run_until_complete(finalize())
 
 
 @pytest.fixture
-def test_server(aiohttp_server):  # type: ignore  # pragma: no cover
-    warnings.warn("Deprecated, use aiohttp_server fixture instead",
-                  DeprecationWarning)
-    return aiohttp_server
-
-
-@pytest.fixture
 def aiohttp_raw_server(loop):  # type: ignore
     """Factory to create a RawTestServer instance, given a web handler.
 
     aiohttp_raw_server(handler, **kwargs)
     """
     servers = []
 
     async def go(handler, *, port=None, **kwargs):  # type: ignore
         server = RawTestServer(handler, port=port)
-        await server.start_server(loop=loop, **kwargs)
+        await server.start_server(**kwargs)
         servers.append(server)
         return server
 
     yield go
 
     async def finalize():  # type: ignore
         while servers:
             await servers.pop().close()
 
     loop.run_until_complete(finalize())
 
 
 @pytest.fixture
-def raw_test_server(aiohttp_raw_server):  # type: ignore  # pragma: no cover
-    warnings.warn("Deprecated, use aiohttp_raw_server fixture instead",
-                  DeprecationWarning)
-    return aiohttp_raw_server
-
-
-@pytest.fixture
 def aiohttp_client(loop):  # type: ignore
     """Factory to create a TestClient instance.
 
     aiohttp_client(app, **kwargs)
     aiohttp_client(server, **kwargs)
     aiohttp_client(raw_server, **kwargs)
     """
     clients = []
 
-    async def go(__param, *args, server_kwargs=None, **kwargs):  # type: ignore
-
-        if (isinstance(__param, Callable) and  # type: ignore
-                not isinstance(__param, (Application, BaseTestServer))):
-            __param = __param(loop, *args, **kwargs)
-            kwargs = {}
-        else:
-            assert not args, "args should be empty"
-
+    async def go(__param, *, server_kwargs=None, **kwargs):  # type: ignore
         if isinstance(__param, Application):
             server_kwargs = server_kwargs or {}
-            server = TestServer(__param, loop=loop, **server_kwargs)
-            client = TestClient(server, loop=loop, **kwargs)
+            server = TestServer(__param, **server_kwargs)
+            client = TestClient(server, **kwargs)
         elif isinstance(__param, BaseTestServer):
-            client = TestClient(__param, loop=loop, **kwargs)
+            client = TestClient(__param, **kwargs)
         else:
             raise ValueError("Unknown argument type: %r" % type(__param))
 
         await client.start_server()
         clients.append(client)
         return client
 
     yield go
 
     async def finalize():  # type: ignore
         while clients:
             await clients.pop().close()
 
     loop.run_until_complete(finalize())
-
-
-@pytest.fixture
-def test_client(aiohttp_client):  # type: ignore  # pragma: no cover
-    warnings.warn("Deprecated, use aiohttp_client fixture instead",
-                  DeprecationWarning)
-    return aiohttp_client
```

### Comparing `aiohttp-4.0.0a0/aiohttp/resolver.py` & `aiohttp-4.0.0a1/aiohttp/resolver.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,10 +1,9 @@
-import asyncio
 import socket
-from typing import Any, Dict, List, Optional
+from typing import Any, Dict, List
 
 from .abc import AbstractResolver
 from .helpers import get_running_loop
 
 __all__ = ('ThreadedResolver', 'AsyncResolver', 'DefaultResolver')
 
 try:
@@ -17,16 +16,16 @@
 
 
 class ThreadedResolver(AbstractResolver):
     """Use Executor for synchronous getaddrinfo() calls, which defaults to
     concurrent.futures.ThreadPoolExecutor.
     """
 
-    def __init__(self, loop: Optional[asyncio.AbstractEventLoop]=None) -> None:
-        self._loop = get_running_loop(loop)
+    def __init__(self) -> None:
+        self._loop = get_running_loop()
 
     async def resolve(self, host: str, port: int=0,
                       family: int=socket.AF_INET) -> List[Dict[str, Any]]:
         infos = await self._loop.getaddrinfo(
             host, port, type=socket.SOCK_STREAM, family=family)
 
         hosts = []
@@ -42,25 +41,20 @@
     async def close(self) -> None:
         pass
 
 
 class AsyncResolver(AbstractResolver):
     """Use the `aiodns` package to make asynchronous DNS lookups"""
 
-    def __init__(self, loop: Optional[asyncio.AbstractEventLoop]=None,
-                 *args: Any, **kwargs: Any) -> None:
+    def __init__(self, *args: Any, **kwargs: Any) -> None:
         if aiodns is None:
             raise RuntimeError("Resolver requires aiodns library")
 
-        self._loop = get_running_loop(loop)
-        self._resolver = aiodns.DNSResolver(*args, loop=loop, **kwargs)
-
-        if not hasattr(self._resolver, 'gethostbyname'):
-            # aiodns 1.1 is not available, fallback to DNSResolver.query
-            self.resolve = self._resolve_with_query  # type: ignore
+        self._loop = get_running_loop()
+        self._resolver = aiodns.DNSResolver(*args, loop=self._loop, **kwargs)
 
     async def resolve(self, host: str, port: int=0,
                       family: int=socket.AF_INET) -> List[Dict[str, Any]]:
         try:
             resp = await self._resolver.gethostbyname(host, family)
         except aiodns.error.DNSError as exc:
             msg = exc.args[1] if len(exc.args) >= 1 else "DNS lookup failed"
@@ -73,40 +67,13 @@
                  'family': family, 'proto': 0,
                  'flags': socket.AI_NUMERICHOST})
 
         if not hosts:
             raise OSError("DNS lookup failed")
 
         return hosts
-
-    async def _resolve_with_query(
-            self, host: str, port: int=0,
-            family: int=socket.AF_INET) -> List[Dict[str, Any]]:
-        if family == socket.AF_INET6:
-            qtype = 'AAAA'
-        else:
-            qtype = 'A'
-
-        try:
-            resp = await self._resolver.query(host, qtype)
-        except aiodns.error.DNSError as exc:
-            msg = exc.args[1] if len(exc.args) >= 1 else "DNS lookup failed"
-            raise OSError(msg) from exc
-
-        hosts = []
-        for rr in resp:
-            hosts.append(
-                {'hostname': host,
-                 'host': rr.host, 'port': port,
-                 'family': family, 'proto': 0,
-                 'flags': socket.AI_NUMERICHOST})
-
-        if not hosts:
-            raise OSError("DNS lookup failed")
-
-        return hosts
 
     async def close(self) -> None:
         return self._resolver.cancel()
 
 
 DefaultResolver = AsyncResolver if aiodns_default else ThreadedResolver
```

### Comparing `aiohttp-4.0.0a0/aiohttp/signals.py` & `aiohttp-4.0.0a1/aiohttp/signals.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/aiohttp/streams.py` & `aiohttp-4.0.0a1/aiohttp/streams.py`

 * *Files 5% similar despite different names*

```diff
@@ -9,15 +9,14 @@
 from .log import internal_logger
 
 try:  # pragma: no cover
     from typing import Deque  # noqa
 except ImportError:
     from typing_extensions import Deque  # noqa
 
-
 __all__ = (
     'EMPTY_PAYLOAD', 'EofStream', 'StreamReader', 'DataQueue',
     'FlowControlDataQueue')
 
 DEFAULT_LIMIT = 2 ** 16
 
 _T = TypeVar('_T')
@@ -105,29 +104,29 @@
     """
 
     total_bytes = 0
 
     def __init__(self, protocol: BaseProtocol,
                  *, limit: int=DEFAULT_LIMIT,
                  timer: Optional[BaseTimerContext]=None,
-                 loop: Optional[asyncio.AbstractEventLoop]=None) -> None:
+                 loop: asyncio.AbstractEventLoop) -> None:
         self._protocol = protocol
         self._low_water = limit
         self._high_water = limit * 2
         if loop is None:
             loop = asyncio.get_event_loop()
         self._loop = loop
         self._size = 0
         self._cursor = 0
         self._http_chunk_splits = None  # type: Optional[List[int]]
         self._buffer = collections.deque()  # type: Deque[bytes]
         self._buffer_offset = 0
         self._eof = False
-        self._waiter = None  # type: Optional[asyncio.Future[bool]]
-        self._eof_waiter = None  # type: Optional[asyncio.Future[bool]]
+        self._waiter = None  # type: Optional[asyncio.Future[None]]
+        self._eof_waiter = None  # type: Optional[asyncio.Future[None]]
         self._exception = None  # type: Optional[BaseException]
         self._timer = timer
         self._eof_callbacks = []  # type: List[Callable[[], None]]
 
     def __repr__(self) -> str:
         info = [self.__class__.__name__]
         if self._size:
@@ -152,16 +151,16 @@
         waiter = self._waiter
         if waiter is not None:
             self._waiter = None
             set_exception(waiter, exc)
 
         waiter = self._eof_waiter
         if waiter is not None:
-            set_exception(waiter, exc)
             self._eof_waiter = None
+            set_exception(waiter, exc)
 
     def on_eof(self, callback: Callable[[], None]) -> None:
         if self._eof:
             try:
                 callback()
             except Exception:
                 internal_logger.exception('Exception in eof callback')
@@ -170,20 +169,20 @@
 
     def feed_eof(self) -> None:
         self._eof = True
 
         waiter = self._waiter
         if waiter is not None:
             self._waiter = None
-            set_result(waiter, True)
+            set_result(waiter, None)
 
         waiter = self._eof_waiter
         if waiter is not None:
             self._eof_waiter = None
-            set_result(waiter, True)
+            set_result(waiter, None)
 
         for cb in self._eof_callbacks:
             try:
                 cb()
             except Exception:
                 internal_logger.exception('Exception in eof callback')
 
@@ -236,15 +235,15 @@
         self._size += len(data)
         self._buffer.append(data)
         self.total_bytes += len(data)
 
         waiter = self._waiter
         if waiter is not None:
             self._waiter = None
-            set_result(waiter, False)
+            set_result(waiter, None)
 
         if (self._size > self._high_water and
                 not self._protocol._reading_paused):
             self._protocol.pause_reading()
 
     def begin_http_chunk_receiving(self) -> None:
         if self._http_chunk_splits is None:
@@ -257,15 +256,15 @@
         if self._http_chunk_splits is None:
             raise RuntimeError("Called end_chunk_receiving without calling "
                                "begin_chunk_receiving first")
 
         # self._http_chunk_splits contains logical byte offsets from start of
         # the body transfer. Each offset is the offset of the end of a chunk.
         # "Logical" means bytes, accessible for a user.
-        # If no chunks containig logical data were received, current position
+        # If no chunks containing logical data were received, current position
         # is difinitely zero.
         pos = self._http_chunk_splits[-1] if self._http_chunk_splits else 0
 
         if self.total_bytes == pos:
             # We should not add empty chunks here. So we check for that.
             # Note, when chunked + gzip is used, we can receive a chunk
             # of compressed data, but that data may not be enough for gzip FSM
@@ -275,15 +274,15 @@
 
         self._http_chunk_splits.append(self.total_bytes)
 
         # wake up readchunk when end of http chunk received
         waiter = self._waiter
         if waiter is not None:
             self._waiter = None
-            set_result(waiter, False)
+            set_result(waiter, None)
 
     async def _wait(self, func_name: str) -> None:
         # StreamReader uses a future to link the protocol feed_data() method
         # to a read coroutine. Running two read coroutines at the same time
         # would have an unexpected behaviour. It would not possible to know
         # which coroutine would get the next data.
         if self._waiter is not None:
@@ -330,26 +329,14 @@
 
         return b''.join(line)
 
     async def read(self, n: int=-1) -> bytes:
         if self._exception is not None:
             raise self._exception
 
-        # migration problem; with DataQueue you have to catch
-        # EofStream exception, so common way is to run payload.read() inside
-        # infinite loop. what can cause real infinite loop with StreamReader
-        # lets keep this code one major release.
-        if __debug__:
-            if self._eof and not self._buffer:
-                self._eof_counter = getattr(self, '_eof_counter', 0) + 1
-                if self._eof_counter > 5:
-                    internal_logger.warning(
-                        'Multiple access to StreamReader in eof state, '
-                        'might be infinite loop.', stack_info=True)
-
         if not n:
             return b''
 
         if n < 0:
             # This used to just loop creating a new waiter hoping to
             # collect everything in self._buffer, but that would
             # deadlock if the subprocess sends more than self.limit
@@ -358,70 +345,74 @@
             while True:
                 block = await self.readany()
                 if not block:
                     break
                 blocks.append(block)
             return b''.join(blocks)
 
-        if not self._buffer and not self._eof:
+        # TODO: should be `if` instead of `while`
+        # because waiter maybe triggered on chunk end,
+        # without feeding any data
+        while not self._buffer and not self._eof:
             await self._wait('read')
 
         return self._read_nowait(n)
 
     async def readany(self) -> bytes:
         if self._exception is not None:
             raise self._exception
 
-        if not self._buffer and not self._eof:
+        # TODO: should be `if` instead of `while`
+        # because waiter maybe triggered on chunk end,
+        # without feeding any data
+        while not self._buffer and not self._eof:
             await self._wait('readany')
 
         return self._read_nowait(-1)
 
     async def readchunk(self) -> Tuple[bytes, bool]:
         """Returns a tuple of (data, end_of_http_chunk). When chunked transfer
         encoding is used, end_of_http_chunk is a boolean indicating if the end
         of the data corresponds to the end of a HTTP chunk , otherwise it is
         always False.
         """
-        if self._exception is not None:
-            raise self._exception
-
-        if not self._buffer and not self._eof:
-            if (self._http_chunk_splits and
-                    self._cursor == self._http_chunk_splits[0]):
-                # end of http chunk without available data
-                self._http_chunk_splits = self._http_chunk_splits[1:]
-                return (b"", True)
-            await self._wait('readchunk')
+        while True:
+            if self._exception is not None:
+                raise self._exception
 
-        if not self._buffer and not self._http_chunk_splits:
-            # end of file
-            return (b"", False)
-        elif self._http_chunk_splits is not None:
             while self._http_chunk_splits:
-                pos = self._http_chunk_splits[0]
-                self._http_chunk_splits = self._http_chunk_splits[1:]
+                pos = self._http_chunk_splits.pop(0)
                 if pos == self._cursor:
                     return (b"", True)
                 if pos > self._cursor:
                     return (self._read_nowait(pos-self._cursor), True)
-            return (self._read_nowait(-1), False)
-        else:
-            return (self._read_nowait_chunk(-1), False)
+                internal_logger.warning('Skipping HTTP chunk end due to data '
+                                        'consumption beyond chunk boundary')
+
+            if self._buffer:
+                return (self._read_nowait_chunk(-1), False)
+                # return (self._read_nowait(-1), False)
+
+            if self._eof:
+                # Special case for signifying EOF.
+                # (b'', True) is not a final return value actually.
+                return (b'', False)
+
+            await self._wait('readchunk')
 
     async def readexactly(self, n: int) -> bytes:
         if self._exception is not None:
             raise self._exception
 
         blocks = []  # type: List[bytes]
         while n > 0:
             block = await self.read(n)
             if not block:
                 partial = b''.join(blocks)
-                raise asyncio.streams.IncompleteReadError(
+                raise asyncio.IncompleteReadError(
                     partial, len(partial) + n)
             blocks.append(block)
             n -= len(block)
 
         return b''.join(blocks)
 
     def read_nowait(self, n: int=-1) -> bytes:
@@ -452,19 +443,25 @@
 
         else:
             data = self._buffer.popleft()
 
         self._size -= len(data)
         self._cursor += len(data)
 
+        chunk_splits = self._http_chunk_splits
+        # Prevent memory leak: drop useless chunk splits
+        while chunk_splits and chunk_splits[0] < self._cursor:
+            chunk_splits.pop(0)
+
         if self._size < self._low_water and self._protocol._reading_paused:
             self._protocol.resume_reading()
         return data
 
     def _read_nowait(self, n: int) -> bytes:
+        """ Read not more than n bytes, or whole buffer is n == -1 """
         chunks = []
 
         while self._buffer:
             chunk = self._read_nowait_chunk(n)
             chunks.append(chunk)
             if n != -1:
                 n -= len(chunk)
@@ -512,30 +509,30 @@
     async def readany(self) -> bytes:
         return b''
 
     async def readchunk(self) -> Tuple[bytes, bool]:
         return (b'', True)
 
     async def readexactly(self, n: int) -> bytes:
-        raise asyncio.streams.IncompleteReadError(b'', n)
+        raise asyncio.IncompleteReadError(b'', n)
 
     def read_nowait(self) -> bytes:
         return b''
 
 
 EMPTY_PAYLOAD = EmptyStreamReader()
 
 
 class DataQueue(Generic[_T]):
     """DataQueue is a general-purpose blocking queue with one reader."""
 
     def __init__(self, loop: asyncio.AbstractEventLoop) -> None:
         self._loop = loop
         self._eof = False
-        self._waiter = None  # type: Optional[asyncio.Future[bool]]
+        self._waiter = None  # type: Optional[asyncio.Future[None]]
         self._exception = None  # type: Optional[BaseException]
         self._size = 0
         self._buffer = collections.deque()  # type: Deque[Tuple[_T, int]]
 
     def __len__(self) -> int:
         return len(self._buffer)
 
@@ -550,33 +547,33 @@
 
     def set_exception(self, exc: BaseException) -> None:
         self._eof = True
         self._exception = exc
 
         waiter = self._waiter
         if waiter is not None:
-            set_exception(waiter, exc)
             self._waiter = None
+            set_exception(waiter, exc)
 
     def feed_data(self, data: _T, size: int=0) -> None:
         self._size += size
         self._buffer.append((data, size))
 
         waiter = self._waiter
         if waiter is not None:
             self._waiter = None
-            set_result(waiter, True)
+            set_result(waiter, None)
 
     def feed_eof(self) -> None:
         self._eof = True
 
         waiter = self._waiter
         if waiter is not None:
             self._waiter = None
-            set_result(waiter, False)
+            set_result(waiter, None)
 
     async def read(self) -> _T:
         if not self._buffer and not self._eof:
             assert not self._waiter
             self._waiter = self._loop.create_future()
             try:
                 await self._waiter
```

### Comparing `aiohttp-4.0.0a0/aiohttp/tcp_helpers.py` & `aiohttp-4.0.0a1/aiohttp/tcp_helpers.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/aiohttp/test_utils.py` & `aiohttp-4.0.0a1/aiohttp/test_utils.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 """Utilities shared by tests."""
 
 import asyncio
 import contextlib
 import functools
 import gc
+import inspect
 import socket
 import sys
 import unittest
 from abc import ABC, abstractmethod
 from types import TracebackType
 from typing import (  # noqa
     TYPE_CHECKING,
@@ -70,37 +71,35 @@
     """Return a port that is unused on the current host."""
     with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
         s.bind(('127.0.0.1', 0))
         return s.getsockname()[1]
 
 
 class BaseTestServer(ABC):
+    __test__ = False
+
     def __init__(self,
                  *,
                  scheme: Union[str, object]=sentinel,
-                 loop: Optional[asyncio.AbstractEventLoop]=None,
                  host: str='127.0.0.1',
                  port: Optional[int]=None,
                  skip_url_asserts: bool=False,
                  **kwargs: Any) -> None:
-        self._loop = loop
         self.runner = None  # type: Optional[BaseRunner]
         self._root = None  # type: Optional[URL]
         self.host = host
         self.port = port
         self._closed = False
         self.scheme = scheme
         self.skip_url_asserts = skip_url_asserts
 
     async def start_server(self,
-                           loop: Optional[asyncio.AbstractEventLoop]=None,
                            **kwargs: Any) -> None:
         if self.runner:
             return
-        self._loop = loop
         self._ssl = kwargs.pop('ssl', None)
         self.runner = await self._make_runner(**kwargs)
         await self.runner.setup()
         if not self.port:
             self.port = 0
         _sock = get_port_socket(self.host, self.port)
         self.host, self.port = _sock.getsockname()[:2]
@@ -166,26 +165,16 @@
         if self.started and not self.closed:
             assert self.runner is not None
             await self.runner.cleanup()
             self._root = None
             self.port = None
             self._closed = True
 
-    def __enter__(self) -> None:
-        raise TypeError("Use async with instead")
-
-    def __exit__(self,
-                 exc_type: Optional[Type[BaseException]],
-                 exc_value: Optional[BaseException],
-                 traceback: Optional[TracebackType]) -> None:
-        # __exit__ should exist in pair with __enter__ but never executed
-        pass  # pragma: no cover
-
     async def __aenter__(self) -> 'BaseTestServer':
-        await self.start_server(loop=self._loop)
+        await self.start_server()
         return self
 
     async def __aexit__(self,
                         exc_type: Optional[Type[BaseException]],
                         exc_value: Optional[BaseException],
                         traceback: Optional[TracebackType]) -> None:
         await self.close()
@@ -212,49 +201,50 @@
                  host: str='127.0.0.1',
                  port: Optional[int]=None,
                  **kwargs: Any) -> None:
         self._handler = handler
         super().__init__(scheme=scheme, host=host, port=port, **kwargs)
 
     async def _make_runner(self,
-                           debug: bool=True,
                            **kwargs: Any) -> ServerRunner:
         srv = Server(
-            self._handler, loop=self._loop, debug=debug, **kwargs)
-        return ServerRunner(srv, debug=debug, **kwargs)
+            self._handler, **kwargs)
+        return ServerRunner(srv, **kwargs)
 
 
 class TestClient:
     """
     A test client implementation.
 
     To write functional tests for aiohttp based servers.
 
     """
+    __test__ = False
 
     def __init__(self, server: BaseTestServer, *,
                  cookie_jar: Optional[AbstractCookieJar]=None,
-                 loop: Optional[asyncio.AbstractEventLoop]=None,
                  **kwargs: Any) -> None:
         if not isinstance(server, BaseTestServer):
             raise TypeError("server must be TestServer "
                             "instance, found type: %r" % type(server))
         self._server = server
-        self._loop = loop
         if cookie_jar is None:
-            cookie_jar = aiohttp.CookieJar(unsafe=True, loop=loop)
-        self._session = ClientSession(loop=loop,
-                                      cookie_jar=cookie_jar,
+            cookie_jar = aiohttp.CookieJar(unsafe=True)
+        self._session = ClientSession(cookie_jar=cookie_jar,
                                       **kwargs)
         self._closed = False
         self._responses = []  # type: List[ClientResponse]
         self._websockets = []  # type: List[ClientWebSocketResponse]
 
     async def start_server(self) -> None:
-        await self._server.start_server(loop=self._loop)
+        await self._server.start_server()
+
+    @property
+    def scheme(self) -> Union[str, object]:
+        return self._server.scheme
 
     @property
     def host(self) -> str:
         return self._server.host
 
     @property
     def port(self) -> Optional[int]:
@@ -278,70 +268,76 @@
 
         """
         return self._session
 
     def make_url(self, path: str) -> URL:
         return self._server.make_url(path)
 
-    async def request(self, method: str, path: str,
-                      **kwargs: Any) -> ClientResponse:
+    async def _request(self, method: str, path: str,
+                       **kwargs: Any) -> ClientResponse:
+        resp = await self._session.request(
+            method, self.make_url(path), **kwargs
+        )
+        # save it to close later
+        self._responses.append(resp)
+        return resp
+
+    def request(self, method: str, path: str,
+                **kwargs: Any) -> _RequestContextManager:
         """Routes a request to tested http server.
 
         The interface is identical to aiohttp.ClientSession.request,
         except the loop kwarg is overridden by the instance used by the
         test server.
 
         """
-        resp = await self._session.request(
-            method, self.make_url(path), **kwargs
+        return _RequestContextManager(
+            self._request(method, path, **kwargs)
         )
-        # save it to close later
-        self._responses.append(resp)
-        return resp
 
     def get(self, path: str, **kwargs: Any) -> _RequestContextManager:
         """Perform an HTTP GET request."""
         return _RequestContextManager(
-            self.request(hdrs.METH_GET, path, **kwargs)
+            self._request(hdrs.METH_GET, path, **kwargs)
         )
 
     def post(self, path: str, **kwargs: Any) -> _RequestContextManager:
         """Perform an HTTP POST request."""
         return _RequestContextManager(
-            self.request(hdrs.METH_POST, path, **kwargs)
+            self._request(hdrs.METH_POST, path, **kwargs)
         )
 
     def options(self, path: str, **kwargs: Any) -> _RequestContextManager:
         """Perform an HTTP OPTIONS request."""
         return _RequestContextManager(
-            self.request(hdrs.METH_OPTIONS, path, **kwargs)
+            self._request(hdrs.METH_OPTIONS, path, **kwargs)
         )
 
     def head(self, path: str, **kwargs: Any) -> _RequestContextManager:
         """Perform an HTTP HEAD request."""
         return _RequestContextManager(
-            self.request(hdrs.METH_HEAD, path, **kwargs)
+            self._request(hdrs.METH_HEAD, path, **kwargs)
         )
 
     def put(self, path: str, **kwargs: Any) -> _RequestContextManager:
         """Perform an HTTP PUT request."""
         return _RequestContextManager(
-            self.request(hdrs.METH_PUT, path, **kwargs)
+            self._request(hdrs.METH_PUT, path, **kwargs)
         )
 
     def patch(self, path: str, **kwargs: Any) -> _RequestContextManager:
         """Perform an HTTP PATCH request."""
         return _RequestContextManager(
-            self.request(hdrs.METH_PATCH, path, **kwargs)
+            self._request(hdrs.METH_PATCH, path, **kwargs)
         )
 
     def delete(self, path: str, **kwargs: Any) -> _RequestContextManager:
         """Perform an HTTP PATCH request."""
         return _RequestContextManager(
-            self.request(hdrs.METH_DELETE, path, **kwargs)
+            self._request(hdrs.METH_DELETE, path, **kwargs)
         )
 
     def ws_connect(self, path: str, **kwargs: Any) -> _WSRequestContextManager:
         """Initiate websocket connection.
 
         The api corresponds to aiohttp.ClientSession.ws_connect.
 
@@ -374,24 +370,14 @@
                 resp.close()
             for ws in self._websockets:
                 await ws.close()
             await self._session.close()
             await self._server.close()
             self._closed = True
 
-    def __enter__(self) -> None:
-        raise TypeError("Use async with instead")
-
-    def __exit__(self,
-                 exc_type: Optional[Type[BaseException]],
-                 exc: Optional[BaseException],
-                 tb: Optional[TracebackType]) -> None:
-        # __exit__ should exist in pair with __enter__ but never executed
-        pass  # pragma: no cover
-
     async def __aenter__(self) -> 'TestClient':
         await self.start_server()
         return self
 
     async def __aexit__(self,
                         exc_type: Optional[Type[BaseException]],
                         exc: Optional[BaseException],
@@ -453,19 +439,19 @@
         teardown_test_loop(self.loop)
 
     async def tearDownAsync(self) -> None:
         pass
 
     async def get_server(self, app: Application) -> TestServer:
         """Return a TestServer instance."""
-        return TestServer(app, loop=self.loop)
+        return TestServer(app)
 
     async def get_client(self, server: TestServer) -> TestClient:
         """Return a TestClient instance."""
-        return TestClient(server, loop=self.loop)
+        return TestClient(server)
 
 
 def unittest_run_loop(func: Any, *args: Any, **kwargs: Any) -> Any:
     """A decorator dedicated to use with asynchronous methods of an
     AioHTTPTestCase.
 
     Handles executing an asynchronous function, using
@@ -547,15 +533,14 @@
         app.__app_dict[key] = value
 
     app = mock.MagicMock()
     app.__app_dict = {}
     app.__getitem__ = get_dict
     app.__setitem__ = set_dict
 
-    app._debug = False
     app.on_response_prepare = Signal(app)
     app.on_response_prepare.freeze()
     return app
 
 
 def _create_transport(sslcontext: Optional[SSLContext]=None) -> mock.Mock:
     transport = mock.Mock()
@@ -646,14 +631,15 @@
 
     return req
 
 
 def make_mocked_coro(return_value: Any=sentinel,
                      raise_exception: Any=sentinel) -> Any:
     """Creates a coroutine mock."""
-    @asyncio.coroutine
-    def mock_coro(*args: Any, **kwargs: Any) -> Any:
+    async def mock_coro(*args: Any, **kwargs: Any) -> Any:
         if raise_exception is not sentinel:
             raise raise_exception
-        return return_value
+        if not inspect.isawaitable(return_value):
+            return return_value
+        await return_value
 
     return mock.Mock(wraps=mock_coro)
```

### Comparing `aiohttp-4.0.0a0/aiohttp/tracing.py` & `aiohttp-4.0.0a1/aiohttp/tracing.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,21 +1,39 @@
 from types import SimpleNamespace
-from typing import TYPE_CHECKING, Awaitable, Callable, Type
+from typing import TYPE_CHECKING, Awaitable, Callable, Type, Union
 
 import attr
 from multidict import CIMultiDict  # noqa
 from yarl import URL
 
 from .client_reqrep import ClientResponse
 from .signals import Signal
 
 if TYPE_CHECKING:  # pragma: no cover
     from .client import ClientSession  # noqa
 
-    _Signal = Signal[Callable[['TraceConfig'], Awaitable[None]]]
+    _SignalArgs = Union[
+        'TraceRequestStartParams',
+        'TraceRequestEndParams',
+        'TraceRequestExceptionParams',
+        'TraceConnectionQueuedStartParams',
+        'TraceConnectionQueuedEndParams',
+        'TraceConnectionCreateStartParams',
+        'TraceConnectionCreateEndParams',
+        'TraceConnectionReuseconnParams',
+        'TraceDnsResolveHostStartParams',
+        'TraceDnsResolveHostEndParams',
+        'TraceDnsCacheHitParams',
+        'TraceDnsCacheMissParams',
+        'TraceRequestRedirectParams',
+        'TraceRequestChunkSentParams',
+        'TraceResponseChunkReceivedParams',
+    ]
+    _Signal = Signal[Callable[[ClientSession, SimpleNamespace, _SignalArgs],
+                              Awaitable[None]]]
 else:
     _Signal = Signal
 
 
 __all__ = (
     'TraceConfig', 'TraceRequestStartParams', 'TraceRequestEndParams',
     'TraceRequestExceptionParams', 'TraceConnectionQueuedStartParams',
```

### Comparing `aiohttp-4.0.0a0/aiohttp/typedefs.py` & `aiohttp-4.0.0a1/aiohttp/typedefs.py`

 * *Files 4% similar despite different names*

```diff
@@ -8,15 +8,21 @@
     Callable,
     Iterable,
     Mapping,
     Tuple,
     Union,
 )
 
-from multidict import CIMultiDict, CIMultiDictProxy, MultiDict, MultiDictProxy
+from multidict import (
+    CIMultiDict,
+    CIMultiDictProxy,
+    MultiDict,
+    MultiDictProxy,
+    istr,
+)
 from yarl import URL
 
 DEFAULT_JSON_ENCODER = json.dumps
 DEFAULT_JSON_DECODER = json.loads
 
 if TYPE_CHECKING:  # pragma: no cover
     _CIMultiDict = CIMultiDict[str]
@@ -29,15 +35,16 @@
     _CIMultiDictProxy = CIMultiDictProxy
     _MultiDict = MultiDict
     _MultiDictProxy = MultiDictProxy
 
 Byteish = Union[bytes, bytearray, memoryview]
 JSONEncoder = Callable[[Any], str]
 JSONDecoder = Callable[[str], Any]
-LooseHeaders = Union[Mapping[str, str], _CIMultiDict, _CIMultiDictProxy]
+LooseHeaders = Union[Mapping[Union[str, istr], str], _CIMultiDict,
+                     _CIMultiDictProxy]
 RawHeaders = Tuple[Tuple[bytes, bytes], ...]
 StrOrURL = Union[str, URL]
 LooseCookies = Union[Iterable[Tuple[str, 'BaseCookie[str]']],
                      Mapping[str, 'BaseCookie[str]'], 'BaseCookie[str]']
 
 
 if sys.version_info >= (3, 6):
```

### Comparing `aiohttp-4.0.0a0/aiohttp/web_app.py` & `aiohttp-4.0.0a1/aiohttp/web_app.py`

 * *Files 18% similar despite different names*

```diff
@@ -18,34 +18,24 @@
     Sequence,
     Tuple,
     Type,
     Union,
     cast,
 )
 
+from typing_extensions import final
+
 from . import hdrs
-from .abc import (
-    AbstractAccessLogger,
-    AbstractMatchInfo,
-    AbstractRouter,
-    AbstractStreamWriter,
-)
 from .frozenlist import FrozenList
-from .helpers import DEBUG
-from .http_parser import RawRequestMessage
 from .log import web_logger
 from .signals import Signal
-from .streams import StreamReader
-from .web_log import AccessLogger
 from .web_middlewares import _fix_request_current_app
-from .web_protocol import RequestHandler
 from .web_request import Request
 from .web_response import StreamResponse
 from .web_routedef import AbstractRouteDef
-from .web_server import Server
 from .web_urldispatcher import (
     AbstractResource,
     Domain,
     MaskDomain,
     MatchedSubAppResource,
     PrefixedSubAppResource,
     UrlDispatcher,
@@ -55,74 +45,59 @@
 
 
 if TYPE_CHECKING:  # pragma: no cover
     _AppSignal = Signal[Callable[['Application'], Awaitable[None]]]
     _RespPrepareSignal = Signal[Callable[[Request, StreamResponse],
                                          Awaitable[None]]]
     _Handler = Callable[[Request], Awaitable[StreamResponse]]
-    _Middleware = Union[Callable[[Request, _Handler],
-                                 Awaitable[StreamResponse]],
-                        Callable[['Application', _Handler],  # old-style
-                                 Awaitable[_Handler]]]
+    _Middleware = Callable[[Request, _Handler], Awaitable[StreamResponse]]
     _Middlewares = FrozenList[_Middleware]
-    _MiddlewaresHandlers = Optional[Sequence[Tuple[_Middleware, bool]]]
+    _MiddlewaresHandlers = Sequence[_Middleware]
     _Subapps = List['Application']
 else:
     # No type checker mode, skip types
     _AppSignal = Signal
     _RespPrepareSignal = Signal
     _Handler = Callable
     _Middleware = Callable
     _Middlewares = FrozenList
-    _MiddlewaresHandlers = Optional[Sequence]
+    _MiddlewaresHandlers = Sequence
     _Subapps = List
 
 
+@final
 class Application(MutableMapping[str, Any]):
-    ATTRS = frozenset([
+    __slots__ = (
         'logger', '_debug', '_router', '_loop', '_handler_args',
         '_middlewares', '_middlewares_handlers', '_run_middlewares',
         '_state', '_frozen', '_pre_frozen', '_subapps',
         '_on_response_prepare', '_on_startup', '_on_shutdown',
-        '_on_cleanup', '_client_max_size', '_cleanup_ctx'])
+        '_on_cleanup', '_client_max_size', '_cleanup_ctx')
 
     def __init__(self, *,
                  logger: logging.Logger=web_logger,
-                 router: Optional[UrlDispatcher]=None,
-                 middlewares: Sequence[_Middleware]=(),
+                 middlewares: Iterable[_Middleware]=(),
                  handler_args: Mapping[str, Any]=None,
                  client_max_size: int=1024**2,
-                 loop: Optional[asyncio.AbstractEventLoop]=None,
                  debug: Any=...  # mypy doesn't support ellipsis
                  ) -> None:
-        if router is None:
-            router = UrlDispatcher()
-        else:
-            warnings.warn("router argument is deprecated", DeprecationWarning,
-                          stacklevel=2)
-        assert isinstance(router, AbstractRouter), router
-
-        if loop is not None:
-            warnings.warn("loop argument is deprecated", DeprecationWarning,
-                          stacklevel=2)
 
         if debug is not ...:
-            warnings.warn("debug argument is deprecated",
+            warnings.warn("debug argument is no-op since 4.0 "
+                          "and scheduled for removal in 5.0",
                           DeprecationWarning,
                           stacklevel=2)
-        self._debug = debug
-        self._router = router  # type: UrlDispatcher
-        self._loop = loop
+        self._router = UrlDispatcher()
         self._handler_args = handler_args
         self.logger = logger
 
         self._middlewares = FrozenList(middlewares)  # type: _Middlewares
 
         # initialized on freezing
-        self._middlewares_handlers = None  # type: _MiddlewaresHandlers
+        self._middlewares_handlers = tuple()  # type: _MiddlewaresHandlers
         # initialized on freezing
         self._run_middlewares = None  # type: Optional[bool]
 
         self._state = {}  # type: Dict[str, Any]
         self._frozen = False
         self._pre_frozen = False
         self._subapps = []  # type: _Subapps
@@ -133,42 +108,29 @@
         self._on_cleanup = Signal(self)  # type: _AppSignal
         self._cleanup_ctx = CleanupContext()
         self._on_startup.append(self._cleanup_ctx._on_startup)
         self._on_cleanup.append(self._cleanup_ctx._on_cleanup)
         self._client_max_size = client_max_size
 
     def __init_subclass__(cls: Type['Application']) -> None:
-        warnings.warn("Inheritance class {} from web.Application "
-                      "is discouraged".format(cls.__name__),
-                      DeprecationWarning,
-                      stacklevel=2)
-
-    if DEBUG:  # pragma: no cover
-        def __setattr__(self, name: str, val: Any) -> None:
-            if name not in self.ATTRS:
-                warnings.warn("Setting custom web.Application.{} attribute "
-                              "is discouraged".format(name),
-                              DeprecationWarning,
-                              stacklevel=2)
-            super().__setattr__(name, val)
+        raise TypeError("Inheritance class {} from web.Application "
+                        "is forbidden".format(cls.__name__))
 
     # MutableMapping API
 
     def __eq__(self, other: object) -> bool:
         return self is other
 
     def __getitem__(self, key: str) -> Any:
         return self._state[key]
 
     def _check_frozen(self) -> None:
         if self._frozen:
-            warnings.warn("Changing state of started or joined "
-                          "application is deprecated",
-                          DeprecationWarning,
-                          stacklevel=3)
+            raise RuntimeError("Changing state of started or joined "
+                               "application is forbidden")
 
     def __setitem__(self, key: str, value: Any) -> None:
         self._check_frozen()
         self._state[key] = value
 
     def __delitem__(self, key: str) -> None:
         self._check_frozen()
@@ -177,40 +139,19 @@
     def __len__(self) -> int:
         return len(self._state)
 
     def __iter__(self) -> Iterator[str]:
         return iter(self._state)
 
     ########
-    @property
-    def loop(self) -> asyncio.AbstractEventLoop:
-        # Technically the loop can be None
-        # but we mask it by explicit type cast
-        # to provide more convinient type annotation
-        warnings.warn("loop property is deprecated",
+    def _set_loop(self, loop: Optional[asyncio.AbstractEventLoop]) -> None:
+        warnings.warn("_set_loop() is no-op since 4.0 "
+                      "and scheduled for removal in 5.0",
                       DeprecationWarning,
                       stacklevel=2)
-        return cast(asyncio.AbstractEventLoop, self._loop)
-
-    def _set_loop(self, loop: Optional[asyncio.AbstractEventLoop]) -> None:
-        if loop is None:
-            loop = asyncio.get_event_loop()
-        if self._loop is not None and self._loop is not loop:
-            raise RuntimeError(
-                "web.Application instance initialized with different loop")
-
-        self._loop = loop
-
-        # set loop debug
-        if self._debug is ...:
-            self._debug = loop.get_debug()
-
-        # set loop to sub applications
-        for subapp in self._subapps:
-            subapp._set_loop(loop)
 
     @property
     def pre_frozen(self) -> bool:
         return self._pre_frozen
 
     def pre_freeze(self) -> None:
         if self._pre_frozen:
@@ -249,18 +190,19 @@
         self.pre_freeze()
         self._frozen = True
         for subapp in self._subapps:
             subapp.freeze()
 
     @property
     def debug(self) -> bool:
-        warnings.warn("debug property is deprecated",
+        warnings.warn("debug property is deprecated since 4.0"
+                      "and scheduled for removal in 5.0",
                       DeprecationWarning,
                       stacklevel=2)
-        return self._debug
+        return asyncio.get_event_loop().get_debug()
 
     def _reg_subapp_signals(self, subapp: 'Application') -> None:
 
         def reg_handler(signame: str) -> None:
             subsig = getattr(subapp, signame)
 
             async def handler(app: 'Application') -> None:
@@ -291,16 +233,14 @@
         if subapp.frozen:
             raise RuntimeError("Cannot add frozen application")
         resource = resource_factory()
         self.router.register_resource(resource)
         self._reg_subapp_signals(subapp)
         self._subapps.append(subapp)
         subapp.pre_freeze()
-        if self._loop is not None:
-            subapp._set_loop(self._loop)
         return resource
 
     def add_domain(self, domain: str,
                    subapp: 'Application') -> AbstractResource:
         if not isinstance(domain, str):
             raise TypeError("Domain must be str")
         elif '*' in domain:
@@ -337,54 +277,14 @@
     def router(self) -> UrlDispatcher:
         return self._router
 
     @property
     def middlewares(self) -> _Middlewares:
         return self._middlewares
 
-    def _make_handler(self, *,
-                      loop: Optional[asyncio.AbstractEventLoop]=None,
-                      access_log_class: Type[
-                          AbstractAccessLogger]=AccessLogger,
-                      **kwargs: Any) -> Server:
-
-        if not issubclass(access_log_class, AbstractAccessLogger):
-            raise TypeError(
-                'access_log_class must be subclass of '
-                'aiohttp.abc.AbstractAccessLogger, got {}'.format(
-                    access_log_class))
-
-        self._set_loop(loop)
-        self.freeze()
-
-        kwargs['debug'] = self._debug
-        kwargs['access_log_class'] = access_log_class
-        if self._handler_args:
-            for k, v in self._handler_args.items():
-                kwargs[k] = v
-
-        return Server(self._handle,  # type: ignore
-                      request_factory=self._make_request,
-                      loop=self._loop, **kwargs)
-
-    def make_handler(self, *,
-                     loop: Optional[asyncio.AbstractEventLoop]=None,
-                     access_log_class: Type[
-                         AbstractAccessLogger]=AccessLogger,
-                     **kwargs: Any) -> Server:
-
-        warnings.warn("Application.make_handler(...) is deprecated, "
-                      "use AppRunner API instead",
-                      DeprecationWarning,
-                      stacklevel=2)
-
-        return self._make_handler(loop=loop,
-                                  access_log_class=access_log_class,
-                                  **kwargs)
-
     async def startup(self) -> None:
         """Causes on_startup signal
 
         Should be called in the event loop along with the request handler.
         """
         await self.on_startup.send(self)
 
@@ -398,78 +298,53 @@
     async def cleanup(self) -> None:
         """Causes on_cleanup signal
 
         Should be called after shutdown()
         """
         await self.on_cleanup.send(self)
 
-    def _make_request(self, message: RawRequestMessage,
-                      payload: StreamReader,
-                      protocol: RequestHandler,
-                      writer: AbstractStreamWriter,
-                      task: 'asyncio.Task[None]',
-                      _cls: Type[Request]=Request) -> Request:
-        return _cls(
-            message, payload, protocol, writer, task,
-            self._loop,
-            client_max_size=self._client_max_size)
-
-    def _prepare_middleware(self) -> Iterator[Tuple[_Middleware, bool]]:
-        for m in reversed(self._middlewares):
-            if getattr(m, '__middleware_version__', None) == 1:
-                yield m, True
-            else:
-                warnings.warn('old-style middleware "{!r}" deprecated, '
-                              'see #2252'.format(m),
-                              DeprecationWarning, stacklevel=2)
-                yield m, False
-
-        yield _fix_request_current_app(self), True
+    def _prepare_middleware(self) -> Iterator[_Middleware]:
+        yield from reversed(self._middlewares)
+        yield _fix_request_current_app(self)
 
     async def _handle(self, request: Request) -> StreamResponse:
-        loop = asyncio.get_event_loop()
-        debug = loop.get_debug()
         match_info = await self._router.resolve(request)
-        if debug:  # pragma: no cover
-            if not isinstance(match_info, AbstractMatchInfo):
-                raise TypeError("match_info should be AbstractMatchInfo "
-                                "instance, not {!r}".format(match_info))
         match_info.add_app(self)
-
         match_info.freeze()
 
         resp = None
         request._match_info = match_info  # type: ignore
         expect = request.headers.get(hdrs.EXPECT)
         if expect:
             resp = await match_info.expect_handler(request)
             await request.writer.drain()
 
         if resp is None:
             handler = match_info.handler
 
             if self._run_middlewares:
                 for app in match_info.apps[::-1]:
-                    for m, new_style in app._middlewares_handlers:  # type: ignore  # noqa
-                        if new_style:
-                            handler = partial(m, handler=handler)
-                        else:
-                            handler = await m(app, handler)  # type: ignore
+                    assert app.pre_frozen, "middleware handlers are not ready"
+                    for m in app._middlewares_handlers:  # noqa
+                        handler = partial(m, handler=handler)
 
             resp = await handler(request)
 
         return resp
 
     def __call__(self) -> 'Application':
         """gunicorn compatibility"""
         return self
 
     def __repr__(self) -> str:
         return "<Application 0x{:x}>".format(id(self))
 
+    def __bool__(self) -> bool:
+        return True
+
 
 class CleanupError(RuntimeError):
     @property
     def exceptions(self) -> List[BaseException]:
         return self.args[1]
```

### Comparing `aiohttp-4.0.0a0/aiohttp/web_exceptions.py` & `aiohttp-4.0.0a1/aiohttp/web_exceptions.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,12 +1,16 @@
 import warnings
-from typing import Any, Dict, Iterable, List, Optional, Set  # noqa
+from http import HTTPStatus
+from typing import Any, Iterable, Optional, Set, Tuple
 
+from multidict import CIMultiDict
+from yarl import URL
+
+from . import hdrs
 from .typedefs import LooseHeaders, StrOrURL
-from .web_response import Response
 
 __all__ = (
     'HTTPException',
     'HTTPError',
     'HTTPRedirection',
     'HTTPSuccessful',
     'HTTPOk',
@@ -65,44 +69,95 @@
 )
 
 
 ############################################################
 # HTTP Exceptions
 ############################################################
 
-class HTTPException(Response, Exception):
+class HTTPException(Exception):
 
     # You should set in subclasses:
     # status = 200
 
     status_code = -1
     empty_body = False
-
-    __http_exception__ = True
+    default_reason = ""  # Initialized at the end of the module
 
     def __init__(self, *,
                  headers: Optional[LooseHeaders]=None,
                  reason: Optional[str]=None,
-                 body: Any=None,
                  text: Optional[str]=None,
                  content_type: Optional[str]=None) -> None:
-        if body is not None:
-            warnings.warn(
-                "body argument is deprecated for http web exceptions",
-                DeprecationWarning)
-        Response.__init__(self, status=self.status_code,
-                          headers=headers, reason=reason,
-                          body=body, text=text, content_type=content_type)
-        Exception.__init__(self, self.reason)
-        if self.body is None and not self.empty_body:
-            self.text = "{}: {}".format(self.status, self.reason)
+        if reason is None:
+            reason = self.default_reason
+
+        if text is None:
+            if not self.empty_body:
+                text = "{}: {}".format(self.status_code, reason)
+        else:
+            if self.empty_body:
+                warnings.warn(
+                    "text argument is deprecated for HTTP status {} "
+                    "since 4.0 and scheduled for removal in 5.0 (#3462),"
+                    "the response should be provided without a body".format(
+                        self.status_code),
+                    DeprecationWarning,
+                    stacklevel=2)
+
+        if headers is not None:
+            real_headers = CIMultiDict(headers)
+        else:
+            real_headers = CIMultiDict()
+
+        if content_type is not None:
+            if not text:
+                warnings.warn("content_type without text is deprecated "
+                              "since 4.0 and scheduled for removal in 5.0 "
+                              "(#3462)",
+                              DeprecationWarning,
+                              stacklevel=2)
+            real_headers[hdrs.CONTENT_TYPE] = content_type
+        elif hdrs.CONTENT_TYPE not in real_headers and text:
+            real_headers[hdrs.CONTENT_TYPE] = 'text/plain'
+
+        self._reason = reason
+        self._text = text
+        self._headers = real_headers
+        self.args = ()
 
     def __bool__(self) -> bool:
         return True
 
+    @property
+    def status(self) -> int:
+        return self.status_code
+
+    @property
+    def reason(self) -> str:
+        return self._reason
+
+    @property
+    def text(self) -> Optional[str]:
+        return self._text
+
+    @property
+    def headers(self) -> 'CIMultiDict[str]':
+        return self._headers
+
+    def __str__(self) -> str:
+        return self.reason
+
+    def __repr__(self) -> str:
+        return "<%s: %s>" % (self.__class__.__name__, self.reason)
+
+    __reduce__ = object.__reduce__
+
+    def __getnewargs__(self) -> Tuple[Any, ...]:
+        return self.args
+
 
 class HTTPError(HTTPException):
     """Base class for exceptions with status codes in the 400s and 500s."""
 
 
 class HTTPRedirection(HTTPException):
     """Base class for exceptions with status codes in the 300s."""
@@ -143,66 +198,69 @@
 
 
 ############################################################
 # 3xx redirection
 ############################################################
 
 
-class _HTTPMove(HTTPRedirection):
+class HTTPMove(HTTPRedirection):
 
     def __init__(self,
                  location: StrOrURL,
                  *,
                  headers: Optional[LooseHeaders]=None,
                  reason: Optional[str]=None,
-                 body: Any=None,
                  text: Optional[str]=None,
                  content_type: Optional[str]=None) -> None:
         if not location:
             raise ValueError("HTTP redirects need a location to redirect to.")
         super().__init__(headers=headers, reason=reason,
-                         body=body, text=text, content_type=content_type)
-        self.headers['Location'] = str(location)
-        self.location = location
+                         text=text, content_type=content_type)
+        self._location = URL(location)
+        self.headers['Location'] = str(self.location)
 
+    @property
+    def location(self) -> URL:
+        return self._location
 
-class HTTPMultipleChoices(_HTTPMove):
+
+class HTTPMultipleChoices(HTTPMove):
     status_code = 300
 
 
-class HTTPMovedPermanently(_HTTPMove):
+class HTTPMovedPermanently(HTTPMove):
     status_code = 301
 
 
-class HTTPFound(_HTTPMove):
+class HTTPFound(HTTPMove):
     status_code = 302
 
 
 # This one is safe after a POST (the redirected location will be
 # retrieved with GET):
-class HTTPSeeOther(_HTTPMove):
+class HTTPSeeOther(HTTPMove):
     status_code = 303
 
 
 class HTTPNotModified(HTTPRedirection):
     # FIXME: this should include a date or etag header
     status_code = 304
     empty_body = True
 
 
-class HTTPUseProxy(_HTTPMove):
+class HTTPUseProxy(HTTPMove):
     # Not a move, but looks a little like one
     status_code = 305
 
 
-class HTTPTemporaryRedirect(_HTTPMove):
+class HTTPTemporaryRedirect(HTTPMove):
     status_code = 307
 
 
-class HTTPPermanentRedirect(_HTTPMove):
+class HTTPPermanentRedirect(HTTPMove):
     status_code = 308
 
 
 ############################################################
 # 4xx client error
 ############################################################
 
@@ -236,23 +294,30 @@
 
     def __init__(self,
                  method: str,
                  allowed_methods: Iterable[str],
                  *,
                  headers: Optional[LooseHeaders]=None,
                  reason: Optional[str]=None,
-                 body: Any=None,
                  text: Optional[str]=None,
                  content_type: Optional[str]=None) -> None:
         allow = ','.join(sorted(allowed_methods))
         super().__init__(headers=headers, reason=reason,
-                         body=body, text=text, content_type=content_type)
+                         text=text, content_type=content_type)
         self.headers['Allow'] = allow
-        self.allowed_methods = set(allowed_methods)  # type: Set[str]
-        self.method = method.upper()
+        self._allowed = set(allowed_methods)  # type: Set[str]
+        self._method = method
+
+    @property
+    def allowed_methods(self) -> Set[str]:
+        return self._allowed
+
+    @property
+    def method(self) -> str:
+        return self._method
 
 
 class HTTPNotAcceptable(HTTPClientError):
     status_code = 406
 
 
 class HTTPProxyAuthenticationRequired(HTTPClientError):
@@ -279,16 +344,16 @@
     status_code = 412
 
 
 class HTTPRequestEntityTooLarge(HTTPClientError):
     status_code = 413
 
     def __init__(self,
-                 max_size: float,
-                 actual_size: float,
+                 max_size: int,
+                 actual_size: int,
                  **kwargs: Any) -> None:
         kwargs.setdefault(
             'text',
             'Maximum request body size {} exceeded, '
             'actual body size {}'.format(max_size, actual_size)
         )
         super().__init__(**kwargs)
@@ -338,25 +403,28 @@
     status_code = 431
 
 
 class HTTPUnavailableForLegalReasons(HTTPClientError):
     status_code = 451
 
     def __init__(self,
-                 link: str,
+                 link: StrOrURL,
                  *,
                  headers: Optional[LooseHeaders]=None,
                  reason: Optional[str]=None,
-                 body: Any=None,
                  text: Optional[str]=None,
                  content_type: Optional[str]=None) -> None:
         super().__init__(headers=headers, reason=reason,
-                         body=body, text=text, content_type=content_type)
-        self.headers['Link'] = '<%s>; rel="blocked-by"' % link
-        self.link = link
+                         text=text, content_type=content_type)
+        self.headers['Link'] = '<{}>; rel="blocked-by"'.format(str(link))
+        self._link = URL(link)
+
+    @property
+    def link(self) -> URL:
+        return self._link
 
 
 ############################################################
 # 5xx Server Error
 ############################################################
 #  Response status codes beginning with the digit "5" indicate cases in
 #  which the server is aware that it has erred or is incapable of
@@ -405,7 +473,22 @@
 
 class HTTPNotExtended(HTTPServerError):
     status_code = 510
 
 
 class HTTPNetworkAuthenticationRequired(HTTPServerError):
     status_code = 511
+
+
+def _initialize_default_reason() -> None:
+    for obj in globals().values():
+        if isinstance(obj, type) and issubclass(obj, HTTPException):
+            if obj.status_code >= 0:
+                try:
+                    status = HTTPStatus(obj.status_code)
+                    obj.default_reason = status.phrase
+                except ValueError:
+                    pass
+
+
+_initialize_default_reason()
+del _initialize_default_reason
```

### Comparing `aiohttp-4.0.0a0/aiohttp/web_fileresponse.py` & `aiohttp-4.0.0a1/aiohttp/web_fileresponse.py`

 * *Files 1% similar despite different names*

```diff
@@ -20,15 +20,14 @@
 from .base_protocol import BaseProtocol
 from .helpers import set_exception, set_result
 from .http_writer import StreamWriter
 from .log import server_logger
 from .typedefs import LooseHeaders
 from .web_exceptions import (
     HTTPNotModified,
-    HTTPOk,
     HTTPPartialContent,
     HTTPPreconditionFailed,
     HTTPRequestRangeNotSatisfiable,
 )
 from .web_response import StreamResponse
 
 __all__ = ('FileResponse',)
@@ -241,15 +240,15 @@
             if not ct:
                 ct = 'application/octet-stream'
             should_set_ct = True
         else:
             encoding = 'gzip' if gzip else None
             should_set_ct = False
 
-        status = HTTPOk.status_code
+        status = self._status
         file_size = st.st_size
         count = file_size
 
         start = None
 
         ifrange = request.if_range
         if ifrange is None or st.st_mtime <= ifrange.timestamp():
@@ -314,16 +313,16 @@
                         file_size)
                     self.set_status(HTTPRequestRangeNotSatisfiable.status_code)
                     return await super().prepare(request)
 
                 status = HTTPPartialContent.status_code
                 # Even though you are sending the whole file, you should still
                 # return a HTTP 206 for a Range request.
+                self.set_status(status)
 
-        self.set_status(status)
         if should_set_ct:
             self.content_type = ct  # type: ignore
         if encoding:
             self.headers[hdrs.CONTENT_ENCODING] = encoding
         if gzip:
             self.headers[hdrs.VARY] = hdrs.ACCEPT_ENCODING
         self.last_modified = st.st_mtime  # type: ignore
@@ -333,12 +332,15 @@
 
         real_start = cast(int, start)
 
         if status == HTTPPartialContent.status_code:
             self.headers[hdrs.CONTENT_RANGE] = 'bytes {0}-{1}/{2}'.format(
                 real_start, real_start + count - 1, file_size)
 
-        with (await loop.run_in_executor(None, filepath.open, 'rb')) as fobj:
-            if start:  # be aware that start could be None or int=0 here.
-                await loop.run_in_executor(None, fobj.seek, start)
+        fobj = await loop.run_in_executor(None, filepath.open, 'rb')
+        if start:  # be aware that start could be None or int=0 here.
+            await loop.run_in_executor(None, fobj.seek, start)
 
+        try:
             return await self._sendfile(request, fobj, count)
+        finally:
+            await loop.run_in_executor(None, fobj.close)
```

### Comparing `aiohttp-4.0.0a0/aiohttp/web_log.py` & `aiohttp-4.0.0a1/aiohttp/web_log.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 import datetime
 import functools
 import logging
 import os
 import re
+import time as time_mod
 from collections import namedtuple
-from typing import Callable, Dict, Iterable, List, Tuple  # noqa
+from typing import Any, Callable, Dict, Iterable, List, Tuple  # noqa
 
 from .abc import AbstractAccessLogger
 from .web_request import BaseRequest
 from .web_response import StreamResponse
 
 KeyMethod = namedtuple('KeyMethod', 'key method')
 
@@ -145,17 +146,18 @@
         ip = request.remote
         return ip if ip is not None else '-'
 
     @staticmethod
     def _format_t(request: BaseRequest,
                   response: StreamResponse,
                   time: float) -> str:
-        now = datetime.datetime.utcnow()
+        tz = datetime.timezone(datetime.timedelta(seconds=-time_mod.timezone))
+        now = datetime.datetime.now(tz)
         start_time = now - datetime.timedelta(seconds=time)
-        return start_time.strftime('[%d/%b/%Y:%H:%M:%S +0000]')
+        return start_time.strftime('[%d/%b/%Y:%H:%M:%S %z]')
 
     @staticmethod
     def _format_P(request: BaseRequest,
                   response: StreamResponse,
                   time: float) -> str:
         return "<%s>" % os.getpid()
 
@@ -222,14 +224,14 @@
             for key, value in fmt_info:
                 values.append(value)
 
                 if key.__class__ is str:
                     extra[key] = value
                 else:
                     k1, k2 = key
-                    dct = extra.get(k1, {})
-                    dct[k2] = value  # type: ignore
-                    extra[k1] = dct  # type: ignore
+                    dct = extra.get(k1, {})  # type: Any
+                    dct[k2] = value
+                    extra[k1] = dct
 
             self.logger.info(self._log_format % tuple(values), extra=extra)
         except Exception:
             self.logger.exception("Error in logging")
```

### Comparing `aiohttp-4.0.0a0/aiohttp/web_middlewares.py` & `aiohttp-4.0.0a1/aiohttp/web_middlewares.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 import re
+import warnings
 from typing import TYPE_CHECKING, Awaitable, Callable, Tuple, Type, TypeVar
 
-from .web_exceptions import HTTPMovedPermanently, _HTTPMove
+from .web_exceptions import HTTPMove, HTTPPermanentRedirect
 from .web_request import Request
 from .web_response import StreamResponse
 from .web_urldispatcher import SystemRoute
 
 __all__ = (
     'middleware',
     'normalize_path_middleware',
@@ -27,26 +28,31 @@
     if match_info.http_exception is None:
         return True, alt_request
 
     return False, request
 
 
 def middleware(f: _Func) -> _Func:
-    f.__middleware_version__ = 1  # type: ignore
+    warnings.warn(
+        'Middleware decorator is deprecated since 4.0 '
+        'and its behaviour is default, '
+        'you can simply remove this decorator.',
+        DeprecationWarning,
+        stacklevel=2)
     return f
 
 
 _Handler = Callable[[Request], Awaitable[StreamResponse]]
 _Middleware = Callable[[Request, _Handler], Awaitable[StreamResponse]]
 
 
 def normalize_path_middleware(
         *, append_slash: bool=True, remove_slash: bool=False,
         merge_slashes: bool=True,
-        redirect_class: Type[_HTTPMove]=HTTPMovedPermanently) -> _Middleware:
+        redirect_class: Type[HTTPMove]=HTTPPermanentRedirect) -> _Middleware:
     """
     Middleware factory which produces a middleware that normalizes
     the path of a request. By normalizing it means:
 
         - Add or remove a trailing slash to the path.
         - Double slashes are replaced by one.
 
@@ -72,15 +78,14 @@
     If merge_slashes is True, merge multiple consecutive slashes in the
     path into one.
     """
 
     correct_configuration = not (append_slash and remove_slash)
     assert correct_configuration, "Cannot both remove and append slash"
 
-    @middleware
     async def impl(request: Request, handler: _Handler) -> StreamResponse:
         if isinstance(request.match_info.route, SystemRoute):
             paths_to_check = []
             if '?' in request.raw_path:
                 path, query = request.raw_path.split('?', 1)
                 query = '?' + query
             else:
@@ -92,15 +97,15 @@
             if append_slash and not request.path.endswith('/'):
                 paths_to_check.append(path + '/')
             if remove_slash and request.path.endswith('/'):
                 paths_to_check.append(path[:-1])
             if merge_slashes and append_slash:
                 paths_to_check.append(
                     re.sub('//+', '/', path + '/'))
-            if merge_slashes and remove_slash:
+            if merge_slashes and remove_slash and path.endswith('/'):
                 merged_slashes = re.sub('//+', '/', path)
                 paths_to_check.append(merged_slashes[:-1])
 
             for path in paths_to_check:
                 resolves, request = await _check_request_resolves(
                     request, path)
                 if resolves:
@@ -109,12 +114,11 @@
         return await handler(request)
 
     return impl
 
 
 def _fix_request_current_app(app: 'Application') -> _Middleware:
 
-    @middleware
     async def impl(request: Request, handler: _Handler) -> StreamResponse:
         with request.match_info.set_current_app(app):
             return await handler(request)
     return impl
```

### Comparing `aiohttp-4.0.0a0/aiohttp/web_protocol.py` & `aiohttp-4.0.0a1/aiohttp/web_protocol.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,29 +1,34 @@
 import asyncio
 import asyncio.streams
 import traceback
-import warnings
 from collections import deque
 from contextlib import suppress
 from html import escape as html_escape
 from http import HTTPStatus
 from logging import Logger
 from typing import (
     TYPE_CHECKING,
     Any,
     Awaitable,
     Callable,
     Optional,
+    Tuple,
     Type,
+    Union,
     cast,
 )
 
 import yarl
 
-from .abc import AbstractAccessLogger, AbstractStreamWriter
+from .abc import (
+    AbstractAccessLogger,
+    AbstractAsyncAccessLogger,
+    AbstractStreamWriter,
+)
 from .base_protocol import BaseProtocol
 from .helpers import CeilTimeout, current_task
 from .http import (
     HttpProcessingError,
     HttpRequestParser,
     HttpVersion10,
     RawRequestMessage,
@@ -47,14 +52,18 @@
                             StreamReader,
                             'RequestHandler',
                             AbstractStreamWriter,
                             'asyncio.Task[None]'],
                            BaseRequest]
 
 _RequestHandler = Callable[[BaseRequest], Awaitable[StreamResponse]]
+_AnyAbstractAccessLogger = Union[
+    Type[AbstractAsyncAccessLogger],
+    Type[AbstractAccessLogger],
+]
 
 
 ERROR = RawRequestMessage(
     'UNKNOWN', '/', HttpVersion10, {},
     {}, True, False, False, False, yarl.URL('/'))
 
 
@@ -62,14 +71,30 @@
     """Payload parsing error."""
 
 
 class PayloadAccessError(Exception):
     """Payload was accessed after response was sent."""
 
 
+class AccessLoggerWrapper(AbstractAsyncAccessLogger):
+    """
+    Wraps an AbstractAccessLogger so it behaves
+    like an AbstractAsyncAccessLogger.
+    """
+    def __init__(self, access_logger: AbstractAccessLogger):
+        self.access_logger = access_logger
+        super().__init__()
+
+    async def log(self,
+                  request: BaseRequest,
+                  response: StreamResponse,
+                  request_start: float) -> None:
+        self.access_logger.log(request, response, request_start)
+
+
 class RequestHandler(BaseProtocol):
     """HTTP protocol implementation.
 
     RequestHandler handles incoming HTTP request. It reads request line,
     request headers and request payload and calls handle_request() method.
     By default it always returns with 404 response.
 
@@ -79,16 +104,14 @@
 
     :param keepalive_timeout: number of seconds before closing
                               keep-alive connection
     :type keepalive_timeout: int or None
 
     :param bool tcp_keepalive: TCP keep-alive is on, default is on
 
-    :param bool debug: enable debug mode
-
     :param logger: custom logger object
     :type logger: aiohttp.log.server_logger
 
     :param access_log_class: custom class for access_logger
     :type access_log_class: aiohttp.abc.AbstractAccessLogger
 
     :param access_log: custom logging object
@@ -103,41 +126,42 @@
     :param int max_field_size: Optional maximum header field size
 
     :param int max_headers: Optional maximum header size
 
     """
     KEEPALIVE_RESCHEDULE_DELAY = 1
 
-    __slots__ = ('_request_count', '_keep_alive', '_manager',
+    __slots__ = ('_request_count', '_keepalive', '_manager',
                  '_request_handler', '_request_factory', '_tcp_keepalive',
                  '_keepalive_time', '_keepalive_handle', '_keepalive_timeout',
                  '_lingering_time', '_messages', '_message_tail',
                  '_waiter', '_error_handler', '_task_handler',
                  '_upgrade', '_payload_parser', '_request_parser',
-                 '_reading_paused', 'logger', 'debug', 'access_log',
-                 'access_logger', '_close', '_force_close')
+                 '_reading_paused', 'logger', 'access_log',
+                 'access_logger', '_close', '_force_close',
+                 '_current_request')
 
     def __init__(self, manager: 'Server', *,
                  loop: asyncio.AbstractEventLoop,
                  keepalive_timeout: float=75.,  # NGINX default is 75 secs
                  tcp_keepalive: bool=True,
                  logger: Logger=server_logger,
-                 access_log_class: Type[AbstractAccessLogger]=AccessLogger,
+                 access_log_class: _AnyAbstractAccessLogger=AccessLogger,
                  access_log: Logger=access_logger,
                  access_log_format: str=AccessLogger.LOG_FORMAT,
-                 debug: bool=False,
                  max_line_size: int=8190,
                  max_headers: int=32768,
                  max_field_size: int=8190,
                  lingering_time: float=10.0):
 
         super().__init__(loop)
 
         self._request_count = 0
         self._keepalive = False
+        self._current_request = None  # type: Optional[BaseRequest]
         self._manager = manager  # type: Optional[Server]
         self._request_handler = manager.request_handler  # type: Optional[_RequestHandler]  # noqa
         self._request_factory = manager.request_factory  # type: Optional[_RequestFactory]  # noqa
 
         self._tcp_keepalive = tcp_keepalive
         # placeholder to be replaced on keepalive timeout setup
         self._keepalive_time = 0.0
@@ -158,19 +182,21 @@
             self, loop,
             max_line_size=max_line_size,
             max_field_size=max_field_size,
             max_headers=max_headers,
             payload_exception=RequestPayloadError)   # type: Optional[HttpRequestParser]  # noqa
 
         self.logger = logger
-        self.debug = debug
         self.access_log = access_log
         if access_log:
-            self.access_logger = access_log_class(
-                access_log, access_log_format)  # type: Optional[AbstractAccessLogger]  # noqa
+            if issubclass(access_log_class, AbstractAsyncAccessLogger):
+                self.access_logger = access_log_class()  # type: Optional[AbstractAsyncAccessLogger]  # noqa
+            else:
+                access_logger = access_log_class(access_log, access_log_format)
+                self.access_logger = AccessLoggerWrapper(access_logger)
         else:
             self.access_logger = None
 
         self._close = False
         self._force_close = False
 
     def __repr__(self) -> str:
@@ -197,14 +223,17 @@
         # wait for handlers
         with suppress(asyncio.CancelledError, asyncio.TimeoutError):
             with CeilTimeout(timeout, loop=self._loop):
                 if (self._error_handler is not None and
                         not self._error_handler.done()):
                     await self._error_handler
 
+                if self._current_request is not None:
+                    self._current_request._cancel(asyncio.CancelledError())
+
                 if (self._task_handler is not None and
                         not self._task_handler.done()):
                     await self._task_handler
 
         # force-close non-idle handler
         if self._task_handler is not None:
             self._task_handler.cancel()
@@ -236,16 +265,18 @@
         self._request_factory = None
         self._request_handler = None
         self._request_parser = None
 
         if self._keepalive_handle is not None:
             self._keepalive_handle.cancel()
 
-        if self._task_handler is not None:
-            self._task_handler.cancel()
+        if self._current_request is not None:
+            if exc is None:
+                exc = ConnectionResetError("Connetion lost")
+            self._current_request._cancel(exc)
 
         if self._error_handler is not None:
             self._error_handler.cancel()
 
         self._task_handler = None
 
         if self._payload_parser is not None:
@@ -336,23 +367,24 @@
         self._force_close = True
         if self._waiter:
             self._waiter.cancel()
         if self.transport is not None:
             self.transport.close()
             self.transport = None
 
-    def log_access(self,
-                   request: BaseRequest,
-                   response: StreamResponse,
-                   time: float) -> None:
+    async def log_access(self,
+                         request: BaseRequest,
+                         response: StreamResponse,
+                         request_start: float) -> None:
         if self.access_logger is not None:
-            self.access_logger.log(request, response, time)
+            await self.access_logger.log(request, response,
+                                         self._loop.time() - request_start)
 
     def log_debug(self, *args: Any, **kw: Any) -> None:
-        if self.debug:
+        if self._loop.get_debug():
             self.logger.debug(*args, **kw)
 
     def log_exception(self, *args: Any, **kw: Any) -> None:
         self.logger.exception(*args, **kw)
 
     def _process_keepalive(self) -> None:
         if self._force_close or not self._keepalive:
@@ -367,14 +399,45 @@
                 return
 
         # not all request handlers are done,
         # reschedule itself to next second
         self._keepalive_handle = self._loop.call_later(
             self.KEEPALIVE_RESCHEDULE_DELAY, self._process_keepalive)
 
+    async def _handle_request(self,
+                              request: BaseRequest,
+                              start_time: float,
+                              ) -> Tuple[StreamResponse, bool]:
+        assert self._request_handler is not None
+        try:
+            try:
+                self._current_request = request
+                resp = await self._request_handler(request)
+            finally:
+                self._current_request = None
+        except HTTPException as exc:
+            resp = Response(status=exc.status,
+                            reason=exc.reason,
+                            text=exc.text,
+                            headers=exc.headers)
+            reset = await self.finish_response(request, resp, start_time)
+        except asyncio.CancelledError:
+            raise
+        except asyncio.TimeoutError as exc:
+            self.log_debug('Request handler timed out.', exc_info=exc)
+            resp = self.handle_error(request, 504)
+            reset = await self.finish_response(request, resp, start_time)
+        except Exception as exc:
+            resp = self.handle_error(request, 500, exc)
+            reset = await self.finish_response(request, resp, start_time)
+        else:
+            reset = await self.finish_response(request, resp, start_time)
+
+        return resp, reset
+
     async def start(self) -> None:
         """Process incoming request.
 
         It reads request line, request headers and request payload, then
         calls handle_request() method. Subclass has to override
         handle_request(). start() handles various exceptions in request
         or response handling. Connection is being closed always unless
@@ -399,65 +462,39 @@
                 except asyncio.CancelledError:
                     break
                 finally:
                     self._waiter = None
 
             message, payload = self._messages.popleft()
 
-            if self.access_log:
-                now = loop.time()
+            start = loop.time()
 
             manager.requests_count += 1
             writer = StreamWriter(self, loop)
             request = self._request_factory(
                 message, payload, self, writer, handler)
             try:
+                # a new task is used for copy context vars (#3406)
+                task = self._loop.create_task(
+                    self._handle_request(request, start))
                 try:
-                    # a new task is used for copy context vars (#3406)
-                    task = self._loop.create_task(
-                        self._request_handler(request))
-                    resp = await task
-                except HTTPException as exc:
-                    resp = exc
-                except asyncio.CancelledError:
+                    resp, reset = await task
+                except (asyncio.CancelledError, ConnectionError):
                     self.log_debug('Ignored premature client disconnection')
                     break
-                except asyncio.TimeoutError as exc:
-                    self.log_debug('Request handler timed out.', exc_info=exc)
-                    resp = self.handle_error(request, 504)
-                except Exception as exc:
-                    resp = self.handle_error(request, 500, exc)
-                else:
-                    # Deprecation warning (See #2415)
-                    if getattr(resp, '__http_exception__', False):
-                        warnings.warn(
-                            "returning HTTPException object is deprecated "
-                            "(#2415) and will be removed, "
-                            "please raise the exception instead",
-                            DeprecationWarning)
-
-                if self.debug:
-                    if not isinstance(resp, StreamResponse):
-                        if resp is None:
-                            raise RuntimeError("Missing return "
-                                               "statement on request handler")
-                        else:
-                            raise RuntimeError("Web-handler should return "
-                                               "a response instance, "
-                                               "got {!r}".format(resp))
-                await resp.prepare(request)
-                await resp.write_eof()
+
+                # Drop the processed task from asyncio.Task.all_tasks() early
+                del task
+                if reset:
+                    self.log_debug('Ignored premature client disconnection 2')
+                    break
 
                 # notify server about keep-alive
                 self._keepalive = bool(resp.keep_alive)
 
-                # log access
-                if self.access_log:
-                    self.log_access(request, resp, loop.time() - now)
-
                 # check payload
                 if not payload.is_eof():
                     lingering_time = self._lingering_time
                     if not self._force_close and lingering_time:
                         self.log_debug(
                             'Start lingering close timer for %s sec.',
                             lingering_time)
@@ -480,15 +517,15 @@
 
                 payload.set_exception(PayloadAccessError())
 
             except asyncio.CancelledError:
                 self.log_debug('Ignored premature client disconnection ')
                 break
             except RuntimeError as exc:
-                if self.debug:
+                if self._loop.get_debug():
                     self.log_exception(
                         'Unhandled runtime exception', exc_info=exc)
                 self.force_close()
             except Exception as exc:
                 self.log_exception('Unhandled exception', exc_info=exc)
                 self.force_close()
             finally:
@@ -509,14 +546,50 @@
 
         # remove handler, close transport if no handlers left
         if not self._force_close:
             self._task_handler = None
             if self.transport is not None and self._error_handler is None:
                 self.transport.close()
 
+    async def finish_response(self,
+                              request: BaseRequest,
+                              resp: StreamResponse,
+                              start_time: float) -> bool:
+        """
+        Prepare the response and write_eof, then log access. This has to
+        be called within the context of any exception so the access logger
+        can get exception information. Returns True if the client disconnects
+        prematurely.
+        """
+        if self._request_parser is not None:
+            self._request_parser.set_upgraded(False)
+            self._upgrade = False
+            if self._message_tail:
+                self._request_parser.feed_data(self._message_tail)
+                self._message_tail = b''
+        try:
+            prepare_meth = resp.prepare
+        except AttributeError:
+            if resp is None:
+                raise RuntimeError("Missing return "
+                                   "statement on request handler")
+            else:
+                raise RuntimeError("Web-handler should return "
+                                   "a response instance, "
+                                   "got {!r}".format(resp))
+        try:
+            await prepare_meth(request)
+            await resp.write_eof()
+        except ConnectionError:
+            await self.log_access(request, resp, start_time)
+            return True
+        else:
+            await self.log_access(request, resp, start_time)
+            return False
+
     def handle_error(self,
                      request: BaseRequest,
                      status: int=500,
                      exc: Optional[BaseException]=None,
                      message: Optional[str]=None) -> StreamResponse:
         """Handle errors.
 
@@ -527,15 +600,15 @@
         ct = 'text/plain'
         if status == HTTPStatus.INTERNAL_SERVER_ERROR:
             title = '{0.value} {0.phrase}'.format(
                 HTTPStatus.INTERNAL_SERVER_ERROR
             )
             msg = HTTPStatus.INTERNAL_SERVER_ERROR.description
             tb = None
-            if self.debug:
+            if self._loop.get_debug():
                 with suppress(Exception):
                     tb = traceback.format_exc()
 
             if 'text/html' in request.headers.get('Accept', ''):
                 if tb:
                     tb = html_escape(tb)
                     msg = '<h2>Traceback:</h2>\n<pre>{}</pre>'.format(tb)
```

### Comparing `aiohttp-4.0.0a0/aiohttp/web_request.py` & `aiohttp-4.0.0a1/aiohttp/web_request.py`

 * *Files 4% similar despite different names*

```diff
@@ -2,15 +2,14 @@
 import datetime
 import io
 import re
 import socket
 import string
 import tempfile
 import types
-import warnings
 from email.utils import parsedate
 from http.cookies import SimpleCookie
 from types import MappingProxyType
 from typing import (  # noqa
     TYPE_CHECKING,
     Any,
     Dict,
@@ -26,26 +25,36 @@
 
 import attr
 from multidict import CIMultiDict, CIMultiDictProxy, MultiDict, MultiDictProxy
 from yarl import URL
 
 from . import hdrs
 from .abc import AbstractStreamWriter
-from .helpers import DEBUG, ChainMapProxy, HeadersMixin, reify, sentinel
+from .helpers import (
+    ChainMapProxy,
+    HeadersMixin,
+    is_expected_content_type,
+    reify,
+    sentinel,
+)
 from .http_parser import RawRequestMessage
-from .multipart import MultipartReader
+from .multipart import BodyPartReader, MultipartReader
 from .streams import EmptyStreamReader, StreamReader
 from .typedefs import (
     DEFAULT_JSON_DECODER,
     JSONDecoder,
     LooseHeaders,
     RawHeaders,
     StrOrURL,
 )
-from .web_exceptions import HTTPRequestEntityTooLarge
+from .web_exceptions import (
+    HTTPBadRequest,
+    HTTPRequestEntityTooLarge,
+    HTTPUnsupportedMediaType,
+)
 from .web_response import StreamResponse
 
 __all__ = ('BaseRequest', 'FileField', 'Request')
 
 
 if TYPE_CHECKING:  # pragma: no cover
     from .web_app import Application  # noqa
@@ -93,30 +102,31 @@
 
 
 class BaseRequest(MutableMapping[str, Any], HeadersMixin):
 
     POST_METHODS = {hdrs.METH_PATCH, hdrs.METH_POST, hdrs.METH_PUT,
                     hdrs.METH_TRACE, hdrs.METH_DELETE}
 
-    ATTRS = HeadersMixin.ATTRS | frozenset([
+    __slots__ = (
         '_message', '_protocol', '_payload_writer', '_payload', '_headers',
         '_method', '_version', '_rel_url', '_post', '_read_bytes',
         '_state', '_cache', '_task', '_client_max_size', '_loop',
-        '_transport_sslcontext', '_transport_peername'])
+        '_transport_sslcontext', '_transport_peername')
 
     def __init__(self, message: RawRequestMessage,
                  payload: StreamReader, protocol: 'RequestHandler',
                  payload_writer: AbstractStreamWriter,
                  task: 'asyncio.Task[None]',
                  loop: asyncio.AbstractEventLoop,
                  *, client_max_size: int=1024**2,
                  state: Optional[Dict[str, Any]]=None,
                  scheme: Optional[str]=None,
                  host: Optional[str]=None,
                  remote: Optional[str]=None) -> None:
+        super().__init__()
         if state is None:
             state = {}
         self._message = message
         self._protocol = protocol
         self._payload_writer = payload_writer
 
         self._payload = payload
@@ -210,31 +220,17 @@
         return self._protocol.transport
 
     @property
     def writer(self) -> AbstractStreamWriter:
         return self._payload_writer
 
     @reify
-    def message(self) -> RawRequestMessage:
-        warnings.warn("Request.message is deprecated",
-                      DeprecationWarning,
-                      stacklevel=3)
-        return self._message
-
-    @reify
     def rel_url(self) -> URL:
         return self._rel_url
 
-    @reify
-    def loop(self) -> asyncio.AbstractEventLoop:
-        warnings.warn("request.loop property is deprecated",
-                      DeprecationWarning,
-                      stacklevel=2)
-        return self._loop
-
     # MutableMapping API
 
     def __getitem__(self, key: str) -> Any:
         return self._state[key]
 
     def __setitem__(self, key: str, value: Any) -> None:
         self._state[key] = value
@@ -521,22 +517,14 @@
 
     @reify
     def content(self) -> StreamReader:
         """Return raw payload stream."""
         return self._payload
 
     @property
-    def has_body(self) -> bool:
-        """Return True if request's HTTP BODY can be read, False otherwise."""
-        warnings.warn(
-            "Deprecated, use .can_read_body #2005",
-            DeprecationWarning, stacklevel=2)
-        return not self._payload.at_eof()
-
-    @property
     def can_read_body(self) -> bool:
         """Return True if request's HTTP BODY can be read, False otherwise."""
         return not self._payload.at_eof()
 
     @reify
     def body_exists(self) -> bool:
         """Return True if request has HTTP BODY, False otherwise."""
@@ -572,19 +560,30 @@
             self._read_bytes = bytes(body)
         return self._read_bytes
 
     async def text(self) -> str:
         """Return BODY as text using encoding from .charset."""
         bytes_body = await self.read()
         encoding = self.charset or 'utf-8'
-        return bytes_body.decode(encoding)
-
-    async def json(self, *, loads: JSONDecoder=DEFAULT_JSON_DECODER) -> Any:
+        try:
+            return bytes_body.decode(encoding)
+        except LookupError:
+            raise HTTPUnsupportedMediaType()
+
+    async def json(self, *,
+                   loads: JSONDecoder=DEFAULT_JSON_DECODER,
+                   content_type: Optional[str]='application/json') -> Any:
         """Return BODY as JSON."""
         body = await self.text()
+        if content_type:
+            ctype = self.headers.get(hdrs.CONTENT_TYPE, '').lower()
+            if not is_expected_content_type(ctype, content_type):
+                raise HTTPBadRequest(text=('Attempt to decode JSON with '
+                                           'unexpected mimetype: %s' % ctype))
+
         return loads(body)
 
     async def multipart(self) -> MultipartReader:
         """Return async iterator to process BODY as multipart."""
         return MultipartReader(self._headers, self._payload)
 
     async def post(self) -> 'MultiDictProxy[Union[str, bytes, FileField]]':
@@ -607,58 +606,71 @@
         if content_type == 'multipart/form-data':
             multipart = await self.multipart()
             max_size = self._client_max_size
 
             field = await multipart.next()
             while field is not None:
                 size = 0
-                content_type = field.headers.get(hdrs.CONTENT_TYPE)
+                field_ct = field.headers.get(hdrs.CONTENT_TYPE)
 
-                if field.filename:
-                    # store file in temp file
-                    tmp = tempfile.TemporaryFile()
-                    chunk = await field.read_chunk(size=2**16)
-                    while chunk:
-                        chunk = field.decode(chunk)
-                        tmp.write(chunk)
-                        size += len(chunk)
+                if isinstance(field, BodyPartReader):
+                    if field.filename and field_ct:
+                        # store file in temp file
+                        tmp = tempfile.TemporaryFile()
+                        chunk = await field.read_chunk(size=2**16)
+                        while chunk:
+                            chunk = field.decode(chunk)
+                            tmp.write(chunk)
+                            size += len(chunk)
+                            if 0 < max_size < size:
+                                raise HTTPRequestEntityTooLarge(
+                                    max_size=max_size,
+                                    actual_size=size
+                                )
+                            chunk = await field.read_chunk(size=2**16)
+                        tmp.seek(0)
+
+                        ff = FileField(field.name, field.filename,
+                                       cast(io.BufferedReader, tmp),
+                                       field_ct, field.headers)
+                        out.add(field.name, ff)
+                    else:
+                        # deal with ordinary data
+                        value = await field.read(decode=True)
+                        if field_ct is None or \
+                                field_ct.startswith('text/'):
+                            charset = field.get_charset(default='utf-8')
+                            out.add(field.name, value.decode(charset))
+                        else:
+                            out.add(field.name, value)
+                        size += len(value)
                         if 0 < max_size < size:
                             raise HTTPRequestEntityTooLarge(
                                 max_size=max_size,
                                 actual_size=size
                             )
-                        chunk = await field.read_chunk(size=2**16)
-                    tmp.seek(0)
-
-                    ff = FileField(field.name, field.filename,
-                                   cast(io.BufferedReader, tmp),
-                                   content_type, field.headers)
-                    out.add(field.name, ff)
                 else:
-                    value = await field.read(decode=True)
-                    if content_type is None or \
-                            content_type.startswith('text/'):
-                        charset = field.get_charset(default='utf-8')
-                        value = value.decode(charset)
-                    out.add(field.name, value)
-                    size += len(value)
-                    if 0 < max_size < size:
-                        raise HTTPRequestEntityTooLarge(
-                            max_size=max_size,
-                            actual_size=size
-                        )
+                    raise ValueError(
+                        'To decode nested multipart you need '
+                        'to use custom reader',
+                    )
 
                 field = await multipart.next()
         else:
             data = await self.read()
             if data:
                 charset = self.charset or 'utf-8'
+                bytes_query = data.rstrip()
+                try:
+                    query = bytes_query.decode(charset)
+                except LookupError:
+                    raise HTTPUnsupportedMediaType()
                 out.extend(
                     parse_qsl(
-                        data.rstrip().decode(charset),
+                        qs=query,
                         keep_blank_values=True,
                         encoding=charset))
 
         self._post = MultiDictProxy(out)
         return self._post
 
     def __repr__(self) -> str:
@@ -666,41 +678,37 @@
             .decode('ascii')
         return "<{} {} {} >".format(self.__class__.__name__,
                                     self._method, ascii_encodable_path)
 
     def __eq__(self, other: object) -> bool:
         return id(self) == id(other)
 
+    def __bool__(self) -> bool:
+        return True
+
     async def _prepare_hook(self, response: StreamResponse) -> None:
         return
 
+    def _cancel(self, exc: BaseException) -> None:
+        self._payload.set_exception(exc)
+
 
 class Request(BaseRequest):
 
-    ATTRS = BaseRequest.ATTRS | frozenset(['_match_info'])
+    __slots__ = ('_match_info',)
 
     def __init__(self, *args: Any, **kwargs: Any) -> None:
         super().__init__(*args, **kwargs)
 
         # matchdict, route_name, handler
         # or information about traversal lookup
 
         # initialized after route resolving
         self._match_info = None  # type: Optional[UrlMappingMatchInfo]
 
-    if DEBUG:
-        def __setattr__(self, name: str, val: Any) -> None:
-            if name not in self.ATTRS:
-                warnings.warn("Setting custom {}.{} attribute "
-                              "is discouraged".format(self.__class__.__name__,
-                                                      name),
-                              DeprecationWarning,
-                              stacklevel=2)
-            super().__setattr__(name, val)
-
     def clone(self, *, method: str=sentinel, rel_url:
               StrOrURL=sentinel, headers: LooseHeaders=sentinel,
               scheme: str=sentinel, host: str=sentinel, remote:
               str=sentinel) -> 'Request':
         ret = super().clone(method=method,
                             rel_url=rel_url,
                             headers=headers,
```

### Comparing `aiohttp-4.0.0a0/aiohttp/web_response.py` & `aiohttp-4.0.0a1/aiohttp/web_response.py`

 * *Files 5% similar despite different names*

```diff
@@ -55,20 +55,25 @@
 ############################################################
 # HTTP Response classes
 ############################################################
 
 
 class StreamResponse(BaseClass, HeadersMixin):
 
-    _length_check = True
+    __slots__ = ('_length_check', '_body', '_keep_alive', '_chunked',
+                 '_compression', '_compression_force', '_cookies', '_req',
+                 '_payload_writer', '_eof_sent', '_body_length', '_state',
+                 '_headers', '_status', '_reason')
 
     def __init__(self, *,
                  status: int=200,
                  reason: Optional[str]=None,
                  headers: Optional[LooseHeaders]=None) -> None:
+        super().__init__()
+        self._length_check = True
         self._body = None
         self._keep_alive = None  # type: Optional[bool]
         self._chunked = False
         self._compression = False
         self._compression_force = None  # type: Optional[ContentCoding]
         self._cookies = SimpleCookie()
 
@@ -77,15 +82,15 @@
         self._eof_sent = False
         self._body_length = 0
         self._state = {}  # type: Dict[str, Any]
 
         if headers is not None:
             self._headers = CIMultiDict(headers)  # type: CIMultiDict[str]
         else:
-            self._headers = CIMultiDict()  # type: CIMultiDict[str]
+            self._headers = CIMultiDict()
 
         self.set_status(status, reason)
 
     @property
     def prepared(self) -> bool:
         return self._payload_writer is not None
 
@@ -131,44 +136,27 @@
     def force_close(self) -> None:
         self._keep_alive = False
 
     @property
     def body_length(self) -> int:
         return self._body_length
 
-    @property
-    def output_length(self) -> int:
-        warnings.warn('output_length is deprecated', DeprecationWarning)
-        assert self._payload_writer
-        return self._payload_writer.buffer_size
-
-    def enable_chunked_encoding(self, chunk_size: Optional[int]=None) -> None:
+    def enable_chunked_encoding(self) -> None:
         """Enables automatic chunked transfer encoding."""
         self._chunked = True
 
         if hdrs.CONTENT_LENGTH in self._headers:
             raise RuntimeError("You can't enable chunked encoding when "
                                "a content length is set")
-        if chunk_size is not None:
-            warnings.warn('Chunk size is deprecated #1615', DeprecationWarning)
 
     def enable_compression(self,
-                           force: Optional[Union[bool, ContentCoding]]=None
+                           force: Optional[ContentCoding]=None
                            ) -> None:
         """Enables response compression encoding."""
         # Backwards compatibility for when force was a bool <0.17.
-        if type(force) == bool:
-            force = ContentCoding.deflate if force else ContentCoding.identity
-            warnings.warn("Using boolean for force is deprecated #3318",
-                          DeprecationWarning)
-        elif force is not None:
-            assert isinstance(force, ContentCoding), ("force should one of "
-                                                      "None, bool or "
-                                                      "ContentEncoding")
-
         self._compression = True
         self._compression_force = force
 
     @property
     def headers(self) -> 'CIMultiDict[str]':
         return self._headers
 
@@ -478,14 +466,19 @@
 
     def __eq__(self, other: object) -> bool:
         return self is other
 
 
 class Response(StreamResponse):
 
+    __slots__ = ('_body_payload',
+                 '_compressed_body',
+                 '_zlib_executor_size',
+                 '_zlib_executor')
+
     def __init__(self, *,
                  body: Any=None,
                  status: int=200,
                  reason: Optional[str]=None,
                  text: Optional[str]=None,
                  headers: Optional[LooseHeaders]=None,
                  content_type: Optional[str]=None,
```

### Comparing `aiohttp-4.0.0a0/aiohttp/web_routedef.py` & `aiohttp-4.0.0a1/aiohttp/web_routedef.py`

 * *Files 0% similar despite different names*

```diff
@@ -6,14 +6,15 @@
     Awaitable,
     Callable,
     Dict,
     Iterator,
     List,
     Optional,
     Sequence,
+    Type,
     Union,
     overload,
 )
 
 import attr
 
 from . import hdrs
@@ -36,15 +37,15 @@
 class AbstractRouteDef(abc.ABC):
     @abc.abstractmethod
     def register(self, router: UrlDispatcher) -> None:
         pass  # pragma: no cover
 
 
 _SimpleHandler = Callable[[Request], Awaitable[StreamResponse]]
-_HandlerType = Union[AbstractView, _SimpleHandler]
+_HandlerType = Union[Type[AbstractView], _SimpleHandler]
 
 
 @attr.s(frozen=True, repr=False, slots=True)
 class RouteDef(AbstractRouteDef):
     method = attr.ib(type=str)
     path = attr.ib(type=str)
     handler = attr.ib()  # type: _HandlerType
@@ -116,15 +117,15 @@
     return route(hdrs.METH_PATCH, path, handler, **kwargs)
 
 
 def delete(path: str, handler: _HandlerType, **kwargs: Any) -> RouteDef:
     return route(hdrs.METH_DELETE, path, handler, **kwargs)
 
 
-def view(path: str, handler: AbstractView, **kwargs: Any) -> RouteDef:
+def view(path: str, handler: Type[AbstractView], **kwargs: Any) -> RouteDef:
     return route(hdrs.METH_ANY, path, handler, **kwargs)
 
 
 def static(prefix: str, path: PathLike,
            **kwargs: Any) -> StaticDef:
     return StaticDef(prefix, path, kwargs)
```

### Comparing `aiohttp-4.0.0a0/aiohttp/web_runner.py` & `aiohttp-4.0.0a1/aiohttp/web_runner.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,26 +1,33 @@
 import asyncio
 import signal
 import socket
 from abc import ABC, abstractmethod
-from typing import Any, List, Optional, Set
+from typing import Any, List, Optional, Set, Type
 
 from yarl import URL
 
+from .abc import AbstractAccessLogger, AbstractStreamWriter
+from .helpers import get_running_loop
+from .http_parser import RawRequestMessage
+from .streams import StreamReader
 from .web_app import Application
+from .web_log import AccessLogger
+from .web_protocol import RequestHandler
+from .web_request import Request
 from .web_server import Server
 
 try:
     from ssl import SSLContext
 except ImportError:
     SSLContext = object  # type: ignore
 
 
-__all__ = ('BaseSite', 'TCPSite', 'UnixSite', 'SockSite', 'BaseRunner',
-           'AppRunner', 'ServerRunner', 'GracefulExit')
+__all__ = ('BaseSite', 'TCPSite', 'UnixSite', 'NamedPipeSite', 'SockSite',
+           'BaseRunner', 'AppRunner', 'ServerRunner', 'GracefulExit')
 
 
 class GracefulExit(SystemExit):
     code = 1
 
 
 def _raise_graceful_exit() -> None:
@@ -54,15 +61,17 @@
 
     async def stop(self) -> None:
         self._runner._check_site(self)
         if self._server is None:
             self._runner._unreg_site(self)
             return  # not started yet
         self._server.close()
-        await self._server.wait_closed()
+        # named pipes do not have wait_closed property
+        if hasattr(self._server, 'wait_closed'):
+            await self._server.wait_closed()
         await self._runner.shutdown()
         assert self._runner.server
         await self._runner.server.shutdown(self._shutdown_timeout)
         self._runner._unreg_site(self)
 
 
 class TCPSite(BaseSite):
@@ -91,15 +100,15 @@
         return str(URL.build(scheme=scheme, host=self._host, port=self._port))
 
     async def start(self) -> None:
         await super().start()
         loop = asyncio.get_event_loop()
         server = self._runner.server
         assert server is not None
-        self._server = await loop.create_server(
+        self._server = await loop.create_server(  # type: ignore
             server, self._host, self._port,
             ssl=self._ssl_context, backlog=self._backlog,
             reuse_address=self._reuse_address,
             reuse_port=self._reuse_port)
 
 
 class UnixSite(BaseSite):
@@ -124,14 +133,41 @@
         server = self._runner.server
         assert server is not None
         self._server = await loop.create_unix_server(
             server, self._path,
             ssl=self._ssl_context, backlog=self._backlog)
 
 
+class NamedPipeSite(BaseSite):
+    __slots__ = ('_path', )
+
+    def __init__(self, runner: 'BaseRunner', path: str, *,
+                 shutdown_timeout: float=60.0) -> None:
+        loop = asyncio.get_event_loop()
+        if not isinstance(loop, asyncio.ProactorEventLoop):  # type: ignore
+            raise RuntimeError("Named Pipes only available in proactor"
+                               "loop under windows")
+        super().__init__(runner, shutdown_timeout=shutdown_timeout)
+        self._path = path
+
+    @property
+    def name(self) -> str:
+        return self._path
+
+    async def start(self) -> None:
+        await super().start()
+        loop = asyncio.get_event_loop()
+        server = self._runner.server
+        assert server is not None
+        _server = await loop.start_serving_pipe(  # type: ignore
+            server, self._path
+        )
+        self._server = _server[0]
+
+
 class SockSite(BaseSite):
     __slots__ = ('_sock', '_name')
 
     def __init__(self, runner: 'BaseRunner', sock: socket.socket, *,
                  shutdown_timeout: float=60.0,
                  ssl_context: Optional[SSLContext]=None,
                  backlog: int=128) -> None:
@@ -151,15 +187,15 @@
         return self._name
 
     async def start(self) -> None:
         await super().start()
         loop = asyncio.get_event_loop()
         server = self._runner.server
         assert server is not None
-        self._server = await loop.create_server(
+        self._server = await loop.create_server(  # type: ignore
             server, sock=self._sock,
             ssl=self._ssl_context, backlog=self._backlog)
 
 
 class BaseRunner(ABC):
     __slots__ = ('_handle_signals', '_kwargs', '_server', '_sites')
 
@@ -211,15 +247,15 @@
 
         if self._server is None:
             # no started yet, do nothing
             return
 
         # The loop over sites is intentional, an exception on gather()
         # leaves self._sites in unpredictable state.
-        # The loop guaranties that a site is either deleted on success or
+        # The loop guarantees that a site is either deleted on success or
         # still present on failure
         for site in list(self._sites):
             await site.stop()
         await self._cleanup_server()
         self._server = None
         if self._handle_signals:
             try:
@@ -277,32 +313,60 @@
 
 class AppRunner(BaseRunner):
     """Web Application runner"""
 
     __slots__ = ('_app',)
 
     def __init__(self, app: Application, *,
-                 handle_signals: bool=False, **kwargs: Any) -> None:
-        super().__init__(handle_signals=handle_signals, **kwargs)
+                 handle_signals: bool=False,
+                 access_log_class: Type[
+                     AbstractAccessLogger]=AccessLogger,
+                 **kwargs: Any) -> None:
+
         if not isinstance(app, Application):
             raise TypeError("The first argument should be web.Application "
                             "instance, got {!r}".format(app))
+        kwargs['access_log_class'] = access_log_class
+
+        if app._handler_args:
+            for k, v in app._handler_args.items():
+                kwargs[k] = v
+
+        if not issubclass(kwargs['access_log_class'], AbstractAccessLogger):
+            raise TypeError(
+                'access_log_class must be subclass of '
+                'aiohttp.abc.AbstractAccessLogger, got {}'.format(
+                    kwargs['access_log_class']))
+
+        super().__init__(handle_signals=handle_signals, **kwargs)
         self._app = app
 
     @property
     def app(self) -> Application:
         return self._app
 
     async def shutdown(self) -> None:
         await self._app.shutdown()
 
     async def _make_server(self) -> Server:
-        loop = asyncio.get_event_loop()
-        self._app._set_loop(loop)
         self._app.on_startup.freeze()
         await self._app.startup()
         self._app.freeze()
 
-        return self._app._make_handler(loop=loop, **self._kwargs)
+        return Server(self._app._handle,  # type: ignore
+                      request_factory=self._make_request,
+                      **self._kwargs)
+
+    def _make_request(self, message: RawRequestMessage,
+                      payload: StreamReader,
+                      protocol: RequestHandler,
+                      writer: AbstractStreamWriter,
+                      task: 'asyncio.Task[None]',
+                      _cls: Type[Request]=Request) -> Request:
+        loop = get_running_loop()
+        return _cls(
+            message, payload, protocol, writer, task,
+            loop,
+            client_max_size=self.app._client_max_size)
 
     async def _cleanup_server(self) -> None:
         await self._app.cleanup()
```

### Comparing `aiohttp-4.0.0a0/aiohttp/web_server.py` & `aiohttp-4.0.0a1/aiohttp/web_server.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,9 +1,10 @@
 """Low level HTTP server."""
 import asyncio
+import warnings
 from typing import Any, Awaitable, Callable, Dict, List, Optional  # noqa
 
 from .abc import AbstractStreamWriter
 from .helpers import get_running_loop
 from .http_parser import RawRequestMessage
 from .streams import StreamReader
 from .web_protocol import RequestHandler, _RequestFactory, _RequestHandler
@@ -14,17 +15,22 @@
 
 class Server:
 
     def __init__(self,
                  handler: _RequestHandler,
                  *,
                  request_factory: Optional[_RequestFactory]=None,
-                 loop: Optional[asyncio.AbstractEventLoop]=None,
+                 debug: Optional[bool]=None,
                  **kwargs: Any) -> None:
-        self._loop = get_running_loop(loop)
+        if debug is not None:
+            warnings.warn("debug argument is no-op since 4.0 "
+                          "and scheduled for removal in 5.0",
+                          DeprecationWarning,
+                          stacklevel=2)
+        self._loop = get_running_loop()
         self._connections = {}  # type: Dict[RequestHandler, asyncio.Transport]
         self._kwargs = kwargs
         self.requests_count = 0
         self.request_handler = handler
         self.request_factory = request_factory or self._make_request
 
     @property
```

### Comparing `aiohttp-4.0.0a0/aiohttp/web_urldispatcher.py` & `aiohttp-4.0.0a1/aiohttp/web_urldispatcher.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,18 +1,15 @@
 import abc
 import asyncio
 import base64
 import hashlib
-import inspect
 import keyword
 import os
 import re
-import warnings
 from contextlib import contextmanager
-from functools import wraps
 from pathlib import Path
 from types import MappingProxyType
 from typing import (  # noqa
     TYPE_CHECKING,
     Any,
     Awaitable,
     Callable,
@@ -23,14 +20,15 @@
     Iterator,
     List,
     Mapping,
     Optional,
     Set,
     Sized,
     Tuple,
+    Type,
     Union,
     cast,
 )
 
 from yarl import URL
 
 from . import hdrs
@@ -119,49 +117,35 @@
     def raw_match(self, path: str) -> bool:
         """Perform a raw match against path"""
 
 
 class AbstractRoute(abc.ABC):
 
     def __init__(self, method: str,
-                 handler: Union[_WebHandler, AbstractView], *,
+                 handler: Union[_WebHandler, Type[AbstractView]], *,
                  expect_handler: _ExpectHandler=None,
                  resource: AbstractResource=None) -> None:
 
         if expect_handler is None:
             expect_handler = _default_expect_handler
 
         assert asyncio.iscoroutinefunction(expect_handler), \
             'Coroutine is expected, got {!r}'.format(expect_handler)
 
         method = method.upper()
         if not HTTP_METHOD_RE.match(method):
             raise ValueError("{} is not allowed HTTP method".format(method))
 
-        assert callable(handler), handler
         if asyncio.iscoroutinefunction(handler):
             pass
-        elif inspect.isgeneratorfunction(handler):
-            warnings.warn("Bare generators are deprecated, "
-                          "use @coroutine wrapper", DeprecationWarning)
-        elif (isinstance(handler, type) and
-              issubclass(handler, AbstractView)):
+        elif isinstance(handler, type) and issubclass(handler, AbstractView):
             pass
         else:
-            warnings.warn("Bare functions are deprecated, "
-                          "use async ones", DeprecationWarning)
-
-            @wraps(handler)
-            async def handler_wrapper(request: Request) -> StreamResponse:
-                result = old_handler(request)
-                if asyncio.iscoroutine(result):
-                    result = await result
-                return result
-            old_handler = handler
-            handler = handler_wrapper
+            raise TypeError("Only async functions are allowed as web-handlers "
+                            ", got {!r}".format(handler))
 
         self._method = method
         self._handler = handler
         self._expect_handler = expect_handler
         self._resource = resource
 
     @property
@@ -292,15 +276,15 @@
 class Resource(AbstractResource):
 
     def __init__(self, *, name: Optional[str]=None) -> None:
         super().__init__(name=name)
         self._routes = []  # type: List[ResourceRoute]
 
     def add_route(self, method: str,
-                  handler: Union[AbstractView, _WebHandler], *,
+                  handler: Union[Type[AbstractView], _WebHandler], *,
                   expect_handler: Optional[_ExpectHandler]=None
                   ) -> 'ResourceRoute':
 
         for route_obj in self._routes:
             if route_obj.method == method or route_obj.method == hdrs.METH_ANY:
                 raise RuntimeError("Added route will never be executed, "
                                    "method {route.method} is already "
@@ -496,15 +480,15 @@
     VERSION_KEY = 'v'
 
     def __init__(self, prefix: str, directory: PathLike,
                  *, name: Optional[str]=None,
                  expect_handler: Optional[_ExpectHandler]=None,
                  chunk_size: int=256 * 1024,
                  show_index: bool=False, follow_symlinks: bool=False,
-                 append_version: bool=False)-> None:
+                 append_version: bool=False) -> None:
         super().__init__(prefix, name=name)
         try:
             directory = Path(directory)
             if str(directory).startswith('~'):
                 directory = Path(os.path.expanduser(str(directory)))
             directory = directory.resolve()
             if not directory.is_dir():
@@ -694,15 +678,16 @@
                            "by sub-application root")
 
     def get_info(self) -> Dict[str, Any]:
         return {'app': self._app,
                 'prefix': self._prefix}
 
     async def resolve(self, request: Request) -> _Resolve:
-        if not request.url.raw_path.startswith(self._prefix):
+        if not request.url.raw_path.startswith(self._prefix + '/') and \
+                request.url.raw_path != self._prefix:
             return None, set()
         match_info = await self._app.router.resolve(request)
         match_info.add_app(self._app)
         if isinstance(match_info.http_exception, HTTPMethodNotAllowed):
             methods = match_info.http_exception.allowed_methods
         else:
             methods = set()
@@ -821,15 +806,15 @@
                "".format(app=self._app)
 
 
 class ResourceRoute(AbstractRoute):
     """A route with resource"""
 
     def __init__(self, method: str,
-                 handler: Union[_WebHandler, AbstractView],
+                 handler: Union[_WebHandler, Type[AbstractView]],
                  resource: AbstractResource, *,
                  expect_handler: Optional[_ExpectHandler]=None) -> None:
         super().__init__(method, handler, expect_handler=expect_handler,
                          resource=resource)
 
     def __repr__(self) -> str:
         return "<ResourceRoute [{method}] {resource} -> {handler!r}".format(
@@ -1021,15 +1006,15 @@
             self.register_resource(resource)
             return resource
         resource = DynamicResource(path, name=name)
         self.register_resource(resource)
         return resource
 
     def add_route(self, method: str, path: str,
-                  handler: Union[_WebHandler, AbstractView],
+                  handler: Union[_WebHandler, Type[AbstractView]],
                   *, name: Optional[str]=None,
                   expect_handler: Optional[_ExpectHandler]=None
                   ) -> AbstractRoute:
         resource = self.add_resource(path, name=name)
         return resource.add_route(method, handler,
                                   expect_handler=expect_handler)
 
@@ -1108,15 +1093,15 @@
     def add_delete(self, path: str, handler: _WebHandler,
                    **kwargs: Any) -> AbstractRoute:
         """
         Shortcut for add_route with method DELETE
         """
         return self.add_route(hdrs.METH_DELETE, path, handler, **kwargs)
 
-    def add_view(self, path: str, handler: AbstractView,
+    def add_view(self, path: str, handler: Type[AbstractView],
                  **kwargs: Any) -> AbstractRoute:
         """
         Shortcut for add_route with ANY methods for a class-based view
         """
         return self.add_route(hdrs.METH_ANY, path, handler, **kwargs)
 
     def freeze(self) -> None:
```

### Comparing `aiohttp-4.0.0a0/aiohttp/web_ws.py` & `aiohttp-4.0.0a1/aiohttp/web_ws.py`

 * *Files 3% similar despite different names*

```diff
@@ -16,22 +16,21 @@
     WS_CLOSED_MESSAGE,
     WS_CLOSING_MESSAGE,
     WS_KEY,
     WebSocketError,
     WebSocketReader,
     WebSocketWriter,
     WSMessage,
-    WSMsgType,
-    ws_ext_gen,
-    ws_ext_parse,
 )
+from .http import WSMsgType as WSMsgType
+from .http import ws_ext_gen, ws_ext_parse
 from .log import ws_logger
 from .streams import EofStream, FlowControlDataQueue
 from .typedefs import JSONDecoder, JSONEncoder
-from .web_exceptions import HTTPBadRequest, HTTPException, HTTPMethodNotAllowed
+from .web_exceptions import HTTPBadRequest, HTTPException
 from .web_request import BaseRequest
 from .web_response import StreamResponse
 
 __all__ = ('WebSocketResponse', 'WebSocketReady', 'WSMsgType',)
 
 THRESHOLD_CONNLOST_ACCESS = 5
 
@@ -42,22 +41,28 @@
     protocol = attr.ib(type=Optional[str])
 
     def __bool__(self) -> bool:
         return self.ok
 
 
 class WebSocketResponse(StreamResponse):
+    __slots__ = ('_protocols', '_ws_protocol', '_writer', '_reader', '_closed',
+                 '_closing', '_conn_lost', '_close_code', '_loop', '_waiting',
+                 '_exception', '_timeout', '_receive_timeout', '_autoclose',
+                 '_autoping', '_heartbeat', '_heartbeat_cb', '_pong_heartbeat',
+                 '_pong_response_cb', '_compress', '_max_msg_size')
 
     def __init__(self, *,
                  timeout: float=10.0, receive_timeout: Optional[float]=None,
                  autoclose: bool=True, autoping: bool=True,
                  heartbeat: Optional[float]=None,
                  protocols: Iterable[str]=(),
                  compress: bool=True, max_msg_size: int=4*1024*1024) -> None:
         super().__init__(status=101)
+        self._length_check = False
         self._protocols = protocols
         self._ws_protocol = None  # type: Optional[str]
         self._writer = None  # type: Optional[WebSocketWriter]
         self._reader = None  # type: Optional[FlowControlDataQueue[WSMessage]]
         self._closed = False
         self._closing = False
         self._conn_lost = 0
@@ -125,16 +130,14 @@
         return payload_writer
 
     def _handshake(self, request: BaseRequest) -> Tuple['CIMultiDict[str]',
                                                         str,
                                                         bool,
                                                         bool]:
         headers = request.headers
-        if request.method != hdrs.METH_GET:
-            raise HTTPMethodNotAllowed(request.method, [hdrs.METH_GET])
         if 'websocket' != headers.get(hdrs.UPGRADE, '').lower().strip():
             raise HTTPBadRequest(
                 text=('No WebSocket UPGRADE hdr: {}\n Can '
                       '"Upgrade" only to "WebSocket".')
                 .format(headers.get(hdrs.UPGRADE)))
 
         if 'upgrade' not in headers.get(hdrs.CONNECTION, '').lower():
@@ -175,15 +178,14 @@
                 text='Handshake error: {!r}'.format(key)) from None
 
         accept_val = base64.b64encode(
             hashlib.sha1(key.encode() + WS_KEY).digest()).decode()
         response_headers = CIMultiDict(  # type: ignore
             {hdrs.UPGRADE: 'websocket',
              hdrs.CONNECTION: 'upgrade',
-             hdrs.TRANSFER_ENCODING: 'chunked',
              hdrs.SEC_WEBSOCKET_ACCEPT: accept_val})
 
         notakeover = False
         compress = 0
         if self._compress:
             extensions = headers.get(hdrs.SEC_WEBSOCKET_EXTENSIONS)
             # Server side always get return with no exception.
@@ -452,7 +454,11 @@
     async def __anext__(self) -> WSMessage:
         msg = await self.receive()
         if msg.type in (WSMsgType.CLOSE,
                         WSMsgType.CLOSING,
                         WSMsgType.CLOSED):
             raise StopAsyncIteration  # NOQA
         return msg
+
+    def _cancel(self, exc: BaseException) -> None:
+        if self._reader is not None:
+            self._reader.set_exception(exc)
```

### Comparing `aiohttp-4.0.0a0/aiohttp/worker.py` & `aiohttp-4.0.0a1/aiohttp/worker.py`

 * *Files 7% similar despite different names*

```diff
@@ -40,16 +40,14 @@
 
         self._task = None  # type: Optional[asyncio.Task[None]]
         self.exit_code = 0
         self._notify_waiter = None  # type: Optional[asyncio.Future[bool]]
 
     def init_process(self) -> None:
         # create new event_loop after fork
-        asyncio.get_event_loop().close()
-
         self.loop = asyncio.new_event_loop()
         asyncio.set_event_loop(self.loop)
 
         super().init_process()
 
     def run(self) -> None:
         self._task = self.loop.create_task(self._run())
@@ -80,15 +78,14 @@
                                access_log=access_log,
                                access_log_format=self._get_valid_log_format(
                                    self.cfg.access_log_format))
         await runner.setup()
 
         ctx = self._create_ssl_context(self.cfg) if self.cfg.is_ssl else None
 
-        runner = runner
         assert runner is not None
         server = runner.server
         assert server is not None
         for sock in self.sockets:
             site = web.SockSite(
                 runner, sock, ssl_context=ctx,
                 shutdown_timeout=self.cfg.graceful_timeout / 100 * 95)
@@ -209,34 +206,26 @@
 
 
 class GunicornUVLoopWebWorker(GunicornWebWorker):
 
     def init_process(self) -> None:
         import uvloop
 
-        # Close any existing event loop before setting a
-        # new policy.
-        asyncio.get_event_loop().close()
-
         # Setup uvloop policy, so that every
         # asyncio.get_event_loop() will create an instance
         # of uvloop event loop.
         asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())
 
         super().init_process()
 
 
 class GunicornTokioWebWorker(GunicornWebWorker):
 
     def init_process(self) -> None:  # pragma: no cover
         import tokio
 
-        # Close any existing event loop before setting a
-        # new policy.
-        asyncio.get_event_loop().close()
-
         # Setup tokio policy, so that every
         # asyncio.get_event_loop() will create an instance
         # of tokio event loop.
         asyncio.set_event_loop_policy(tokio.EventLoopPolicy())
 
         super().init_process()
```

### Comparing `aiohttp-4.0.0a0/aiohttp/_cparser.pxd` & `aiohttp-4.0.0a1/aiohttp/_cparser.pxd`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/aiohttp/_find_header.c` & `aiohttp-4.0.0a1/aiohttp/_find_header.c`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/aiohttp/_frozenlist.c` & `aiohttp-4.0.0a1/aiohttp/_frozenlist.c`

 * *Files 1% similar despite different names*

```diff
@@ -1,31 +1,19 @@
-/* Generated by Cython 0.29.2 */
-
-/* BEGIN: Cython Metadata
-{
-    "distutils": {
-        "name": "aiohttp._frozenlist",
-        "sources": [
-            "aiohttp/_frozenlist.pyx"
-        ]
-    },
-    "module_name": "aiohttp._frozenlist"
-}
-END: Cython Metadata */
+/* Generated by Cython 0.29.13 */
 
 #define PY_SSIZE_T_CLEAN
 #include "Python.h"
 #ifndef Py_PYTHON_H
     #error Python headers needed to compile C extensions, please install development version of Python.
 #elif PY_VERSION_HEX < 0x02060000 || (0x03000000 <= PY_VERSION_HEX && PY_VERSION_HEX < 0x03030000)
     #error Cython requires Python 2.6+ or Python 3.3+.
 #else
-#define CYTHON_ABI "0_29_2"
-#define CYTHON_HEX_VERSION 0x001D02F0
-#define CYTHON_FUTURE_DIVISION 0
+#define CYTHON_ABI "0_29_13"
+#define CYTHON_HEX_VERSION 0x001D0DF0
+#define CYTHON_FUTURE_DIVISION 1
 #include <stddef.h>
 #ifndef offsetof
   #define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
 #endif
 #if !defined(WIN32) && !defined(MS_WINDOWS)
   #ifndef __stdcall
     #define __stdcall
@@ -318,16 +306,21 @@
 #if PY_MAJOR_VERSION < 3
   #define __Pyx_BUILTIN_MODULE_NAME "__builtin__"
   #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
           PyCode_New(a+k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
   #define __Pyx_DefaultClassType PyClass_Type
 #else
   #define __Pyx_BUILTIN_MODULE_NAME "builtins"
+#if PY_VERSION_HEX >= 0x030800A4 && PY_VERSION_HEX < 0x030800B2
+  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
+          PyCode_New(a, 0, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
+#else
   #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
           PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
+#endif
   #define __Pyx_DefaultClassType PyType_Type
 #endif
 #ifndef Py_TPFLAGS_CHECKTYPES
   #define Py_TPFLAGS_CHECKTYPES 0
 #endif
 #ifndef Py_TPFLAGS_HAVE_INDEX
   #define Py_TPFLAGS_HAVE_INDEX 0
@@ -354,34 +347,14 @@
 #endif
 #if CYTHON_FAST_PYCCALL
 #define __Pyx_PyFastCFunction_Check(func)\
     ((PyCFunction_Check(func) && (METH_FASTCALL == (PyCFunction_GET_FLAGS(func) & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS | METH_STACKLESS)))))
 #else
 #define __Pyx_PyFastCFunction_Check(func) 0
 #endif
-#if CYTHON_USE_DICT_VERSIONS
-#define __PYX_GET_DICT_VERSION(dict)  (((PyDictObject*)(dict))->ma_version_tag)
-#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)\
-    (version_var) = __PYX_GET_DICT_VERSION(dict);\
-    (cache_var) = (value);
-#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP) {\
-        static PY_UINT64_T __pyx_dict_version = 0;\
-        static PyObject *__pyx_dict_cached_value = NULL;\
-        if (likely(__PYX_GET_DICT_VERSION(DICT) == __pyx_dict_version)) {\
-            (VAR) = __pyx_dict_cached_value;\
-        } else {\
-            (VAR) = __pyx_dict_cached_value = (LOOKUP);\
-            __pyx_dict_version = __PYX_GET_DICT_VERSION(DICT);\
-        }\
-    }
-#else
-#define __PYX_GET_DICT_VERSION(dict)  (0)
-#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)
-#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP)  (VAR) = (LOOKUP);
-#endif
 #if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Malloc)
   #define PyObject_Malloc(s)   PyMem_Malloc(s)
   #define PyObject_Free(p)     PyMem_Free(p)
   #define PyObject_Realloc(p)  PyMem_Realloc(p)
 #endif
 #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x030400A1
   #define PyMem_RawMalloc(n)           PyMem_Malloc(n)
@@ -406,15 +379,15 @@
 #endif
 #if PY_VERSION_HEX < 0x030700A2 && !defined(PyThread_tss_create) && !defined(Py_tss_NEEDS_INIT)
 #include "pythread.h"
 #define Py_tss_NEEDS_INIT 0
 typedef int Py_tss_t;
 static CYTHON_INLINE int PyThread_tss_create(Py_tss_t *key) {
   *key = PyThread_create_key();
-  return 0; // PyThread_create_key reports success always
+  return 0;
 }
 static CYTHON_INLINE Py_tss_t * PyThread_tss_alloc(void) {
   Py_tss_t *key = (Py_tss_t *)PyObject_Malloc(sizeof(Py_tss_t));
   *key = Py_tss_NEEDS_INIT;
   return key;
 }
 static CYTHON_INLINE void PyThread_tss_free(Py_tss_t *key) {
@@ -429,15 +402,15 @@
 }
 static CYTHON_INLINE int PyThread_tss_set(Py_tss_t *key, void *value) {
   return PyThread_set_key_value(*key, value);
 }
 static CYTHON_INLINE void * PyThread_tss_get(Py_tss_t *key) {
   return PyThread_get_key_value(*key);
 }
-#endif // TSS (Thread Specific Storage) API
+#endif
 #if CYTHON_COMPILING_IN_CPYTHON || defined(_PyDict_NewPresized)
 #define __Pyx_PyDict_NewPresized(n)  ((n <= 8) ? PyDict_New() : _PyDict_NewPresized(n))
 #else
 #define __Pyx_PyDict_NewPresized(n)  PyDict_New()
 #endif
 #if PY_MAJOR_VERSION >= 3 || CYTHON_FUTURE_DIVISION
   #define __Pyx_PyNumber_Divide(x,y)         PyNumber_TrueDivide(x,y)
@@ -628,15 +601,16 @@
 #define CYTHON_WITHOUT_ASSERTIONS
 #endif
 
 typedef struct {PyObject **p; const char *s; const Py_ssize_t n; const char* encoding;
                 const char is_unicode; const char is_str; const char intern; } __Pyx_StringTabEntry;
 
 #define __PYX_DEFAULT_STRING_ENCODING_IS_ASCII 0
-#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT 0
+#define __PYX_DEFAULT_STRING_ENCODING_IS_UTF8 0
+#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT (PY_MAJOR_VERSION >= 3 && __PYX_DEFAULT_STRING_ENCODING_IS_UTF8)
 #define __PYX_DEFAULT_STRING_ENCODING ""
 #define __Pyx_PyObject_FromString __Pyx_PyBytes_FromString
 #define __Pyx_PyObject_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
 #define __Pyx_uchar_cast(c) ((unsigned char)c)
 #define __Pyx_long_cast(x) ((long)x)
 #define __Pyx_fits_Py_ssize_t(v, type, is_signed)  (\
     (sizeof(type) < sizeof(Py_ssize_t))  ||\
@@ -823,15 +797,15 @@
 static int __pyx_lineno;
 static int __pyx_clineno = 0;
 static const char * __pyx_cfilenm= __FILE__;
 static const char *__pyx_filename;
 
 
 static const char *__pyx_f[] = {
-  "aiohttp\\_frozenlist.pyx",
+  "aiohttp/_frozenlist.pyx",
   "stringsource",
 };
 
 /*--- Type declarations ---*/
 struct __pyx_obj_7aiohttp_11_frozenlist_FrozenList;
 
 /* "aiohttp/_frozenlist.pyx":4
@@ -1019,15 +993,15 @@
 #endif
 
 /* PyFunctionFastCall.proto */
 #if CYTHON_FAST_PYCALL
 #define __Pyx_PyFunction_FastCall(func, args, nargs)\
     __Pyx_PyFunction_FastCallDict((func), (args), (nargs), NULL)
 #if 1 || PY_VERSION_HEX < 0x030600B1
-static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs);
+static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, Py_ssize_t nargs, PyObject *kwargs);
 #else
 #define __Pyx_PyFunction_FastCallDict(func, args, nargs, kwargs) _PyFunction_FastCallDict(func, args, nargs, kwargs)
 #endif
 #define __Pyx_BUILD_ASSERT_EXPR(cond)\
     (sizeof(char [1 - 2*!(cond)]) - 1)
 #ifndef Py_MEMBER_SIZE
 #define Py_MEMBER_SIZE(type, member) sizeof(((type *)0)->member)
@@ -1085,26 +1059,26 @@
 static PyObject* __Pyx__PyObject_PopNewIndex(PyObject* L, PyObject* py_ix);
 static PyObject* __Pyx__PyObject_PopIndex(PyObject* L, PyObject* py_ix);
 #if CYTHON_USE_PYLIST_INTERNALS && CYTHON_ASSUME_SAFE_MACROS
 static PyObject* __Pyx__PyList_PopIndex(PyObject* L, PyObject* py_ix, Py_ssize_t ix);
 #define __Pyx_PyObject_PopIndex(L, py_ix, ix, is_signed, type, to_py_func) (\
     (likely(PyList_CheckExact(L) && __Pyx_fits_Py_ssize_t(ix, type, is_signed))) ?\
         __Pyx__PyList_PopIndex(L, py_ix, ix) : (\
-        (unlikely(py_ix == Py_None)) ? __Pyx__PyObject_PopNewIndex(L, to_py_func(ix)) :\
+        (unlikely((py_ix) == Py_None)) ? __Pyx__PyObject_PopNewIndex(L, to_py_func(ix)) :\
             __Pyx__PyObject_PopIndex(L, py_ix)))
 #define __Pyx_PyList_PopIndex(L, py_ix, ix, is_signed, type, to_py_func) (\
     __Pyx_fits_Py_ssize_t(ix, type, is_signed) ?\
         __Pyx__PyList_PopIndex(L, py_ix, ix) : (\
-        (unlikely(py_ix == Py_None)) ? __Pyx__PyObject_PopNewIndex(L, to_py_func(ix)) :\
+        (unlikely((py_ix) == Py_None)) ? __Pyx__PyObject_PopNewIndex(L, to_py_func(ix)) :\
             __Pyx__PyObject_PopIndex(L, py_ix)))
 #else
 #define __Pyx_PyList_PopIndex(L, py_ix, ix, is_signed, type, to_py_func)\
     __Pyx_PyObject_PopIndex(L, py_ix, ix, is_signed, type, to_py_func)
 #define __Pyx_PyObject_PopIndex(L, py_ix, ix, is_signed, type, to_py_func) (\
-    (unlikely(py_ix == Py_None)) ? __Pyx__PyObject_PopNewIndex(L, to_py_func(ix)) :\
+    (unlikely((py_ix) == Py_None)) ? __Pyx__PyObject_PopNewIndex(L, to_py_func(ix)) :\
         __Pyx__PyObject_PopIndex(L, py_ix))
 #endif
 
 /* ListAppend.proto */
 #if CYTHON_USE_PYLIST_INTERNALS && CYTHON_ASSUME_SAFE_MACROS
 static CYTHON_INLINE int __Pyx_PyList_Append(PyObject* list, PyObject* x) {
     PyListObject* L = (PyListObject*) list;
@@ -1131,14 +1105,40 @@
 
 /* GetAttr.proto */
 static CYTHON_INLINE PyObject *__Pyx_GetAttr(PyObject *, PyObject *);
 
 /* GetAttr3.proto */
 static CYTHON_INLINE PyObject *__Pyx_GetAttr3(PyObject *, PyObject *, PyObject *);
 
+/* PyDictVersioning.proto */
+#if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_TYPE_SLOTS
+#define __PYX_DICT_VERSION_INIT  ((PY_UINT64_T) -1)
+#define __PYX_GET_DICT_VERSION(dict)  (((PyDictObject*)(dict))->ma_version_tag)
+#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)\
+    (version_var) = __PYX_GET_DICT_VERSION(dict);\
+    (cache_var) = (value);
+#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP) {\
+    static PY_UINT64_T __pyx_dict_version = 0;\
+    static PyObject *__pyx_dict_cached_value = NULL;\
+    if (likely(__PYX_GET_DICT_VERSION(DICT) == __pyx_dict_version)) {\
+        (VAR) = __pyx_dict_cached_value;\
+    } else {\
+        (VAR) = __pyx_dict_cached_value = (LOOKUP);\
+        __pyx_dict_version = __PYX_GET_DICT_VERSION(DICT);\
+    }\
+}
+static CYTHON_INLINE PY_UINT64_T __Pyx_get_tp_dict_version(PyObject *obj);
+static CYTHON_INLINE PY_UINT64_T __Pyx_get_object_dict_version(PyObject *obj);
+static CYTHON_INLINE int __Pyx_object_dict_version_matches(PyObject* obj, PY_UINT64_T tp_dict_version, PY_UINT64_T obj_dict_version);
+#else
+#define __PYX_GET_DICT_VERSION(dict)  (0)
+#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)
+#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP)  (VAR) = (LOOKUP);
+#endif
+
 /* GetModuleGlobalName.proto */
 #if CYTHON_USE_DICT_VERSIONS
 #define __Pyx_GetModuleGlobalName(var, name)  {\
     static PY_UINT64_T __pyx_dict_version = 0;\
     static PyObject *__pyx_dict_cached_value = NULL;\
     (var) = (likely(__pyx_dict_version == __PYX_GET_DICT_VERSION(__pyx_d))) ?\
         (likely(__pyx_dict_cached_value) ? __Pyx_NewRef(__pyx_dict_cached_value) : __Pyx_GetBuiltinName(name)) :\
@@ -1294,17 +1294,17 @@
 static const char __pyx_k_setstate_cython[] = "__setstate_cython__";
 static const char __pyx_k_cline_in_traceback[] = "cline_in_traceback";
 static const char __pyx_k_FrozenList_frozen_r[] = "<FrozenList(frozen={}, {!r})>";
 static const char __pyx_k_aiohttp__frozenlist[] = "aiohttp._frozenlist";
 static const char __pyx_k_pyx_unpickle_FrozenList[] = "__pyx_unpickle_FrozenList";
 static const char __pyx_k_Cannot_modify_frozen_list[] = "Cannot modify frozen list.";
 static const char __pyx_k_Incompatible_checksums_s_vs_0x94[] = "Incompatible checksums (%s vs 0x949a143 = (_items, frozen))";
-static PyObject *__pyx_kp_s_Cannot_modify_frozen_list;
+static PyObject *__pyx_kp_u_Cannot_modify_frozen_list;
 static PyObject *__pyx_n_s_FrozenList;
-static PyObject *__pyx_kp_s_FrozenList_frozen_r;
+static PyObject *__pyx_kp_u_FrozenList_frozen_r;
 static PyObject *__pyx_kp_s_Incompatible_checksums_s_vs_0x94;
 static PyObject *__pyx_n_s_MutableSequence;
 static PyObject *__pyx_n_s_PickleError;
 static PyObject *__pyx_n_s_RuntimeError;
 static PyObject *__pyx_n_s_aiohttp__frozenlist;
 static PyObject *__pyx_n_s_clear;
 static PyObject *__pyx_n_s_cline_in_traceback;
@@ -3423,15 +3423,15 @@
  * 
  *     def __repr__(self):
  *         return '<FrozenList(frozen={}, {!r})>'.format(self.frozen,             # <<<<<<<<<<<<<<
  *                                                       self._items)
  * 
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_FrozenList_frozen_r, __pyx_n_s_format); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 104, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_kp_u_FrozenList_frozen_r, __pyx_n_s_format); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 104, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __pyx_t_3 = __Pyx_PyBool_FromLong(__pyx_v_self->frozen); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 104, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_3);
 
   /* "aiohttp/_frozenlist.pyx":105
  *     def __repr__(self):
  *         return '<FrozenList(frozen={}, {!r})>'.format(self.frozen,
@@ -3959,15 +3959,15 @@
  *     __pyx_result = FrozenList.__new__(__pyx_type)
  */
     __pyx_t_2 = PyList_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 5, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_2);
     __Pyx_INCREF(__pyx_n_s_PickleError);
     __Pyx_GIVEREF(__pyx_n_s_PickleError);
     PyList_SET_ITEM(__pyx_t_2, 0, __pyx_n_s_PickleError);
-    __pyx_t_3 = __Pyx_Import(__pyx_n_s_pickle, __pyx_t_2, -1); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 5, __pyx_L1_error)
+    __pyx_t_3 = __Pyx_Import(__pyx_n_s_pickle, __pyx_t_2, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 5, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
     __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
     __pyx_t_2 = __Pyx_ImportFrom(__pyx_t_3, __pyx_n_s_PickleError); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 5, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_2);
     __Pyx_INCREF(__pyx_t_2);
     __pyx_v___pyx_PickleError = __pyx_t_2;
     __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
@@ -4468,14 +4468,17 @@
   0, /*tp_subclasses*/
   0, /*tp_weaklist*/
   0, /*tp_del*/
   0, /*tp_version_tag*/
   #if PY_VERSION_HEX >= 0x030400a1
   0, /*tp_finalize*/
   #endif
+  #if PY_VERSION_HEX >= 0x030800b1
+  0, /*tp_vectorcall*/
+  #endif
 };
 
 static PyMethodDef __pyx_methods[] = {
   {0, 0, 0, 0}
 };
 
 #if PY_MAJOR_VERSION >= 3
@@ -4516,17 +4519,17 @@
     #define CYTHON_SMALL_CODE __attribute__((cold))
 #else
     #define CYTHON_SMALL_CODE
 #endif
 #endif
 
 static __Pyx_StringTabEntry __pyx_string_tab[] = {
-  {&__pyx_kp_s_Cannot_modify_frozen_list, __pyx_k_Cannot_modify_frozen_list, sizeof(__pyx_k_Cannot_modify_frozen_list), 0, 0, 1, 0},
+  {&__pyx_kp_u_Cannot_modify_frozen_list, __pyx_k_Cannot_modify_frozen_list, sizeof(__pyx_k_Cannot_modify_frozen_list), 0, 1, 0, 0},
   {&__pyx_n_s_FrozenList, __pyx_k_FrozenList, sizeof(__pyx_k_FrozenList), 0, 0, 1, 1},
-  {&__pyx_kp_s_FrozenList_frozen_r, __pyx_k_FrozenList_frozen_r, sizeof(__pyx_k_FrozenList_frozen_r), 0, 0, 1, 0},
+  {&__pyx_kp_u_FrozenList_frozen_r, __pyx_k_FrozenList_frozen_r, sizeof(__pyx_k_FrozenList_frozen_r), 0, 1, 0, 0},
   {&__pyx_kp_s_Incompatible_checksums_s_vs_0x94, __pyx_k_Incompatible_checksums_s_vs_0x94, sizeof(__pyx_k_Incompatible_checksums_s_vs_0x94), 0, 0, 1, 0},
   {&__pyx_n_s_MutableSequence, __pyx_k_MutableSequence, sizeof(__pyx_k_MutableSequence), 0, 0, 1, 1},
   {&__pyx_n_s_PickleError, __pyx_k_PickleError, sizeof(__pyx_k_PickleError), 0, 0, 1, 1},
   {&__pyx_n_s_RuntimeError, __pyx_k_RuntimeError, sizeof(__pyx_k_RuntimeError), 0, 0, 1, 1},
   {&__pyx_n_s_aiohttp__frozenlist, __pyx_k_aiohttp__frozenlist, sizeof(__pyx_k_aiohttp__frozenlist), 0, 0, 1, 1},
   {&__pyx_n_s_clear, __pyx_k_clear, sizeof(__pyx_k_clear), 0, 0, 1, 1},
   {&__pyx_n_s_cline_in_traceback, __pyx_k_cline_in_traceback, sizeof(__pyx_k_cline_in_traceback), 0, 0, 1, 1},
@@ -4580,15 +4583,15 @@
   /* "aiohttp/_frozenlist.pyx":19
  *     cdef object _check_frozen(self):
  *         if self.frozen:
  *             raise RuntimeError("Cannot modify frozen list.")             # <<<<<<<<<<<<<<
  * 
  *     cdef inline object _fast_len(self):
  */
-  __pyx_tuple_ = PyTuple_Pack(1, __pyx_kp_s_Cannot_modify_frozen_list); if (unlikely(!__pyx_tuple_)) __PYX_ERR(0, 19, __pyx_L1_error)
+  __pyx_tuple_ = PyTuple_Pack(1, __pyx_kp_u_Cannot_modify_frozen_list); if (unlikely(!__pyx_tuple_)) __PYX_ERR(0, 19, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple_);
   __Pyx_GIVEREF(__pyx_tuple_);
 
   /* "(tree fragment)":1
  * def __pyx_unpickle_FrozenList(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
  *     cdef object __pyx_PickleError
  *     cdef object __pyx_result
@@ -4655,15 +4658,17 @@
   __Pyx_RefNannyDeclarations
   __Pyx_RefNannySetupContext("__Pyx_modinit_type_init_code", 0);
   /*--- Type init code ---*/
   __pyx_vtabptr_7aiohttp_11_frozenlist_FrozenList = &__pyx_vtable_7aiohttp_11_frozenlist_FrozenList;
   __pyx_vtable_7aiohttp_11_frozenlist_FrozenList._check_frozen = (PyObject *(*)(struct __pyx_obj_7aiohttp_11_frozenlist_FrozenList *))__pyx_f_7aiohttp_11_frozenlist_10FrozenList__check_frozen;
   __pyx_vtable_7aiohttp_11_frozenlist_FrozenList._fast_len = (PyObject *(*)(struct __pyx_obj_7aiohttp_11_frozenlist_FrozenList *))__pyx_f_7aiohttp_11_frozenlist_10FrozenList__fast_len;
   if (PyType_Ready(&__pyx_type_7aiohttp_11_frozenlist_FrozenList) < 0) __PYX_ERR(0, 4, __pyx_L1_error)
+  #if PY_VERSION_HEX < 0x030800B1
   __pyx_type_7aiohttp_11_frozenlist_FrozenList.tp_print = 0;
+  #endif
   if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_7aiohttp_11_frozenlist_FrozenList.tp_dictoffset && __pyx_type_7aiohttp_11_frozenlist_FrozenList.tp_getattro == PyObject_GenericGetAttr)) {
     __pyx_type_7aiohttp_11_frozenlist_FrozenList.tp_getattro = __Pyx_PyObject_GenericGetAttr;
   }
   if (__Pyx_SetVtable(__pyx_type_7aiohttp_11_frozenlist_FrozenList.tp_dict, __pyx_vtabptr_7aiohttp_11_frozenlist_FrozenList) < 0) __PYX_ERR(0, 4, __pyx_L1_error)
   if (PyObject_SetAttr(__pyx_m, __pyx_n_s_FrozenList, (PyObject *)&__pyx_type_7aiohttp_11_frozenlist_FrozenList) < 0) __PYX_ERR(0, 4, __pyx_L1_error)
   if (__Pyx_setup_reduce((PyObject*)&__pyx_type_7aiohttp_11_frozenlist_FrozenList) < 0) __PYX_ERR(0, 4, __pyx_L1_error)
   __pyx_ptype_7aiohttp_11_frozenlist_FrozenList = &__pyx_type_7aiohttp_11_frozenlist_FrozenList;
@@ -4855,18 +4860,17 @@
   __pyx_m = PyModule_Create(&__pyx_moduledef);
   #endif
   if (unlikely(!__pyx_m)) __PYX_ERR(0, 1, __pyx_L1_error)
   #endif
   __pyx_d = PyModule_GetDict(__pyx_m); if (unlikely(!__pyx_d)) __PYX_ERR(0, 1, __pyx_L1_error)
   Py_INCREF(__pyx_d);
   __pyx_b = PyImport_AddModule(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_b)) __PYX_ERR(0, 1, __pyx_L1_error)
-  __pyx_cython_runtime = PyImport_AddModule((char *) "cython_runtime"); if (unlikely(!__pyx_cython_runtime)) __PYX_ERR(0, 1, __pyx_L1_error)
-  #if CYTHON_COMPILING_IN_PYPY
   Py_INCREF(__pyx_b);
-  #endif
+  __pyx_cython_runtime = PyImport_AddModule((char *) "cython_runtime"); if (unlikely(!__pyx_cython_runtime)) __PYX_ERR(0, 1, __pyx_L1_error)
+  Py_INCREF(__pyx_cython_runtime);
   if (PyObject_SetAttrString(__pyx_m, "__builtins__", __pyx_b) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
   /*--- Initialize various global constants etc. ---*/
   if (__Pyx_InitGlobals() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
   #if PY_MAJOR_VERSION < 3 && (__PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT)
   if (__Pyx_init_sys_getdefaultencoding_params() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
   #endif
   if (__pyx_module_is_main_aiohttp___frozenlist) {
@@ -4877,17 +4881,17 @@
     PyObject *modules = PyImport_GetModuleDict(); if (unlikely(!modules)) __PYX_ERR(0, 1, __pyx_L1_error)
     if (!PyDict_GetItemString(modules, "aiohttp._frozenlist")) {
       if (unlikely(PyDict_SetItemString(modules, "aiohttp._frozenlist", __pyx_m) < 0)) __PYX_ERR(0, 1, __pyx_L1_error)
     }
   }
   #endif
   /*--- Builtin init code ---*/
-  if (__Pyx_InitCachedBuiltins() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
+  if (__Pyx_InitCachedBuiltins() < 0) goto __pyx_L1_error;
   /*--- Constants init code ---*/
-  if (__Pyx_InitCachedConstants() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
+  if (__Pyx_InitCachedConstants() < 0) goto __pyx_L1_error;
   /*--- Global type/function init code ---*/
   (void)__Pyx_modinit_global_init_code();
   (void)__Pyx_modinit_variable_export_code();
   (void)__Pyx_modinit_function_export_code();
   if (unlikely(__Pyx_modinit_type_init_code() != 0)) goto __pyx_L1_error;
   (void)__Pyx_modinit_type_import_code();
   (void)__Pyx_modinit_variable_import_code();
@@ -4903,15 +4907,15 @@
  * 
  */
   __pyx_t_1 = PyList_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __Pyx_INCREF(__pyx_n_s_MutableSequence);
   __Pyx_GIVEREF(__pyx_n_s_MutableSequence);
   PyList_SET_ITEM(__pyx_t_1, 0, __pyx_n_s_MutableSequence);
-  __pyx_t_2 = __Pyx_Import(__pyx_n_s_collections_abc, __pyx_t_1, -1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_Import(__pyx_n_s_collections_abc, __pyx_t_1, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
   __pyx_t_1 = __Pyx_ImportFrom(__pyx_t_2, __pyx_n_s_MutableSequence); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   if (PyDict_SetItem(__pyx_d, __pyx_n_s_MutableSequence, __pyx_t_1) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
   __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
@@ -5510,15 +5514,15 @@
     result = PyEval_EvalFrameEx(f,0);
     ++tstate->recursion_depth;
     Py_DECREF(f);
     --tstate->recursion_depth;
     return result;
 }
 #if 1 || PY_VERSION_HEX < 0x030600B1
-static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs) {
+static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, Py_ssize_t nargs, PyObject *kwargs) {
     PyCodeObject *co = (PyCodeObject *)PyFunction_GET_CODE(func);
     PyObject *globals = PyFunction_GET_GLOBALS(func);
     PyObject *argdefs = PyFunction_GET_DEFAULTS(func);
     PyObject *closure;
 #if PY_MAJOR_VERSION >= 3
     PyObject *kwdefs;
 #endif
@@ -5581,20 +5585,20 @@
     }
     else {
         d = NULL;
         nd = 0;
     }
 #if PY_MAJOR_VERSION >= 3
     result = PyEval_EvalCodeEx((PyObject*)co, globals, (PyObject *)NULL,
-                               args, nargs,
+                               args, (int)nargs,
                                k, (int)nk,
                                d, (int)nd, kwdefs, closure);
 #else
     result = PyEval_EvalCodeEx(co, globals, (PyObject *)NULL,
-                               args, nargs,
+                               args, (int)nargs,
                                k, (int)nk,
                                d, (int)nd, closure);
 #endif
     Py_XDECREF(kwtuple);
 done:
     Py_LeaveRecursiveCall();
     return result;
@@ -6001,14 +6005,40 @@
     return d;
 }
 static CYTHON_INLINE PyObject *__Pyx_GetAttr3(PyObject *o, PyObject *n, PyObject *d) {
     PyObject *r = __Pyx_GetAttr(o, n);
     return (likely(r)) ? r : __Pyx_GetAttr3Default(d);
 }
 
+/* PyDictVersioning */
+#if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_TYPE_SLOTS
+static CYTHON_INLINE PY_UINT64_T __Pyx_get_tp_dict_version(PyObject *obj) {
+    PyObject *dict = Py_TYPE(obj)->tp_dict;
+    return likely(dict) ? __PYX_GET_DICT_VERSION(dict) : 0;
+}
+static CYTHON_INLINE PY_UINT64_T __Pyx_get_object_dict_version(PyObject *obj) {
+    PyObject **dictptr = NULL;
+    Py_ssize_t offset = Py_TYPE(obj)->tp_dictoffset;
+    if (offset) {
+#if CYTHON_COMPILING_IN_CPYTHON
+        dictptr = (likely(offset > 0)) ? (PyObject **) ((char *)obj + offset) : _PyObject_GetDictPtr(obj);
+#else
+        dictptr = _PyObject_GetDictPtr(obj);
+#endif
+    }
+    return (dictptr && *dictptr) ? __PYX_GET_DICT_VERSION(*dictptr) : 0;
+}
+static CYTHON_INLINE int __Pyx_object_dict_version_matches(PyObject* obj, PY_UINT64_T tp_dict_version, PY_UINT64_T obj_dict_version) {
+    PyObject *dict = Py_TYPE(obj)->tp_dict;
+    if (unlikely(!dict) || unlikely(tp_dict_version != __PYX_GET_DICT_VERSION(dict)))
+        return 0;
+    return obj_dict_version == __Pyx_get_object_dict_version(obj);
+}
+#endif
+
 /* GetModuleGlobalName */
 #if CYTHON_USE_DICT_VERSIONS
 static PyObject *__Pyx__GetModuleGlobalName(PyObject *name, PY_UINT64_T *dict_version, PyObject **dict_cached_value)
 #else
 static CYTHON_INLINE PyObject *__Pyx__GetModuleGlobalName(PyObject *name)
 #endif
 {
```

### Comparing `aiohttp-4.0.0a0/aiohttp/_frozenlist.pyx` & `aiohttp-4.0.0a1/aiohttp/_frozenlist.pyx`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/aiohttp/_headers.pxi` & `aiohttp-4.0.0a1/aiohttp/_headers.pxi`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/aiohttp/_helpers.c` & `aiohttp-4.0.0a1/aiohttp/_helpers.c`

 * *Files 1% similar despite different names*

```diff
@@ -1,31 +1,19 @@
-/* Generated by Cython 0.29.2 */
-
-/* BEGIN: Cython Metadata
-{
-    "distutils": {
-        "name": "aiohttp._helpers",
-        "sources": [
-            "aiohttp/_helpers.pyx"
-        ]
-    },
-    "module_name": "aiohttp._helpers"
-}
-END: Cython Metadata */
+/* Generated by Cython 0.29.13 */
 
 #define PY_SSIZE_T_CLEAN
 #include "Python.h"
 #ifndef Py_PYTHON_H
     #error Python headers needed to compile C extensions, please install development version of Python.
 #elif PY_VERSION_HEX < 0x02060000 || (0x03000000 <= PY_VERSION_HEX && PY_VERSION_HEX < 0x03030000)
     #error Cython requires Python 2.6+ or Python 3.3+.
 #else
-#define CYTHON_ABI "0_29_2"
-#define CYTHON_HEX_VERSION 0x001D02F0
-#define CYTHON_FUTURE_DIVISION 0
+#define CYTHON_ABI "0_29_13"
+#define CYTHON_HEX_VERSION 0x001D0DF0
+#define CYTHON_FUTURE_DIVISION 1
 #include <stddef.h>
 #ifndef offsetof
   #define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
 #endif
 #if !defined(WIN32) && !defined(MS_WINDOWS)
   #ifndef __stdcall
     #define __stdcall
@@ -318,16 +306,21 @@
 #if PY_MAJOR_VERSION < 3
   #define __Pyx_BUILTIN_MODULE_NAME "__builtin__"
   #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
           PyCode_New(a+k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
   #define __Pyx_DefaultClassType PyClass_Type
 #else
   #define __Pyx_BUILTIN_MODULE_NAME "builtins"
+#if PY_VERSION_HEX >= 0x030800A4 && PY_VERSION_HEX < 0x030800B2
+  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
+          PyCode_New(a, 0, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
+#else
   #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
           PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
+#endif
   #define __Pyx_DefaultClassType PyType_Type
 #endif
 #ifndef Py_TPFLAGS_CHECKTYPES
   #define Py_TPFLAGS_CHECKTYPES 0
 #endif
 #ifndef Py_TPFLAGS_HAVE_INDEX
   #define Py_TPFLAGS_HAVE_INDEX 0
@@ -354,34 +347,14 @@
 #endif
 #if CYTHON_FAST_PYCCALL
 #define __Pyx_PyFastCFunction_Check(func)\
     ((PyCFunction_Check(func) && (METH_FASTCALL == (PyCFunction_GET_FLAGS(func) & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS | METH_STACKLESS)))))
 #else
 #define __Pyx_PyFastCFunction_Check(func) 0
 #endif
-#if CYTHON_USE_DICT_VERSIONS
-#define __PYX_GET_DICT_VERSION(dict)  (((PyDictObject*)(dict))->ma_version_tag)
-#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)\
-    (version_var) = __PYX_GET_DICT_VERSION(dict);\
-    (cache_var) = (value);
-#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP) {\
-        static PY_UINT64_T __pyx_dict_version = 0;\
-        static PyObject *__pyx_dict_cached_value = NULL;\
-        if (likely(__PYX_GET_DICT_VERSION(DICT) == __pyx_dict_version)) {\
-            (VAR) = __pyx_dict_cached_value;\
-        } else {\
-            (VAR) = __pyx_dict_cached_value = (LOOKUP);\
-            __pyx_dict_version = __PYX_GET_DICT_VERSION(DICT);\
-        }\
-    }
-#else
-#define __PYX_GET_DICT_VERSION(dict)  (0)
-#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)
-#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP)  (VAR) = (LOOKUP);
-#endif
 #if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Malloc)
   #define PyObject_Malloc(s)   PyMem_Malloc(s)
   #define PyObject_Free(p)     PyMem_Free(p)
   #define PyObject_Realloc(p)  PyMem_Realloc(p)
 #endif
 #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x030400A1
   #define PyMem_RawMalloc(n)           PyMem_Malloc(n)
@@ -406,15 +379,15 @@
 #endif
 #if PY_VERSION_HEX < 0x030700A2 && !defined(PyThread_tss_create) && !defined(Py_tss_NEEDS_INIT)
 #include "pythread.h"
 #define Py_tss_NEEDS_INIT 0
 typedef int Py_tss_t;
 static CYTHON_INLINE int PyThread_tss_create(Py_tss_t *key) {
   *key = PyThread_create_key();
-  return 0; // PyThread_create_key reports success always
+  return 0;
 }
 static CYTHON_INLINE Py_tss_t * PyThread_tss_alloc(void) {
   Py_tss_t *key = (Py_tss_t *)PyObject_Malloc(sizeof(Py_tss_t));
   *key = Py_tss_NEEDS_INIT;
   return key;
 }
 static CYTHON_INLINE void PyThread_tss_free(Py_tss_t *key) {
@@ -429,15 +402,15 @@
 }
 static CYTHON_INLINE int PyThread_tss_set(Py_tss_t *key, void *value) {
   return PyThread_set_key_value(*key, value);
 }
 static CYTHON_INLINE void * PyThread_tss_get(Py_tss_t *key) {
   return PyThread_get_key_value(*key);
 }
-#endif // TSS (Thread Specific Storage) API
+#endif
 #if CYTHON_COMPILING_IN_CPYTHON || defined(_PyDict_NewPresized)
 #define __Pyx_PyDict_NewPresized(n)  ((n <= 8) ? PyDict_New() : _PyDict_NewPresized(n))
 #else
 #define __Pyx_PyDict_NewPresized(n)  PyDict_New()
 #endif
 #if PY_MAJOR_VERSION >= 3 || CYTHON_FUTURE_DIVISION
   #define __Pyx_PyNumber_Divide(x,y)         PyNumber_TrueDivide(x,y)
@@ -628,15 +601,16 @@
 #define CYTHON_WITHOUT_ASSERTIONS
 #endif
 
 typedef struct {PyObject **p; const char *s; const Py_ssize_t n; const char* encoding;
                 const char is_unicode; const char is_str; const char intern; } __Pyx_StringTabEntry;
 
 #define __PYX_DEFAULT_STRING_ENCODING_IS_ASCII 0
-#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT 0
+#define __PYX_DEFAULT_STRING_ENCODING_IS_UTF8 0
+#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT (PY_MAJOR_VERSION >= 3 && __PYX_DEFAULT_STRING_ENCODING_IS_UTF8)
 #define __PYX_DEFAULT_STRING_ENCODING ""
 #define __Pyx_PyObject_FromString __Pyx_PyBytes_FromString
 #define __Pyx_PyObject_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
 #define __Pyx_uchar_cast(c) ((unsigned char)c)
 #define __Pyx_long_cast(x) ((long)x)
 #define __Pyx_fits_Py_ssize_t(v, type, is_signed)  (\
     (sizeof(type) < sizeof(Py_ssize_t))  ||\
@@ -823,15 +797,15 @@
 static int __pyx_lineno;
 static int __pyx_clineno = 0;
 static const char * __pyx_cfilenm= __FILE__;
 static const char *__pyx_filename;
 
 
 static const char *__pyx_f[] = {
-  "aiohttp\\_helpers.pyx",
+  "aiohttp/_helpers.pyx",
   "stringsource",
 };
 
 /*--- Type declarations ---*/
 struct __pyx_obj_7aiohttp_8_helpers_reify;
 
 /* "aiohttp/_helpers.pyx":1
@@ -1012,15 +986,15 @@
 #endif
 
 /* PyFunctionFastCall.proto */
 #if CYTHON_FAST_PYCALL
 #define __Pyx_PyFunction_FastCall(func, args, nargs)\
     __Pyx_PyFunction_FastCallDict((func), (args), (nargs), NULL)
 #if 1 || PY_VERSION_HEX < 0x030600B1
-static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs);
+static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, Py_ssize_t nargs, PyObject *kwargs);
 #else
 #define __Pyx_PyFunction_FastCallDict(func, args, nargs, kwargs) _PyFunction_FastCallDict(func, args, nargs, kwargs)
 #endif
 #define __Pyx_BUILD_ASSERT_EXPR(cond)\
     (sizeof(char [1 - 2*!(cond)]) - 1)
 #ifndef Py_MEMBER_SIZE
 #define Py_MEMBER_SIZE(type, member) sizeof(((type *)0)->member)
@@ -1082,14 +1056,40 @@
 
 /* GetAttr.proto */
 static CYTHON_INLINE PyObject *__Pyx_GetAttr(PyObject *, PyObject *);
 
 /* GetAttr3.proto */
 static CYTHON_INLINE PyObject *__Pyx_GetAttr3(PyObject *, PyObject *, PyObject *);
 
+/* PyDictVersioning.proto */
+#if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_TYPE_SLOTS
+#define __PYX_DICT_VERSION_INIT  ((PY_UINT64_T) -1)
+#define __PYX_GET_DICT_VERSION(dict)  (((PyDictObject*)(dict))->ma_version_tag)
+#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)\
+    (version_var) = __PYX_GET_DICT_VERSION(dict);\
+    (cache_var) = (value);
+#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP) {\
+    static PY_UINT64_T __pyx_dict_version = 0;\
+    static PyObject *__pyx_dict_cached_value = NULL;\
+    if (likely(__PYX_GET_DICT_VERSION(DICT) == __pyx_dict_version)) {\
+        (VAR) = __pyx_dict_cached_value;\
+    } else {\
+        (VAR) = __pyx_dict_cached_value = (LOOKUP);\
+        __pyx_dict_version = __PYX_GET_DICT_VERSION(DICT);\
+    }\
+}
+static CYTHON_INLINE PY_UINT64_T __Pyx_get_tp_dict_version(PyObject *obj);
+static CYTHON_INLINE PY_UINT64_T __Pyx_get_object_dict_version(PyObject *obj);
+static CYTHON_INLINE int __Pyx_object_dict_version_matches(PyObject* obj, PY_UINT64_T tp_dict_version, PY_UINT64_T obj_dict_version);
+#else
+#define __PYX_GET_DICT_VERSION(dict)  (0)
+#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)
+#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP)  (VAR) = (LOOKUP);
+#endif
+
 /* GetModuleGlobalName.proto */
 #if CYTHON_USE_DICT_VERSIONS
 #define __Pyx_GetModuleGlobalName(var, name)  {\
     static PY_UINT64_T __pyx_dict_version = 0;\
     static PyObject *__pyx_dict_cached_value = NULL;\
     (var) = (likely(__pyx_dict_version == __PYX_GET_DICT_VERSION(__pyx_d))) ?\
         (likely(__pyx_dict_cached_value) ? __Pyx_NewRef(__pyx_dict_cached_value) : __Pyx_GetBuiltinName(name)) :\
@@ -1250,15 +1250,15 @@
 static PyObject *__pyx_n_s_pyx_result;
 static PyObject *__pyx_n_s_pyx_state;
 static PyObject *__pyx_n_s_pyx_type;
 static PyObject *__pyx_n_s_pyx_unpickle_reify;
 static PyObject *__pyx_n_s_reduce;
 static PyObject *__pyx_n_s_reduce_cython;
 static PyObject *__pyx_n_s_reduce_ex;
-static PyObject *__pyx_kp_s_reified_property_is_read_only;
+static PyObject *__pyx_kp_u_reified_property_is_read_only;
 static PyObject *__pyx_n_s_reify;
 static PyObject *__pyx_n_s_setstate;
 static PyObject *__pyx_n_s_setstate_cython;
 static PyObject *__pyx_kp_s_stringsource;
 static PyObject *__pyx_n_s_test;
 static PyObject *__pyx_n_s_update;
 static PyObject *__pyx_n_s_wrapped;
@@ -1653,20 +1653,20 @@
  *     def __get__(self, inst, owner):
  *         try:             # <<<<<<<<<<<<<<
  *             try:
  *                 return inst._cache[self.name]
  */
     }
     __pyx_L3_error:;
-    __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
-    __Pyx_XDECREF(__pyx_t_12); __pyx_t_12 = 0;
+    __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
     __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
-    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
+    __Pyx_XDECREF(__pyx_t_12); __pyx_t_12 = 0;
+    __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
     __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
-    __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
+    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
 
     /* "aiohttp/_helpers.pyx":29
  *                 inst._cache[self.name] = val
  *                 return val
  *         except AttributeError:             # <<<<<<<<<<<<<<
  *             if inst is None:
  *                 return self
@@ -2246,15 +2246,15 @@
  *     __pyx_result = reify.__new__(__pyx_type)
  */
     __pyx_t_2 = PyList_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 5, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_2);
     __Pyx_INCREF(__pyx_n_s_PickleError);
     __Pyx_GIVEREF(__pyx_n_s_PickleError);
     PyList_SET_ITEM(__pyx_t_2, 0, __pyx_n_s_PickleError);
-    __pyx_t_3 = __Pyx_Import(__pyx_n_s_pickle, __pyx_t_2, -1); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 5, __pyx_L1_error)
+    __pyx_t_3 = __Pyx_Import(__pyx_n_s_pickle, __pyx_t_2, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 5, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
     __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
     __pyx_t_2 = __Pyx_ImportFrom(__pyx_t_3, __pyx_n_s_PickleError); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 5, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_2);
     __Pyx_INCREF(__pyx_t_2);
     __pyx_v___pyx_PickleError = __pyx_t_2;
     __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
@@ -2672,14 +2672,17 @@
   0, /*tp_subclasses*/
   0, /*tp_weaklist*/
   0, /*tp_del*/
   0, /*tp_version_tag*/
   #if PY_VERSION_HEX >= 0x030400a1
   0, /*tp_finalize*/
   #endif
+  #if PY_VERSION_HEX >= 0x030800b1
+  0, /*tp_vectorcall*/
+  #endif
 };
 
 static PyMethodDef __pyx_methods[] = {
   {0, 0, 0, 0}
 };
 
 #if PY_MAJOR_VERSION >= 3
@@ -2744,15 +2747,15 @@
   {&__pyx_n_s_pyx_result, __pyx_k_pyx_result, sizeof(__pyx_k_pyx_result), 0, 0, 1, 1},
   {&__pyx_n_s_pyx_state, __pyx_k_pyx_state, sizeof(__pyx_k_pyx_state), 0, 0, 1, 1},
   {&__pyx_n_s_pyx_type, __pyx_k_pyx_type, sizeof(__pyx_k_pyx_type), 0, 0, 1, 1},
   {&__pyx_n_s_pyx_unpickle_reify, __pyx_k_pyx_unpickle_reify, sizeof(__pyx_k_pyx_unpickle_reify), 0, 0, 1, 1},
   {&__pyx_n_s_reduce, __pyx_k_reduce, sizeof(__pyx_k_reduce), 0, 0, 1, 1},
   {&__pyx_n_s_reduce_cython, __pyx_k_reduce_cython, sizeof(__pyx_k_reduce_cython), 0, 0, 1, 1},
   {&__pyx_n_s_reduce_ex, __pyx_k_reduce_ex, sizeof(__pyx_k_reduce_ex), 0, 0, 1, 1},
-  {&__pyx_kp_s_reified_property_is_read_only, __pyx_k_reified_property_is_read_only, sizeof(__pyx_k_reified_property_is_read_only), 0, 0, 1, 0},
+  {&__pyx_kp_u_reified_property_is_read_only, __pyx_k_reified_property_is_read_only, sizeof(__pyx_k_reified_property_is_read_only), 0, 1, 0, 0},
   {&__pyx_n_s_reify, __pyx_k_reify, sizeof(__pyx_k_reify), 0, 0, 1, 1},
   {&__pyx_n_s_setstate, __pyx_k_setstate, sizeof(__pyx_k_setstate), 0, 0, 1, 1},
   {&__pyx_n_s_setstate_cython, __pyx_k_setstate_cython, sizeof(__pyx_k_setstate_cython), 0, 0, 1, 1},
   {&__pyx_kp_s_stringsource, __pyx_k_stringsource, sizeof(__pyx_k_stringsource), 0, 0, 1, 0},
   {&__pyx_n_s_test, __pyx_k_test, sizeof(__pyx_k_test), 0, 0, 1, 1},
   {&__pyx_n_s_update, __pyx_k_update, sizeof(__pyx_k_update), 0, 0, 1, 1},
   {&__pyx_n_s_wrapped, __pyx_k_wrapped, sizeof(__pyx_k_wrapped), 0, 0, 1, 1},
@@ -2771,15 +2774,15 @@
   __Pyx_RefNannySetupContext("__Pyx_InitCachedConstants", 0);
 
   /* "aiohttp/_helpers.pyx":35
  * 
  *     def __set__(self, inst, value):
  *         raise AttributeError("reified property is read-only")             # <<<<<<<<<<<<<<
  */
-  __pyx_tuple_ = PyTuple_Pack(1, __pyx_kp_s_reified_property_is_read_only); if (unlikely(!__pyx_tuple_)) __PYX_ERR(0, 35, __pyx_L1_error)
+  __pyx_tuple_ = PyTuple_Pack(1, __pyx_kp_u_reified_property_is_read_only); if (unlikely(!__pyx_tuple_)) __PYX_ERR(0, 35, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple_);
   __Pyx_GIVEREF(__pyx_tuple_);
 
   /* "(tree fragment)":1
  * def __pyx_unpickle_reify(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
  *     cdef object __pyx_PickleError
  *     cdef object __pyx_result
@@ -2836,15 +2839,17 @@
 }
 
 static int __Pyx_modinit_type_init_code(void) {
   __Pyx_RefNannyDeclarations
   __Pyx_RefNannySetupContext("__Pyx_modinit_type_init_code", 0);
   /*--- Type init code ---*/
   if (PyType_Ready(&__pyx_type_7aiohttp_8_helpers_reify) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
+  #if PY_VERSION_HEX < 0x030800B1
   __pyx_type_7aiohttp_8_helpers_reify.tp_print = 0;
+  #endif
   if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_7aiohttp_8_helpers_reify.tp_dictoffset && __pyx_type_7aiohttp_8_helpers_reify.tp_getattro == PyObject_GenericGetAttr)) {
     __pyx_type_7aiohttp_8_helpers_reify.tp_getattro = __Pyx_PyObject_GenericGetAttr;
   }
   if (PyObject_SetAttr(__pyx_m, __pyx_n_s_reify, (PyObject *)&__pyx_type_7aiohttp_8_helpers_reify) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
   if (__Pyx_setup_reduce((PyObject*)&__pyx_type_7aiohttp_8_helpers_reify) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
   __pyx_ptype_7aiohttp_8_helpers_reify = &__pyx_type_7aiohttp_8_helpers_reify;
   __Pyx_RefNannyFinishContext();
@@ -3034,18 +3039,17 @@
   __pyx_m = PyModule_Create(&__pyx_moduledef);
   #endif
   if (unlikely(!__pyx_m)) __PYX_ERR(0, 1, __pyx_L1_error)
   #endif
   __pyx_d = PyModule_GetDict(__pyx_m); if (unlikely(!__pyx_d)) __PYX_ERR(0, 1, __pyx_L1_error)
   Py_INCREF(__pyx_d);
   __pyx_b = PyImport_AddModule(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_b)) __PYX_ERR(0, 1, __pyx_L1_error)
-  __pyx_cython_runtime = PyImport_AddModule((char *) "cython_runtime"); if (unlikely(!__pyx_cython_runtime)) __PYX_ERR(0, 1, __pyx_L1_error)
-  #if CYTHON_COMPILING_IN_PYPY
   Py_INCREF(__pyx_b);
-  #endif
+  __pyx_cython_runtime = PyImport_AddModule((char *) "cython_runtime"); if (unlikely(!__pyx_cython_runtime)) __PYX_ERR(0, 1, __pyx_L1_error)
+  Py_INCREF(__pyx_cython_runtime);
   if (PyObject_SetAttrString(__pyx_m, "__builtins__", __pyx_b) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
   /*--- Initialize various global constants etc. ---*/
   if (__Pyx_InitGlobals() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
   #if PY_MAJOR_VERSION < 3 && (__PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT)
   if (__Pyx_init_sys_getdefaultencoding_params() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
   #endif
   if (__pyx_module_is_main_aiohttp___helpers) {
@@ -3056,17 +3060,17 @@
     PyObject *modules = PyImport_GetModuleDict(); if (unlikely(!modules)) __PYX_ERR(0, 1, __pyx_L1_error)
     if (!PyDict_GetItemString(modules, "aiohttp._helpers")) {
       if (unlikely(PyDict_SetItemString(modules, "aiohttp._helpers", __pyx_m) < 0)) __PYX_ERR(0, 1, __pyx_L1_error)
     }
   }
   #endif
   /*--- Builtin init code ---*/
-  if (__Pyx_InitCachedBuiltins() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
+  if (__Pyx_InitCachedBuiltins() < 0) goto __pyx_L1_error;
   /*--- Constants init code ---*/
-  if (__Pyx_InitCachedConstants() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
+  if (__Pyx_InitCachedConstants() < 0) goto __pyx_L1_error;
   /*--- Global type/function init code ---*/
   (void)__Pyx_modinit_global_init_code();
   (void)__Pyx_modinit_variable_export_code();
   (void)__Pyx_modinit_function_export_code();
   if (unlikely(__Pyx_modinit_type_init_code() != 0)) goto __pyx_L1_error;
   (void)__Pyx_modinit_type_import_code();
   (void)__Pyx_modinit_variable_import_code();
@@ -3629,15 +3633,15 @@
     result = PyEval_EvalFrameEx(f,0);
     ++tstate->recursion_depth;
     Py_DECREF(f);
     --tstate->recursion_depth;
     return result;
 }
 #if 1 || PY_VERSION_HEX < 0x030600B1
-static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs) {
+static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, Py_ssize_t nargs, PyObject *kwargs) {
     PyCodeObject *co = (PyCodeObject *)PyFunction_GET_CODE(func);
     PyObject *globals = PyFunction_GET_GLOBALS(func);
     PyObject *argdefs = PyFunction_GET_DEFAULTS(func);
     PyObject *closure;
 #if PY_MAJOR_VERSION >= 3
     PyObject *kwdefs;
 #endif
@@ -3700,20 +3704,20 @@
     }
     else {
         d = NULL;
         nd = 0;
     }
 #if PY_MAJOR_VERSION >= 3
     result = PyEval_EvalCodeEx((PyObject*)co, globals, (PyObject *)NULL,
-                               args, nargs,
+                               args, (int)nargs,
                                k, (int)nk,
                                d, (int)nd, kwdefs, closure);
 #else
     result = PyEval_EvalCodeEx(co, globals, (PyObject *)NULL,
-                               args, nargs,
+                               args, (int)nargs,
                                k, (int)nk,
                                d, (int)nd, closure);
 #endif
     Py_XDECREF(kwtuple);
 done:
     Py_LeaveRecursiveCall();
     return result;
@@ -4037,14 +4041,40 @@
     return d;
 }
 static CYTHON_INLINE PyObject *__Pyx_GetAttr3(PyObject *o, PyObject *n, PyObject *d) {
     PyObject *r = __Pyx_GetAttr(o, n);
     return (likely(r)) ? r : __Pyx_GetAttr3Default(d);
 }
 
+/* PyDictVersioning */
+#if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_TYPE_SLOTS
+static CYTHON_INLINE PY_UINT64_T __Pyx_get_tp_dict_version(PyObject *obj) {
+    PyObject *dict = Py_TYPE(obj)->tp_dict;
+    return likely(dict) ? __PYX_GET_DICT_VERSION(dict) : 0;
+}
+static CYTHON_INLINE PY_UINT64_T __Pyx_get_object_dict_version(PyObject *obj) {
+    PyObject **dictptr = NULL;
+    Py_ssize_t offset = Py_TYPE(obj)->tp_dictoffset;
+    if (offset) {
+#if CYTHON_COMPILING_IN_CPYTHON
+        dictptr = (likely(offset > 0)) ? (PyObject **) ((char *)obj + offset) : _PyObject_GetDictPtr(obj);
+#else
+        dictptr = _PyObject_GetDictPtr(obj);
+#endif
+    }
+    return (dictptr && *dictptr) ? __PYX_GET_DICT_VERSION(*dictptr) : 0;
+}
+static CYTHON_INLINE int __Pyx_object_dict_version_matches(PyObject* obj, PY_UINT64_T tp_dict_version, PY_UINT64_T obj_dict_version) {
+    PyObject *dict = Py_TYPE(obj)->tp_dict;
+    if (unlikely(!dict) || unlikely(tp_dict_version != __PYX_GET_DICT_VERSION(dict)))
+        return 0;
+    return obj_dict_version == __Pyx_get_object_dict_version(obj);
+}
+#endif
+
 /* GetModuleGlobalName */
 #if CYTHON_USE_DICT_VERSIONS
 static PyObject *__Pyx__GetModuleGlobalName(PyObject *name, PY_UINT64_T *dict_version, PyObject **dict_cached_value)
 #else
 static CYTHON_INLINE PyObject *__Pyx__GetModuleGlobalName(PyObject *name)
 #endif
 {
```

### Comparing `aiohttp-4.0.0a0/aiohttp/_helpers.pyx` & `aiohttp-4.0.0a1/aiohttp/_helpers.pyx`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/aiohttp/_http_parser.c` & `aiohttp-4.0.0a1/aiohttp/_http_parser.c`

 * *Files 0% similar despite different names*

```diff
@@ -1,39 +1,18 @@
-/* Generated by Cython 0.29.2 */
-
-/* BEGIN: Cython Metadata
-{
-    "distutils": {
-        "define_macros": [
-            [
-                "HTTP_PARSER_STRICT",
-                0
-            ]
-        ],
-        "depends": [],
-        "name": "aiohttp._http_parser",
-        "sources": [
-            "aiohttp/_http_parser.pyx",
-            "vendor/http-parser/http_parser.c",
-            "aiohttp/_find_header.c"
-        ]
-    },
-    "module_name": "aiohttp._http_parser"
-}
-END: Cython Metadata */
+/* Generated by Cython 0.29.13 */
 
 #define PY_SSIZE_T_CLEAN
 #include "Python.h"
 #ifndef Py_PYTHON_H
     #error Python headers needed to compile C extensions, please install development version of Python.
 #elif PY_VERSION_HEX < 0x02060000 || (0x03000000 <= PY_VERSION_HEX && PY_VERSION_HEX < 0x03030000)
     #error Cython requires Python 2.6+ or Python 3.3+.
 #else
-#define CYTHON_ABI "0_29_2"
-#define CYTHON_HEX_VERSION 0x001D02F0
+#define CYTHON_ABI "0_29_13"
+#define CYTHON_HEX_VERSION 0x001D0DF0
 #define CYTHON_FUTURE_DIVISION 1
 #include <stddef.h>
 #ifndef offsetof
   #define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
 #endif
 #if !defined(WIN32) && !defined(MS_WINDOWS)
   #ifndef __stdcall
@@ -327,16 +306,21 @@
 #if PY_MAJOR_VERSION < 3
   #define __Pyx_BUILTIN_MODULE_NAME "__builtin__"
   #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
           PyCode_New(a+k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
   #define __Pyx_DefaultClassType PyClass_Type
 #else
   #define __Pyx_BUILTIN_MODULE_NAME "builtins"
+#if PY_VERSION_HEX >= 0x030800A4 && PY_VERSION_HEX < 0x030800B2
+  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
+          PyCode_New(a, 0, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
+#else
   #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
           PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
+#endif
   #define __Pyx_DefaultClassType PyType_Type
 #endif
 #ifndef Py_TPFLAGS_CHECKTYPES
   #define Py_TPFLAGS_CHECKTYPES 0
 #endif
 #ifndef Py_TPFLAGS_HAVE_INDEX
   #define Py_TPFLAGS_HAVE_INDEX 0
@@ -363,34 +347,14 @@
 #endif
 #if CYTHON_FAST_PYCCALL
 #define __Pyx_PyFastCFunction_Check(func)\
     ((PyCFunction_Check(func) && (METH_FASTCALL == (PyCFunction_GET_FLAGS(func) & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS | METH_STACKLESS)))))
 #else
 #define __Pyx_PyFastCFunction_Check(func) 0
 #endif
-#if CYTHON_USE_DICT_VERSIONS
-#define __PYX_GET_DICT_VERSION(dict)  (((PyDictObject*)(dict))->ma_version_tag)
-#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)\
-    (version_var) = __PYX_GET_DICT_VERSION(dict);\
-    (cache_var) = (value);
-#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP) {\
-        static PY_UINT64_T __pyx_dict_version = 0;\
-        static PyObject *__pyx_dict_cached_value = NULL;\
-        if (likely(__PYX_GET_DICT_VERSION(DICT) == __pyx_dict_version)) {\
-            (VAR) = __pyx_dict_cached_value;\
-        } else {\
-            (VAR) = __pyx_dict_cached_value = (LOOKUP);\
-            __pyx_dict_version = __PYX_GET_DICT_VERSION(DICT);\
-        }\
-    }
-#else
-#define __PYX_GET_DICT_VERSION(dict)  (0)
-#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)
-#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP)  (VAR) = (LOOKUP);
-#endif
 #if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Malloc)
   #define PyObject_Malloc(s)   PyMem_Malloc(s)
   #define PyObject_Free(p)     PyMem_Free(p)
   #define PyObject_Realloc(p)  PyMem_Realloc(p)
 #endif
 #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x030400A1
   #define PyMem_RawMalloc(n)           PyMem_Malloc(n)
@@ -415,15 +379,15 @@
 #endif
 #if PY_VERSION_HEX < 0x030700A2 && !defined(PyThread_tss_create) && !defined(Py_tss_NEEDS_INIT)
 #include "pythread.h"
 #define Py_tss_NEEDS_INIT 0
 typedef int Py_tss_t;
 static CYTHON_INLINE int PyThread_tss_create(Py_tss_t *key) {
   *key = PyThread_create_key();
-  return 0; // PyThread_create_key reports success always
+  return 0;
 }
 static CYTHON_INLINE Py_tss_t * PyThread_tss_alloc(void) {
   Py_tss_t *key = (Py_tss_t *)PyObject_Malloc(sizeof(Py_tss_t));
   *key = Py_tss_NEEDS_INIT;
   return key;
 }
 static CYTHON_INLINE void PyThread_tss_free(Py_tss_t *key) {
@@ -438,15 +402,15 @@
 }
 static CYTHON_INLINE int PyThread_tss_set(Py_tss_t *key, void *value) {
   return PyThread_set_key_value(*key, value);
 }
 static CYTHON_INLINE void * PyThread_tss_get(Py_tss_t *key) {
   return PyThread_get_key_value(*key);
 }
-#endif // TSS (Thread Specific Storage) API
+#endif
 #if CYTHON_COMPILING_IN_CPYTHON || defined(_PyDict_NewPresized)
 #define __Pyx_PyDict_NewPresized(n)  ((n <= 8) ? PyDict_New() : _PyDict_NewPresized(n))
 #else
 #define __Pyx_PyDict_NewPresized(n)  PyDict_New()
 #endif
 #if PY_MAJOR_VERSION >= 3 || CYTHON_FUTURE_DIVISION
   #define __Pyx_PyNumber_Divide(x,y)         PyNumber_TrueDivide(x,y)
@@ -643,15 +607,16 @@
 #define CYTHON_WITHOUT_ASSERTIONS
 #endif
 
 typedef struct {PyObject **p; const char *s; const Py_ssize_t n; const char* encoding;
                 const char is_unicode; const char is_str; const char intern; } __Pyx_StringTabEntry;
 
 #define __PYX_DEFAULT_STRING_ENCODING_IS_ASCII 0
-#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT 0
+#define __PYX_DEFAULT_STRING_ENCODING_IS_UTF8 0
+#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT (PY_MAJOR_VERSION >= 3 && __PYX_DEFAULT_STRING_ENCODING_IS_UTF8)
 #define __PYX_DEFAULT_STRING_ENCODING ""
 #define __Pyx_PyObject_FromString __Pyx_PyBytes_FromString
 #define __Pyx_PyObject_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
 #define __Pyx_uchar_cast(c) ((unsigned char)c)
 #define __Pyx_long_cast(x) ((long)x)
 #define __Pyx_fits_Py_ssize_t(v, type, is_signed)  (\
     (sizeof(type) < sizeof(Py_ssize_t))  ||\
@@ -838,20 +803,20 @@
 static int __pyx_lineno;
 static int __pyx_clineno = 0;
 static const char * __pyx_cfilenm= __FILE__;
 static const char *__pyx_filename;
 
 
 static const char *__pyx_f[] = {
-  "aiohttp\\_http_parser.pyx",
+  "aiohttp/_http_parser.pyx",
   "stringsource",
   "type.pxd",
   "bool.pxd",
   "complex.pxd",
-  "aiohttp\\_headers.pxi",
+  "aiohttp/_headers.pxi",
 };
 
 /*--- Type declarations ---*/
 struct __pyx_obj_7aiohttp_12_http_parser_RawRequestMessage;
 struct __pyx_obj_7aiohttp_12_http_parser_RawResponseMessage;
 struct __pyx_obj_7aiohttp_12_http_parser_HttpParser;
 struct __pyx_obj_7aiohttp_12_http_parser_HttpRequestParser;
@@ -960,27 +925,27 @@
   PyObject *_last_error;
   int _auto_decompress;
   PyObject *_content_encoding;
   Py_buffer py_buf;
 };
 
 
-/* "aiohttp/_http_parser.pyx":537
+/* "aiohttp/_http_parser.pyx":540
  * 
  * 
  * cdef class HttpRequestParser(HttpParser):             # <<<<<<<<<<<<<<
  * 
  *     def __init__(self, protocol, loop, timer=None,
  */
 struct __pyx_obj_7aiohttp_12_http_parser_HttpRequestParser {
   struct __pyx_obj_7aiohttp_12_http_parser_HttpParser __pyx_base;
 };
 
 
-/* "aiohttp/_http_parser.pyx":564
+/* "aiohttp/_http_parser.pyx":567
  * 
  * 
  * cdef class HttpResponseParser(HttpParser):             # <<<<<<<<<<<<<<
  * 
  *     def __init__(self, protocol, loop, timer=None,
  */
 struct __pyx_obj_7aiohttp_12_http_parser_HttpResponseParser {
@@ -1065,29 +1030,29 @@
   PyObject *(*_on_status_complete)(struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *);
   PyObject *(*http_version)(struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *);
 };
 static struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpParser *__pyx_vtabptr_7aiohttp_12_http_parser_HttpParser;
 static CYTHON_INLINE PyObject *__pyx_f_7aiohttp_12_http_parser_10HttpParser_http_version(struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *);
 
 
-/* "aiohttp/_http_parser.pyx":537
+/* "aiohttp/_http_parser.pyx":540
  * 
  * 
  * cdef class HttpRequestParser(HttpParser):             # <<<<<<<<<<<<<<
  * 
  *     def __init__(self, protocol, loop, timer=None,
  */
 
 struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpRequestParser {
   struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpParser __pyx_base;
 };
 static struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpRequestParser *__pyx_vtabptr_7aiohttp_12_http_parser_HttpRequestParser;
 
 
-/* "aiohttp/_http_parser.pyx":564
+/* "aiohttp/_http_parser.pyx":567
  * 
  * 
  * cdef class HttpResponseParser(HttpParser):             # <<<<<<<<<<<<<<
  * 
  *     def __init__(self, protocol, loop, timer=None,
  */
 
@@ -1352,14 +1317,40 @@
 
 /* GetAttr.proto */
 static CYTHON_INLINE PyObject *__Pyx_GetAttr(PyObject *, PyObject *);
 
 /* GetAttr3.proto */
 static CYTHON_INLINE PyObject *__Pyx_GetAttr3(PyObject *, PyObject *, PyObject *);
 
+/* PyDictVersioning.proto */
+#if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_TYPE_SLOTS
+#define __PYX_DICT_VERSION_INIT  ((PY_UINT64_T) -1)
+#define __PYX_GET_DICT_VERSION(dict)  (((PyDictObject*)(dict))->ma_version_tag)
+#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)\
+    (version_var) = __PYX_GET_DICT_VERSION(dict);\
+    (cache_var) = (value);
+#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP) {\
+    static PY_UINT64_T __pyx_dict_version = 0;\
+    static PyObject *__pyx_dict_cached_value = NULL;\
+    if (likely(__PYX_GET_DICT_VERSION(DICT) == __pyx_dict_version)) {\
+        (VAR) = __pyx_dict_cached_value;\
+    } else {\
+        (VAR) = __pyx_dict_cached_value = (LOOKUP);\
+        __pyx_dict_version = __PYX_GET_DICT_VERSION(DICT);\
+    }\
+}
+static CYTHON_INLINE PY_UINT64_T __Pyx_get_tp_dict_version(PyObject *obj);
+static CYTHON_INLINE PY_UINT64_T __Pyx_get_object_dict_version(PyObject *obj);
+static CYTHON_INLINE int __Pyx_object_dict_version_matches(PyObject* obj, PY_UINT64_T tp_dict_version, PY_UINT64_T obj_dict_version);
+#else
+#define __PYX_GET_DICT_VERSION(dict)  (0)
+#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)
+#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP)  (VAR) = (LOOKUP);
+#endif
+
 /* GetModuleGlobalName.proto */
 #if CYTHON_USE_DICT_VERSIONS
 #define __Pyx_GetModuleGlobalName(var, name)  {\
     static PY_UINT64_T __pyx_dict_version = 0;\
     static PyObject *__pyx_dict_cached_value = NULL;\
     (var) = (likely(__pyx_dict_version == __PYX_GET_DICT_VERSION(__pyx_d))) ?\
         (likely(__pyx_dict_cached_value) ? __Pyx_NewRef(__pyx_dict_cached_value) : __Pyx_GetBuiltinName(name)) :\
@@ -1378,15 +1369,15 @@
 #endif
 
 /* PyFunctionFastCall.proto */
 #if CYTHON_FAST_PYCALL
 #define __Pyx_PyFunction_FastCall(func, args, nargs)\
     __Pyx_PyFunction_FastCallDict((func), (args), (nargs), NULL)
 #if 1 || PY_VERSION_HEX < 0x030600B1
-static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs);
+static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, Py_ssize_t nargs, PyObject *kwargs);
 #else
 #define __Pyx_PyFunction_FastCallDict(func, args, nargs, kwargs) _PyFunction_FastCallDict(func, args, nargs, kwargs)
 #endif
 #define __Pyx_BUILD_ASSERT_EXPR(cond)\
     (sizeof(char [1 - 2*!(cond)]) - 1)
 #ifndef Py_MEMBER_SIZE
 #define Py_MEMBER_SIZE(type, member) sizeof(((type *)0)->member)
@@ -2070,15 +2061,15 @@
 static const char __pyx_k_repr___locals_genexpr[] = "__repr__.<locals>.genexpr";
 static const char __pyx_k_ACCESS_CONTROL_MAX_AGE[] = "ACCESS_CONTROL_MAX_AGE";
 static const char __pyx_k_SEC_WEBSOCKET_PROTOCOL[] = "SEC_WEBSOCKET_PROTOCOL";
 static const char __pyx_k_Header_name_is_too_long[] = "Header name is too long";
 static const char __pyx_k_Status_line_is_too_long[] = "Status line is too long";
 static const char __pyx_k_Header_value_is_too_long[] = "Header value is too long";
 static const char __pyx_k_SEC_WEBSOCKET_EXTENSIONS[] = "SEC_WEBSOCKET_EXTENSIONS";
-static const char __pyx_k_aiohttp__http_parser_pyx[] = "aiohttp\\_http_parser.pyx";
+static const char __pyx_k_aiohttp__http_parser_pyx[] = "aiohttp/_http_parser.pyx";
 static const char __pyx_k_end_http_chunk_receiving[] = "end_http_chunk_receiving";
 static const char __pyx_k_CONTENT_TRANSFER_ENCODING[] = "CONTENT_TRANSFER_ENCODING";
 static const char __pyx_k_begin_http_chunk_receiving[] = "begin_http_chunk_receiving";
 static const char __pyx_k_ACCESS_CONTROL_ALLOW_ORIGIN[] = "ACCESS_CONTROL_ALLOW_ORIGIN";
 static const char __pyx_k_ACCESS_CONTROL_ALLOW_HEADERS[] = "ACCESS_CONTROL_ALLOW_HEADERS";
 static const char __pyx_k_ACCESS_CONTROL_ALLOW_METHODS[] = "ACCESS_CONTROL_ALLOW_METHODS";
 static const char __pyx_k_ACCESS_CONTROL_EXPOSE_HEADERS[] = "ACCESS_CONTROL_EXPOSE_HEADERS";
@@ -2357,16 +2348,17 @@
 static PyObject *__pyx_pf_7aiohttp_12_http_parser_18RawResponseMessage_7chunked___get__(struct __pyx_obj_7aiohttp_12_http_parser_RawResponseMessage *__pyx_v_self); /* proto */
 static PyObject *__pyx_pf_7aiohttp_12_http_parser_18RawResponseMessage_4__reduce_cython__(struct __pyx_obj_7aiohttp_12_http_parser_RawResponseMessage *__pyx_v_self); /* proto */
 static PyObject *__pyx_pf_7aiohttp_12_http_parser_18RawResponseMessage_6__setstate_cython__(struct __pyx_obj_7aiohttp_12_http_parser_RawResponseMessage *__pyx_v_self, PyObject *__pyx_v___pyx_state); /* proto */
 static int __pyx_pf_7aiohttp_12_http_parser_10HttpParser___cinit__(struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *__pyx_v_self); /* proto */
 static void __pyx_pf_7aiohttp_12_http_parser_10HttpParser_2__dealloc__(struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *__pyx_v_self); /* proto */
 static PyObject *__pyx_pf_7aiohttp_12_http_parser_10HttpParser_4feed_eof(struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *__pyx_v_self); /* proto */
 static PyObject *__pyx_pf_7aiohttp_12_http_parser_10HttpParser_6feed_data(struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *__pyx_v_self, PyObject *__pyx_v_data); /* proto */
-static PyObject *__pyx_pf_7aiohttp_12_http_parser_10HttpParser_8__reduce_cython__(CYTHON_UNUSED struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *__pyx_v_self); /* proto */
-static PyObject *__pyx_pf_7aiohttp_12_http_parser_10HttpParser_10__setstate_cython__(CYTHON_UNUSED struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v___pyx_state); /* proto */
+static PyObject *__pyx_pf_7aiohttp_12_http_parser_10HttpParser_8set_upgraded(struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *__pyx_v_self, PyObject *__pyx_v_val); /* proto */
+static PyObject *__pyx_pf_7aiohttp_12_http_parser_10HttpParser_10__reduce_cython__(CYTHON_UNUSED struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *__pyx_v_self); /* proto */
+static PyObject *__pyx_pf_7aiohttp_12_http_parser_10HttpParser_12__setstate_cython__(CYTHON_UNUSED struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v___pyx_state); /* proto */
 static int __pyx_pf_7aiohttp_12_http_parser_17HttpRequestParser___init__(struct __pyx_obj_7aiohttp_12_http_parser_HttpRequestParser *__pyx_v_self, PyObject *__pyx_v_protocol, PyObject *__pyx_v_loop, PyObject *__pyx_v_timer, size_t __pyx_v_max_line_size, size_t __pyx_v_max_headers, size_t __pyx_v_max_field_size, PyObject *__pyx_v_payload_exception, int __pyx_v_response_with_body, CYTHON_UNUSED int __pyx_v_read_until_eof); /* proto */
 static PyObject *__pyx_pf_7aiohttp_12_http_parser_17HttpRequestParser_2__reduce_cython__(CYTHON_UNUSED struct __pyx_obj_7aiohttp_12_http_parser_HttpRequestParser *__pyx_v_self); /* proto */
 static PyObject *__pyx_pf_7aiohttp_12_http_parser_17HttpRequestParser_4__setstate_cython__(CYTHON_UNUSED struct __pyx_obj_7aiohttp_12_http_parser_HttpRequestParser *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v___pyx_state); /* proto */
 static int __pyx_pf_7aiohttp_12_http_parser_18HttpResponseParser___init__(struct __pyx_obj_7aiohttp_12_http_parser_HttpResponseParser *__pyx_v_self, PyObject *__pyx_v_protocol, PyObject *__pyx_v_loop, PyObject *__pyx_v_timer, size_t __pyx_v_max_line_size, size_t __pyx_v_max_headers, size_t __pyx_v_max_field_size, PyObject *__pyx_v_payload_exception, int __pyx_v_response_with_body, CYTHON_UNUSED int __pyx_v_read_until_eof, int __pyx_v_auto_decompress); /* proto */
 static PyObject *__pyx_pf_7aiohttp_12_http_parser_18HttpResponseParser_2__reduce_cython__(CYTHON_UNUSED struct __pyx_obj_7aiohttp_12_http_parser_HttpResponseParser *__pyx_v_self); /* proto */
 static PyObject *__pyx_pf_7aiohttp_12_http_parser_18HttpResponseParser_4__setstate_cython__(CYTHON_UNUSED struct __pyx_obj_7aiohttp_12_http_parser_HttpResponseParser *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v___pyx_state); /* proto */
 static PyObject *__pyx_pf_7aiohttp_12_http_parser_parse_url(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_url); /* proto */
@@ -9495,15 +9487,15 @@
   }
 
   /* "aiohttp/_http_parser.pyx":534
  *             return messages, True, data[nb:]
  *         else:
  *             return messages, False, b''             # <<<<<<<<<<<<<<
  * 
- * 
+ *     def set_upgraded(self, val):
  */
   /*else*/ {
     __Pyx_XDECREF(__pyx_r);
     __pyx_t_5 = PyTuple_New(3); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 534, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_5);
     __Pyx_INCREF(__pyx_v_messages);
     __Pyx_GIVEREF(__pyx_v_messages);
@@ -9537,34 +9529,91 @@
   __Pyx_XDECREF(__pyx_v_ex);
   __Pyx_XDECREF(__pyx_v_messages);
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
+/* "aiohttp/_http_parser.pyx":536
+ *             return messages, False, b''
+ * 
+ *     def set_upgraded(self, val):             # <<<<<<<<<<<<<<
+ *         self._upgraded = val
+ * 
+ */
+
+/* Python wrapper */
+static PyObject *__pyx_pw_7aiohttp_12_http_parser_10HttpParser_9set_upgraded(PyObject *__pyx_v_self, PyObject *__pyx_v_val); /*proto*/
+static PyObject *__pyx_pw_7aiohttp_12_http_parser_10HttpParser_9set_upgraded(PyObject *__pyx_v_self, PyObject *__pyx_v_val) {
+  PyObject *__pyx_r = 0;
+  __Pyx_RefNannyDeclarations
+  __Pyx_RefNannySetupContext("set_upgraded (wrapper)", 0);
+  __pyx_r = __pyx_pf_7aiohttp_12_http_parser_10HttpParser_8set_upgraded(((struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *)__pyx_v_self), ((PyObject *)__pyx_v_val));
+
+  /* function exit code */
+  __Pyx_RefNannyFinishContext();
+  return __pyx_r;
+}
+
+static PyObject *__pyx_pf_7aiohttp_12_http_parser_10HttpParser_8set_upgraded(struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *__pyx_v_self, PyObject *__pyx_v_val) {
+  PyObject *__pyx_r = NULL;
+  __Pyx_RefNannyDeclarations
+  int __pyx_t_1;
+  __Pyx_RefNannySetupContext("set_upgraded", 0);
+
+  /* "aiohttp/_http_parser.pyx":537
+ * 
+ *     def set_upgraded(self, val):
+ *         self._upgraded = val             # <<<<<<<<<<<<<<
+ * 
+ * 
+ */
+  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_val); if (unlikely((__pyx_t_1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 537, __pyx_L1_error)
+  __pyx_v_self->_upgraded = __pyx_t_1;
+
+  /* "aiohttp/_http_parser.pyx":536
+ *             return messages, False, b''
+ * 
+ *     def set_upgraded(self, val):             # <<<<<<<<<<<<<<
+ *         self._upgraded = val
+ * 
+ */
+
+  /* function exit code */
+  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
+  goto __pyx_L0;
+  __pyx_L1_error:;
+  __Pyx_AddTraceback("aiohttp._http_parser.HttpParser.set_upgraded", __pyx_clineno, __pyx_lineno, __pyx_filename);
+  __pyx_r = NULL;
+  __pyx_L0:;
+  __Pyx_XGIVEREF(__pyx_r);
+  __Pyx_RefNannyFinishContext();
+  return __pyx_r;
+}
+
 /* "(tree fragment)":1
  * def __reduce_cython__(self):             # <<<<<<<<<<<<<<
  *     raise TypeError("no default __reduce__ due to non-trivial __cinit__")
  * def __setstate_cython__(self, __pyx_state):
  */
 
 /* Python wrapper */
-static PyObject *__pyx_pw_7aiohttp_12_http_parser_10HttpParser_9__reduce_cython__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
-static PyObject *__pyx_pw_7aiohttp_12_http_parser_10HttpParser_9__reduce_cython__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
+static PyObject *__pyx_pw_7aiohttp_12_http_parser_10HttpParser_11__reduce_cython__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
+static PyObject *__pyx_pw_7aiohttp_12_http_parser_10HttpParser_11__reduce_cython__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
   PyObject *__pyx_r = 0;
   __Pyx_RefNannyDeclarations
   __Pyx_RefNannySetupContext("__reduce_cython__ (wrapper)", 0);
-  __pyx_r = __pyx_pf_7aiohttp_12_http_parser_10HttpParser_8__reduce_cython__(((struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *)__pyx_v_self));
+  __pyx_r = __pyx_pf_7aiohttp_12_http_parser_10HttpParser_10__reduce_cython__(((struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *)__pyx_v_self));
 
   /* function exit code */
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-static PyObject *__pyx_pf_7aiohttp_12_http_parser_10HttpParser_8__reduce_cython__(CYTHON_UNUSED struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *__pyx_v_self) {
+static PyObject *__pyx_pf_7aiohttp_12_http_parser_10HttpParser_10__reduce_cython__(CYTHON_UNUSED struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *__pyx_v_self) {
   PyObject *__pyx_r = NULL;
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   __Pyx_RefNannySetupContext("__reduce_cython__", 0);
 
   /* "(tree fragment)":2
  * def __reduce_cython__(self):
@@ -9598,27 +9647,27 @@
  * def __reduce_cython__(self):
  *     raise TypeError("no default __reduce__ due to non-trivial __cinit__")
  * def __setstate_cython__(self, __pyx_state):             # <<<<<<<<<<<<<<
  *     raise TypeError("no default __reduce__ due to non-trivial __cinit__")
  */
 
 /* Python wrapper */
-static PyObject *__pyx_pw_7aiohttp_12_http_parser_10HttpParser_11__setstate_cython__(PyObject *__pyx_v_self, PyObject *__pyx_v___pyx_state); /*proto*/
-static PyObject *__pyx_pw_7aiohttp_12_http_parser_10HttpParser_11__setstate_cython__(PyObject *__pyx_v_self, PyObject *__pyx_v___pyx_state) {
+static PyObject *__pyx_pw_7aiohttp_12_http_parser_10HttpParser_13__setstate_cython__(PyObject *__pyx_v_self, PyObject *__pyx_v___pyx_state); /*proto*/
+static PyObject *__pyx_pw_7aiohttp_12_http_parser_10HttpParser_13__setstate_cython__(PyObject *__pyx_v_self, PyObject *__pyx_v___pyx_state) {
   PyObject *__pyx_r = 0;
   __Pyx_RefNannyDeclarations
   __Pyx_RefNannySetupContext("__setstate_cython__ (wrapper)", 0);
-  __pyx_r = __pyx_pf_7aiohttp_12_http_parser_10HttpParser_10__setstate_cython__(((struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *)__pyx_v_self), ((PyObject *)__pyx_v___pyx_state));
+  __pyx_r = __pyx_pf_7aiohttp_12_http_parser_10HttpParser_12__setstate_cython__(((struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *)__pyx_v_self), ((PyObject *)__pyx_v___pyx_state));
 
   /* function exit code */
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-static PyObject *__pyx_pf_7aiohttp_12_http_parser_10HttpParser_10__setstate_cython__(CYTHON_UNUSED struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v___pyx_state) {
+static PyObject *__pyx_pf_7aiohttp_12_http_parser_10HttpParser_12__setstate_cython__(CYTHON_UNUSED struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v___pyx_state) {
   PyObject *__pyx_r = NULL;
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   __Pyx_RefNannySetupContext("__setstate_cython__", 0);
 
   /* "(tree fragment)":4
  *     raise TypeError("no default __reduce__ due to non-trivial __cinit__")
@@ -9644,15 +9693,15 @@
   __Pyx_AddTraceback("aiohttp._http_parser.HttpParser.__setstate_cython__", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __pyx_r = NULL;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "aiohttp/_http_parser.pyx":539
+/* "aiohttp/_http_parser.pyx":542
  * cdef class HttpRequestParser(HttpParser):
  * 
  *     def __init__(self, protocol, loop, timer=None,             # <<<<<<<<<<<<<<
  *                  size_t max_line_size=8190, size_t max_headers=32768,
  *                  size_t max_field_size=8190, payload_exception=None,
  */
 
@@ -9672,15 +9721,15 @@
   __Pyx_RefNannyDeclarations
   __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
   {
     static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_protocol,&__pyx_n_s_loop,&__pyx_n_s_timer,&__pyx_n_s_max_line_size,&__pyx_n_s_max_headers,&__pyx_n_s_max_field_size,&__pyx_n_s_payload_exception,&__pyx_n_s_response_with_body,&__pyx_n_s_read_until_eof,0};
     PyObject* values[9] = {0,0,0,0,0,0,0,0,0};
     values[2] = ((PyObject *)Py_None);
 
-    /* "aiohttp/_http_parser.pyx":541
+    /* "aiohttp/_http_parser.pyx":544
  *     def __init__(self, protocol, loop, timer=None,
  *                  size_t max_line_size=8190, size_t max_headers=32768,
  *                  size_t max_field_size=8190, payload_exception=None,             # <<<<<<<<<<<<<<
  *                  bint response_with_body=True, bint read_until_eof=False):
  *          self._init(cparser.HTTP_REQUEST, protocol, loop, timer,
  */
     values[6] = ((PyObject *)Py_None);
@@ -9714,15 +9763,15 @@
         case  0:
         if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_protocol)) != 0)) kw_args--;
         else goto __pyx_L5_argtuple_error;
         CYTHON_FALLTHROUGH;
         case  1:
         if (likely((values[1] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_loop)) != 0)) kw_args--;
         else {
-          __Pyx_RaiseArgtupleInvalid("__init__", 0, 2, 9, 1); __PYX_ERR(0, 539, __pyx_L3_error)
+          __Pyx_RaiseArgtupleInvalid("__init__", 0, 2, 9, 1); __PYX_ERR(0, 542, __pyx_L3_error)
         }
         CYTHON_FALLTHROUGH;
         case  2:
         if (kw_args > 0) {
           PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_timer);
           if (value) { values[2] = value; kw_args--; }
         }
@@ -9760,15 +9809,15 @@
         case  8:
         if (kw_args > 0) {
           PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_read_until_eof);
           if (value) { values[8] = value; kw_args--; }
         }
       }
       if (unlikely(kw_args > 0)) {
-        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__init__") < 0)) __PYX_ERR(0, 539, __pyx_L3_error)
+        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__init__") < 0)) __PYX_ERR(0, 542, __pyx_L3_error)
       }
     } else {
       switch (PyTuple_GET_SIZE(__pyx_args)) {
         case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
         CYTHON_FALLTHROUGH;
         case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
         CYTHON_FALLTHROUGH;
@@ -9788,59 +9837,59 @@
         default: goto __pyx_L5_argtuple_error;
       }
     }
     __pyx_v_protocol = values[0];
     __pyx_v_loop = values[1];
     __pyx_v_timer = values[2];
     if (values[3]) {
-      __pyx_v_max_line_size = __Pyx_PyInt_As_size_t(values[3]); if (unlikely((__pyx_v_max_line_size == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 540, __pyx_L3_error)
+      __pyx_v_max_line_size = __Pyx_PyInt_As_size_t(values[3]); if (unlikely((__pyx_v_max_line_size == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 543, __pyx_L3_error)
     } else {
       __pyx_v_max_line_size = ((size_t)0x1FFE);
     }
     if (values[4]) {
-      __pyx_v_max_headers = __Pyx_PyInt_As_size_t(values[4]); if (unlikely((__pyx_v_max_headers == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 540, __pyx_L3_error)
+      __pyx_v_max_headers = __Pyx_PyInt_As_size_t(values[4]); if (unlikely((__pyx_v_max_headers == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 543, __pyx_L3_error)
     } else {
       __pyx_v_max_headers = ((size_t)0x8000);
     }
     if (values[5]) {
-      __pyx_v_max_field_size = __Pyx_PyInt_As_size_t(values[5]); if (unlikely((__pyx_v_max_field_size == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 541, __pyx_L3_error)
+      __pyx_v_max_field_size = __Pyx_PyInt_As_size_t(values[5]); if (unlikely((__pyx_v_max_field_size == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 544, __pyx_L3_error)
     } else {
       __pyx_v_max_field_size = ((size_t)0x1FFE);
     }
     __pyx_v_payload_exception = values[6];
     if (values[7]) {
-      __pyx_v_response_with_body = __Pyx_PyObject_IsTrue(values[7]); if (unlikely((__pyx_v_response_with_body == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 542, __pyx_L3_error)
+      __pyx_v_response_with_body = __Pyx_PyObject_IsTrue(values[7]); if (unlikely((__pyx_v_response_with_body == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 545, __pyx_L3_error)
     } else {
 
-      /* "aiohttp/_http_parser.pyx":542
+      /* "aiohttp/_http_parser.pyx":545
  *                  size_t max_line_size=8190, size_t max_headers=32768,
  *                  size_t max_field_size=8190, payload_exception=None,
  *                  bint response_with_body=True, bint read_until_eof=False):             # <<<<<<<<<<<<<<
  *          self._init(cparser.HTTP_REQUEST, protocol, loop, timer,
  *                     max_line_size, max_headers, max_field_size,
  */
       __pyx_v_response_with_body = ((int)1);
     }
     if (values[8]) {
-      __pyx_v_read_until_eof = __Pyx_PyObject_IsTrue(values[8]); if (unlikely((__pyx_v_read_until_eof == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 542, __pyx_L3_error)
+      __pyx_v_read_until_eof = __Pyx_PyObject_IsTrue(values[8]); if (unlikely((__pyx_v_read_until_eof == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 545, __pyx_L3_error)
     } else {
       __pyx_v_read_until_eof = ((int)0);
     }
   }
   goto __pyx_L4_argument_unpacking_done;
   __pyx_L5_argtuple_error:;
-  __Pyx_RaiseArgtupleInvalid("__init__", 0, 2, 9, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 539, __pyx_L3_error)
+  __Pyx_RaiseArgtupleInvalid("__init__", 0, 2, 9, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 542, __pyx_L3_error)
   __pyx_L3_error:;
   __Pyx_AddTraceback("aiohttp._http_parser.HttpRequestParser.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __Pyx_RefNannyFinishContext();
   return -1;
   __pyx_L4_argument_unpacking_done:;
   __pyx_r = __pyx_pf_7aiohttp_12_http_parser_17HttpRequestParser___init__(((struct __pyx_obj_7aiohttp_12_http_parser_HttpRequestParser *)__pyx_v_self), __pyx_v_protocol, __pyx_v_loop, __pyx_v_timer, __pyx_v_max_line_size, __pyx_v_max_headers, __pyx_v_max_field_size, __pyx_v_payload_exception, __pyx_v_response_with_body, __pyx_v_read_until_eof);
 
-  /* "aiohttp/_http_parser.pyx":539
+  /* "aiohttp/_http_parser.pyx":542
  * cdef class HttpRequestParser(HttpParser):
  * 
  *     def __init__(self, protocol, loop, timer=None,             # <<<<<<<<<<<<<<
  *                  size_t max_line_size=8190, size_t max_headers=32768,
  *                  size_t max_field_size=8190, payload_exception=None,
  */
 
@@ -9852,33 +9901,33 @@
 static int __pyx_pf_7aiohttp_12_http_parser_17HttpRequestParser___init__(struct __pyx_obj_7aiohttp_12_http_parser_HttpRequestParser *__pyx_v_self, PyObject *__pyx_v_protocol, PyObject *__pyx_v_loop, PyObject *__pyx_v_timer, size_t __pyx_v_max_line_size, size_t __pyx_v_max_headers, size_t __pyx_v_max_field_size, PyObject *__pyx_v_payload_exception, int __pyx_v_response_with_body, CYTHON_UNUSED int __pyx_v_read_until_eof) {
   int __pyx_r;
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   struct __pyx_opt_args_7aiohttp_12_http_parser_10HttpParser__init __pyx_t_2;
   __Pyx_RefNannySetupContext("__init__", 0);
 
-  /* "aiohttp/_http_parser.pyx":543
+  /* "aiohttp/_http_parser.pyx":546
  *                  size_t max_field_size=8190, payload_exception=None,
  *                  bint response_with_body=True, bint read_until_eof=False):
  *          self._init(cparser.HTTP_REQUEST, protocol, loop, timer,             # <<<<<<<<<<<<<<
  *                     max_line_size, max_headers, max_field_size,
  *                     payload_exception, response_with_body)
  */
   __pyx_t_2.__pyx_n = 6;
   __pyx_t_2.timer = __pyx_v_timer;
   __pyx_t_2.max_line_size = __pyx_v_max_line_size;
   __pyx_t_2.max_headers = __pyx_v_max_headers;
   __pyx_t_2.max_field_size = __pyx_v_max_field_size;
   __pyx_t_2.payload_exception = __pyx_v_payload_exception;
   __pyx_t_2.response_with_body = __pyx_v_response_with_body;
-  __pyx_t_1 = ((struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpRequestParser *)__pyx_v_self->__pyx_base.__pyx_vtab)->__pyx_base._init(((struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *)__pyx_v_self), HTTP_REQUEST, __pyx_v_protocol, __pyx_v_loop, &__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 543, __pyx_L1_error)
+  __pyx_t_1 = ((struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpRequestParser *)__pyx_v_self->__pyx_base.__pyx_vtab)->__pyx_base._init(((struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *)__pyx_v_self), HTTP_REQUEST, __pyx_v_protocol, __pyx_v_loop, &__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 546, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
 
-  /* "aiohttp/_http_parser.pyx":539
+  /* "aiohttp/_http_parser.pyx":542
  * cdef class HttpRequestParser(HttpParser):
  * 
  *     def __init__(self, protocol, loop, timer=None,             # <<<<<<<<<<<<<<
  *                  size_t max_line_size=8190, size_t max_headers=32768,
  *                  size_t max_field_size=8190, payload_exception=None,
  */
 
@@ -9890,15 +9939,15 @@
   __Pyx_AddTraceback("aiohttp._http_parser.HttpRequestParser.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __pyx_r = -1;
   __pyx_L0:;
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "aiohttp/_http_parser.pyx":547
+/* "aiohttp/_http_parser.pyx":550
  *                     payload_exception, response_with_body)
  * 
  *     cdef object _on_status_complete(self):             # <<<<<<<<<<<<<<
  *          cdef Py_buffer py_buf
  *          if not self._buf:
  */
 
@@ -9918,75 +9967,75 @@
   PyObject *__pyx_t_10 = NULL;
   PyObject *__pyx_t_11 = NULL;
   PyObject *__pyx_t_12 = NULL;
   PyObject *__pyx_t_13 = NULL;
   PyObject *__pyx_t_14 = NULL;
   __Pyx_RefNannySetupContext("_on_status_complete", 0);
 
-  /* "aiohttp/_http_parser.pyx":549
+  /* "aiohttp/_http_parser.pyx":552
  *     cdef object _on_status_complete(self):
  *          cdef Py_buffer py_buf
  *          if not self._buf:             # <<<<<<<<<<<<<<
  *              return
  *          self._path = self._buf.decode('utf-8', 'surrogateescape')
  */
   __pyx_t_1 = (__pyx_v_self->__pyx_base._buf != Py_None)&&(PyByteArray_GET_SIZE(__pyx_v_self->__pyx_base._buf) != 0);
   __pyx_t_2 = ((!__pyx_t_1) != 0);
   if (__pyx_t_2) {
 
-    /* "aiohttp/_http_parser.pyx":550
+    /* "aiohttp/_http_parser.pyx":553
  *          cdef Py_buffer py_buf
  *          if not self._buf:
  *              return             # <<<<<<<<<<<<<<
  *          self._path = self._buf.decode('utf-8', 'surrogateescape')
  *          if self._cparser.method == 5:  # CONNECT
  */
     __Pyx_XDECREF(__pyx_r);
     __pyx_r = Py_None; __Pyx_INCREF(Py_None);
     goto __pyx_L0;
 
-    /* "aiohttp/_http_parser.pyx":549
+    /* "aiohttp/_http_parser.pyx":552
  *     cdef object _on_status_complete(self):
  *          cdef Py_buffer py_buf
  *          if not self._buf:             # <<<<<<<<<<<<<<
  *              return
  *          self._path = self._buf.decode('utf-8', 'surrogateescape')
  */
   }
 
-  /* "aiohttp/_http_parser.pyx":551
+  /* "aiohttp/_http_parser.pyx":554
  *          if not self._buf:
  *              return
  *          self._path = self._buf.decode('utf-8', 'surrogateescape')             # <<<<<<<<<<<<<<
  *          if self._cparser.method == 5:  # CONNECT
  *              self._url = URL(self._path)
  */
   if (unlikely(__pyx_v_self->__pyx_base._buf == Py_None)) {
     PyErr_Format(PyExc_AttributeError, "'NoneType' object has no attribute '%.30s'", "decode");
-    __PYX_ERR(0, 551, __pyx_L1_error)
+    __PYX_ERR(0, 554, __pyx_L1_error)
   }
-  __pyx_t_3 = __Pyx_decode_bytearray(__pyx_v_self->__pyx_base._buf, 0, PY_SSIZE_T_MAX, NULL, ((char const *)"surrogateescape"), PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 551, __pyx_L1_error)
+  __pyx_t_3 = __Pyx_decode_bytearray(__pyx_v_self->__pyx_base._buf, 0, PY_SSIZE_T_MAX, NULL, ((char const *)"surrogateescape"), PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 554, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_3);
   __Pyx_GIVEREF(__pyx_t_3);
   __Pyx_GOTREF(__pyx_v_self->__pyx_base._path);
   __Pyx_DECREF(__pyx_v_self->__pyx_base._path);
   __pyx_v_self->__pyx_base._path = ((PyObject*)__pyx_t_3);
   __pyx_t_3 = 0;
 
-  /* "aiohttp/_http_parser.pyx":552
+  /* "aiohttp/_http_parser.pyx":555
  *              return
  *          self._path = self._buf.decode('utf-8', 'surrogateescape')
  *          if self._cparser.method == 5:  # CONNECT             # <<<<<<<<<<<<<<
  *              self._url = URL(self._path)
  *          else:
  */
   __pyx_t_2 = ((__pyx_v_self->__pyx_base._cparser->method == 5) != 0);
   if (__pyx_t_2) {
 
-    /* "aiohttp/_http_parser.pyx":553
+    /* "aiohttp/_http_parser.pyx":556
  *          self._path = self._buf.decode('utf-8', 'surrogateescape')
  *          if self._cparser.method == 5:  # CONNECT
  *              self._url = URL(self._path)             # <<<<<<<<<<<<<<
  *          else:
  *              PyObject_GetBuffer(self._buf, &py_buf, PyBUF_SIMPLE)
  */
     __Pyx_INCREF(__pyx_v_7aiohttp_12_http_parser_URL);
@@ -9998,72 +10047,72 @@
         __Pyx_INCREF(__pyx_t_5);
         __Pyx_INCREF(function);
         __Pyx_DECREF_SET(__pyx_t_4, function);
       }
     }
     __pyx_t_3 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_5, __pyx_v_self->__pyx_base._path) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_v_self->__pyx_base._path);
     __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
-    if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 553, __pyx_L1_error)
+    if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 556, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
     __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
     __Pyx_GIVEREF(__pyx_t_3);
     __Pyx_GOTREF(__pyx_v_self->__pyx_base._url);
     __Pyx_DECREF(__pyx_v_self->__pyx_base._url);
     __pyx_v_self->__pyx_base._url = __pyx_t_3;
     __pyx_t_3 = 0;
 
-    /* "aiohttp/_http_parser.pyx":552
+    /* "aiohttp/_http_parser.pyx":555
  *              return
  *          self._path = self._buf.decode('utf-8', 'surrogateescape')
  *          if self._cparser.method == 5:  # CONNECT             # <<<<<<<<<<<<<<
  *              self._url = URL(self._path)
  *          else:
  */
     goto __pyx_L4;
   }
 
-  /* "aiohttp/_http_parser.pyx":555
+  /* "aiohttp/_http_parser.pyx":558
  *              self._url = URL(self._path)
  *          else:
  *              PyObject_GetBuffer(self._buf, &py_buf, PyBUF_SIMPLE)             # <<<<<<<<<<<<<<
  *              try:
  *                  self._url = _parse_url(<char*>py_buf.buf,
  */
   /*else*/ {
     __pyx_t_3 = __pyx_v_self->__pyx_base._buf;
     __Pyx_INCREF(__pyx_t_3);
-    __pyx_t_6 = PyObject_GetBuffer(__pyx_t_3, (&__pyx_v_py_buf), PyBUF_SIMPLE); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(0, 555, __pyx_L1_error)
+    __pyx_t_6 = PyObject_GetBuffer(__pyx_t_3, (&__pyx_v_py_buf), PyBUF_SIMPLE); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(0, 558, __pyx_L1_error)
     __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
 
-    /* "aiohttp/_http_parser.pyx":556
+    /* "aiohttp/_http_parser.pyx":559
  *          else:
  *              PyObject_GetBuffer(self._buf, &py_buf, PyBUF_SIMPLE)
  *              try:             # <<<<<<<<<<<<<<
  *                  self._url = _parse_url(<char*>py_buf.buf,
  *                                         py_buf.len)
  */
     /*try:*/ {
 
-      /* "aiohttp/_http_parser.pyx":557
+      /* "aiohttp/_http_parser.pyx":560
  *              PyObject_GetBuffer(self._buf, &py_buf, PyBUF_SIMPLE)
  *              try:
  *                  self._url = _parse_url(<char*>py_buf.buf,             # <<<<<<<<<<<<<<
  *                                         py_buf.len)
  *              finally:
  */
-      __pyx_t_3 = __pyx_f_7aiohttp_12_http_parser__parse_url(((char *)__pyx_v_py_buf.buf), __pyx_v_py_buf.len); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 557, __pyx_L6_error)
+      __pyx_t_3 = __pyx_f_7aiohttp_12_http_parser__parse_url(((char *)__pyx_v_py_buf.buf), __pyx_v_py_buf.len); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 560, __pyx_L6_error)
       __Pyx_GOTREF(__pyx_t_3);
       __Pyx_GIVEREF(__pyx_t_3);
       __Pyx_GOTREF(__pyx_v_self->__pyx_base._url);
       __Pyx_DECREF(__pyx_v_self->__pyx_base._url);
       __pyx_v_self->__pyx_base._url = __pyx_t_3;
       __pyx_t_3 = 0;
     }
 
-    /* "aiohttp/_http_parser.pyx":560
+    /* "aiohttp/_http_parser.pyx":563
  *                                         py_buf.len)
  *              finally:
  *                  PyBuffer_Release(&py_buf)             # <<<<<<<<<<<<<<
  *          PyByteArray_Resize(self._buf, 0)
  * 
  */
     /*finally:*/ {
@@ -10072,17 +10121,17 @@
         goto __pyx_L7;
       }
       __pyx_L6_error:;
       /*exception exit:*/{
         __Pyx_PyThreadState_declare
         __Pyx_PyThreadState_assign
         __pyx_t_9 = 0; __pyx_t_10 = 0; __pyx_t_11 = 0; __pyx_t_12 = 0; __pyx_t_13 = 0; __pyx_t_14 = 0;
-        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
-        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
         __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
+        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
+        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
         if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_12, &__pyx_t_13, &__pyx_t_14);
         if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_9, &__pyx_t_10, &__pyx_t_11) < 0)) __Pyx_ErrFetch(&__pyx_t_9, &__pyx_t_10, &__pyx_t_11);
         __Pyx_XGOTREF(__pyx_t_9);
         __Pyx_XGOTREF(__pyx_t_10);
         __Pyx_XGOTREF(__pyx_t_11);
         __Pyx_XGOTREF(__pyx_t_12);
         __Pyx_XGOTREF(__pyx_t_13);
@@ -10106,27 +10155,27 @@
         goto __pyx_L1_error;
       }
       __pyx_L7:;
     }
   }
   __pyx_L4:;
 
-  /* "aiohttp/_http_parser.pyx":561
+  /* "aiohttp/_http_parser.pyx":564
  *              finally:
  *                  PyBuffer_Release(&py_buf)
  *          PyByteArray_Resize(self._buf, 0)             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_t_3 = __pyx_v_self->__pyx_base._buf;
   __Pyx_INCREF(__pyx_t_3);
-  __pyx_t_7 = PyByteArray_Resize(__pyx_t_3, 0); if (unlikely(__pyx_t_7 == ((int)-1))) __PYX_ERR(0, 561, __pyx_L1_error)
+  __pyx_t_7 = PyByteArray_Resize(__pyx_t_3, 0); if (unlikely(__pyx_t_7 == ((int)-1))) __PYX_ERR(0, 564, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
 
-  /* "aiohttp/_http_parser.pyx":547
+  /* "aiohttp/_http_parser.pyx":550
  *                     payload_exception, response_with_body)
  * 
  *     cdef object _on_status_complete(self):             # <<<<<<<<<<<<<<
  *          cdef Py_buffer py_buf
  *          if not self._buf:
  */
 
@@ -10248,15 +10297,15 @@
   __Pyx_AddTraceback("aiohttp._http_parser.HttpRequestParser.__setstate_cython__", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __pyx_r = NULL;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "aiohttp/_http_parser.pyx":566
+/* "aiohttp/_http_parser.pyx":569
  * cdef class HttpResponseParser(HttpParser):
  * 
  *     def __init__(self, protocol, loop, timer=None,             # <<<<<<<<<<<<<<
  *                  size_t max_line_size=8190, size_t max_headers=32768,
  *                  size_t max_field_size=8190, payload_exception=None,
  */
 
@@ -10277,15 +10326,15 @@
   __Pyx_RefNannyDeclarations
   __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
   {
     static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_protocol,&__pyx_n_s_loop,&__pyx_n_s_timer,&__pyx_n_s_max_line_size,&__pyx_n_s_max_headers,&__pyx_n_s_max_field_size,&__pyx_n_s_payload_exception,&__pyx_n_s_response_with_body,&__pyx_n_s_read_until_eof,&__pyx_n_s_auto_decompress,0};
     PyObject* values[10] = {0,0,0,0,0,0,0,0,0,0};
     values[2] = ((PyObject *)Py_None);
 
-    /* "aiohttp/_http_parser.pyx":568
+    /* "aiohttp/_http_parser.pyx":571
  *     def __init__(self, protocol, loop, timer=None,
  *                  size_t max_line_size=8190, size_t max_headers=32768,
  *                  size_t max_field_size=8190, payload_exception=None,             # <<<<<<<<<<<<<<
  *                  bint response_with_body=True, bint read_until_eof=False,
  *                  bint auto_decompress=True):
  */
     values[6] = ((PyObject *)Py_None);
@@ -10321,15 +10370,15 @@
         case  0:
         if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_protocol)) != 0)) kw_args--;
         else goto __pyx_L5_argtuple_error;
         CYTHON_FALLTHROUGH;
         case  1:
         if (likely((values[1] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_loop)) != 0)) kw_args--;
         else {
-          __Pyx_RaiseArgtupleInvalid("__init__", 0, 2, 10, 1); __PYX_ERR(0, 566, __pyx_L3_error)
+          __Pyx_RaiseArgtupleInvalid("__init__", 0, 2, 10, 1); __PYX_ERR(0, 569, __pyx_L3_error)
         }
         CYTHON_FALLTHROUGH;
         case  2:
         if (kw_args > 0) {
           PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_timer);
           if (value) { values[2] = value; kw_args--; }
         }
@@ -10373,15 +10422,15 @@
         case  9:
         if (kw_args > 0) {
           PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_auto_decompress);
           if (value) { values[9] = value; kw_args--; }
         }
       }
       if (unlikely(kw_args > 0)) {
-        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__init__") < 0)) __PYX_ERR(0, 566, __pyx_L3_error)
+        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__init__") < 0)) __PYX_ERR(0, 569, __pyx_L3_error)
       }
     } else {
       switch (PyTuple_GET_SIZE(__pyx_args)) {
         case 10: values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
         CYTHON_FALLTHROUGH;
         case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
         CYTHON_FALLTHROUGH;
@@ -10403,72 +10452,72 @@
         default: goto __pyx_L5_argtuple_error;
       }
     }
     __pyx_v_protocol = values[0];
     __pyx_v_loop = values[1];
     __pyx_v_timer = values[2];
     if (values[3]) {
-      __pyx_v_max_line_size = __Pyx_PyInt_As_size_t(values[3]); if (unlikely((__pyx_v_max_line_size == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 567, __pyx_L3_error)
+      __pyx_v_max_line_size = __Pyx_PyInt_As_size_t(values[3]); if (unlikely((__pyx_v_max_line_size == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 570, __pyx_L3_error)
     } else {
       __pyx_v_max_line_size = ((size_t)0x1FFE);
     }
     if (values[4]) {
-      __pyx_v_max_headers = __Pyx_PyInt_As_size_t(values[4]); if (unlikely((__pyx_v_max_headers == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 567, __pyx_L3_error)
+      __pyx_v_max_headers = __Pyx_PyInt_As_size_t(values[4]); if (unlikely((__pyx_v_max_headers == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 570, __pyx_L3_error)
     } else {
       __pyx_v_max_headers = ((size_t)0x8000);
     }
     if (values[5]) {
-      __pyx_v_max_field_size = __Pyx_PyInt_As_size_t(values[5]); if (unlikely((__pyx_v_max_field_size == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 568, __pyx_L3_error)
+      __pyx_v_max_field_size = __Pyx_PyInt_As_size_t(values[5]); if (unlikely((__pyx_v_max_field_size == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 571, __pyx_L3_error)
     } else {
       __pyx_v_max_field_size = ((size_t)0x1FFE);
     }
     __pyx_v_payload_exception = values[6];
     if (values[7]) {
-      __pyx_v_response_with_body = __Pyx_PyObject_IsTrue(values[7]); if (unlikely((__pyx_v_response_with_body == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 569, __pyx_L3_error)
+      __pyx_v_response_with_body = __Pyx_PyObject_IsTrue(values[7]); if (unlikely((__pyx_v_response_with_body == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 572, __pyx_L3_error)
     } else {
 
-      /* "aiohttp/_http_parser.pyx":569
+      /* "aiohttp/_http_parser.pyx":572
  *                  size_t max_line_size=8190, size_t max_headers=32768,
  *                  size_t max_field_size=8190, payload_exception=None,
  *                  bint response_with_body=True, bint read_until_eof=False,             # <<<<<<<<<<<<<<
  *                  bint auto_decompress=True):
  *         self._init(cparser.HTTP_RESPONSE, protocol, loop, timer,
  */
       __pyx_v_response_with_body = ((int)1);
     }
     if (values[8]) {
-      __pyx_v_read_until_eof = __Pyx_PyObject_IsTrue(values[8]); if (unlikely((__pyx_v_read_until_eof == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 569, __pyx_L3_error)
+      __pyx_v_read_until_eof = __Pyx_PyObject_IsTrue(values[8]); if (unlikely((__pyx_v_read_until_eof == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 572, __pyx_L3_error)
     } else {
       __pyx_v_read_until_eof = ((int)0);
     }
     if (values[9]) {
-      __pyx_v_auto_decompress = __Pyx_PyObject_IsTrue(values[9]); if (unlikely((__pyx_v_auto_decompress == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 570, __pyx_L3_error)
+      __pyx_v_auto_decompress = __Pyx_PyObject_IsTrue(values[9]); if (unlikely((__pyx_v_auto_decompress == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 573, __pyx_L3_error)
     } else {
 
-      /* "aiohttp/_http_parser.pyx":570
+      /* "aiohttp/_http_parser.pyx":573
  *                  size_t max_field_size=8190, payload_exception=None,
  *                  bint response_with_body=True, bint read_until_eof=False,
  *                  bint auto_decompress=True):             # <<<<<<<<<<<<<<
  *         self._init(cparser.HTTP_RESPONSE, protocol, loop, timer,
  *                    max_line_size, max_headers, max_field_size,
  */
       __pyx_v_auto_decompress = ((int)1);
     }
   }
   goto __pyx_L4_argument_unpacking_done;
   __pyx_L5_argtuple_error:;
-  __Pyx_RaiseArgtupleInvalid("__init__", 0, 2, 10, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 566, __pyx_L3_error)
+  __Pyx_RaiseArgtupleInvalid("__init__", 0, 2, 10, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 569, __pyx_L3_error)
   __pyx_L3_error:;
   __Pyx_AddTraceback("aiohttp._http_parser.HttpResponseParser.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __Pyx_RefNannyFinishContext();
   return -1;
   __pyx_L4_argument_unpacking_done:;
   __pyx_r = __pyx_pf_7aiohttp_12_http_parser_18HttpResponseParser___init__(((struct __pyx_obj_7aiohttp_12_http_parser_HttpResponseParser *)__pyx_v_self), __pyx_v_protocol, __pyx_v_loop, __pyx_v_timer, __pyx_v_max_line_size, __pyx_v_max_headers, __pyx_v_max_field_size, __pyx_v_payload_exception, __pyx_v_response_with_body, __pyx_v_read_until_eof, __pyx_v_auto_decompress);
 
-  /* "aiohttp/_http_parser.pyx":566
+  /* "aiohttp/_http_parser.pyx":569
  * cdef class HttpResponseParser(HttpParser):
  * 
  *     def __init__(self, protocol, loop, timer=None,             # <<<<<<<<<<<<<<
  *                  size_t max_line_size=8190, size_t max_headers=32768,
  *                  size_t max_field_size=8190, payload_exception=None,
  */
 
@@ -10480,34 +10529,34 @@
 static int __pyx_pf_7aiohttp_12_http_parser_18HttpResponseParser___init__(struct __pyx_obj_7aiohttp_12_http_parser_HttpResponseParser *__pyx_v_self, PyObject *__pyx_v_protocol, PyObject *__pyx_v_loop, PyObject *__pyx_v_timer, size_t __pyx_v_max_line_size, size_t __pyx_v_max_headers, size_t __pyx_v_max_field_size, PyObject *__pyx_v_payload_exception, int __pyx_v_response_with_body, CYTHON_UNUSED int __pyx_v_read_until_eof, int __pyx_v_auto_decompress) {
   int __pyx_r;
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   struct __pyx_opt_args_7aiohttp_12_http_parser_10HttpParser__init __pyx_t_2;
   __Pyx_RefNannySetupContext("__init__", 0);
 
-  /* "aiohttp/_http_parser.pyx":571
+  /* "aiohttp/_http_parser.pyx":574
  *                  bint response_with_body=True, bint read_until_eof=False,
  *                  bint auto_decompress=True):
  *         self._init(cparser.HTTP_RESPONSE, protocol, loop, timer,             # <<<<<<<<<<<<<<
  *                    max_line_size, max_headers, max_field_size,
  *                    payload_exception, response_with_body, auto_decompress)
  */
   __pyx_t_2.__pyx_n = 7;
   __pyx_t_2.timer = __pyx_v_timer;
   __pyx_t_2.max_line_size = __pyx_v_max_line_size;
   __pyx_t_2.max_headers = __pyx_v_max_headers;
   __pyx_t_2.max_field_size = __pyx_v_max_field_size;
   __pyx_t_2.payload_exception = __pyx_v_payload_exception;
   __pyx_t_2.response_with_body = __pyx_v_response_with_body;
   __pyx_t_2.auto_decompress = __pyx_v_auto_decompress;
-  __pyx_t_1 = ((struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpResponseParser *)__pyx_v_self->__pyx_base.__pyx_vtab)->__pyx_base._init(((struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *)__pyx_v_self), HTTP_RESPONSE, __pyx_v_protocol, __pyx_v_loop, &__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 571, __pyx_L1_error)
+  __pyx_t_1 = ((struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpResponseParser *)__pyx_v_self->__pyx_base.__pyx_vtab)->__pyx_base._init(((struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *)__pyx_v_self), HTTP_RESPONSE, __pyx_v_protocol, __pyx_v_loop, &__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 574, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
 
-  /* "aiohttp/_http_parser.pyx":566
+  /* "aiohttp/_http_parser.pyx":569
  * cdef class HttpResponseParser(HttpParser):
  * 
  *     def __init__(self, protocol, loop, timer=None,             # <<<<<<<<<<<<<<
  *                  size_t max_line_size=8190, size_t max_headers=32768,
  *                  size_t max_field_size=8190, payload_exception=None,
  */
 
@@ -10519,15 +10568,15 @@
   __Pyx_AddTraceback("aiohttp._http_parser.HttpResponseParser.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __pyx_r = -1;
   __pyx_L0:;
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "aiohttp/_http_parser.pyx":575
+/* "aiohttp/_http_parser.pyx":578
  *                    payload_exception, response_with_body, auto_decompress)
  * 
  *     cdef object _on_status_complete(self):             # <<<<<<<<<<<<<<
  *         if self._buf:
  *             self._reason = self._buf.decode('utf-8', 'surrogateescape')
  */
 
@@ -10535,65 +10584,92 @@
   PyObject *__pyx_r = NULL;
   __Pyx_RefNannyDeclarations
   int __pyx_t_1;
   PyObject *__pyx_t_2 = NULL;
   int __pyx_t_3;
   __Pyx_RefNannySetupContext("_on_status_complete", 0);
 
-  /* "aiohttp/_http_parser.pyx":576
+  /* "aiohttp/_http_parser.pyx":579
  * 
  *     cdef object _on_status_complete(self):
  *         if self._buf:             # <<<<<<<<<<<<<<
  *             self._reason = self._buf.decode('utf-8', 'surrogateescape')
  *             PyByteArray_Resize(self._buf, 0)
  */
   __pyx_t_1 = (__pyx_v_self->__pyx_base._buf != Py_None)&&(PyByteArray_GET_SIZE(__pyx_v_self->__pyx_base._buf) != 0);
   if (__pyx_t_1) {
 
-    /* "aiohttp/_http_parser.pyx":577
+    /* "aiohttp/_http_parser.pyx":580
  *     cdef object _on_status_complete(self):
  *         if self._buf:
  *             self._reason = self._buf.decode('utf-8', 'surrogateescape')             # <<<<<<<<<<<<<<
  *             PyByteArray_Resize(self._buf, 0)
- * 
+ *         else:
  */
     if (unlikely(__pyx_v_self->__pyx_base._buf == Py_None)) {
       PyErr_Format(PyExc_AttributeError, "'NoneType' object has no attribute '%.30s'", "decode");
-      __PYX_ERR(0, 577, __pyx_L1_error)
+      __PYX_ERR(0, 580, __pyx_L1_error)
     }
-    __pyx_t_2 = __Pyx_decode_bytearray(__pyx_v_self->__pyx_base._buf, 0, PY_SSIZE_T_MAX, NULL, ((char const *)"surrogateescape"), PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 577, __pyx_L1_error)
+    __pyx_t_2 = __Pyx_decode_bytearray(__pyx_v_self->__pyx_base._buf, 0, PY_SSIZE_T_MAX, NULL, ((char const *)"surrogateescape"), PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 580, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_2);
     __Pyx_GIVEREF(__pyx_t_2);
     __Pyx_GOTREF(__pyx_v_self->__pyx_base._reason);
     __Pyx_DECREF(__pyx_v_self->__pyx_base._reason);
     __pyx_v_self->__pyx_base._reason = ((PyObject*)__pyx_t_2);
     __pyx_t_2 = 0;
 
-    /* "aiohttp/_http_parser.pyx":578
+    /* "aiohttp/_http_parser.pyx":581
  *         if self._buf:
  *             self._reason = self._buf.decode('utf-8', 'surrogateescape')
  *             PyByteArray_Resize(self._buf, 0)             # <<<<<<<<<<<<<<
- * 
- * 
+ *         else:
+ *             self._reason = self._reason or ''
  */
     __pyx_t_2 = __pyx_v_self->__pyx_base._buf;
     __Pyx_INCREF(__pyx_t_2);
-    __pyx_t_3 = PyByteArray_Resize(__pyx_t_2, 0); if (unlikely(__pyx_t_3 == ((int)-1))) __PYX_ERR(0, 578, __pyx_L1_error)
+    __pyx_t_3 = PyByteArray_Resize(__pyx_t_2, 0); if (unlikely(__pyx_t_3 == ((int)-1))) __PYX_ERR(0, 581, __pyx_L1_error)
     __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
 
-    /* "aiohttp/_http_parser.pyx":576
+    /* "aiohttp/_http_parser.pyx":579
  * 
  *     cdef object _on_status_complete(self):
  *         if self._buf:             # <<<<<<<<<<<<<<
  *             self._reason = self._buf.decode('utf-8', 'surrogateescape')
  *             PyByteArray_Resize(self._buf, 0)
  */
+    goto __pyx_L3;
+  }
+
+  /* "aiohttp/_http_parser.pyx":583
+ *             PyByteArray_Resize(self._buf, 0)
+ *         else:
+ *             self._reason = self._reason or ''             # <<<<<<<<<<<<<<
+ * 
+ * cdef int cb_on_message_begin(cparser.http_parser* parser) except -1:
+ */
+  /*else*/ {
+    __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_self->__pyx_base._reason); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 583, __pyx_L1_error)
+    if (!__pyx_t_1) {
+    } else {
+      __Pyx_INCREF(__pyx_v_self->__pyx_base._reason);
+      __pyx_t_2 = __pyx_v_self->__pyx_base._reason;
+      goto __pyx_L4_bool_binop_done;
+    }
+    __Pyx_INCREF(__pyx_kp_u__4);
+    __pyx_t_2 = __pyx_kp_u__4;
+    __pyx_L4_bool_binop_done:;
+    __Pyx_GIVEREF(__pyx_t_2);
+    __Pyx_GOTREF(__pyx_v_self->__pyx_base._reason);
+    __Pyx_DECREF(__pyx_v_self->__pyx_base._reason);
+    __pyx_v_self->__pyx_base._reason = ((PyObject*)__pyx_t_2);
+    __pyx_t_2 = 0;
   }
+  __pyx_L3:;
 
-  /* "aiohttp/_http_parser.pyx":575
+  /* "aiohttp/_http_parser.pyx":578
  *                    payload_exception, response_with_body, auto_decompress)
  * 
  *     cdef object _on_status_complete(self):             # <<<<<<<<<<<<<<
  *         if self._buf:
  *             self._reason = self._buf.decode('utf-8', 'surrogateescape')
  */
 
@@ -10713,16 +10789,16 @@
   __Pyx_AddTraceback("aiohttp._http_parser.HttpResponseParser.__setstate_cython__", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __pyx_r = NULL;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "aiohttp/_http_parser.pyx":581
- * 
+/* "aiohttp/_http_parser.pyx":585
+ *             self._reason = self._reason or ''
  * 
  * cdef int cb_on_message_begin(cparser.http_parser* parser) except -1:             # <<<<<<<<<<<<<<
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  * 
  */
 
 static int __pyx_f_7aiohttp_12_http_parser_cb_on_message_begin(struct http_parser *__pyx_v_parser) {
@@ -10731,36 +10807,36 @@
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   PyObject *__pyx_t_2 = NULL;
   PyObject *__pyx_t_3 = NULL;
   int __pyx_t_4;
   __Pyx_RefNannySetupContext("cb_on_message_begin", 0);
 
-  /* "aiohttp/_http_parser.pyx":582
+  /* "aiohttp/_http_parser.pyx":586
  * 
  * cdef int cb_on_message_begin(cparser.http_parser* parser) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data             # <<<<<<<<<<<<<<
  * 
  *     pyparser._started = True
  */
   __pyx_t_1 = ((PyObject *)__pyx_v_parser->data);
   __Pyx_INCREF(__pyx_t_1);
   __pyx_v_pyparser = ((struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *)__pyx_t_1);
   __pyx_t_1 = 0;
 
-  /* "aiohttp/_http_parser.pyx":584
+  /* "aiohttp/_http_parser.pyx":588
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  * 
  *     pyparser._started = True             # <<<<<<<<<<<<<<
  *     pyparser._headers = CIMultiDict()
  *     pyparser._raw_headers = []
  */
   __pyx_v_pyparser->_started = 1;
 
-  /* "aiohttp/_http_parser.pyx":585
+  /* "aiohttp/_http_parser.pyx":589
  * 
  *     pyparser._started = True
  *     pyparser._headers = CIMultiDict()             # <<<<<<<<<<<<<<
  *     pyparser._raw_headers = []
  *     PyByteArray_Resize(pyparser._buf, 0)
  */
   __Pyx_INCREF(__pyx_v_7aiohttp_12_http_parser_CIMultiDict);
@@ -10772,88 +10848,88 @@
       __Pyx_INCREF(__pyx_t_3);
       __Pyx_INCREF(function);
       __Pyx_DECREF_SET(__pyx_t_2, function);
     }
   }
   __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3) : __Pyx_PyObject_CallNoArg(__pyx_t_2);
   __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
-  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 585, __pyx_L1_error)
+  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 589, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
   __Pyx_GIVEREF(__pyx_t_1);
   __Pyx_GOTREF(__pyx_v_pyparser->_headers);
   __Pyx_DECREF(__pyx_v_pyparser->_headers);
   __pyx_v_pyparser->_headers = __pyx_t_1;
   __pyx_t_1 = 0;
 
-  /* "aiohttp/_http_parser.pyx":586
+  /* "aiohttp/_http_parser.pyx":590
  *     pyparser._started = True
  *     pyparser._headers = CIMultiDict()
  *     pyparser._raw_headers = []             # <<<<<<<<<<<<<<
  *     PyByteArray_Resize(pyparser._buf, 0)
  *     pyparser._path = None
  */
-  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 586, __pyx_L1_error)
+  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 590, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __Pyx_GIVEREF(__pyx_t_1);
   __Pyx_GOTREF(__pyx_v_pyparser->_raw_headers);
   __Pyx_DECREF(__pyx_v_pyparser->_raw_headers);
   __pyx_v_pyparser->_raw_headers = ((PyObject*)__pyx_t_1);
   __pyx_t_1 = 0;
 
-  /* "aiohttp/_http_parser.pyx":587
+  /* "aiohttp/_http_parser.pyx":591
  *     pyparser._headers = CIMultiDict()
  *     pyparser._raw_headers = []
  *     PyByteArray_Resize(pyparser._buf, 0)             # <<<<<<<<<<<<<<
  *     pyparser._path = None
  *     pyparser._reason = None
  */
   __pyx_t_1 = __pyx_v_pyparser->_buf;
   __Pyx_INCREF(__pyx_t_1);
-  __pyx_t_4 = PyByteArray_Resize(__pyx_t_1, 0); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 587, __pyx_L1_error)
+  __pyx_t_4 = PyByteArray_Resize(__pyx_t_1, 0); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 591, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
 
-  /* "aiohttp/_http_parser.pyx":588
+  /* "aiohttp/_http_parser.pyx":592
  *     pyparser._raw_headers = []
  *     PyByteArray_Resize(pyparser._buf, 0)
  *     pyparser._path = None             # <<<<<<<<<<<<<<
  *     pyparser._reason = None
  *     return 0
  */
   __Pyx_INCREF(Py_None);
   __Pyx_GIVEREF(Py_None);
   __Pyx_GOTREF(__pyx_v_pyparser->_path);
   __Pyx_DECREF(__pyx_v_pyparser->_path);
   __pyx_v_pyparser->_path = ((PyObject*)Py_None);
 
-  /* "aiohttp/_http_parser.pyx":589
+  /* "aiohttp/_http_parser.pyx":593
  *     PyByteArray_Resize(pyparser._buf, 0)
  *     pyparser._path = None
  *     pyparser._reason = None             # <<<<<<<<<<<<<<
  *     return 0
  * 
  */
   __Pyx_INCREF(Py_None);
   __Pyx_GIVEREF(Py_None);
   __Pyx_GOTREF(__pyx_v_pyparser->_reason);
   __Pyx_DECREF(__pyx_v_pyparser->_reason);
   __pyx_v_pyparser->_reason = ((PyObject*)Py_None);
 
-  /* "aiohttp/_http_parser.pyx":590
+  /* "aiohttp/_http_parser.pyx":594
  *     pyparser._path = None
  *     pyparser._reason = None
  *     return 0             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_r = 0;
   goto __pyx_L0;
 
-  /* "aiohttp/_http_parser.pyx":581
- * 
+  /* "aiohttp/_http_parser.pyx":585
+ *             self._reason = self._reason or ''
  * 
  * cdef int cb_on_message_begin(cparser.http_parser* parser) except -1:             # <<<<<<<<<<<<<<
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  * 
  */
 
   /* function exit code */
@@ -10865,15 +10941,15 @@
   __pyx_r = -1;
   __pyx_L0:;
   __Pyx_XDECREF((PyObject *)__pyx_v_pyparser);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "aiohttp/_http_parser.pyx":593
+/* "aiohttp/_http_parser.pyx":597
  * 
  * 
  * cdef int cb_on_url(cparser.http_parser* parser,             # <<<<<<<<<<<<<<
  *                    const char *at, size_t length) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  */
 
@@ -10891,27 +10967,27 @@
   PyObject *__pyx_t_7 = NULL;
   PyObject *__pyx_t_8 = NULL;
   PyObject *__pyx_t_9 = NULL;
   int __pyx_t_10;
   PyObject *__pyx_t_11 = NULL;
   __Pyx_RefNannySetupContext("cb_on_url", 0);
 
-  /* "aiohttp/_http_parser.pyx":595
+  /* "aiohttp/_http_parser.pyx":599
  * cdef int cb_on_url(cparser.http_parser* parser,
  *                    const char *at, size_t length) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data             # <<<<<<<<<<<<<<
  *     try:
  *         if length > pyparser._max_line_size:
  */
   __pyx_t_1 = ((PyObject *)__pyx_v_parser->data);
   __Pyx_INCREF(__pyx_t_1);
   __pyx_v_pyparser = ((struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *)__pyx_t_1);
   __pyx_t_1 = 0;
 
-  /* "aiohttp/_http_parser.pyx":596
+  /* "aiohttp/_http_parser.pyx":600
  *                    const char *at, size_t length) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:             # <<<<<<<<<<<<<<
  *         if length > pyparser._max_line_size:
  *             raise LineTooLong(
  */
   {
@@ -10919,44 +10995,44 @@
     __Pyx_PyThreadState_assign
     __Pyx_ExceptionSave(&__pyx_t_2, &__pyx_t_3, &__pyx_t_4);
     __Pyx_XGOTREF(__pyx_t_2);
     __Pyx_XGOTREF(__pyx_t_3);
     __Pyx_XGOTREF(__pyx_t_4);
     /*try:*/ {
 
-      /* "aiohttp/_http_parser.pyx":597
+      /* "aiohttp/_http_parser.pyx":601
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:
  *         if length > pyparser._max_line_size:             # <<<<<<<<<<<<<<
  *             raise LineTooLong(
  *                 'Status line is too long', pyparser._max_line_size, length)
  */
       __pyx_t_5 = ((__pyx_v_length > __pyx_v_pyparser->_max_line_size) != 0);
       if (unlikely(__pyx_t_5)) {
 
-        /* "aiohttp/_http_parser.pyx":598
+        /* "aiohttp/_http_parser.pyx":602
  *     try:
  *         if length > pyparser._max_line_size:
  *             raise LineTooLong(             # <<<<<<<<<<<<<<
  *                 'Status line is too long', pyparser._max_line_size, length)
  *         extend(pyparser._buf, at, length)
  */
-        __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_LineTooLong); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 598, __pyx_L3_error)
+        __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_LineTooLong); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 602, __pyx_L3_error)
         __Pyx_GOTREF(__pyx_t_6);
 
-        /* "aiohttp/_http_parser.pyx":599
+        /* "aiohttp/_http_parser.pyx":603
  *         if length > pyparser._max_line_size:
  *             raise LineTooLong(
  *                 'Status line is too long', pyparser._max_line_size, length)             # <<<<<<<<<<<<<<
  *         extend(pyparser._buf, at, length)
  *     except BaseException as ex:
  */
-        __pyx_t_7 = __Pyx_PyInt_FromSize_t(__pyx_v_pyparser->_max_line_size); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 599, __pyx_L3_error)
+        __pyx_t_7 = __Pyx_PyInt_FromSize_t(__pyx_v_pyparser->_max_line_size); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 603, __pyx_L3_error)
         __Pyx_GOTREF(__pyx_t_7);
-        __pyx_t_8 = __Pyx_PyInt_FromSize_t(__pyx_v_length); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 599, __pyx_L3_error)
+        __pyx_t_8 = __Pyx_PyInt_FromSize_t(__pyx_v_length); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 603, __pyx_L3_error)
         __Pyx_GOTREF(__pyx_t_8);
         __pyx_t_9 = NULL;
         __pyx_t_10 = 0;
         if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
           __pyx_t_9 = PyMethod_GET_SELF(__pyx_t_6);
           if (likely(__pyx_t_9)) {
             PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
@@ -10965,152 +11041,152 @@
             __Pyx_DECREF_SET(__pyx_t_6, function);
             __pyx_t_10 = 1;
           }
         }
         #if CYTHON_FAST_PYCALL
         if (PyFunction_Check(__pyx_t_6)) {
           PyObject *__pyx_temp[4] = {__pyx_t_9, __pyx_kp_u_Status_line_is_too_long, __pyx_t_7, __pyx_t_8};
-          __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 598, __pyx_L3_error)
+          __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 602, __pyx_L3_error)
           __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
           __Pyx_GOTREF(__pyx_t_1);
           __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
           __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
         } else
         #endif
         #if CYTHON_FAST_PYCCALL
         if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
           PyObject *__pyx_temp[4] = {__pyx_t_9, __pyx_kp_u_Status_line_is_too_long, __pyx_t_7, __pyx_t_8};
-          __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 598, __pyx_L3_error)
+          __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 602, __pyx_L3_error)
           __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
           __Pyx_GOTREF(__pyx_t_1);
           __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
           __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
         } else
         #endif
         {
-          __pyx_t_11 = PyTuple_New(3+__pyx_t_10); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 598, __pyx_L3_error)
+          __pyx_t_11 = PyTuple_New(3+__pyx_t_10); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 602, __pyx_L3_error)
           __Pyx_GOTREF(__pyx_t_11);
           if (__pyx_t_9) {
             __Pyx_GIVEREF(__pyx_t_9); PyTuple_SET_ITEM(__pyx_t_11, 0, __pyx_t_9); __pyx_t_9 = NULL;
           }
           __Pyx_INCREF(__pyx_kp_u_Status_line_is_too_long);
           __Pyx_GIVEREF(__pyx_kp_u_Status_line_is_too_long);
           PyTuple_SET_ITEM(__pyx_t_11, 0+__pyx_t_10, __pyx_kp_u_Status_line_is_too_long);
           __Pyx_GIVEREF(__pyx_t_7);
           PyTuple_SET_ITEM(__pyx_t_11, 1+__pyx_t_10, __pyx_t_7);
           __Pyx_GIVEREF(__pyx_t_8);
           PyTuple_SET_ITEM(__pyx_t_11, 2+__pyx_t_10, __pyx_t_8);
           __pyx_t_7 = 0;
           __pyx_t_8 = 0;
-          __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_11, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 598, __pyx_L3_error)
+          __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_11, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 602, __pyx_L3_error)
           __Pyx_GOTREF(__pyx_t_1);
           __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
         }
         __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
         __Pyx_Raise(__pyx_t_1, 0, 0, 0);
         __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
-        __PYX_ERR(0, 598, __pyx_L3_error)
+        __PYX_ERR(0, 602, __pyx_L3_error)
 
-        /* "aiohttp/_http_parser.pyx":597
+        /* "aiohttp/_http_parser.pyx":601
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:
  *         if length > pyparser._max_line_size:             # <<<<<<<<<<<<<<
  *             raise LineTooLong(
  *                 'Status line is too long', pyparser._max_line_size, length)
  */
       }
 
-      /* "aiohttp/_http_parser.pyx":600
+      /* "aiohttp/_http_parser.pyx":604
  *             raise LineTooLong(
  *                 'Status line is too long', pyparser._max_line_size, length)
  *         extend(pyparser._buf, at, length)             # <<<<<<<<<<<<<<
  *     except BaseException as ex:
  *         pyparser._last_error = ex
  */
       __pyx_t_1 = __pyx_v_pyparser->_buf;
       __Pyx_INCREF(__pyx_t_1);
-      __pyx_t_6 = __pyx_f_7aiohttp_12_http_parser_extend(__pyx_t_1, __pyx_v_at, __pyx_v_length); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 600, __pyx_L3_error)
+      __pyx_t_6 = __pyx_f_7aiohttp_12_http_parser_extend(__pyx_t_1, __pyx_v_at, __pyx_v_length); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 604, __pyx_L3_error)
       __Pyx_GOTREF(__pyx_t_6);
       __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
       __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
 
-      /* "aiohttp/_http_parser.pyx":596
+      /* "aiohttp/_http_parser.pyx":600
  *                    const char *at, size_t length) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:             # <<<<<<<<<<<<<<
  *         if length > pyparser._max_line_size:
  *             raise LineTooLong(
  */
     }
 
-    /* "aiohttp/_http_parser.pyx":605
+    /* "aiohttp/_http_parser.pyx":609
  *         return -1
  *     else:
  *         return 0             # <<<<<<<<<<<<<<
  * 
  * 
  */
     /*else:*/ {
       __pyx_r = 0;
       goto __pyx_L6_except_return;
     }
     __pyx_L3_error:;
-    __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
-    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
-    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
-    __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
     __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
+    __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
     __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
+    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
+    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
+    __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
 
-    /* "aiohttp/_http_parser.pyx":601
+    /* "aiohttp/_http_parser.pyx":605
  *                 'Status line is too long', pyparser._max_line_size, length)
  *         extend(pyparser._buf, at, length)
  *     except BaseException as ex:             # <<<<<<<<<<<<<<
  *         pyparser._last_error = ex
  *         return -1
  */
     __pyx_t_10 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_BaseException);
     if (__pyx_t_10) {
       __Pyx_AddTraceback("aiohttp._http_parser.cb_on_url", __pyx_clineno, __pyx_lineno, __pyx_filename);
-      if (__Pyx_GetException(&__pyx_t_6, &__pyx_t_1, &__pyx_t_11) < 0) __PYX_ERR(0, 601, __pyx_L5_except_error)
+      if (__Pyx_GetException(&__pyx_t_6, &__pyx_t_1, &__pyx_t_11) < 0) __PYX_ERR(0, 605, __pyx_L5_except_error)
       __Pyx_GOTREF(__pyx_t_6);
       __Pyx_GOTREF(__pyx_t_1);
       __Pyx_GOTREF(__pyx_t_11);
       __Pyx_INCREF(__pyx_t_1);
       __pyx_v_ex = __pyx_t_1;
       /*try:*/ {
 
-        /* "aiohttp/_http_parser.pyx":602
+        /* "aiohttp/_http_parser.pyx":606
  *         extend(pyparser._buf, at, length)
  *     except BaseException as ex:
  *         pyparser._last_error = ex             # <<<<<<<<<<<<<<
  *         return -1
  *     else:
  */
         __Pyx_INCREF(__pyx_v_ex);
         __Pyx_GIVEREF(__pyx_v_ex);
         __Pyx_GOTREF(__pyx_v_pyparser->_last_error);
         __Pyx_DECREF(__pyx_v_pyparser->_last_error);
         __pyx_v_pyparser->_last_error = __pyx_v_ex;
 
-        /* "aiohttp/_http_parser.pyx":603
+        /* "aiohttp/_http_parser.pyx":607
  *     except BaseException as ex:
  *         pyparser._last_error = ex
  *         return -1             # <<<<<<<<<<<<<<
  *     else:
  *         return 0
  */
         __pyx_r = -1;
         __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
         __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
         __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
         goto __pyx_L14_return;
       }
 
-      /* "aiohttp/_http_parser.pyx":601
+      /* "aiohttp/_http_parser.pyx":605
  *                 'Status line is too long', pyparser._max_line_size, length)
  *         extend(pyparser._buf, at, length)
  *     except BaseException as ex:             # <<<<<<<<<<<<<<
  *         pyparser._last_error = ex
  *         return -1
  */
       /*finally:*/ {
@@ -11122,15 +11198,15 @@
           goto __pyx_L6_except_return;
         }
       }
     }
     goto __pyx_L5_except_error;
     __pyx_L5_except_error:;
 
-    /* "aiohttp/_http_parser.pyx":596
+    /* "aiohttp/_http_parser.pyx":600
  *                    const char *at, size_t length) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:             # <<<<<<<<<<<<<<
  *         if length > pyparser._max_line_size:
  *             raise LineTooLong(
  */
     __Pyx_XGIVEREF(__pyx_t_2);
@@ -11142,15 +11218,15 @@
     __Pyx_XGIVEREF(__pyx_t_2);
     __Pyx_XGIVEREF(__pyx_t_3);
     __Pyx_XGIVEREF(__pyx_t_4);
     __Pyx_ExceptionReset(__pyx_t_2, __pyx_t_3, __pyx_t_4);
     goto __pyx_L0;
   }
 
-  /* "aiohttp/_http_parser.pyx":593
+  /* "aiohttp/_http_parser.pyx":597
  * 
  * 
  * cdef int cb_on_url(cparser.http_parser* parser,             # <<<<<<<<<<<<<<
  *                    const char *at, size_t length) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  */
 
@@ -11167,15 +11243,15 @@
   __pyx_L0:;
   __Pyx_XDECREF((PyObject *)__pyx_v_pyparser);
   __Pyx_XDECREF(__pyx_v_ex);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "aiohttp/_http_parser.pyx":608
+/* "aiohttp/_http_parser.pyx":612
  * 
  * 
  * cdef int cb_on_status(cparser.http_parser* parser,             # <<<<<<<<<<<<<<
  *                       const char *at, size_t length) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  */
 
@@ -11193,27 +11269,27 @@
   PyObject *__pyx_t_7 = NULL;
   PyObject *__pyx_t_8 = NULL;
   PyObject *__pyx_t_9 = NULL;
   int __pyx_t_10;
   PyObject *__pyx_t_11 = NULL;
   __Pyx_RefNannySetupContext("cb_on_status", 0);
 
-  /* "aiohttp/_http_parser.pyx":610
+  /* "aiohttp/_http_parser.pyx":614
  * cdef int cb_on_status(cparser.http_parser* parser,
  *                       const char *at, size_t length) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data             # <<<<<<<<<<<<<<
  *     cdef str reason
  *     try:
  */
   __pyx_t_1 = ((PyObject *)__pyx_v_parser->data);
   __Pyx_INCREF(__pyx_t_1);
   __pyx_v_pyparser = ((struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *)__pyx_t_1);
   __pyx_t_1 = 0;
 
-  /* "aiohttp/_http_parser.pyx":612
+  /* "aiohttp/_http_parser.pyx":616
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     cdef str reason
  *     try:             # <<<<<<<<<<<<<<
  *         if length > pyparser._max_line_size:
  *             raise LineTooLong(
  */
   {
@@ -11221,44 +11297,44 @@
     __Pyx_PyThreadState_assign
     __Pyx_ExceptionSave(&__pyx_t_2, &__pyx_t_3, &__pyx_t_4);
     __Pyx_XGOTREF(__pyx_t_2);
     __Pyx_XGOTREF(__pyx_t_3);
     __Pyx_XGOTREF(__pyx_t_4);
     /*try:*/ {
 
-      /* "aiohttp/_http_parser.pyx":613
+      /* "aiohttp/_http_parser.pyx":617
  *     cdef str reason
  *     try:
  *         if length > pyparser._max_line_size:             # <<<<<<<<<<<<<<
  *             raise LineTooLong(
  *                 'Status line is too long', pyparser._max_line_size, length)
  */
       __pyx_t_5 = ((__pyx_v_length > __pyx_v_pyparser->_max_line_size) != 0);
       if (unlikely(__pyx_t_5)) {
 
-        /* "aiohttp/_http_parser.pyx":614
+        /* "aiohttp/_http_parser.pyx":618
  *     try:
  *         if length > pyparser._max_line_size:
  *             raise LineTooLong(             # <<<<<<<<<<<<<<
  *                 'Status line is too long', pyparser._max_line_size, length)
  *         extend(pyparser._buf, at, length)
  */
-        __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_LineTooLong); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 614, __pyx_L3_error)
+        __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_LineTooLong); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 618, __pyx_L3_error)
         __Pyx_GOTREF(__pyx_t_6);
 
-        /* "aiohttp/_http_parser.pyx":615
+        /* "aiohttp/_http_parser.pyx":619
  *         if length > pyparser._max_line_size:
  *             raise LineTooLong(
  *                 'Status line is too long', pyparser._max_line_size, length)             # <<<<<<<<<<<<<<
  *         extend(pyparser._buf, at, length)
  *     except BaseException as ex:
  */
-        __pyx_t_7 = __Pyx_PyInt_FromSize_t(__pyx_v_pyparser->_max_line_size); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 615, __pyx_L3_error)
+        __pyx_t_7 = __Pyx_PyInt_FromSize_t(__pyx_v_pyparser->_max_line_size); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 619, __pyx_L3_error)
         __Pyx_GOTREF(__pyx_t_7);
-        __pyx_t_8 = __Pyx_PyInt_FromSize_t(__pyx_v_length); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 615, __pyx_L3_error)
+        __pyx_t_8 = __Pyx_PyInt_FromSize_t(__pyx_v_length); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 619, __pyx_L3_error)
         __Pyx_GOTREF(__pyx_t_8);
         __pyx_t_9 = NULL;
         __pyx_t_10 = 0;
         if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
           __pyx_t_9 = PyMethod_GET_SELF(__pyx_t_6);
           if (likely(__pyx_t_9)) {
             PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
@@ -11267,152 +11343,152 @@
             __Pyx_DECREF_SET(__pyx_t_6, function);
             __pyx_t_10 = 1;
           }
         }
         #if CYTHON_FAST_PYCALL
         if (PyFunction_Check(__pyx_t_6)) {
           PyObject *__pyx_temp[4] = {__pyx_t_9, __pyx_kp_u_Status_line_is_too_long, __pyx_t_7, __pyx_t_8};
-          __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 614, __pyx_L3_error)
+          __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 618, __pyx_L3_error)
           __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
           __Pyx_GOTREF(__pyx_t_1);
           __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
           __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
         } else
         #endif
         #if CYTHON_FAST_PYCCALL
         if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
           PyObject *__pyx_temp[4] = {__pyx_t_9, __pyx_kp_u_Status_line_is_too_long, __pyx_t_7, __pyx_t_8};
-          __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 614, __pyx_L3_error)
+          __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 618, __pyx_L3_error)
           __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
           __Pyx_GOTREF(__pyx_t_1);
           __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
           __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
         } else
         #endif
         {
-          __pyx_t_11 = PyTuple_New(3+__pyx_t_10); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 614, __pyx_L3_error)
+          __pyx_t_11 = PyTuple_New(3+__pyx_t_10); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 618, __pyx_L3_error)
           __Pyx_GOTREF(__pyx_t_11);
           if (__pyx_t_9) {
             __Pyx_GIVEREF(__pyx_t_9); PyTuple_SET_ITEM(__pyx_t_11, 0, __pyx_t_9); __pyx_t_9 = NULL;
           }
           __Pyx_INCREF(__pyx_kp_u_Status_line_is_too_long);
           __Pyx_GIVEREF(__pyx_kp_u_Status_line_is_too_long);
           PyTuple_SET_ITEM(__pyx_t_11, 0+__pyx_t_10, __pyx_kp_u_Status_line_is_too_long);
           __Pyx_GIVEREF(__pyx_t_7);
           PyTuple_SET_ITEM(__pyx_t_11, 1+__pyx_t_10, __pyx_t_7);
           __Pyx_GIVEREF(__pyx_t_8);
           PyTuple_SET_ITEM(__pyx_t_11, 2+__pyx_t_10, __pyx_t_8);
           __pyx_t_7 = 0;
           __pyx_t_8 = 0;
-          __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_11, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 614, __pyx_L3_error)
+          __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_11, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 618, __pyx_L3_error)
           __Pyx_GOTREF(__pyx_t_1);
           __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
         }
         __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
         __Pyx_Raise(__pyx_t_1, 0, 0, 0);
         __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
-        __PYX_ERR(0, 614, __pyx_L3_error)
+        __PYX_ERR(0, 618, __pyx_L3_error)
 
-        /* "aiohttp/_http_parser.pyx":613
+        /* "aiohttp/_http_parser.pyx":617
  *     cdef str reason
  *     try:
  *         if length > pyparser._max_line_size:             # <<<<<<<<<<<<<<
  *             raise LineTooLong(
  *                 'Status line is too long', pyparser._max_line_size, length)
  */
       }
 
-      /* "aiohttp/_http_parser.pyx":616
+      /* "aiohttp/_http_parser.pyx":620
  *             raise LineTooLong(
  *                 'Status line is too long', pyparser._max_line_size, length)
  *         extend(pyparser._buf, at, length)             # <<<<<<<<<<<<<<
  *     except BaseException as ex:
  *         pyparser._last_error = ex
  */
       __pyx_t_1 = __pyx_v_pyparser->_buf;
       __Pyx_INCREF(__pyx_t_1);
-      __pyx_t_6 = __pyx_f_7aiohttp_12_http_parser_extend(__pyx_t_1, __pyx_v_at, __pyx_v_length); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 616, __pyx_L3_error)
+      __pyx_t_6 = __pyx_f_7aiohttp_12_http_parser_extend(__pyx_t_1, __pyx_v_at, __pyx_v_length); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 620, __pyx_L3_error)
       __Pyx_GOTREF(__pyx_t_6);
       __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
       __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
 
-      /* "aiohttp/_http_parser.pyx":612
+      /* "aiohttp/_http_parser.pyx":616
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     cdef str reason
  *     try:             # <<<<<<<<<<<<<<
  *         if length > pyparser._max_line_size:
  *             raise LineTooLong(
  */
     }
 
-    /* "aiohttp/_http_parser.pyx":621
+    /* "aiohttp/_http_parser.pyx":625
  *         return -1
  *     else:
  *         return 0             # <<<<<<<<<<<<<<
  * 
  * 
  */
     /*else:*/ {
       __pyx_r = 0;
       goto __pyx_L6_except_return;
     }
     __pyx_L3_error:;
-    __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
-    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
-    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
-    __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
     __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
+    __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
     __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
+    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
+    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
+    __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
 
-    /* "aiohttp/_http_parser.pyx":617
+    /* "aiohttp/_http_parser.pyx":621
  *                 'Status line is too long', pyparser._max_line_size, length)
  *         extend(pyparser._buf, at, length)
  *     except BaseException as ex:             # <<<<<<<<<<<<<<
  *         pyparser._last_error = ex
  *         return -1
  */
     __pyx_t_10 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_BaseException);
     if (__pyx_t_10) {
       __Pyx_AddTraceback("aiohttp._http_parser.cb_on_status", __pyx_clineno, __pyx_lineno, __pyx_filename);
-      if (__Pyx_GetException(&__pyx_t_6, &__pyx_t_1, &__pyx_t_11) < 0) __PYX_ERR(0, 617, __pyx_L5_except_error)
+      if (__Pyx_GetException(&__pyx_t_6, &__pyx_t_1, &__pyx_t_11) < 0) __PYX_ERR(0, 621, __pyx_L5_except_error)
       __Pyx_GOTREF(__pyx_t_6);
       __Pyx_GOTREF(__pyx_t_1);
       __Pyx_GOTREF(__pyx_t_11);
       __Pyx_INCREF(__pyx_t_1);
       __pyx_v_ex = __pyx_t_1;
       /*try:*/ {
 
-        /* "aiohttp/_http_parser.pyx":618
+        /* "aiohttp/_http_parser.pyx":622
  *         extend(pyparser._buf, at, length)
  *     except BaseException as ex:
  *         pyparser._last_error = ex             # <<<<<<<<<<<<<<
  *         return -1
  *     else:
  */
         __Pyx_INCREF(__pyx_v_ex);
         __Pyx_GIVEREF(__pyx_v_ex);
         __Pyx_GOTREF(__pyx_v_pyparser->_last_error);
         __Pyx_DECREF(__pyx_v_pyparser->_last_error);
         __pyx_v_pyparser->_last_error = __pyx_v_ex;
 
-        /* "aiohttp/_http_parser.pyx":619
+        /* "aiohttp/_http_parser.pyx":623
  *     except BaseException as ex:
  *         pyparser._last_error = ex
  *         return -1             # <<<<<<<<<<<<<<
  *     else:
  *         return 0
  */
         __pyx_r = -1;
         __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
         __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
         __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
         goto __pyx_L14_return;
       }
 
-      /* "aiohttp/_http_parser.pyx":617
+      /* "aiohttp/_http_parser.pyx":621
  *                 'Status line is too long', pyparser._max_line_size, length)
  *         extend(pyparser._buf, at, length)
  *     except BaseException as ex:             # <<<<<<<<<<<<<<
  *         pyparser._last_error = ex
  *         return -1
  */
       /*finally:*/ {
@@ -11424,15 +11500,15 @@
           goto __pyx_L6_except_return;
         }
       }
     }
     goto __pyx_L5_except_error;
     __pyx_L5_except_error:;
 
-    /* "aiohttp/_http_parser.pyx":612
+    /* "aiohttp/_http_parser.pyx":616
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     cdef str reason
  *     try:             # <<<<<<<<<<<<<<
  *         if length > pyparser._max_line_size:
  *             raise LineTooLong(
  */
     __Pyx_XGIVEREF(__pyx_t_2);
@@ -11444,15 +11520,15 @@
     __Pyx_XGIVEREF(__pyx_t_2);
     __Pyx_XGIVEREF(__pyx_t_3);
     __Pyx_XGIVEREF(__pyx_t_4);
     __Pyx_ExceptionReset(__pyx_t_2, __pyx_t_3, __pyx_t_4);
     goto __pyx_L0;
   }
 
-  /* "aiohttp/_http_parser.pyx":608
+  /* "aiohttp/_http_parser.pyx":612
  * 
  * 
  * cdef int cb_on_status(cparser.http_parser* parser,             # <<<<<<<<<<<<<<
  *                       const char *at, size_t length) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  */
 
@@ -11469,15 +11545,15 @@
   __pyx_L0:;
   __Pyx_XDECREF((PyObject *)__pyx_v_pyparser);
   __Pyx_XDECREF(__pyx_v_ex);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "aiohttp/_http_parser.pyx":624
+/* "aiohttp/_http_parser.pyx":628
  * 
  * 
  * cdef int cb_on_header_field(cparser.http_parser* parser,             # <<<<<<<<<<<<<<
  *                             const char *at, size_t length) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  */
 
@@ -11497,27 +11573,27 @@
   PyObject *__pyx_t_8 = NULL;
   PyObject *__pyx_t_9 = NULL;
   PyObject *__pyx_t_10 = NULL;
   int __pyx_t_11;
   PyObject *__pyx_t_12 = NULL;
   __Pyx_RefNannySetupContext("cb_on_header_field", 0);
 
-  /* "aiohttp/_http_parser.pyx":626
+  /* "aiohttp/_http_parser.pyx":630
  * cdef int cb_on_header_field(cparser.http_parser* parser,
  *                             const char *at, size_t length) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data             # <<<<<<<<<<<<<<
  *     cdef Py_ssize_t size
  *     try:
  */
   __pyx_t_1 = ((PyObject *)__pyx_v_parser->data);
   __Pyx_INCREF(__pyx_t_1);
   __pyx_v_pyparser = ((struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *)__pyx_t_1);
   __pyx_t_1 = 0;
 
-  /* "aiohttp/_http_parser.pyx":628
+  /* "aiohttp/_http_parser.pyx":632
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     cdef Py_ssize_t size
  *     try:             # <<<<<<<<<<<<<<
  *         pyparser._on_status_complete()
  *         size = len(pyparser._raw_name) + length
  */
   {
@@ -11525,72 +11601,72 @@
     __Pyx_PyThreadState_assign
     __Pyx_ExceptionSave(&__pyx_t_2, &__pyx_t_3, &__pyx_t_4);
     __Pyx_XGOTREF(__pyx_t_2);
     __Pyx_XGOTREF(__pyx_t_3);
     __Pyx_XGOTREF(__pyx_t_4);
     /*try:*/ {
 
-      /* "aiohttp/_http_parser.pyx":629
+      /* "aiohttp/_http_parser.pyx":633
  *     cdef Py_ssize_t size
  *     try:
  *         pyparser._on_status_complete()             # <<<<<<<<<<<<<<
  *         size = len(pyparser._raw_name) + length
  *         if size > pyparser._max_field_size:
  */
-      __pyx_t_1 = ((struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpParser *)__pyx_v_pyparser->__pyx_vtab)->_on_status_complete(__pyx_v_pyparser); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 629, __pyx_L3_error)
+      __pyx_t_1 = ((struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpParser *)__pyx_v_pyparser->__pyx_vtab)->_on_status_complete(__pyx_v_pyparser); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 633, __pyx_L3_error)
       __Pyx_GOTREF(__pyx_t_1);
       __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
 
-      /* "aiohttp/_http_parser.pyx":630
+      /* "aiohttp/_http_parser.pyx":634
  *     try:
  *         pyparser._on_status_complete()
  *         size = len(pyparser._raw_name) + length             # <<<<<<<<<<<<<<
  *         if size > pyparser._max_field_size:
  *             raise LineTooLong(
  */
       __pyx_t_1 = __pyx_v_pyparser->_raw_name;
       __Pyx_INCREF(__pyx_t_1);
       if (unlikely(__pyx_t_1 == Py_None)) {
         PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
-        __PYX_ERR(0, 630, __pyx_L3_error)
+        __PYX_ERR(0, 634, __pyx_L3_error)
       }
-      __pyx_t_5 = PyByteArray_GET_SIZE(__pyx_t_1); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 630, __pyx_L3_error)
+      __pyx_t_5 = PyByteArray_GET_SIZE(__pyx_t_1); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 634, __pyx_L3_error)
       __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
       __pyx_v_size = (__pyx_t_5 + __pyx_v_length);
 
-      /* "aiohttp/_http_parser.pyx":631
+      /* "aiohttp/_http_parser.pyx":635
  *         pyparser._on_status_complete()
  *         size = len(pyparser._raw_name) + length
  *         if size > pyparser._max_field_size:             # <<<<<<<<<<<<<<
  *             raise LineTooLong(
  *                 'Header name is too long', pyparser._max_field_size, size)
  */
       __pyx_t_6 = ((__pyx_v_size > __pyx_v_pyparser->_max_field_size) != 0);
       if (unlikely(__pyx_t_6)) {
 
-        /* "aiohttp/_http_parser.pyx":632
+        /* "aiohttp/_http_parser.pyx":636
  *         size = len(pyparser._raw_name) + length
  *         if size > pyparser._max_field_size:
  *             raise LineTooLong(             # <<<<<<<<<<<<<<
  *                 'Header name is too long', pyparser._max_field_size, size)
  *         pyparser._on_header_field(at, length)
  */
-        __Pyx_GetModuleGlobalName(__pyx_t_7, __pyx_n_s_LineTooLong); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 632, __pyx_L3_error)
+        __Pyx_GetModuleGlobalName(__pyx_t_7, __pyx_n_s_LineTooLong); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 636, __pyx_L3_error)
         __Pyx_GOTREF(__pyx_t_7);
 
-        /* "aiohttp/_http_parser.pyx":633
+        /* "aiohttp/_http_parser.pyx":637
  *         if size > pyparser._max_field_size:
  *             raise LineTooLong(
  *                 'Header name is too long', pyparser._max_field_size, size)             # <<<<<<<<<<<<<<
  *         pyparser._on_header_field(at, length)
  *     except BaseException as ex:
  */
-        __pyx_t_8 = __Pyx_PyInt_FromSize_t(__pyx_v_pyparser->_max_field_size); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 633, __pyx_L3_error)
+        __pyx_t_8 = __Pyx_PyInt_FromSize_t(__pyx_v_pyparser->_max_field_size); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 637, __pyx_L3_error)
         __Pyx_GOTREF(__pyx_t_8);
-        __pyx_t_9 = PyInt_FromSsize_t(__pyx_v_size); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 633, __pyx_L3_error)
+        __pyx_t_9 = PyInt_FromSsize_t(__pyx_v_size); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 637, __pyx_L3_error)
         __Pyx_GOTREF(__pyx_t_9);
         __pyx_t_10 = NULL;
         __pyx_t_11 = 0;
         if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_7))) {
           __pyx_t_10 = PyMethod_GET_SELF(__pyx_t_7);
           if (likely(__pyx_t_10)) {
             PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
@@ -11599,149 +11675,149 @@
             __Pyx_DECREF_SET(__pyx_t_7, function);
             __pyx_t_11 = 1;
           }
         }
         #if CYTHON_FAST_PYCALL
         if (PyFunction_Check(__pyx_t_7)) {
           PyObject *__pyx_temp[4] = {__pyx_t_10, __pyx_kp_u_Header_name_is_too_long, __pyx_t_8, __pyx_t_9};
-          __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_11, 3+__pyx_t_11); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 632, __pyx_L3_error)
+          __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_11, 3+__pyx_t_11); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 636, __pyx_L3_error)
           __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
           __Pyx_GOTREF(__pyx_t_1);
           __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
           __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
         } else
         #endif
         #if CYTHON_FAST_PYCCALL
         if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
           PyObject *__pyx_temp[4] = {__pyx_t_10, __pyx_kp_u_Header_name_is_too_long, __pyx_t_8, __pyx_t_9};
-          __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_11, 3+__pyx_t_11); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 632, __pyx_L3_error)
+          __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_11, 3+__pyx_t_11); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 636, __pyx_L3_error)
           __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
           __Pyx_GOTREF(__pyx_t_1);
           __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
           __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
         } else
         #endif
         {
-          __pyx_t_12 = PyTuple_New(3+__pyx_t_11); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 632, __pyx_L3_error)
+          __pyx_t_12 = PyTuple_New(3+__pyx_t_11); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 636, __pyx_L3_error)
           __Pyx_GOTREF(__pyx_t_12);
           if (__pyx_t_10) {
             __Pyx_GIVEREF(__pyx_t_10); PyTuple_SET_ITEM(__pyx_t_12, 0, __pyx_t_10); __pyx_t_10 = NULL;
           }
           __Pyx_INCREF(__pyx_kp_u_Header_name_is_too_long);
           __Pyx_GIVEREF(__pyx_kp_u_Header_name_is_too_long);
           PyTuple_SET_ITEM(__pyx_t_12, 0+__pyx_t_11, __pyx_kp_u_Header_name_is_too_long);
           __Pyx_GIVEREF(__pyx_t_8);
           PyTuple_SET_ITEM(__pyx_t_12, 1+__pyx_t_11, __pyx_t_8);
           __Pyx_GIVEREF(__pyx_t_9);
           PyTuple_SET_ITEM(__pyx_t_12, 2+__pyx_t_11, __pyx_t_9);
           __pyx_t_8 = 0;
           __pyx_t_9 = 0;
-          __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_12, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 632, __pyx_L3_error)
+          __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_12, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 636, __pyx_L3_error)
           __Pyx_GOTREF(__pyx_t_1);
           __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
         }
         __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
         __Pyx_Raise(__pyx_t_1, 0, 0, 0);
         __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
-        __PYX_ERR(0, 632, __pyx_L3_error)
+        __PYX_ERR(0, 636, __pyx_L3_error)
 
-        /* "aiohttp/_http_parser.pyx":631
+        /* "aiohttp/_http_parser.pyx":635
  *         pyparser._on_status_complete()
  *         size = len(pyparser._raw_name) + length
  *         if size > pyparser._max_field_size:             # <<<<<<<<<<<<<<
  *             raise LineTooLong(
  *                 'Header name is too long', pyparser._max_field_size, size)
  */
       }
 
-      /* "aiohttp/_http_parser.pyx":634
+      /* "aiohttp/_http_parser.pyx":638
  *             raise LineTooLong(
  *                 'Header name is too long', pyparser._max_field_size, size)
  *         pyparser._on_header_field(at, length)             # <<<<<<<<<<<<<<
  *     except BaseException as ex:
  *         pyparser._last_error = ex
  */
-      __pyx_t_1 = ((struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpParser *)__pyx_v_pyparser->__pyx_vtab)->_on_header_field(__pyx_v_pyparser, __pyx_v_at, __pyx_v_length); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 634, __pyx_L3_error)
+      __pyx_t_1 = ((struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpParser *)__pyx_v_pyparser->__pyx_vtab)->_on_header_field(__pyx_v_pyparser, __pyx_v_at, __pyx_v_length); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 638, __pyx_L3_error)
       __Pyx_GOTREF(__pyx_t_1);
       __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
 
-      /* "aiohttp/_http_parser.pyx":628
+      /* "aiohttp/_http_parser.pyx":632
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     cdef Py_ssize_t size
  *     try:             # <<<<<<<<<<<<<<
  *         pyparser._on_status_complete()
  *         size = len(pyparser._raw_name) + length
  */
     }
 
-    /* "aiohttp/_http_parser.pyx":639
+    /* "aiohttp/_http_parser.pyx":643
  *         return -1
  *     else:
  *         return 0             # <<<<<<<<<<<<<<
  * 
  * 
  */
     /*else:*/ {
       __pyx_r = 0;
       goto __pyx_L6_except_return;
     }
     __pyx_L3_error:;
+    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
     __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
-    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
-    __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
     __Pyx_XDECREF(__pyx_t_12); __pyx_t_12 = 0;
     __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
-    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
+    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
+    __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
 
-    /* "aiohttp/_http_parser.pyx":635
+    /* "aiohttp/_http_parser.pyx":639
  *                 'Header name is too long', pyparser._max_field_size, size)
  *         pyparser._on_header_field(at, length)
  *     except BaseException as ex:             # <<<<<<<<<<<<<<
  *         pyparser._last_error = ex
  *         return -1
  */
     __pyx_t_11 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_BaseException);
     if (__pyx_t_11) {
       __Pyx_AddTraceback("aiohttp._http_parser.cb_on_header_field", __pyx_clineno, __pyx_lineno, __pyx_filename);
-      if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_7, &__pyx_t_12) < 0) __PYX_ERR(0, 635, __pyx_L5_except_error)
+      if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_7, &__pyx_t_12) < 0) __PYX_ERR(0, 639, __pyx_L5_except_error)
       __Pyx_GOTREF(__pyx_t_1);
       __Pyx_GOTREF(__pyx_t_7);
       __Pyx_GOTREF(__pyx_t_12);
       __Pyx_INCREF(__pyx_t_7);
       __pyx_v_ex = __pyx_t_7;
       /*try:*/ {
 
-        /* "aiohttp/_http_parser.pyx":636
+        /* "aiohttp/_http_parser.pyx":640
  *         pyparser._on_header_field(at, length)
  *     except BaseException as ex:
  *         pyparser._last_error = ex             # <<<<<<<<<<<<<<
  *         return -1
  *     else:
  */
         __Pyx_INCREF(__pyx_v_ex);
         __Pyx_GIVEREF(__pyx_v_ex);
         __Pyx_GOTREF(__pyx_v_pyparser->_last_error);
         __Pyx_DECREF(__pyx_v_pyparser->_last_error);
         __pyx_v_pyparser->_last_error = __pyx_v_ex;
 
-        /* "aiohttp/_http_parser.pyx":637
+        /* "aiohttp/_http_parser.pyx":641
  *     except BaseException as ex:
  *         pyparser._last_error = ex
  *         return -1             # <<<<<<<<<<<<<<
  *     else:
  *         return 0
  */
         __pyx_r = -1;
         __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
         __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
         __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
         goto __pyx_L14_return;
       }
 
-      /* "aiohttp/_http_parser.pyx":635
+      /* "aiohttp/_http_parser.pyx":639
  *                 'Header name is too long', pyparser._max_field_size, size)
  *         pyparser._on_header_field(at, length)
  *     except BaseException as ex:             # <<<<<<<<<<<<<<
  *         pyparser._last_error = ex
  *         return -1
  */
       /*finally:*/ {
@@ -11753,15 +11829,15 @@
           goto __pyx_L6_except_return;
         }
       }
     }
     goto __pyx_L5_except_error;
     __pyx_L5_except_error:;
 
-    /* "aiohttp/_http_parser.pyx":628
+    /* "aiohttp/_http_parser.pyx":632
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     cdef Py_ssize_t size
  *     try:             # <<<<<<<<<<<<<<
  *         pyparser._on_status_complete()
  *         size = len(pyparser._raw_name) + length
  */
     __Pyx_XGIVEREF(__pyx_t_2);
@@ -11773,15 +11849,15 @@
     __Pyx_XGIVEREF(__pyx_t_2);
     __Pyx_XGIVEREF(__pyx_t_3);
     __Pyx_XGIVEREF(__pyx_t_4);
     __Pyx_ExceptionReset(__pyx_t_2, __pyx_t_3, __pyx_t_4);
     goto __pyx_L0;
   }
 
-  /* "aiohttp/_http_parser.pyx":624
+  /* "aiohttp/_http_parser.pyx":628
  * 
  * 
  * cdef int cb_on_header_field(cparser.http_parser* parser,             # <<<<<<<<<<<<<<
  *                             const char *at, size_t length) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  */
 
@@ -11798,15 +11874,15 @@
   __pyx_L0:;
   __Pyx_XDECREF((PyObject *)__pyx_v_pyparser);
   __Pyx_XDECREF(__pyx_v_ex);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "aiohttp/_http_parser.pyx":642
+/* "aiohttp/_http_parser.pyx":646
  * 
  * 
  * cdef int cb_on_header_value(cparser.http_parser* parser,             # <<<<<<<<<<<<<<
  *                             const char *at, size_t length) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  */
 
@@ -11826,27 +11902,27 @@
   PyObject *__pyx_t_8 = NULL;
   PyObject *__pyx_t_9 = NULL;
   PyObject *__pyx_t_10 = NULL;
   int __pyx_t_11;
   PyObject *__pyx_t_12 = NULL;
   __Pyx_RefNannySetupContext("cb_on_header_value", 0);
 
-  /* "aiohttp/_http_parser.pyx":644
+  /* "aiohttp/_http_parser.pyx":648
  * cdef int cb_on_header_value(cparser.http_parser* parser,
  *                             const char *at, size_t length) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data             # <<<<<<<<<<<<<<
  *     cdef Py_ssize_t size
  *     try:
  */
   __pyx_t_1 = ((PyObject *)__pyx_v_parser->data);
   __Pyx_INCREF(__pyx_t_1);
   __pyx_v_pyparser = ((struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *)__pyx_t_1);
   __pyx_t_1 = 0;
 
-  /* "aiohttp/_http_parser.pyx":646
+  /* "aiohttp/_http_parser.pyx":650
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     cdef Py_ssize_t size
  *     try:             # <<<<<<<<<<<<<<
  *         size = len(pyparser._raw_value) + length
  *         if size > pyparser._max_field_size:
  */
   {
@@ -11854,61 +11930,61 @@
     __Pyx_PyThreadState_assign
     __Pyx_ExceptionSave(&__pyx_t_2, &__pyx_t_3, &__pyx_t_4);
     __Pyx_XGOTREF(__pyx_t_2);
     __Pyx_XGOTREF(__pyx_t_3);
     __Pyx_XGOTREF(__pyx_t_4);
     /*try:*/ {
 
-      /* "aiohttp/_http_parser.pyx":647
+      /* "aiohttp/_http_parser.pyx":651
  *     cdef Py_ssize_t size
  *     try:
  *         size = len(pyparser._raw_value) + length             # <<<<<<<<<<<<<<
  *         if size > pyparser._max_field_size:
  *             raise LineTooLong(
  */
       __pyx_t_1 = __pyx_v_pyparser->_raw_value;
       __Pyx_INCREF(__pyx_t_1);
       if (unlikely(__pyx_t_1 == Py_None)) {
         PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
-        __PYX_ERR(0, 647, __pyx_L3_error)
+        __PYX_ERR(0, 651, __pyx_L3_error)
       }
-      __pyx_t_5 = PyByteArray_GET_SIZE(__pyx_t_1); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 647, __pyx_L3_error)
+      __pyx_t_5 = PyByteArray_GET_SIZE(__pyx_t_1); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 651, __pyx_L3_error)
       __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
       __pyx_v_size = (__pyx_t_5 + __pyx_v_length);
 
-      /* "aiohttp/_http_parser.pyx":648
+      /* "aiohttp/_http_parser.pyx":652
  *     try:
  *         size = len(pyparser._raw_value) + length
  *         if size > pyparser._max_field_size:             # <<<<<<<<<<<<<<
  *             raise LineTooLong(
  *                 'Header value is too long', pyparser._max_field_size, size)
  */
       __pyx_t_6 = ((__pyx_v_size > __pyx_v_pyparser->_max_field_size) != 0);
       if (unlikely(__pyx_t_6)) {
 
-        /* "aiohttp/_http_parser.pyx":649
+        /* "aiohttp/_http_parser.pyx":653
  *         size = len(pyparser._raw_value) + length
  *         if size > pyparser._max_field_size:
  *             raise LineTooLong(             # <<<<<<<<<<<<<<
  *                 'Header value is too long', pyparser._max_field_size, size)
  *         pyparser._on_header_value(at, length)
  */
-        __Pyx_GetModuleGlobalName(__pyx_t_7, __pyx_n_s_LineTooLong); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 649, __pyx_L3_error)
+        __Pyx_GetModuleGlobalName(__pyx_t_7, __pyx_n_s_LineTooLong); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 653, __pyx_L3_error)
         __Pyx_GOTREF(__pyx_t_7);
 
-        /* "aiohttp/_http_parser.pyx":650
+        /* "aiohttp/_http_parser.pyx":654
  *         if size > pyparser._max_field_size:
  *             raise LineTooLong(
  *                 'Header value is too long', pyparser._max_field_size, size)             # <<<<<<<<<<<<<<
  *         pyparser._on_header_value(at, length)
  *     except BaseException as ex:
  */
-        __pyx_t_8 = __Pyx_PyInt_FromSize_t(__pyx_v_pyparser->_max_field_size); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 650, __pyx_L3_error)
+        __pyx_t_8 = __Pyx_PyInt_FromSize_t(__pyx_v_pyparser->_max_field_size); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 654, __pyx_L3_error)
         __Pyx_GOTREF(__pyx_t_8);
-        __pyx_t_9 = PyInt_FromSsize_t(__pyx_v_size); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 650, __pyx_L3_error)
+        __pyx_t_9 = PyInt_FromSsize_t(__pyx_v_size); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 654, __pyx_L3_error)
         __Pyx_GOTREF(__pyx_t_9);
         __pyx_t_10 = NULL;
         __pyx_t_11 = 0;
         if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_7))) {
           __pyx_t_10 = PyMethod_GET_SELF(__pyx_t_7);
           if (likely(__pyx_t_10)) {
             PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
@@ -11917,149 +11993,149 @@
             __Pyx_DECREF_SET(__pyx_t_7, function);
             __pyx_t_11 = 1;
           }
         }
         #if CYTHON_FAST_PYCALL
         if (PyFunction_Check(__pyx_t_7)) {
           PyObject *__pyx_temp[4] = {__pyx_t_10, __pyx_kp_u_Header_value_is_too_long, __pyx_t_8, __pyx_t_9};
-          __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_11, 3+__pyx_t_11); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 649, __pyx_L3_error)
+          __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_11, 3+__pyx_t_11); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 653, __pyx_L3_error)
           __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
           __Pyx_GOTREF(__pyx_t_1);
           __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
           __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
         } else
         #endif
         #if CYTHON_FAST_PYCCALL
         if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
           PyObject *__pyx_temp[4] = {__pyx_t_10, __pyx_kp_u_Header_value_is_too_long, __pyx_t_8, __pyx_t_9};
-          __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_11, 3+__pyx_t_11); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 649, __pyx_L3_error)
+          __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_11, 3+__pyx_t_11); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 653, __pyx_L3_error)
           __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
           __Pyx_GOTREF(__pyx_t_1);
           __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
           __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
         } else
         #endif
         {
-          __pyx_t_12 = PyTuple_New(3+__pyx_t_11); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 649, __pyx_L3_error)
+          __pyx_t_12 = PyTuple_New(3+__pyx_t_11); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 653, __pyx_L3_error)
           __Pyx_GOTREF(__pyx_t_12);
           if (__pyx_t_10) {
             __Pyx_GIVEREF(__pyx_t_10); PyTuple_SET_ITEM(__pyx_t_12, 0, __pyx_t_10); __pyx_t_10 = NULL;
           }
           __Pyx_INCREF(__pyx_kp_u_Header_value_is_too_long);
           __Pyx_GIVEREF(__pyx_kp_u_Header_value_is_too_long);
           PyTuple_SET_ITEM(__pyx_t_12, 0+__pyx_t_11, __pyx_kp_u_Header_value_is_too_long);
           __Pyx_GIVEREF(__pyx_t_8);
           PyTuple_SET_ITEM(__pyx_t_12, 1+__pyx_t_11, __pyx_t_8);
           __Pyx_GIVEREF(__pyx_t_9);
           PyTuple_SET_ITEM(__pyx_t_12, 2+__pyx_t_11, __pyx_t_9);
           __pyx_t_8 = 0;
           __pyx_t_9 = 0;
-          __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_12, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 649, __pyx_L3_error)
+          __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_12, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 653, __pyx_L3_error)
           __Pyx_GOTREF(__pyx_t_1);
           __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
         }
         __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
         __Pyx_Raise(__pyx_t_1, 0, 0, 0);
         __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
-        __PYX_ERR(0, 649, __pyx_L3_error)
+        __PYX_ERR(0, 653, __pyx_L3_error)
 
-        /* "aiohttp/_http_parser.pyx":648
+        /* "aiohttp/_http_parser.pyx":652
  *     try:
  *         size = len(pyparser._raw_value) + length
  *         if size > pyparser._max_field_size:             # <<<<<<<<<<<<<<
  *             raise LineTooLong(
  *                 'Header value is too long', pyparser._max_field_size, size)
  */
       }
 
-      /* "aiohttp/_http_parser.pyx":651
+      /* "aiohttp/_http_parser.pyx":655
  *             raise LineTooLong(
  *                 'Header value is too long', pyparser._max_field_size, size)
  *         pyparser._on_header_value(at, length)             # <<<<<<<<<<<<<<
  *     except BaseException as ex:
  *         pyparser._last_error = ex
  */
-      __pyx_t_1 = ((struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpParser *)__pyx_v_pyparser->__pyx_vtab)->_on_header_value(__pyx_v_pyparser, __pyx_v_at, __pyx_v_length); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 651, __pyx_L3_error)
+      __pyx_t_1 = ((struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpParser *)__pyx_v_pyparser->__pyx_vtab)->_on_header_value(__pyx_v_pyparser, __pyx_v_at, __pyx_v_length); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 655, __pyx_L3_error)
       __Pyx_GOTREF(__pyx_t_1);
       __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
 
-      /* "aiohttp/_http_parser.pyx":646
+      /* "aiohttp/_http_parser.pyx":650
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     cdef Py_ssize_t size
  *     try:             # <<<<<<<<<<<<<<
  *         size = len(pyparser._raw_value) + length
  *         if size > pyparser._max_field_size:
  */
     }
 
-    /* "aiohttp/_http_parser.pyx":656
+    /* "aiohttp/_http_parser.pyx":660
  *         return -1
  *     else:
  *         return 0             # <<<<<<<<<<<<<<
  * 
  * 
  */
     /*else:*/ {
       __pyx_r = 0;
       goto __pyx_L6_except_return;
     }
     __pyx_L3_error:;
+    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
     __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
-    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
-    __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
     __Pyx_XDECREF(__pyx_t_12); __pyx_t_12 = 0;
     __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
-    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
+    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
+    __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
 
-    /* "aiohttp/_http_parser.pyx":652
+    /* "aiohttp/_http_parser.pyx":656
  *                 'Header value is too long', pyparser._max_field_size, size)
  *         pyparser._on_header_value(at, length)
  *     except BaseException as ex:             # <<<<<<<<<<<<<<
  *         pyparser._last_error = ex
  *         return -1
  */
     __pyx_t_11 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_BaseException);
     if (__pyx_t_11) {
       __Pyx_AddTraceback("aiohttp._http_parser.cb_on_header_value", __pyx_clineno, __pyx_lineno, __pyx_filename);
-      if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_7, &__pyx_t_12) < 0) __PYX_ERR(0, 652, __pyx_L5_except_error)
+      if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_7, &__pyx_t_12) < 0) __PYX_ERR(0, 656, __pyx_L5_except_error)
       __Pyx_GOTREF(__pyx_t_1);
       __Pyx_GOTREF(__pyx_t_7);
       __Pyx_GOTREF(__pyx_t_12);
       __Pyx_INCREF(__pyx_t_7);
       __pyx_v_ex = __pyx_t_7;
       /*try:*/ {
 
-        /* "aiohttp/_http_parser.pyx":653
+        /* "aiohttp/_http_parser.pyx":657
  *         pyparser._on_header_value(at, length)
  *     except BaseException as ex:
  *         pyparser._last_error = ex             # <<<<<<<<<<<<<<
  *         return -1
  *     else:
  */
         __Pyx_INCREF(__pyx_v_ex);
         __Pyx_GIVEREF(__pyx_v_ex);
         __Pyx_GOTREF(__pyx_v_pyparser->_last_error);
         __Pyx_DECREF(__pyx_v_pyparser->_last_error);
         __pyx_v_pyparser->_last_error = __pyx_v_ex;
 
-        /* "aiohttp/_http_parser.pyx":654
+        /* "aiohttp/_http_parser.pyx":658
  *     except BaseException as ex:
  *         pyparser._last_error = ex
  *         return -1             # <<<<<<<<<<<<<<
  *     else:
  *         return 0
  */
         __pyx_r = -1;
         __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
         __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
         __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
         goto __pyx_L14_return;
       }
 
-      /* "aiohttp/_http_parser.pyx":652
+      /* "aiohttp/_http_parser.pyx":656
  *                 'Header value is too long', pyparser._max_field_size, size)
  *         pyparser._on_header_value(at, length)
  *     except BaseException as ex:             # <<<<<<<<<<<<<<
  *         pyparser._last_error = ex
  *         return -1
  */
       /*finally:*/ {
@@ -12071,15 +12147,15 @@
           goto __pyx_L6_except_return;
         }
       }
     }
     goto __pyx_L5_except_error;
     __pyx_L5_except_error:;
 
-    /* "aiohttp/_http_parser.pyx":646
+    /* "aiohttp/_http_parser.pyx":650
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     cdef Py_ssize_t size
  *     try:             # <<<<<<<<<<<<<<
  *         size = len(pyparser._raw_value) + length
  *         if size > pyparser._max_field_size:
  */
     __Pyx_XGIVEREF(__pyx_t_2);
@@ -12091,15 +12167,15 @@
     __Pyx_XGIVEREF(__pyx_t_2);
     __Pyx_XGIVEREF(__pyx_t_3);
     __Pyx_XGIVEREF(__pyx_t_4);
     __Pyx_ExceptionReset(__pyx_t_2, __pyx_t_3, __pyx_t_4);
     goto __pyx_L0;
   }
 
-  /* "aiohttp/_http_parser.pyx":642
+  /* "aiohttp/_http_parser.pyx":646
  * 
  * 
  * cdef int cb_on_header_value(cparser.http_parser* parser,             # <<<<<<<<<<<<<<
  *                             const char *at, size_t length) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  */
 
@@ -12116,15 +12192,15 @@
   __pyx_L0:;
   __Pyx_XDECREF((PyObject *)__pyx_v_pyparser);
   __Pyx_XDECREF(__pyx_v_ex);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "aiohttp/_http_parser.pyx":659
+/* "aiohttp/_http_parser.pyx":663
  * 
  * 
  * cdef int cb_on_headers_complete(cparser.http_parser* parser) except -1:             # <<<<<<<<<<<<<<
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:
  */
 
@@ -12140,27 +12216,27 @@
   int __pyx_t_5;
   int __pyx_t_6;
   int __pyx_t_7;
   PyObject *__pyx_t_8 = NULL;
   PyObject *__pyx_t_9 = NULL;
   __Pyx_RefNannySetupContext("cb_on_headers_complete", 0);
 
-  /* "aiohttp/_http_parser.pyx":660
+  /* "aiohttp/_http_parser.pyx":664
  * 
  * cdef int cb_on_headers_complete(cparser.http_parser* parser) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data             # <<<<<<<<<<<<<<
  *     try:
  *         pyparser._on_status_complete()
  */
   __pyx_t_1 = ((PyObject *)__pyx_v_parser->data);
   __Pyx_INCREF(__pyx_t_1);
   __pyx_v_pyparser = ((struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *)__pyx_t_1);
   __pyx_t_1 = 0;
 
-  /* "aiohttp/_http_parser.pyx":661
+  /* "aiohttp/_http_parser.pyx":665
  * cdef int cb_on_headers_complete(cparser.http_parser* parser) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:             # <<<<<<<<<<<<<<
  *         pyparser._on_status_complete()
  *         pyparser._on_headers_complete()
  */
   {
@@ -12168,46 +12244,46 @@
     __Pyx_PyThreadState_assign
     __Pyx_ExceptionSave(&__pyx_t_2, &__pyx_t_3, &__pyx_t_4);
     __Pyx_XGOTREF(__pyx_t_2);
     __Pyx_XGOTREF(__pyx_t_3);
     __Pyx_XGOTREF(__pyx_t_4);
     /*try:*/ {
 
-      /* "aiohttp/_http_parser.pyx":662
+      /* "aiohttp/_http_parser.pyx":666
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:
  *         pyparser._on_status_complete()             # <<<<<<<<<<<<<<
  *         pyparser._on_headers_complete()
  *     except BaseException as exc:
  */
-      __pyx_t_1 = ((struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpParser *)__pyx_v_pyparser->__pyx_vtab)->_on_status_complete(__pyx_v_pyparser); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 662, __pyx_L3_error)
+      __pyx_t_1 = ((struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpParser *)__pyx_v_pyparser->__pyx_vtab)->_on_status_complete(__pyx_v_pyparser); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 666, __pyx_L3_error)
       __Pyx_GOTREF(__pyx_t_1);
       __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
 
-      /* "aiohttp/_http_parser.pyx":663
+      /* "aiohttp/_http_parser.pyx":667
  *     try:
  *         pyparser._on_status_complete()
  *         pyparser._on_headers_complete()             # <<<<<<<<<<<<<<
  *     except BaseException as exc:
  *         pyparser._last_error = exc
  */
-      __pyx_t_1 = ((struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpParser *)__pyx_v_pyparser->__pyx_vtab)->_on_headers_complete(__pyx_v_pyparser); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 663, __pyx_L3_error)
+      __pyx_t_1 = ((struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpParser *)__pyx_v_pyparser->__pyx_vtab)->_on_headers_complete(__pyx_v_pyparser); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 667, __pyx_L3_error)
       __Pyx_GOTREF(__pyx_t_1);
       __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
 
-      /* "aiohttp/_http_parser.pyx":661
+      /* "aiohttp/_http_parser.pyx":665
  * cdef int cb_on_headers_complete(cparser.http_parser* parser) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:             # <<<<<<<<<<<<<<
  *         pyparser._on_status_complete()
  *         pyparser._on_headers_complete()
  */
     }
 
-    /* "aiohttp/_http_parser.pyx":668
+    /* "aiohttp/_http_parser.pyx":672
  *         return -1
  *     else:
  *         if pyparser._cparser.upgrade or pyparser._cparser.method == 5: # CONNECT             # <<<<<<<<<<<<<<
  *             return 2
  *         else:
  */
     /*else:*/ {
@@ -12218,94 +12294,94 @@
         goto __pyx_L10_bool_binop_done;
       }
       __pyx_t_6 = ((__pyx_v_pyparser->_cparser->method == 5) != 0);
       __pyx_t_5 = __pyx_t_6;
       __pyx_L10_bool_binop_done:;
       if (__pyx_t_5) {
 
-        /* "aiohttp/_http_parser.pyx":669
+        /* "aiohttp/_http_parser.pyx":673
  *     else:
  *         if pyparser._cparser.upgrade or pyparser._cparser.method == 5: # CONNECT
  *             return 2             # <<<<<<<<<<<<<<
  *         else:
  *             return 0
  */
         __pyx_r = 2;
         goto __pyx_L6_except_return;
 
-        /* "aiohttp/_http_parser.pyx":668
+        /* "aiohttp/_http_parser.pyx":672
  *         return -1
  *     else:
  *         if pyparser._cparser.upgrade or pyparser._cparser.method == 5: # CONNECT             # <<<<<<<<<<<<<<
  *             return 2
  *         else:
  */
       }
 
-      /* "aiohttp/_http_parser.pyx":671
+      /* "aiohttp/_http_parser.pyx":675
  *             return 2
  *         else:
  *             return 0             # <<<<<<<<<<<<<<
  * 
  * 
  */
       /*else*/ {
         __pyx_r = 0;
         goto __pyx_L6_except_return;
       }
     }
     __pyx_L3_error:;
     __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
 
-    /* "aiohttp/_http_parser.pyx":664
+    /* "aiohttp/_http_parser.pyx":668
  *         pyparser._on_status_complete()
  *         pyparser._on_headers_complete()
  *     except BaseException as exc:             # <<<<<<<<<<<<<<
  *         pyparser._last_error = exc
  *         return -1
  */
     __pyx_t_7 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_BaseException);
     if (__pyx_t_7) {
       __Pyx_AddTraceback("aiohttp._http_parser.cb_on_headers_complete", __pyx_clineno, __pyx_lineno, __pyx_filename);
-      if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_8, &__pyx_t_9) < 0) __PYX_ERR(0, 664, __pyx_L5_except_error)
+      if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_8, &__pyx_t_9) < 0) __PYX_ERR(0, 668, __pyx_L5_except_error)
       __Pyx_GOTREF(__pyx_t_1);
       __Pyx_GOTREF(__pyx_t_8);
       __Pyx_GOTREF(__pyx_t_9);
       __Pyx_INCREF(__pyx_t_8);
       __pyx_v_exc = __pyx_t_8;
       /*try:*/ {
 
-        /* "aiohttp/_http_parser.pyx":665
+        /* "aiohttp/_http_parser.pyx":669
  *         pyparser._on_headers_complete()
  *     except BaseException as exc:
  *         pyparser._last_error = exc             # <<<<<<<<<<<<<<
  *         return -1
  *     else:
  */
         __Pyx_INCREF(__pyx_v_exc);
         __Pyx_GIVEREF(__pyx_v_exc);
         __Pyx_GOTREF(__pyx_v_pyparser->_last_error);
         __Pyx_DECREF(__pyx_v_pyparser->_last_error);
         __pyx_v_pyparser->_last_error = __pyx_v_exc;
 
-        /* "aiohttp/_http_parser.pyx":666
+        /* "aiohttp/_http_parser.pyx":670
  *     except BaseException as exc:
  *         pyparser._last_error = exc
  *         return -1             # <<<<<<<<<<<<<<
  *     else:
  *         if pyparser._cparser.upgrade or pyparser._cparser.method == 5: # CONNECT
  */
         __pyx_r = -1;
         __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
         __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
         __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
         goto __pyx_L16_return;
       }
 
-      /* "aiohttp/_http_parser.pyx":664
+      /* "aiohttp/_http_parser.pyx":668
  *         pyparser._on_status_complete()
  *         pyparser._on_headers_complete()
  *     except BaseException as exc:             # <<<<<<<<<<<<<<
  *         pyparser._last_error = exc
  *         return -1
  */
       /*finally:*/ {
@@ -12317,15 +12393,15 @@
           goto __pyx_L6_except_return;
         }
       }
     }
     goto __pyx_L5_except_error;
     __pyx_L5_except_error:;
 
-    /* "aiohttp/_http_parser.pyx":661
+    /* "aiohttp/_http_parser.pyx":665
  * cdef int cb_on_headers_complete(cparser.http_parser* parser) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:             # <<<<<<<<<<<<<<
  *         pyparser._on_status_complete()
  *         pyparser._on_headers_complete()
  */
     __Pyx_XGIVEREF(__pyx_t_2);
@@ -12337,15 +12413,15 @@
     __Pyx_XGIVEREF(__pyx_t_2);
     __Pyx_XGIVEREF(__pyx_t_3);
     __Pyx_XGIVEREF(__pyx_t_4);
     __Pyx_ExceptionReset(__pyx_t_2, __pyx_t_3, __pyx_t_4);
     goto __pyx_L0;
   }
 
-  /* "aiohttp/_http_parser.pyx":659
+  /* "aiohttp/_http_parser.pyx":663
  * 
  * 
  * cdef int cb_on_headers_complete(cparser.http_parser* parser) except -1:             # <<<<<<<<<<<<<<
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:
  */
 
@@ -12359,15 +12435,15 @@
   __pyx_L0:;
   __Pyx_XDECREF((PyObject *)__pyx_v_pyparser);
   __Pyx_XDECREF(__pyx_v_exc);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "aiohttp/_http_parser.pyx":674
+/* "aiohttp/_http_parser.pyx":678
  * 
  * 
  * cdef int cb_on_body(cparser.http_parser* parser,             # <<<<<<<<<<<<<<
  *                     const char *at, size_t length) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  */
 
@@ -12398,39 +12474,39 @@
   PyObject *__pyx_t_19 = NULL;
   PyObject *__pyx_t_20 = NULL;
   PyObject *__pyx_t_21 = NULL;
   PyObject *__pyx_t_22 = NULL;
   PyObject *__pyx_t_23 = NULL;
   __Pyx_RefNannySetupContext("cb_on_body", 0);
 
-  /* "aiohttp/_http_parser.pyx":676
+  /* "aiohttp/_http_parser.pyx":680
  * cdef int cb_on_body(cparser.http_parser* parser,
  *                     const char *at, size_t length) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data             # <<<<<<<<<<<<<<
  *     cdef bytes body = at[:length]
  *     try:
  */
   __pyx_t_1 = ((PyObject *)__pyx_v_parser->data);
   __Pyx_INCREF(__pyx_t_1);
   __pyx_v_pyparser = ((struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *)__pyx_t_1);
   __pyx_t_1 = 0;
 
-  /* "aiohttp/_http_parser.pyx":677
+  /* "aiohttp/_http_parser.pyx":681
  *                     const char *at, size_t length) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     cdef bytes body = at[:length]             # <<<<<<<<<<<<<<
  *     try:
  *         pyparser._payload.feed_data(body, length)
  */
-  __pyx_t_1 = __Pyx_PyBytes_FromStringAndSize(__pyx_v_at + 0, __pyx_v_length - 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 677, __pyx_L1_error)
+  __pyx_t_1 = __Pyx_PyBytes_FromStringAndSize(__pyx_v_at + 0, __pyx_v_length - 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 681, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_v_body = ((PyObject*)__pyx_t_1);
   __pyx_t_1 = 0;
 
-  /* "aiohttp/_http_parser.pyx":678
+  /* "aiohttp/_http_parser.pyx":682
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     cdef bytes body = at[:length]
  *     try:             # <<<<<<<<<<<<<<
  *         pyparser._payload.feed_data(body, length)
  *     except BaseException as exc:
  */
   {
@@ -12438,24 +12514,24 @@
     __Pyx_PyThreadState_assign
     __Pyx_ExceptionSave(&__pyx_t_2, &__pyx_t_3, &__pyx_t_4);
     __Pyx_XGOTREF(__pyx_t_2);
     __Pyx_XGOTREF(__pyx_t_3);
     __Pyx_XGOTREF(__pyx_t_4);
     /*try:*/ {
 
-      /* "aiohttp/_http_parser.pyx":679
+      /* "aiohttp/_http_parser.pyx":683
  *     cdef bytes body = at[:length]
  *     try:
  *         pyparser._payload.feed_data(body, length)             # <<<<<<<<<<<<<<
  *     except BaseException as exc:
  *         if pyparser._payload_exception is not None:
  */
-      __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_pyparser->_payload, __pyx_n_s_feed_data); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 679, __pyx_L3_error)
+      __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_pyparser->_payload, __pyx_n_s_feed_data); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 683, __pyx_L3_error)
       __Pyx_GOTREF(__pyx_t_5);
-      __pyx_t_6 = __Pyx_PyInt_FromSize_t(__pyx_v_length); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 679, __pyx_L3_error)
+      __pyx_t_6 = __Pyx_PyInt_FromSize_t(__pyx_v_length); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 683, __pyx_L3_error)
       __Pyx_GOTREF(__pyx_t_6);
       __pyx_t_7 = NULL;
       __pyx_t_8 = 0;
       if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
         __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_5);
         if (likely(__pyx_t_7)) {
           PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
@@ -12464,114 +12540,114 @@
           __Pyx_DECREF_SET(__pyx_t_5, function);
           __pyx_t_8 = 1;
         }
       }
       #if CYTHON_FAST_PYCALL
       if (PyFunction_Check(__pyx_t_5)) {
         PyObject *__pyx_temp[3] = {__pyx_t_7, __pyx_v_body, __pyx_t_6};
-        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_8, 2+__pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 679, __pyx_L3_error)
+        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_8, 2+__pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 683, __pyx_L3_error)
         __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
         __Pyx_GOTREF(__pyx_t_1);
         __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
       } else
       #endif
       #if CYTHON_FAST_PYCCALL
       if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
         PyObject *__pyx_temp[3] = {__pyx_t_7, __pyx_v_body, __pyx_t_6};
-        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_8, 2+__pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 679, __pyx_L3_error)
+        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_8, 2+__pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 683, __pyx_L3_error)
         __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
         __Pyx_GOTREF(__pyx_t_1);
         __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
       } else
       #endif
       {
-        __pyx_t_9 = PyTuple_New(2+__pyx_t_8); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 679, __pyx_L3_error)
+        __pyx_t_9 = PyTuple_New(2+__pyx_t_8); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 683, __pyx_L3_error)
         __Pyx_GOTREF(__pyx_t_9);
         if (__pyx_t_7) {
           __Pyx_GIVEREF(__pyx_t_7); PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_7); __pyx_t_7 = NULL;
         }
         __Pyx_INCREF(__pyx_v_body);
         __Pyx_GIVEREF(__pyx_v_body);
         PyTuple_SET_ITEM(__pyx_t_9, 0+__pyx_t_8, __pyx_v_body);
         __Pyx_GIVEREF(__pyx_t_6);
         PyTuple_SET_ITEM(__pyx_t_9, 1+__pyx_t_8, __pyx_t_6);
         __pyx_t_6 = 0;
-        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_9, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 679, __pyx_L3_error)
+        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_9, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 683, __pyx_L3_error)
         __Pyx_GOTREF(__pyx_t_1);
         __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
       }
       __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
       __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
 
-      /* "aiohttp/_http_parser.pyx":678
+      /* "aiohttp/_http_parser.pyx":682
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     cdef bytes body = at[:length]
  *     try:             # <<<<<<<<<<<<<<
  *         pyparser._payload.feed_data(body, length)
  *     except BaseException as exc:
  */
     }
 
-    /* "aiohttp/_http_parser.pyx":688
+    /* "aiohttp/_http_parser.pyx":692
  *         return -1
  *     else:
  *         return 0             # <<<<<<<<<<<<<<
  * 
  * 
  */
     /*else:*/ {
       __pyx_r = 0;
       goto __pyx_L6_except_return;
     }
     __pyx_L3_error:;
-    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
+    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
+    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
     __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
+    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
     __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
-    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
-    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
 
-    /* "aiohttp/_http_parser.pyx":680
+    /* "aiohttp/_http_parser.pyx":684
  *     try:
  *         pyparser._payload.feed_data(body, length)
  *     except BaseException as exc:             # <<<<<<<<<<<<<<
  *         if pyparser._payload_exception is not None:
  *             pyparser._payload.set_exception(pyparser._payload_exception(str(exc)))
  */
     __pyx_t_8 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_BaseException);
     if (__pyx_t_8) {
       __Pyx_AddTraceback("aiohttp._http_parser.cb_on_body", __pyx_clineno, __pyx_lineno, __pyx_filename);
-      if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_5, &__pyx_t_9) < 0) __PYX_ERR(0, 680, __pyx_L5_except_error)
+      if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_5, &__pyx_t_9) < 0) __PYX_ERR(0, 684, __pyx_L5_except_error)
       __Pyx_GOTREF(__pyx_t_1);
       __Pyx_GOTREF(__pyx_t_5);
       __Pyx_GOTREF(__pyx_t_9);
       __Pyx_INCREF(__pyx_t_5);
       __pyx_v_exc = __pyx_t_5;
       /*try:*/ {
 
-        /* "aiohttp/_http_parser.pyx":681
+        /* "aiohttp/_http_parser.pyx":685
  *         pyparser._payload.feed_data(body, length)
  *     except BaseException as exc:
  *         if pyparser._payload_exception is not None:             # <<<<<<<<<<<<<<
  *             pyparser._payload.set_exception(pyparser._payload_exception(str(exc)))
  *         else:
  */
         __pyx_t_10 = (__pyx_v_pyparser->_payload_exception != Py_None);
         __pyx_t_11 = (__pyx_t_10 != 0);
         if (__pyx_t_11) {
 
-          /* "aiohttp/_http_parser.pyx":682
+          /* "aiohttp/_http_parser.pyx":686
  *     except BaseException as exc:
  *         if pyparser._payload_exception is not None:
  *             pyparser._payload.set_exception(pyparser._payload_exception(str(exc)))             # <<<<<<<<<<<<<<
  *         else:
  *             pyparser._payload.set_exception(exc)
  */
-          __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_pyparser->_payload, __pyx_n_s_set_exception); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 682, __pyx_L14_error)
+          __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_pyparser->_payload, __pyx_n_s_set_exception); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 686, __pyx_L14_error)
           __Pyx_GOTREF(__pyx_t_7);
-          __pyx_t_13 = __Pyx_PyObject_CallOneArg(((PyObject *)(&PyUnicode_Type)), __pyx_v_exc); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 682, __pyx_L14_error)
+          __pyx_t_13 = __Pyx_PyObject_CallOneArg(((PyObject *)(&PyUnicode_Type)), __pyx_v_exc); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 686, __pyx_L14_error)
           __Pyx_GOTREF(__pyx_t_13);
           __Pyx_INCREF(__pyx_v_pyparser->_payload_exception);
           __pyx_t_14 = __pyx_v_pyparser->_payload_exception; __pyx_t_15 = NULL;
           if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_14))) {
             __pyx_t_15 = PyMethod_GET_SELF(__pyx_t_14);
             if (likely(__pyx_t_15)) {
               PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_14);
@@ -12579,15 +12655,15 @@
               __Pyx_INCREF(function);
               __Pyx_DECREF_SET(__pyx_t_14, function);
             }
           }
           __pyx_t_12 = (__pyx_t_15) ? __Pyx_PyObject_Call2Args(__pyx_t_14, __pyx_t_15, __pyx_t_13) : __Pyx_PyObject_CallOneArg(__pyx_t_14, __pyx_t_13);
           __Pyx_XDECREF(__pyx_t_15); __pyx_t_15 = 0;
           __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
-          if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 682, __pyx_L14_error)
+          if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 686, __pyx_L14_error)
           __Pyx_GOTREF(__pyx_t_12);
           __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
           __pyx_t_14 = NULL;
           if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_7))) {
             __pyx_t_14 = PyMethod_GET_SELF(__pyx_t_7);
             if (likely(__pyx_t_14)) {
               PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
@@ -12595,100 +12671,100 @@
               __Pyx_INCREF(function);
               __Pyx_DECREF_SET(__pyx_t_7, function);
             }
           }
           __pyx_t_6 = (__pyx_t_14) ? __Pyx_PyObject_Call2Args(__pyx_t_7, __pyx_t_14, __pyx_t_12) : __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_t_12);
           __Pyx_XDECREF(__pyx_t_14); __pyx_t_14 = 0;
           __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
-          if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 682, __pyx_L14_error)
+          if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 686, __pyx_L14_error)
           __Pyx_GOTREF(__pyx_t_6);
           __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
           __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
 
-          /* "aiohttp/_http_parser.pyx":681
+          /* "aiohttp/_http_parser.pyx":685
  *         pyparser._payload.feed_data(body, length)
  *     except BaseException as exc:
  *         if pyparser._payload_exception is not None:             # <<<<<<<<<<<<<<
  *             pyparser._payload.set_exception(pyparser._payload_exception(str(exc)))
  *         else:
  */
           goto __pyx_L16;
         }
 
-        /* "aiohttp/_http_parser.pyx":684
+        /* "aiohttp/_http_parser.pyx":688
  *             pyparser._payload.set_exception(pyparser._payload_exception(str(exc)))
  *         else:
  *             pyparser._payload.set_exception(exc)             # <<<<<<<<<<<<<<
  *         pyparser._payload_error = 1
  *         return -1
  */
         /*else*/ {
-          __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_pyparser->_payload, __pyx_n_s_set_exception); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 684, __pyx_L14_error)
+          __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_pyparser->_payload, __pyx_n_s_set_exception); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 688, __pyx_L14_error)
           __Pyx_GOTREF(__pyx_t_7);
           __pyx_t_12 = NULL;
           if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_7))) {
             __pyx_t_12 = PyMethod_GET_SELF(__pyx_t_7);
             if (likely(__pyx_t_12)) {
               PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
               __Pyx_INCREF(__pyx_t_12);
               __Pyx_INCREF(function);
               __Pyx_DECREF_SET(__pyx_t_7, function);
             }
           }
           __pyx_t_6 = (__pyx_t_12) ? __Pyx_PyObject_Call2Args(__pyx_t_7, __pyx_t_12, __pyx_v_exc) : __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_v_exc);
           __Pyx_XDECREF(__pyx_t_12); __pyx_t_12 = 0;
-          if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 684, __pyx_L14_error)
+          if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 688, __pyx_L14_error)
           __Pyx_GOTREF(__pyx_t_6);
           __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
           __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
         }
         __pyx_L16:;
 
-        /* "aiohttp/_http_parser.pyx":685
+        /* "aiohttp/_http_parser.pyx":689
  *         else:
  *             pyparser._payload.set_exception(exc)
  *         pyparser._payload_error = 1             # <<<<<<<<<<<<<<
  *         return -1
  *     else:
  */
         __pyx_v_pyparser->_payload_error = 1;
 
-        /* "aiohttp/_http_parser.pyx":686
+        /* "aiohttp/_http_parser.pyx":690
  *             pyparser._payload.set_exception(exc)
  *         pyparser._payload_error = 1
  *         return -1             # <<<<<<<<<<<<<<
  *     else:
  *         return 0
  */
         __pyx_r = -1;
         __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
         __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
         __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
         goto __pyx_L13_return;
       }
 
-      /* "aiohttp/_http_parser.pyx":680
+      /* "aiohttp/_http_parser.pyx":684
  *     try:
  *         pyparser._payload.feed_data(body, length)
  *     except BaseException as exc:             # <<<<<<<<<<<<<<
  *         if pyparser._payload_exception is not None:
  *             pyparser._payload.set_exception(pyparser._payload_exception(str(exc)))
  */
       /*finally:*/ {
         __pyx_L14_error:;
         /*exception exit:*/{
           __Pyx_PyThreadState_declare
           __Pyx_PyThreadState_assign
           __pyx_t_18 = 0; __pyx_t_19 = 0; __pyx_t_20 = 0; __pyx_t_21 = 0; __pyx_t_22 = 0; __pyx_t_23 = 0;
-          __Pyx_XDECREF(__pyx_t_15); __pyx_t_15 = 0;
+          __Pyx_XDECREF(__pyx_t_12); __pyx_t_12 = 0;
           __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
           __Pyx_XDECREF(__pyx_t_14); __pyx_t_14 = 0;
-          __Pyx_XDECREF(__pyx_t_12); __pyx_t_12 = 0;
-          __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
+          __Pyx_XDECREF(__pyx_t_15); __pyx_t_15 = 0;
           __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
+          __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
           if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_21, &__pyx_t_22, &__pyx_t_23);
           if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_18, &__pyx_t_19, &__pyx_t_20) < 0)) __Pyx_ErrFetch(&__pyx_t_18, &__pyx_t_19, &__pyx_t_20);
           __Pyx_XGOTREF(__pyx_t_18);
           __Pyx_XGOTREF(__pyx_t_19);
           __Pyx_XGOTREF(__pyx_t_20);
           __Pyx_XGOTREF(__pyx_t_21);
           __Pyx_XGOTREF(__pyx_t_22);
@@ -12720,15 +12796,15 @@
           goto __pyx_L6_except_return;
         }
       }
     }
     goto __pyx_L5_except_error;
     __pyx_L5_except_error:;
 
-    /* "aiohttp/_http_parser.pyx":678
+    /* "aiohttp/_http_parser.pyx":682
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     cdef bytes body = at[:length]
  *     try:             # <<<<<<<<<<<<<<
  *         pyparser._payload.feed_data(body, length)
  *     except BaseException as exc:
  */
     __Pyx_XGIVEREF(__pyx_t_2);
@@ -12740,15 +12816,15 @@
     __Pyx_XGIVEREF(__pyx_t_2);
     __Pyx_XGIVEREF(__pyx_t_3);
     __Pyx_XGIVEREF(__pyx_t_4);
     __Pyx_ExceptionReset(__pyx_t_2, __pyx_t_3, __pyx_t_4);
     goto __pyx_L0;
   }
 
-  /* "aiohttp/_http_parser.pyx":674
+  /* "aiohttp/_http_parser.pyx":678
  * 
  * 
  * cdef int cb_on_body(cparser.http_parser* parser,             # <<<<<<<<<<<<<<
  *                     const char *at, size_t length) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  */
 
@@ -12769,15 +12845,15 @@
   __Pyx_XDECREF((PyObject *)__pyx_v_pyparser);
   __Pyx_XDECREF(__pyx_v_body);
   __Pyx_XDECREF(__pyx_v_exc);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "aiohttp/_http_parser.pyx":691
+/* "aiohttp/_http_parser.pyx":695
  * 
  * 
  * cdef int cb_on_message_complete(cparser.http_parser* parser) except -1:             # <<<<<<<<<<<<<<
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:
  */
 
@@ -12791,27 +12867,27 @@
   PyObject *__pyx_t_3 = NULL;
   PyObject *__pyx_t_4 = NULL;
   int __pyx_t_5;
   PyObject *__pyx_t_6 = NULL;
   PyObject *__pyx_t_7 = NULL;
   __Pyx_RefNannySetupContext("cb_on_message_complete", 0);
 
-  /* "aiohttp/_http_parser.pyx":692
+  /* "aiohttp/_http_parser.pyx":696
  * 
  * cdef int cb_on_message_complete(cparser.http_parser* parser) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data             # <<<<<<<<<<<<<<
  *     try:
  *         pyparser._started = False
  */
   __pyx_t_1 = ((PyObject *)__pyx_v_parser->data);
   __Pyx_INCREF(__pyx_t_1);
   __pyx_v_pyparser = ((struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *)__pyx_t_1);
   __pyx_t_1 = 0;
 
-  /* "aiohttp/_http_parser.pyx":693
+  /* "aiohttp/_http_parser.pyx":697
  * cdef int cb_on_message_complete(cparser.http_parser* parser) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:             # <<<<<<<<<<<<<<
  *         pyparser._started = False
  *         pyparser._on_message_complete()
  */
   {
@@ -12819,103 +12895,103 @@
     __Pyx_PyThreadState_assign
     __Pyx_ExceptionSave(&__pyx_t_2, &__pyx_t_3, &__pyx_t_4);
     __Pyx_XGOTREF(__pyx_t_2);
     __Pyx_XGOTREF(__pyx_t_3);
     __Pyx_XGOTREF(__pyx_t_4);
     /*try:*/ {
 
-      /* "aiohttp/_http_parser.pyx":694
+      /* "aiohttp/_http_parser.pyx":698
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:
  *         pyparser._started = False             # <<<<<<<<<<<<<<
  *         pyparser._on_message_complete()
  *     except BaseException as exc:
  */
       __pyx_v_pyparser->_started = 0;
 
-      /* "aiohttp/_http_parser.pyx":695
+      /* "aiohttp/_http_parser.pyx":699
  *     try:
  *         pyparser._started = False
  *         pyparser._on_message_complete()             # <<<<<<<<<<<<<<
  *     except BaseException as exc:
  *         pyparser._last_error = exc
  */
-      __pyx_t_1 = ((struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpParser *)__pyx_v_pyparser->__pyx_vtab)->_on_message_complete(__pyx_v_pyparser); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 695, __pyx_L3_error)
+      __pyx_t_1 = ((struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpParser *)__pyx_v_pyparser->__pyx_vtab)->_on_message_complete(__pyx_v_pyparser); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 699, __pyx_L3_error)
       __Pyx_GOTREF(__pyx_t_1);
       __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
 
-      /* "aiohttp/_http_parser.pyx":693
+      /* "aiohttp/_http_parser.pyx":697
  * cdef int cb_on_message_complete(cparser.http_parser* parser) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:             # <<<<<<<<<<<<<<
  *         pyparser._started = False
  *         pyparser._on_message_complete()
  */
     }
 
-    /* "aiohttp/_http_parser.pyx":700
+    /* "aiohttp/_http_parser.pyx":704
  *         return -1
  *     else:
  *         return 0             # <<<<<<<<<<<<<<
  * 
  * 
  */
     /*else:*/ {
       __pyx_r = 0;
       goto __pyx_L6_except_return;
     }
     __pyx_L3_error:;
     __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
 
-    /* "aiohttp/_http_parser.pyx":696
+    /* "aiohttp/_http_parser.pyx":700
  *         pyparser._started = False
  *         pyparser._on_message_complete()
  *     except BaseException as exc:             # <<<<<<<<<<<<<<
  *         pyparser._last_error = exc
  *         return -1
  */
     __pyx_t_5 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_BaseException);
     if (__pyx_t_5) {
       __Pyx_AddTraceback("aiohttp._http_parser.cb_on_message_complete", __pyx_clineno, __pyx_lineno, __pyx_filename);
-      if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(0, 696, __pyx_L5_except_error)
+      if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(0, 700, __pyx_L5_except_error)
       __Pyx_GOTREF(__pyx_t_1);
       __Pyx_GOTREF(__pyx_t_6);
       __Pyx_GOTREF(__pyx_t_7);
       __Pyx_INCREF(__pyx_t_6);
       __pyx_v_exc = __pyx_t_6;
       /*try:*/ {
 
-        /* "aiohttp/_http_parser.pyx":697
+        /* "aiohttp/_http_parser.pyx":701
  *         pyparser._on_message_complete()
  *     except BaseException as exc:
  *         pyparser._last_error = exc             # <<<<<<<<<<<<<<
  *         return -1
  *     else:
  */
         __Pyx_INCREF(__pyx_v_exc);
         __Pyx_GIVEREF(__pyx_v_exc);
         __Pyx_GOTREF(__pyx_v_pyparser->_last_error);
         __Pyx_DECREF(__pyx_v_pyparser->_last_error);
         __pyx_v_pyparser->_last_error = __pyx_v_exc;
 
-        /* "aiohttp/_http_parser.pyx":698
+        /* "aiohttp/_http_parser.pyx":702
  *     except BaseException as exc:
  *         pyparser._last_error = exc
  *         return -1             # <<<<<<<<<<<<<<
  *     else:
  *         return 0
  */
         __pyx_r = -1;
         __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
         __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
         __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
         goto __pyx_L13_return;
       }
 
-      /* "aiohttp/_http_parser.pyx":696
+      /* "aiohttp/_http_parser.pyx":700
  *         pyparser._started = False
  *         pyparser._on_message_complete()
  *     except BaseException as exc:             # <<<<<<<<<<<<<<
  *         pyparser._last_error = exc
  *         return -1
  */
       /*finally:*/ {
@@ -12927,15 +13003,15 @@
           goto __pyx_L6_except_return;
         }
       }
     }
     goto __pyx_L5_except_error;
     __pyx_L5_except_error:;
 
-    /* "aiohttp/_http_parser.pyx":693
+    /* "aiohttp/_http_parser.pyx":697
  * cdef int cb_on_message_complete(cparser.http_parser* parser) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:             # <<<<<<<<<<<<<<
  *         pyparser._started = False
  *         pyparser._on_message_complete()
  */
     __Pyx_XGIVEREF(__pyx_t_2);
@@ -12947,15 +13023,15 @@
     __Pyx_XGIVEREF(__pyx_t_2);
     __Pyx_XGIVEREF(__pyx_t_3);
     __Pyx_XGIVEREF(__pyx_t_4);
     __Pyx_ExceptionReset(__pyx_t_2, __pyx_t_3, __pyx_t_4);
     goto __pyx_L0;
   }
 
-  /* "aiohttp/_http_parser.pyx":691
+  /* "aiohttp/_http_parser.pyx":695
  * 
  * 
  * cdef int cb_on_message_complete(cparser.http_parser* parser) except -1:             # <<<<<<<<<<<<<<
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:
  */
 
@@ -12969,15 +13045,15 @@
   __pyx_L0:;
   __Pyx_XDECREF((PyObject *)__pyx_v_pyparser);
   __Pyx_XDECREF(__pyx_v_exc);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "aiohttp/_http_parser.pyx":703
+/* "aiohttp/_http_parser.pyx":707
  * 
  * 
  * cdef int cb_on_chunk_header(cparser.http_parser* parser) except -1:             # <<<<<<<<<<<<<<
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:
  */
 
@@ -12991,27 +13067,27 @@
   PyObject *__pyx_t_3 = NULL;
   PyObject *__pyx_t_4 = NULL;
   int __pyx_t_5;
   PyObject *__pyx_t_6 = NULL;
   PyObject *__pyx_t_7 = NULL;
   __Pyx_RefNannySetupContext("cb_on_chunk_header", 0);
 
-  /* "aiohttp/_http_parser.pyx":704
+  /* "aiohttp/_http_parser.pyx":708
  * 
  * cdef int cb_on_chunk_header(cparser.http_parser* parser) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data             # <<<<<<<<<<<<<<
  *     try:
  *         pyparser._on_chunk_header()
  */
   __pyx_t_1 = ((PyObject *)__pyx_v_parser->data);
   __Pyx_INCREF(__pyx_t_1);
   __pyx_v_pyparser = ((struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *)__pyx_t_1);
   __pyx_t_1 = 0;
 
-  /* "aiohttp/_http_parser.pyx":705
+  /* "aiohttp/_http_parser.pyx":709
  * cdef int cb_on_chunk_header(cparser.http_parser* parser) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:             # <<<<<<<<<<<<<<
  *         pyparser._on_chunk_header()
  *     except BaseException as exc:
  */
   {
@@ -13019,94 +13095,94 @@
     __Pyx_PyThreadState_assign
     __Pyx_ExceptionSave(&__pyx_t_2, &__pyx_t_3, &__pyx_t_4);
     __Pyx_XGOTREF(__pyx_t_2);
     __Pyx_XGOTREF(__pyx_t_3);
     __Pyx_XGOTREF(__pyx_t_4);
     /*try:*/ {
 
-      /* "aiohttp/_http_parser.pyx":706
+      /* "aiohttp/_http_parser.pyx":710
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:
  *         pyparser._on_chunk_header()             # <<<<<<<<<<<<<<
  *     except BaseException as exc:
  *         pyparser._last_error = exc
  */
-      __pyx_t_1 = ((struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpParser *)__pyx_v_pyparser->__pyx_vtab)->_on_chunk_header(__pyx_v_pyparser); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 706, __pyx_L3_error)
+      __pyx_t_1 = ((struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpParser *)__pyx_v_pyparser->__pyx_vtab)->_on_chunk_header(__pyx_v_pyparser); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 710, __pyx_L3_error)
       __Pyx_GOTREF(__pyx_t_1);
       __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
 
-      /* "aiohttp/_http_parser.pyx":705
+      /* "aiohttp/_http_parser.pyx":709
  * cdef int cb_on_chunk_header(cparser.http_parser* parser) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:             # <<<<<<<<<<<<<<
  *         pyparser._on_chunk_header()
  *     except BaseException as exc:
  */
     }
 
-    /* "aiohttp/_http_parser.pyx":711
+    /* "aiohttp/_http_parser.pyx":715
  *         return -1
  *     else:
  *         return 0             # <<<<<<<<<<<<<<
  * 
  * 
  */
     /*else:*/ {
       __pyx_r = 0;
       goto __pyx_L6_except_return;
     }
     __pyx_L3_error:;
     __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
 
-    /* "aiohttp/_http_parser.pyx":707
+    /* "aiohttp/_http_parser.pyx":711
  *     try:
  *         pyparser._on_chunk_header()
  *     except BaseException as exc:             # <<<<<<<<<<<<<<
  *         pyparser._last_error = exc
  *         return -1
  */
     __pyx_t_5 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_BaseException);
     if (__pyx_t_5) {
       __Pyx_AddTraceback("aiohttp._http_parser.cb_on_chunk_header", __pyx_clineno, __pyx_lineno, __pyx_filename);
-      if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(0, 707, __pyx_L5_except_error)
+      if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(0, 711, __pyx_L5_except_error)
       __Pyx_GOTREF(__pyx_t_1);
       __Pyx_GOTREF(__pyx_t_6);
       __Pyx_GOTREF(__pyx_t_7);
       __Pyx_INCREF(__pyx_t_6);
       __pyx_v_exc = __pyx_t_6;
       /*try:*/ {
 
-        /* "aiohttp/_http_parser.pyx":708
+        /* "aiohttp/_http_parser.pyx":712
  *         pyparser._on_chunk_header()
  *     except BaseException as exc:
  *         pyparser._last_error = exc             # <<<<<<<<<<<<<<
  *         return -1
  *     else:
  */
         __Pyx_INCREF(__pyx_v_exc);
         __Pyx_GIVEREF(__pyx_v_exc);
         __Pyx_GOTREF(__pyx_v_pyparser->_last_error);
         __Pyx_DECREF(__pyx_v_pyparser->_last_error);
         __pyx_v_pyparser->_last_error = __pyx_v_exc;
 
-        /* "aiohttp/_http_parser.pyx":709
+        /* "aiohttp/_http_parser.pyx":713
  *     except BaseException as exc:
  *         pyparser._last_error = exc
  *         return -1             # <<<<<<<<<<<<<<
  *     else:
  *         return 0
  */
         __pyx_r = -1;
         __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
         __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
         __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
         goto __pyx_L13_return;
       }
 
-      /* "aiohttp/_http_parser.pyx":707
+      /* "aiohttp/_http_parser.pyx":711
  *     try:
  *         pyparser._on_chunk_header()
  *     except BaseException as exc:             # <<<<<<<<<<<<<<
  *         pyparser._last_error = exc
  *         return -1
  */
       /*finally:*/ {
@@ -13118,15 +13194,15 @@
           goto __pyx_L6_except_return;
         }
       }
     }
     goto __pyx_L5_except_error;
     __pyx_L5_except_error:;
 
-    /* "aiohttp/_http_parser.pyx":705
+    /* "aiohttp/_http_parser.pyx":709
  * cdef int cb_on_chunk_header(cparser.http_parser* parser) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:             # <<<<<<<<<<<<<<
  *         pyparser._on_chunk_header()
  *     except BaseException as exc:
  */
     __Pyx_XGIVEREF(__pyx_t_2);
@@ -13138,15 +13214,15 @@
     __Pyx_XGIVEREF(__pyx_t_2);
     __Pyx_XGIVEREF(__pyx_t_3);
     __Pyx_XGIVEREF(__pyx_t_4);
     __Pyx_ExceptionReset(__pyx_t_2, __pyx_t_3, __pyx_t_4);
     goto __pyx_L0;
   }
 
-  /* "aiohttp/_http_parser.pyx":703
+  /* "aiohttp/_http_parser.pyx":707
  * 
  * 
  * cdef int cb_on_chunk_header(cparser.http_parser* parser) except -1:             # <<<<<<<<<<<<<<
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:
  */
 
@@ -13160,15 +13236,15 @@
   __pyx_L0:;
   __Pyx_XDECREF((PyObject *)__pyx_v_pyparser);
   __Pyx_XDECREF(__pyx_v_exc);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "aiohttp/_http_parser.pyx":714
+/* "aiohttp/_http_parser.pyx":718
  * 
  * 
  * cdef int cb_on_chunk_complete(cparser.http_parser* parser) except -1:             # <<<<<<<<<<<<<<
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:
  */
 
@@ -13182,27 +13258,27 @@
   PyObject *__pyx_t_3 = NULL;
   PyObject *__pyx_t_4 = NULL;
   int __pyx_t_5;
   PyObject *__pyx_t_6 = NULL;
   PyObject *__pyx_t_7 = NULL;
   __Pyx_RefNannySetupContext("cb_on_chunk_complete", 0);
 
-  /* "aiohttp/_http_parser.pyx":715
+  /* "aiohttp/_http_parser.pyx":719
  * 
  * cdef int cb_on_chunk_complete(cparser.http_parser* parser) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data             # <<<<<<<<<<<<<<
  *     try:
  *         pyparser._on_chunk_complete()
  */
   __pyx_t_1 = ((PyObject *)__pyx_v_parser->data);
   __Pyx_INCREF(__pyx_t_1);
   __pyx_v_pyparser = ((struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *)__pyx_t_1);
   __pyx_t_1 = 0;
 
-  /* "aiohttp/_http_parser.pyx":716
+  /* "aiohttp/_http_parser.pyx":720
  * cdef int cb_on_chunk_complete(cparser.http_parser* parser) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:             # <<<<<<<<<<<<<<
  *         pyparser._on_chunk_complete()
  *     except BaseException as exc:
  */
   {
@@ -13210,94 +13286,94 @@
     __Pyx_PyThreadState_assign
     __Pyx_ExceptionSave(&__pyx_t_2, &__pyx_t_3, &__pyx_t_4);
     __Pyx_XGOTREF(__pyx_t_2);
     __Pyx_XGOTREF(__pyx_t_3);
     __Pyx_XGOTREF(__pyx_t_4);
     /*try:*/ {
 
-      /* "aiohttp/_http_parser.pyx":717
+      /* "aiohttp/_http_parser.pyx":721
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:
  *         pyparser._on_chunk_complete()             # <<<<<<<<<<<<<<
  *     except BaseException as exc:
  *         pyparser._last_error = exc
  */
-      __pyx_t_1 = ((struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpParser *)__pyx_v_pyparser->__pyx_vtab)->_on_chunk_complete(__pyx_v_pyparser); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 717, __pyx_L3_error)
+      __pyx_t_1 = ((struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpParser *)__pyx_v_pyparser->__pyx_vtab)->_on_chunk_complete(__pyx_v_pyparser); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 721, __pyx_L3_error)
       __Pyx_GOTREF(__pyx_t_1);
       __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
 
-      /* "aiohttp/_http_parser.pyx":716
+      /* "aiohttp/_http_parser.pyx":720
  * cdef int cb_on_chunk_complete(cparser.http_parser* parser) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:             # <<<<<<<<<<<<<<
  *         pyparser._on_chunk_complete()
  *     except BaseException as exc:
  */
     }
 
-    /* "aiohttp/_http_parser.pyx":722
+    /* "aiohttp/_http_parser.pyx":726
  *         return -1
  *     else:
  *         return 0             # <<<<<<<<<<<<<<
  * 
  * 
  */
     /*else:*/ {
       __pyx_r = 0;
       goto __pyx_L6_except_return;
     }
     __pyx_L3_error:;
     __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
 
-    /* "aiohttp/_http_parser.pyx":718
+    /* "aiohttp/_http_parser.pyx":722
  *     try:
  *         pyparser._on_chunk_complete()
  *     except BaseException as exc:             # <<<<<<<<<<<<<<
  *         pyparser._last_error = exc
  *         return -1
  */
     __pyx_t_5 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_BaseException);
     if (__pyx_t_5) {
       __Pyx_AddTraceback("aiohttp._http_parser.cb_on_chunk_complete", __pyx_clineno, __pyx_lineno, __pyx_filename);
-      if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(0, 718, __pyx_L5_except_error)
+      if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(0, 722, __pyx_L5_except_error)
       __Pyx_GOTREF(__pyx_t_1);
       __Pyx_GOTREF(__pyx_t_6);
       __Pyx_GOTREF(__pyx_t_7);
       __Pyx_INCREF(__pyx_t_6);
       __pyx_v_exc = __pyx_t_6;
       /*try:*/ {
 
-        /* "aiohttp/_http_parser.pyx":719
+        /* "aiohttp/_http_parser.pyx":723
  *         pyparser._on_chunk_complete()
  *     except BaseException as exc:
  *         pyparser._last_error = exc             # <<<<<<<<<<<<<<
  *         return -1
  *     else:
  */
         __Pyx_INCREF(__pyx_v_exc);
         __Pyx_GIVEREF(__pyx_v_exc);
         __Pyx_GOTREF(__pyx_v_pyparser->_last_error);
         __Pyx_DECREF(__pyx_v_pyparser->_last_error);
         __pyx_v_pyparser->_last_error = __pyx_v_exc;
 
-        /* "aiohttp/_http_parser.pyx":720
+        /* "aiohttp/_http_parser.pyx":724
  *     except BaseException as exc:
  *         pyparser._last_error = exc
  *         return -1             # <<<<<<<<<<<<<<
  *     else:
  *         return 0
  */
         __pyx_r = -1;
         __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
         __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
         __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
         goto __pyx_L13_return;
       }
 
-      /* "aiohttp/_http_parser.pyx":718
+      /* "aiohttp/_http_parser.pyx":722
  *     try:
  *         pyparser._on_chunk_complete()
  *     except BaseException as exc:             # <<<<<<<<<<<<<<
  *         pyparser._last_error = exc
  *         return -1
  */
       /*finally:*/ {
@@ -13309,15 +13385,15 @@
           goto __pyx_L6_except_return;
         }
       }
     }
     goto __pyx_L5_except_error;
     __pyx_L5_except_error:;
 
-    /* "aiohttp/_http_parser.pyx":716
+    /* "aiohttp/_http_parser.pyx":720
  * cdef int cb_on_chunk_complete(cparser.http_parser* parser) except -1:
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:             # <<<<<<<<<<<<<<
  *         pyparser._on_chunk_complete()
  *     except BaseException as exc:
  */
     __Pyx_XGIVEREF(__pyx_t_2);
@@ -13329,15 +13405,15 @@
     __Pyx_XGIVEREF(__pyx_t_2);
     __Pyx_XGIVEREF(__pyx_t_3);
     __Pyx_XGIVEREF(__pyx_t_4);
     __Pyx_ExceptionReset(__pyx_t_2, __pyx_t_3, __pyx_t_4);
     goto __pyx_L0;
   }
 
-  /* "aiohttp/_http_parser.pyx":714
+  /* "aiohttp/_http_parser.pyx":718
  * 
  * 
  * cdef int cb_on_chunk_complete(cparser.http_parser* parser) except -1:             # <<<<<<<<<<<<<<
  *     cdef HttpParser pyparser = <HttpParser>parser.data
  *     try:
  */
 
@@ -13351,15 +13427,15 @@
   __pyx_L0:;
   __Pyx_XDECREF((PyObject *)__pyx_v_pyparser);
   __Pyx_XDECREF(__pyx_v_exc);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "aiohttp/_http_parser.pyx":725
+/* "aiohttp/_http_parser.pyx":729
  * 
  * 
  * cdef parser_error_from_errno(cparser.http_errno errno):             # <<<<<<<<<<<<<<
  *     cdef bytes desc = cparser.http_errno_description(errno)
  * 
  */
 
@@ -13370,220 +13446,220 @@
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   PyObject *__pyx_t_2 = NULL;
   PyObject *__pyx_t_3 = NULL;
   PyObject *__pyx_t_4 = NULL;
   __Pyx_RefNannySetupContext("parser_error_from_errno", 0);
 
-  /* "aiohttp/_http_parser.pyx":726
+  /* "aiohttp/_http_parser.pyx":730
  * 
  * cdef parser_error_from_errno(cparser.http_errno errno):
  *     cdef bytes desc = cparser.http_errno_description(errno)             # <<<<<<<<<<<<<<
  * 
  *     if errno in (cparser.HPE_CB_message_begin,
  */
-  __pyx_t_1 = __Pyx_PyBytes_FromString(http_errno_description(__pyx_v_errno)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 726, __pyx_L1_error)
+  __pyx_t_1 = __Pyx_PyBytes_FromString(http_errno_description(__pyx_v_errno)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 730, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_v_desc = ((PyObject*)__pyx_t_1);
   __pyx_t_1 = 0;
 
-  /* "aiohttp/_http_parser.pyx":728
+  /* "aiohttp/_http_parser.pyx":732
  *     cdef bytes desc = cparser.http_errno_description(errno)
  * 
  *     if errno in (cparser.HPE_CB_message_begin,             # <<<<<<<<<<<<<<
  *                  cparser.HPE_CB_url,
  *                  cparser.HPE_CB_header_field,
  */
   switch (__pyx_v_errno) {
     case HPE_CB_message_begin:
     case HPE_CB_url:
 
-    /* "aiohttp/_http_parser.pyx":729
+    /* "aiohttp/_http_parser.pyx":733
  * 
  *     if errno in (cparser.HPE_CB_message_begin,
  *                  cparser.HPE_CB_url,             # <<<<<<<<<<<<<<
  *                  cparser.HPE_CB_header_field,
  *                  cparser.HPE_CB_header_value,
  */
     case HPE_CB_header_field:
 
-    /* "aiohttp/_http_parser.pyx":730
+    /* "aiohttp/_http_parser.pyx":734
  *     if errno in (cparser.HPE_CB_message_begin,
  *                  cparser.HPE_CB_url,
  *                  cparser.HPE_CB_header_field,             # <<<<<<<<<<<<<<
  *                  cparser.HPE_CB_header_value,
  *                  cparser.HPE_CB_headers_complete,
  */
     case HPE_CB_header_value:
 
-    /* "aiohttp/_http_parser.pyx":731
+    /* "aiohttp/_http_parser.pyx":735
  *                  cparser.HPE_CB_url,
  *                  cparser.HPE_CB_header_field,
  *                  cparser.HPE_CB_header_value,             # <<<<<<<<<<<<<<
  *                  cparser.HPE_CB_headers_complete,
  *                  cparser.HPE_CB_body,
  */
     case HPE_CB_headers_complete:
 
-    /* "aiohttp/_http_parser.pyx":732
+    /* "aiohttp/_http_parser.pyx":736
  *                  cparser.HPE_CB_header_field,
  *                  cparser.HPE_CB_header_value,
  *                  cparser.HPE_CB_headers_complete,             # <<<<<<<<<<<<<<
  *                  cparser.HPE_CB_body,
  *                  cparser.HPE_CB_message_complete,
  */
     case HPE_CB_body:
 
-    /* "aiohttp/_http_parser.pyx":733
+    /* "aiohttp/_http_parser.pyx":737
  *                  cparser.HPE_CB_header_value,
  *                  cparser.HPE_CB_headers_complete,
  *                  cparser.HPE_CB_body,             # <<<<<<<<<<<<<<
  *                  cparser.HPE_CB_message_complete,
  *                  cparser.HPE_CB_status,
  */
     case HPE_CB_message_complete:
 
-    /* "aiohttp/_http_parser.pyx":734
+    /* "aiohttp/_http_parser.pyx":738
  *                  cparser.HPE_CB_headers_complete,
  *                  cparser.HPE_CB_body,
  *                  cparser.HPE_CB_message_complete,             # <<<<<<<<<<<<<<
  *                  cparser.HPE_CB_status,
  *                  cparser.HPE_CB_chunk_header,
  */
     case HPE_CB_status:
 
-    /* "aiohttp/_http_parser.pyx":735
+    /* "aiohttp/_http_parser.pyx":739
  *                  cparser.HPE_CB_body,
  *                  cparser.HPE_CB_message_complete,
  *                  cparser.HPE_CB_status,             # <<<<<<<<<<<<<<
  *                  cparser.HPE_CB_chunk_header,
  *                  cparser.HPE_CB_chunk_complete):
  */
     case HPE_CB_chunk_header:
 
-    /* "aiohttp/_http_parser.pyx":736
+    /* "aiohttp/_http_parser.pyx":740
  *                  cparser.HPE_CB_message_complete,
  *                  cparser.HPE_CB_status,
  *                  cparser.HPE_CB_chunk_header,             # <<<<<<<<<<<<<<
  *                  cparser.HPE_CB_chunk_complete):
  *         cls = BadHttpMessage
  */
     case HPE_CB_chunk_complete:
 
-    /* "aiohttp/_http_parser.pyx":738
+    /* "aiohttp/_http_parser.pyx":742
  *                  cparser.HPE_CB_chunk_header,
  *                  cparser.HPE_CB_chunk_complete):
  *         cls = BadHttpMessage             # <<<<<<<<<<<<<<
  * 
  *     elif errno == cparser.HPE_INVALID_STATUS:
  */
-    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_BadHttpMessage); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 738, __pyx_L1_error)
+    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_BadHttpMessage); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 742, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_1);
     __pyx_v_cls = __pyx_t_1;
     __pyx_t_1 = 0;
 
-    /* "aiohttp/_http_parser.pyx":728
+    /* "aiohttp/_http_parser.pyx":732
  *     cdef bytes desc = cparser.http_errno_description(errno)
  * 
  *     if errno in (cparser.HPE_CB_message_begin,             # <<<<<<<<<<<<<<
  *                  cparser.HPE_CB_url,
  *                  cparser.HPE_CB_header_field,
  */
     break;
     case HPE_INVALID_STATUS:
 
-    /* "aiohttp/_http_parser.pyx":741
+    /* "aiohttp/_http_parser.pyx":745
  * 
  *     elif errno == cparser.HPE_INVALID_STATUS:
  *         cls = BadStatusLine             # <<<<<<<<<<<<<<
  * 
  *     elif errno == cparser.HPE_INVALID_METHOD:
  */
-    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_BadStatusLine); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 741, __pyx_L1_error)
+    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_BadStatusLine); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 745, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_1);
     __pyx_v_cls = __pyx_t_1;
     __pyx_t_1 = 0;
 
-    /* "aiohttp/_http_parser.pyx":740
+    /* "aiohttp/_http_parser.pyx":744
  *         cls = BadHttpMessage
  * 
  *     elif errno == cparser.HPE_INVALID_STATUS:             # <<<<<<<<<<<<<<
  *         cls = BadStatusLine
  * 
  */
     break;
     case HPE_INVALID_METHOD:
 
-    /* "aiohttp/_http_parser.pyx":744
+    /* "aiohttp/_http_parser.pyx":748
  * 
  *     elif errno == cparser.HPE_INVALID_METHOD:
  *         cls = BadStatusLine             # <<<<<<<<<<<<<<
  * 
  *     elif errno == cparser.HPE_INVALID_URL:
  */
-    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_BadStatusLine); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 744, __pyx_L1_error)
+    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_BadStatusLine); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 748, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_1);
     __pyx_v_cls = __pyx_t_1;
     __pyx_t_1 = 0;
 
-    /* "aiohttp/_http_parser.pyx":743
+    /* "aiohttp/_http_parser.pyx":747
  *         cls = BadStatusLine
  * 
  *     elif errno == cparser.HPE_INVALID_METHOD:             # <<<<<<<<<<<<<<
  *         cls = BadStatusLine
  * 
  */
     break;
     case HPE_INVALID_URL:
 
-    /* "aiohttp/_http_parser.pyx":747
+    /* "aiohttp/_http_parser.pyx":751
  * 
  *     elif errno == cparser.HPE_INVALID_URL:
  *         cls = InvalidURLError             # <<<<<<<<<<<<<<
  * 
  *     else:
  */
-    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_InvalidURLError); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 747, __pyx_L1_error)
+    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_InvalidURLError); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 751, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_1);
     __pyx_v_cls = __pyx_t_1;
     __pyx_t_1 = 0;
 
-    /* "aiohttp/_http_parser.pyx":746
+    /* "aiohttp/_http_parser.pyx":750
  *         cls = BadStatusLine
  * 
  *     elif errno == cparser.HPE_INVALID_URL:             # <<<<<<<<<<<<<<
  *         cls = InvalidURLError
  * 
  */
     break;
     default:
 
-    /* "aiohttp/_http_parser.pyx":750
+    /* "aiohttp/_http_parser.pyx":754
  * 
  *     else:
  *         cls = BadHttpMessage             # <<<<<<<<<<<<<<
  * 
  *     return cls(desc.decode('latin-1'))
  */
-    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_BadHttpMessage); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 750, __pyx_L1_error)
+    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_BadHttpMessage); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 754, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_1);
     __pyx_v_cls = __pyx_t_1;
     __pyx_t_1 = 0;
     break;
   }
 
-  /* "aiohttp/_http_parser.pyx":752
+  /* "aiohttp/_http_parser.pyx":756
  *         cls = BadHttpMessage
  * 
  *     return cls(desc.decode('latin-1'))             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_2 = __Pyx_decode_bytes(__pyx_v_desc, 0, PY_SSIZE_T_MAX, NULL, NULL, PyUnicode_DecodeLatin1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 752, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_decode_bytes(__pyx_v_desc, 0, PY_SSIZE_T_MAX, NULL, NULL, PyUnicode_DecodeLatin1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 756, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __Pyx_INCREF(__pyx_v_cls);
   __pyx_t_3 = __pyx_v_cls; __pyx_t_4 = NULL;
   if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
     __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
     if (likely(__pyx_t_4)) {
       PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
@@ -13591,22 +13667,22 @@
       __Pyx_INCREF(function);
       __Pyx_DECREF_SET(__pyx_t_3, function);
     }
   }
   __pyx_t_1 = (__pyx_t_4) ? __Pyx_PyObject_Call2Args(__pyx_t_3, __pyx_t_4, __pyx_t_2) : __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_2);
   __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
   __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
-  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 752, __pyx_L1_error)
+  if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 756, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
   __pyx_r = __pyx_t_1;
   __pyx_t_1 = 0;
   goto __pyx_L0;
 
-  /* "aiohttp/_http_parser.pyx":725
+  /* "aiohttp/_http_parser.pyx":729
  * 
  * 
  * cdef parser_error_from_errno(cparser.http_errno errno):             # <<<<<<<<<<<<<<
  *     cdef bytes desc = cparser.http_errno_description(errno)
  * 
  */
 
@@ -13622,15 +13698,15 @@
   __Pyx_XDECREF(__pyx_v_desc);
   __Pyx_XDECREF(__pyx_v_cls);
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "aiohttp/_http_parser.pyx":755
+/* "aiohttp/_http_parser.pyx":759
  * 
  * 
  * def parse_url(url):             # <<<<<<<<<<<<<<
  *     cdef:
  *         Py_buffer py_buf
  */
 
@@ -13661,57 +13737,57 @@
   PyObject *__pyx_t_6 = NULL;
   PyObject *__pyx_t_7 = NULL;
   PyObject *__pyx_t_8 = NULL;
   PyObject *__pyx_t_9 = NULL;
   PyObject *__pyx_t_10 = NULL;
   __Pyx_RefNannySetupContext("parse_url", 0);
 
-  /* "aiohttp/_http_parser.pyx":760
+  /* "aiohttp/_http_parser.pyx":764
  *         char* buf_data
  * 
  *     PyObject_GetBuffer(url, &py_buf, PyBUF_SIMPLE)             # <<<<<<<<<<<<<<
  *     try:
  *         buf_data = <char*>py_buf.buf
  */
-  __pyx_t_1 = PyObject_GetBuffer(__pyx_v_url, (&__pyx_v_py_buf), PyBUF_SIMPLE); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 760, __pyx_L1_error)
+  __pyx_t_1 = PyObject_GetBuffer(__pyx_v_url, (&__pyx_v_py_buf), PyBUF_SIMPLE); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 764, __pyx_L1_error)
 
-  /* "aiohttp/_http_parser.pyx":761
+  /* "aiohttp/_http_parser.pyx":765
  * 
  *     PyObject_GetBuffer(url, &py_buf, PyBUF_SIMPLE)
  *     try:             # <<<<<<<<<<<<<<
  *         buf_data = <char*>py_buf.buf
  *         return _parse_url(buf_data, py_buf.len)
  */
   /*try:*/ {
 
-    /* "aiohttp/_http_parser.pyx":762
+    /* "aiohttp/_http_parser.pyx":766
  *     PyObject_GetBuffer(url, &py_buf, PyBUF_SIMPLE)
  *     try:
  *         buf_data = <char*>py_buf.buf             # <<<<<<<<<<<<<<
  *         return _parse_url(buf_data, py_buf.len)
  *     finally:
  */
     __pyx_v_buf_data = ((char *)__pyx_v_py_buf.buf);
 
-    /* "aiohttp/_http_parser.pyx":763
+    /* "aiohttp/_http_parser.pyx":767
  *     try:
  *         buf_data = <char*>py_buf.buf
  *         return _parse_url(buf_data, py_buf.len)             # <<<<<<<<<<<<<<
  *     finally:
  *         PyBuffer_Release(&py_buf)
  */
     __Pyx_XDECREF(__pyx_r);
-    __pyx_t_2 = __pyx_f_7aiohttp_12_http_parser__parse_url(__pyx_v_buf_data, __pyx_v_py_buf.len); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 763, __pyx_L4_error)
+    __pyx_t_2 = __pyx_f_7aiohttp_12_http_parser__parse_url(__pyx_v_buf_data, __pyx_v_py_buf.len); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 767, __pyx_L4_error)
     __Pyx_GOTREF(__pyx_t_2);
     __pyx_r = __pyx_t_2;
     __pyx_t_2 = 0;
     goto __pyx_L3_return;
   }
 
-  /* "aiohttp/_http_parser.pyx":765
+  /* "aiohttp/_http_parser.pyx":769
  *         return _parse_url(buf_data, py_buf.len)
  *     finally:
  *         PyBuffer_Release(&py_buf)             # <<<<<<<<<<<<<<
  * 
  * 
  */
   /*finally:*/ {
@@ -13753,15 +13829,15 @@
       PyBuffer_Release((&__pyx_v_py_buf));
       __pyx_r = __pyx_t_10;
       __pyx_t_10 = 0;
       goto __pyx_L0;
     }
   }
 
-  /* "aiohttp/_http_parser.pyx":755
+  /* "aiohttp/_http_parser.pyx":759
  * 
  * 
  * def parse_url(url):             # <<<<<<<<<<<<<<
  *     cdef:
  *         Py_buffer py_buf
  */
 
@@ -13772,15 +13848,15 @@
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "aiohttp/_http_parser.pyx":768
+/* "aiohttp/_http_parser.pyx":772
  * 
  * 
  * cdef _parse_url(char* buf_data, size_t length):             # <<<<<<<<<<<<<<
  *     cdef:
  *         cparser.http_parser_url* parsed
  */
 
@@ -13818,602 +13894,602 @@
   PyObject *__pyx_t_14 = NULL;
   PyObject *__pyx_t_15 = NULL;
   PyObject *__pyx_t_16 = NULL;
   PyObject *__pyx_t_17 = NULL;
   PyObject *__pyx_t_18 = NULL;
   __Pyx_RefNannySetupContext("_parse_url", 0);
 
-  /* "aiohttp/_http_parser.pyx":772
+  /* "aiohttp/_http_parser.pyx":776
  *         cparser.http_parser_url* parsed
  *         int res
  *         str schema = None             # <<<<<<<<<<<<<<
  *         str host = None
  *         object port = None
  */
   __Pyx_INCREF(Py_None);
   __pyx_v_schema = ((PyObject*)Py_None);
 
-  /* "aiohttp/_http_parser.pyx":773
+  /* "aiohttp/_http_parser.pyx":777
  *         int res
  *         str schema = None
  *         str host = None             # <<<<<<<<<<<<<<
  *         object port = None
  *         str path = None
  */
   __Pyx_INCREF(Py_None);
   __pyx_v_host = ((PyObject*)Py_None);
 
-  /* "aiohttp/_http_parser.pyx":774
+  /* "aiohttp/_http_parser.pyx":778
  *         str schema = None
  *         str host = None
  *         object port = None             # <<<<<<<<<<<<<<
  *         str path = None
  *         str query = None
  */
   __Pyx_INCREF(Py_None);
   __pyx_v_port = Py_None;
 
-  /* "aiohttp/_http_parser.pyx":775
+  /* "aiohttp/_http_parser.pyx":779
  *         str host = None
  *         object port = None
  *         str path = None             # <<<<<<<<<<<<<<
  *         str query = None
  *         str fragment = None
  */
   __Pyx_INCREF(Py_None);
   __pyx_v_path = ((PyObject*)Py_None);
 
-  /* "aiohttp/_http_parser.pyx":776
+  /* "aiohttp/_http_parser.pyx":780
  *         object port = None
  *         str path = None
  *         str query = None             # <<<<<<<<<<<<<<
  *         str fragment = None
  *         str user = None
  */
   __Pyx_INCREF(Py_None);
   __pyx_v_query = ((PyObject*)Py_None);
 
-  /* "aiohttp/_http_parser.pyx":777
+  /* "aiohttp/_http_parser.pyx":781
  *         str path = None
  *         str query = None
  *         str fragment = None             # <<<<<<<<<<<<<<
  *         str user = None
  *         str password = None
  */
   __Pyx_INCREF(Py_None);
   __pyx_v_fragment = ((PyObject*)Py_None);
 
-  /* "aiohttp/_http_parser.pyx":778
+  /* "aiohttp/_http_parser.pyx":782
  *         str query = None
  *         str fragment = None
  *         str user = None             # <<<<<<<<<<<<<<
  *         str password = None
  *         str userinfo = None
  */
   __Pyx_INCREF(Py_None);
   __pyx_v_user = ((PyObject*)Py_None);
 
-  /* "aiohttp/_http_parser.pyx":779
+  /* "aiohttp/_http_parser.pyx":783
  *         str fragment = None
  *         str user = None
  *         str password = None             # <<<<<<<<<<<<<<
  *         str userinfo = None
  *         object result = None
  */
   __Pyx_INCREF(Py_None);
   __pyx_v_password = ((PyObject*)Py_None);
 
-  /* "aiohttp/_http_parser.pyx":780
+  /* "aiohttp/_http_parser.pyx":784
  *         str user = None
  *         str password = None
  *         str userinfo = None             # <<<<<<<<<<<<<<
  *         object result = None
  *         int off
  */
   __Pyx_INCREF(Py_None);
   __pyx_v_userinfo = ((PyObject*)Py_None);
 
-  /* "aiohttp/_http_parser.pyx":781
+  /* "aiohttp/_http_parser.pyx":785
  *         str password = None
  *         str userinfo = None
  *         object result = None             # <<<<<<<<<<<<<<
  *         int off
  *         int ln
  */
   __Pyx_INCREF(Py_None);
   __pyx_v_result = Py_None;
 
-  /* "aiohttp/_http_parser.pyx":785
+  /* "aiohttp/_http_parser.pyx":789
  *         int ln
  * 
  *     parsed = <cparser.http_parser_url*> \             # <<<<<<<<<<<<<<
  *                         PyMem_Malloc(sizeof(cparser.http_parser_url))
  *     if parsed is NULL:
  */
   __pyx_v_parsed = ((struct http_parser_url *)PyMem_Malloc((sizeof(struct http_parser_url))));
 
-  /* "aiohttp/_http_parser.pyx":787
+  /* "aiohttp/_http_parser.pyx":791
  *     parsed = <cparser.http_parser_url*> \
  *                         PyMem_Malloc(sizeof(cparser.http_parser_url))
  *     if parsed is NULL:             # <<<<<<<<<<<<<<
  *         raise MemoryError()
  *     cparser.http_parser_url_init(parsed)
  */
   __pyx_t_1 = ((__pyx_v_parsed == NULL) != 0);
   if (unlikely(__pyx_t_1)) {
 
-    /* "aiohttp/_http_parser.pyx":788
+    /* "aiohttp/_http_parser.pyx":792
  *                         PyMem_Malloc(sizeof(cparser.http_parser_url))
  *     if parsed is NULL:
  *         raise MemoryError()             # <<<<<<<<<<<<<<
  *     cparser.http_parser_url_init(parsed)
  *     try:
  */
-    PyErr_NoMemory(); __PYX_ERR(0, 788, __pyx_L1_error)
+    PyErr_NoMemory(); __PYX_ERR(0, 792, __pyx_L1_error)
 
-    /* "aiohttp/_http_parser.pyx":787
+    /* "aiohttp/_http_parser.pyx":791
  *     parsed = <cparser.http_parser_url*> \
  *                         PyMem_Malloc(sizeof(cparser.http_parser_url))
  *     if parsed is NULL:             # <<<<<<<<<<<<<<
  *         raise MemoryError()
  *     cparser.http_parser_url_init(parsed)
  */
   }
 
-  /* "aiohttp/_http_parser.pyx":789
+  /* "aiohttp/_http_parser.pyx":793
  *     if parsed is NULL:
  *         raise MemoryError()
  *     cparser.http_parser_url_init(parsed)             # <<<<<<<<<<<<<<
  *     try:
  *         res = cparser.http_parser_parse_url(buf_data, length, 0, parsed)
  */
   http_parser_url_init(__pyx_v_parsed);
 
-  /* "aiohttp/_http_parser.pyx":790
+  /* "aiohttp/_http_parser.pyx":794
  *         raise MemoryError()
  *     cparser.http_parser_url_init(parsed)
  *     try:             # <<<<<<<<<<<<<<
  *         res = cparser.http_parser_parse_url(buf_data, length, 0, parsed)
  * 
  */
   /*try:*/ {
 
-    /* "aiohttp/_http_parser.pyx":791
+    /* "aiohttp/_http_parser.pyx":795
  *     cparser.http_parser_url_init(parsed)
  *     try:
  *         res = cparser.http_parser_parse_url(buf_data, length, 0, parsed)             # <<<<<<<<<<<<<<
  * 
  *         if res == 0:
  */
     __pyx_v_res = http_parser_parse_url(__pyx_v_buf_data, __pyx_v_length, 0, __pyx_v_parsed);
 
-    /* "aiohttp/_http_parser.pyx":793
+    /* "aiohttp/_http_parser.pyx":797
  *         res = cparser.http_parser_parse_url(buf_data, length, 0, parsed)
  * 
  *         if res == 0:             # <<<<<<<<<<<<<<
  *             if parsed.field_set & (1 << cparser.UF_SCHEMA):
  *                 off = parsed.field_data[<int>cparser.UF_SCHEMA].off
  */
     __pyx_t_1 = ((__pyx_v_res == 0) != 0);
     if (likely(__pyx_t_1)) {
 
-      /* "aiohttp/_http_parser.pyx":794
+      /* "aiohttp/_http_parser.pyx":798
  * 
  *         if res == 0:
  *             if parsed.field_set & (1 << cparser.UF_SCHEMA):             # <<<<<<<<<<<<<<
  *                 off = parsed.field_data[<int>cparser.UF_SCHEMA].off
  *                 ln = parsed.field_data[<int>cparser.UF_SCHEMA].len
  */
       __pyx_t_1 = ((__pyx_v_parsed->field_set & (1 << UF_SCHEMA)) != 0);
       if (__pyx_t_1) {
 
-        /* "aiohttp/_http_parser.pyx":795
+        /* "aiohttp/_http_parser.pyx":799
  *         if res == 0:
  *             if parsed.field_set & (1 << cparser.UF_SCHEMA):
  *                 off = parsed.field_data[<int>cparser.UF_SCHEMA].off             # <<<<<<<<<<<<<<
  *                 ln = parsed.field_data[<int>cparser.UF_SCHEMA].len
  *                 schema = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')
  */
         __pyx_t_2 = (__pyx_v_parsed->field_data[((int)UF_SCHEMA)]).off;
         __pyx_v_off = __pyx_t_2;
 
-        /* "aiohttp/_http_parser.pyx":796
+        /* "aiohttp/_http_parser.pyx":800
  *             if parsed.field_set & (1 << cparser.UF_SCHEMA):
  *                 off = parsed.field_data[<int>cparser.UF_SCHEMA].off
  *                 ln = parsed.field_data[<int>cparser.UF_SCHEMA].len             # <<<<<<<<<<<<<<
  *                 schema = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')
  *             else:
  */
         __pyx_t_2 = (__pyx_v_parsed->field_data[((int)UF_SCHEMA)]).len;
         __pyx_v_ln = __pyx_t_2;
 
-        /* "aiohttp/_http_parser.pyx":797
+        /* "aiohttp/_http_parser.pyx":801
  *                 off = parsed.field_data[<int>cparser.UF_SCHEMA].off
  *                 ln = parsed.field_data[<int>cparser.UF_SCHEMA].len
  *                 schema = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')             # <<<<<<<<<<<<<<
  *             else:
  *                 schema = ''
  */
-        __pyx_t_3 = __Pyx_decode_c_string(__pyx_v_buf_data, __pyx_v_off, (__pyx_v_off + __pyx_v_ln), NULL, ((char const *)"surrogateescape"), PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 797, __pyx_L5_error)
+        __pyx_t_3 = __Pyx_decode_c_string(__pyx_v_buf_data, __pyx_v_off, (__pyx_v_off + __pyx_v_ln), NULL, ((char const *)"surrogateescape"), PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 801, __pyx_L5_error)
         __Pyx_GOTREF(__pyx_t_3);
         __Pyx_DECREF_SET(__pyx_v_schema, ((PyObject*)__pyx_t_3));
         __pyx_t_3 = 0;
 
-        /* "aiohttp/_http_parser.pyx":794
+        /* "aiohttp/_http_parser.pyx":798
  * 
  *         if res == 0:
  *             if parsed.field_set & (1 << cparser.UF_SCHEMA):             # <<<<<<<<<<<<<<
  *                 off = parsed.field_data[<int>cparser.UF_SCHEMA].off
  *                 ln = parsed.field_data[<int>cparser.UF_SCHEMA].len
  */
         goto __pyx_L8;
       }
 
-      /* "aiohttp/_http_parser.pyx":799
+      /* "aiohttp/_http_parser.pyx":803
  *                 schema = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')
  *             else:
  *                 schema = ''             # <<<<<<<<<<<<<<
  * 
  *             if parsed.field_set & (1 << cparser.UF_HOST):
  */
       /*else*/ {
         __Pyx_INCREF(__pyx_kp_u__4);
         __Pyx_DECREF_SET(__pyx_v_schema, __pyx_kp_u__4);
       }
       __pyx_L8:;
 
-      /* "aiohttp/_http_parser.pyx":801
+      /* "aiohttp/_http_parser.pyx":805
  *                 schema = ''
  * 
  *             if parsed.field_set & (1 << cparser.UF_HOST):             # <<<<<<<<<<<<<<
  *                 off = parsed.field_data[<int>cparser.UF_HOST].off
  *                 ln = parsed.field_data[<int>cparser.UF_HOST].len
  */
       __pyx_t_1 = ((__pyx_v_parsed->field_set & (1 << UF_HOST)) != 0);
       if (__pyx_t_1) {
 
-        /* "aiohttp/_http_parser.pyx":802
+        /* "aiohttp/_http_parser.pyx":806
  * 
  *             if parsed.field_set & (1 << cparser.UF_HOST):
  *                 off = parsed.field_data[<int>cparser.UF_HOST].off             # <<<<<<<<<<<<<<
  *                 ln = parsed.field_data[<int>cparser.UF_HOST].len
  *                 host = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')
  */
         __pyx_t_2 = (__pyx_v_parsed->field_data[((int)UF_HOST)]).off;
         __pyx_v_off = __pyx_t_2;
 
-        /* "aiohttp/_http_parser.pyx":803
+        /* "aiohttp/_http_parser.pyx":807
  *             if parsed.field_set & (1 << cparser.UF_HOST):
  *                 off = parsed.field_data[<int>cparser.UF_HOST].off
  *                 ln = parsed.field_data[<int>cparser.UF_HOST].len             # <<<<<<<<<<<<<<
  *                 host = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')
  *             else:
  */
         __pyx_t_2 = (__pyx_v_parsed->field_data[((int)UF_HOST)]).len;
         __pyx_v_ln = __pyx_t_2;
 
-        /* "aiohttp/_http_parser.pyx":804
+        /* "aiohttp/_http_parser.pyx":808
  *                 off = parsed.field_data[<int>cparser.UF_HOST].off
  *                 ln = parsed.field_data[<int>cparser.UF_HOST].len
  *                 host = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')             # <<<<<<<<<<<<<<
  *             else:
  *                 host = ''
  */
-        __pyx_t_3 = __Pyx_decode_c_string(__pyx_v_buf_data, __pyx_v_off, (__pyx_v_off + __pyx_v_ln), NULL, ((char const *)"surrogateescape"), PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 804, __pyx_L5_error)
+        __pyx_t_3 = __Pyx_decode_c_string(__pyx_v_buf_data, __pyx_v_off, (__pyx_v_off + __pyx_v_ln), NULL, ((char const *)"surrogateescape"), PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 808, __pyx_L5_error)
         __Pyx_GOTREF(__pyx_t_3);
         __Pyx_DECREF_SET(__pyx_v_host, ((PyObject*)__pyx_t_3));
         __pyx_t_3 = 0;
 
-        /* "aiohttp/_http_parser.pyx":801
+        /* "aiohttp/_http_parser.pyx":805
  *                 schema = ''
  * 
  *             if parsed.field_set & (1 << cparser.UF_HOST):             # <<<<<<<<<<<<<<
  *                 off = parsed.field_data[<int>cparser.UF_HOST].off
  *                 ln = parsed.field_data[<int>cparser.UF_HOST].len
  */
         goto __pyx_L9;
       }
 
-      /* "aiohttp/_http_parser.pyx":806
+      /* "aiohttp/_http_parser.pyx":810
  *                 host = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')
  *             else:
  *                 host = ''             # <<<<<<<<<<<<<<
  * 
  *             if parsed.field_set & (1 << cparser.UF_PORT):
  */
       /*else*/ {
         __Pyx_INCREF(__pyx_kp_u__4);
         __Pyx_DECREF_SET(__pyx_v_host, __pyx_kp_u__4);
       }
       __pyx_L9:;
 
-      /* "aiohttp/_http_parser.pyx":808
+      /* "aiohttp/_http_parser.pyx":812
  *                 host = ''
  * 
  *             if parsed.field_set & (1 << cparser.UF_PORT):             # <<<<<<<<<<<<<<
  *                 port = parsed.port
  * 
  */
       __pyx_t_1 = ((__pyx_v_parsed->field_set & (1 << UF_PORT)) != 0);
       if (__pyx_t_1) {
 
-        /* "aiohttp/_http_parser.pyx":809
+        /* "aiohttp/_http_parser.pyx":813
  * 
  *             if parsed.field_set & (1 << cparser.UF_PORT):
  *                 port = parsed.port             # <<<<<<<<<<<<<<
  * 
  *             if parsed.field_set & (1 << cparser.UF_PATH):
  */
-        __pyx_t_3 = __Pyx_PyInt_From_uint16_t(__pyx_v_parsed->port); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 809, __pyx_L5_error)
+        __pyx_t_3 = __Pyx_PyInt_From_uint16_t(__pyx_v_parsed->port); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 813, __pyx_L5_error)
         __Pyx_GOTREF(__pyx_t_3);
         __Pyx_DECREF_SET(__pyx_v_port, __pyx_t_3);
         __pyx_t_3 = 0;
 
-        /* "aiohttp/_http_parser.pyx":808
+        /* "aiohttp/_http_parser.pyx":812
  *                 host = ''
  * 
  *             if parsed.field_set & (1 << cparser.UF_PORT):             # <<<<<<<<<<<<<<
  *                 port = parsed.port
  * 
  */
       }
 
-      /* "aiohttp/_http_parser.pyx":811
+      /* "aiohttp/_http_parser.pyx":815
  *                 port = parsed.port
  * 
  *             if parsed.field_set & (1 << cparser.UF_PATH):             # <<<<<<<<<<<<<<
  *                 off = parsed.field_data[<int>cparser.UF_PATH].off
  *                 ln = parsed.field_data[<int>cparser.UF_PATH].len
  */
       __pyx_t_1 = ((__pyx_v_parsed->field_set & (1 << UF_PATH)) != 0);
       if (__pyx_t_1) {
 
-        /* "aiohttp/_http_parser.pyx":812
+        /* "aiohttp/_http_parser.pyx":816
  * 
  *             if parsed.field_set & (1 << cparser.UF_PATH):
  *                 off = parsed.field_data[<int>cparser.UF_PATH].off             # <<<<<<<<<<<<<<
  *                 ln = parsed.field_data[<int>cparser.UF_PATH].len
  *                 path = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')
  */
         __pyx_t_2 = (__pyx_v_parsed->field_data[((int)UF_PATH)]).off;
         __pyx_v_off = __pyx_t_2;
 
-        /* "aiohttp/_http_parser.pyx":813
+        /* "aiohttp/_http_parser.pyx":817
  *             if parsed.field_set & (1 << cparser.UF_PATH):
  *                 off = parsed.field_data[<int>cparser.UF_PATH].off
  *                 ln = parsed.field_data[<int>cparser.UF_PATH].len             # <<<<<<<<<<<<<<
  *                 path = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')
  *             else:
  */
         __pyx_t_2 = (__pyx_v_parsed->field_data[((int)UF_PATH)]).len;
         __pyx_v_ln = __pyx_t_2;
 
-        /* "aiohttp/_http_parser.pyx":814
+        /* "aiohttp/_http_parser.pyx":818
  *                 off = parsed.field_data[<int>cparser.UF_PATH].off
  *                 ln = parsed.field_data[<int>cparser.UF_PATH].len
  *                 path = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')             # <<<<<<<<<<<<<<
  *             else:
  *                 path = ''
  */
-        __pyx_t_3 = __Pyx_decode_c_string(__pyx_v_buf_data, __pyx_v_off, (__pyx_v_off + __pyx_v_ln), NULL, ((char const *)"surrogateescape"), PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 814, __pyx_L5_error)
+        __pyx_t_3 = __Pyx_decode_c_string(__pyx_v_buf_data, __pyx_v_off, (__pyx_v_off + __pyx_v_ln), NULL, ((char const *)"surrogateescape"), PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 818, __pyx_L5_error)
         __Pyx_GOTREF(__pyx_t_3);
         __Pyx_DECREF_SET(__pyx_v_path, ((PyObject*)__pyx_t_3));
         __pyx_t_3 = 0;
 
-        /* "aiohttp/_http_parser.pyx":811
+        /* "aiohttp/_http_parser.pyx":815
  *                 port = parsed.port
  * 
  *             if parsed.field_set & (1 << cparser.UF_PATH):             # <<<<<<<<<<<<<<
  *                 off = parsed.field_data[<int>cparser.UF_PATH].off
  *                 ln = parsed.field_data[<int>cparser.UF_PATH].len
  */
         goto __pyx_L11;
       }
 
-      /* "aiohttp/_http_parser.pyx":816
+      /* "aiohttp/_http_parser.pyx":820
  *                 path = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')
  *             else:
  *                 path = ''             # <<<<<<<<<<<<<<
  * 
  *             if parsed.field_set & (1 << cparser.UF_QUERY):
  */
       /*else*/ {
         __Pyx_INCREF(__pyx_kp_u__4);
         __Pyx_DECREF_SET(__pyx_v_path, __pyx_kp_u__4);
       }
       __pyx_L11:;
 
-      /* "aiohttp/_http_parser.pyx":818
+      /* "aiohttp/_http_parser.pyx":822
  *                 path = ''
  * 
  *             if parsed.field_set & (1 << cparser.UF_QUERY):             # <<<<<<<<<<<<<<
  *                 off = parsed.field_data[<int>cparser.UF_QUERY].off
  *                 ln = parsed.field_data[<int>cparser.UF_QUERY].len
  */
       __pyx_t_1 = ((__pyx_v_parsed->field_set & (1 << UF_QUERY)) != 0);
       if (__pyx_t_1) {
 
-        /* "aiohttp/_http_parser.pyx":819
+        /* "aiohttp/_http_parser.pyx":823
  * 
  *             if parsed.field_set & (1 << cparser.UF_QUERY):
  *                 off = parsed.field_data[<int>cparser.UF_QUERY].off             # <<<<<<<<<<<<<<
  *                 ln = parsed.field_data[<int>cparser.UF_QUERY].len
  *                 query = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')
  */
         __pyx_t_2 = (__pyx_v_parsed->field_data[((int)UF_QUERY)]).off;
         __pyx_v_off = __pyx_t_2;
 
-        /* "aiohttp/_http_parser.pyx":820
+        /* "aiohttp/_http_parser.pyx":824
  *             if parsed.field_set & (1 << cparser.UF_QUERY):
  *                 off = parsed.field_data[<int>cparser.UF_QUERY].off
  *                 ln = parsed.field_data[<int>cparser.UF_QUERY].len             # <<<<<<<<<<<<<<
  *                 query = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')
  *             else:
  */
         __pyx_t_2 = (__pyx_v_parsed->field_data[((int)UF_QUERY)]).len;
         __pyx_v_ln = __pyx_t_2;
 
-        /* "aiohttp/_http_parser.pyx":821
+        /* "aiohttp/_http_parser.pyx":825
  *                 off = parsed.field_data[<int>cparser.UF_QUERY].off
  *                 ln = parsed.field_data[<int>cparser.UF_QUERY].len
  *                 query = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')             # <<<<<<<<<<<<<<
  *             else:
  *                 query = ''
  */
-        __pyx_t_3 = __Pyx_decode_c_string(__pyx_v_buf_data, __pyx_v_off, (__pyx_v_off + __pyx_v_ln), NULL, ((char const *)"surrogateescape"), PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 821, __pyx_L5_error)
+        __pyx_t_3 = __Pyx_decode_c_string(__pyx_v_buf_data, __pyx_v_off, (__pyx_v_off + __pyx_v_ln), NULL, ((char const *)"surrogateescape"), PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 825, __pyx_L5_error)
         __Pyx_GOTREF(__pyx_t_3);
         __Pyx_DECREF_SET(__pyx_v_query, ((PyObject*)__pyx_t_3));
         __pyx_t_3 = 0;
 
-        /* "aiohttp/_http_parser.pyx":818
+        /* "aiohttp/_http_parser.pyx":822
  *                 path = ''
  * 
  *             if parsed.field_set & (1 << cparser.UF_QUERY):             # <<<<<<<<<<<<<<
  *                 off = parsed.field_data[<int>cparser.UF_QUERY].off
  *                 ln = parsed.field_data[<int>cparser.UF_QUERY].len
  */
         goto __pyx_L12;
       }
 
-      /* "aiohttp/_http_parser.pyx":823
+      /* "aiohttp/_http_parser.pyx":827
  *                 query = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')
  *             else:
  *                 query = ''             # <<<<<<<<<<<<<<
  * 
  *             if parsed.field_set & (1 << cparser.UF_FRAGMENT):
  */
       /*else*/ {
         __Pyx_INCREF(__pyx_kp_u__4);
         __Pyx_DECREF_SET(__pyx_v_query, __pyx_kp_u__4);
       }
       __pyx_L12:;
 
-      /* "aiohttp/_http_parser.pyx":825
+      /* "aiohttp/_http_parser.pyx":829
  *                 query = ''
  * 
  *             if parsed.field_set & (1 << cparser.UF_FRAGMENT):             # <<<<<<<<<<<<<<
  *                 off = parsed.field_data[<int>cparser.UF_FRAGMENT].off
  *                 ln = parsed.field_data[<int>cparser.UF_FRAGMENT].len
  */
       __pyx_t_1 = ((__pyx_v_parsed->field_set & (1 << UF_FRAGMENT)) != 0);
       if (__pyx_t_1) {
 
-        /* "aiohttp/_http_parser.pyx":826
+        /* "aiohttp/_http_parser.pyx":830
  * 
  *             if parsed.field_set & (1 << cparser.UF_FRAGMENT):
  *                 off = parsed.field_data[<int>cparser.UF_FRAGMENT].off             # <<<<<<<<<<<<<<
  *                 ln = parsed.field_data[<int>cparser.UF_FRAGMENT].len
  *                 fragment = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')
  */
         __pyx_t_2 = (__pyx_v_parsed->field_data[((int)UF_FRAGMENT)]).off;
         __pyx_v_off = __pyx_t_2;
 
-        /* "aiohttp/_http_parser.pyx":827
+        /* "aiohttp/_http_parser.pyx":831
  *             if parsed.field_set & (1 << cparser.UF_FRAGMENT):
  *                 off = parsed.field_data[<int>cparser.UF_FRAGMENT].off
  *                 ln = parsed.field_data[<int>cparser.UF_FRAGMENT].len             # <<<<<<<<<<<<<<
  *                 fragment = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')
  *             else:
  */
         __pyx_t_2 = (__pyx_v_parsed->field_data[((int)UF_FRAGMENT)]).len;
         __pyx_v_ln = __pyx_t_2;
 
-        /* "aiohttp/_http_parser.pyx":828
+        /* "aiohttp/_http_parser.pyx":832
  *                 off = parsed.field_data[<int>cparser.UF_FRAGMENT].off
  *                 ln = parsed.field_data[<int>cparser.UF_FRAGMENT].len
  *                 fragment = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')             # <<<<<<<<<<<<<<
  *             else:
  *                 fragment = ''
  */
-        __pyx_t_3 = __Pyx_decode_c_string(__pyx_v_buf_data, __pyx_v_off, (__pyx_v_off + __pyx_v_ln), NULL, ((char const *)"surrogateescape"), PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 828, __pyx_L5_error)
+        __pyx_t_3 = __Pyx_decode_c_string(__pyx_v_buf_data, __pyx_v_off, (__pyx_v_off + __pyx_v_ln), NULL, ((char const *)"surrogateescape"), PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 832, __pyx_L5_error)
         __Pyx_GOTREF(__pyx_t_3);
         __Pyx_DECREF_SET(__pyx_v_fragment, ((PyObject*)__pyx_t_3));
         __pyx_t_3 = 0;
 
-        /* "aiohttp/_http_parser.pyx":825
+        /* "aiohttp/_http_parser.pyx":829
  *                 query = ''
  * 
  *             if parsed.field_set & (1 << cparser.UF_FRAGMENT):             # <<<<<<<<<<<<<<
  *                 off = parsed.field_data[<int>cparser.UF_FRAGMENT].off
  *                 ln = parsed.field_data[<int>cparser.UF_FRAGMENT].len
  */
         goto __pyx_L13;
       }
 
-      /* "aiohttp/_http_parser.pyx":830
+      /* "aiohttp/_http_parser.pyx":834
  *                 fragment = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')
  *             else:
  *                 fragment = ''             # <<<<<<<<<<<<<<
  * 
  *             if parsed.field_set & (1 << cparser.UF_USERINFO):
  */
       /*else*/ {
         __Pyx_INCREF(__pyx_kp_u__4);
         __Pyx_DECREF_SET(__pyx_v_fragment, __pyx_kp_u__4);
       }
       __pyx_L13:;
 
-      /* "aiohttp/_http_parser.pyx":832
+      /* "aiohttp/_http_parser.pyx":836
  *                 fragment = ''
  * 
  *             if parsed.field_set & (1 << cparser.UF_USERINFO):             # <<<<<<<<<<<<<<
  *                 off = parsed.field_data[<int>cparser.UF_USERINFO].off
  *                 ln = parsed.field_data[<int>cparser.UF_USERINFO].len
  */
       __pyx_t_1 = ((__pyx_v_parsed->field_set & (1 << UF_USERINFO)) != 0);
       if (__pyx_t_1) {
 
-        /* "aiohttp/_http_parser.pyx":833
+        /* "aiohttp/_http_parser.pyx":837
  * 
  *             if parsed.field_set & (1 << cparser.UF_USERINFO):
  *                 off = parsed.field_data[<int>cparser.UF_USERINFO].off             # <<<<<<<<<<<<<<
  *                 ln = parsed.field_data[<int>cparser.UF_USERINFO].len
  *                 userinfo = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')
  */
         __pyx_t_2 = (__pyx_v_parsed->field_data[((int)UF_USERINFO)]).off;
         __pyx_v_off = __pyx_t_2;
 
-        /* "aiohttp/_http_parser.pyx":834
+        /* "aiohttp/_http_parser.pyx":838
  *             if parsed.field_set & (1 << cparser.UF_USERINFO):
  *                 off = parsed.field_data[<int>cparser.UF_USERINFO].off
  *                 ln = parsed.field_data[<int>cparser.UF_USERINFO].len             # <<<<<<<<<<<<<<
  *                 userinfo = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')
  * 
  */
         __pyx_t_2 = (__pyx_v_parsed->field_data[((int)UF_USERINFO)]).len;
         __pyx_v_ln = __pyx_t_2;
 
-        /* "aiohttp/_http_parser.pyx":835
+        /* "aiohttp/_http_parser.pyx":839
  *                 off = parsed.field_data[<int>cparser.UF_USERINFO].off
  *                 ln = parsed.field_data[<int>cparser.UF_USERINFO].len
  *                 userinfo = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')             # <<<<<<<<<<<<<<
  * 
  *                 user, sep, password = userinfo.partition(':')
  */
-        __pyx_t_3 = __Pyx_decode_c_string(__pyx_v_buf_data, __pyx_v_off, (__pyx_v_off + __pyx_v_ln), NULL, ((char const *)"surrogateescape"), PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 835, __pyx_L5_error)
+        __pyx_t_3 = __Pyx_decode_c_string(__pyx_v_buf_data, __pyx_v_off, (__pyx_v_off + __pyx_v_ln), NULL, ((char const *)"surrogateescape"), PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 839, __pyx_L5_error)
         __Pyx_GOTREF(__pyx_t_3);
         __Pyx_DECREF_SET(__pyx_v_userinfo, ((PyObject*)__pyx_t_3));
         __pyx_t_3 = 0;
 
-        /* "aiohttp/_http_parser.pyx":837
+        /* "aiohttp/_http_parser.pyx":841
  *                 userinfo = buf_data[off:off+ln].decode('utf-8', 'surrogateescape')
  * 
  *                 user, sep, password = userinfo.partition(':')             # <<<<<<<<<<<<<<
  * 
  *             return URL_build(scheme=schema,
  */
-        __pyx_t_3 = __Pyx_CallUnboundCMethod1(&__pyx_umethod_PyUnicode_Type_partition, __pyx_v_userinfo, __pyx_kp_u__11); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 837, __pyx_L5_error)
+        __pyx_t_3 = __Pyx_CallUnboundCMethod1(&__pyx_umethod_PyUnicode_Type_partition, __pyx_v_userinfo, __pyx_kp_u__11); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 841, __pyx_L5_error)
         __Pyx_GOTREF(__pyx_t_3);
         if ((likely(PyTuple_CheckExact(__pyx_t_3))) || (PyList_CheckExact(__pyx_t_3))) {
           PyObject* sequence = __pyx_t_3;
           Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
           if (unlikely(size != 3)) {
             if (size > 3) __Pyx_RaiseTooManyValuesError(3);
             else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
-            __PYX_ERR(0, 837, __pyx_L5_error)
+            __PYX_ERR(0, 841, __pyx_L5_error)
           }
           #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
           if (likely(PyTuple_CheckExact(sequence))) {
             __pyx_t_4 = PyTuple_GET_ITEM(sequence, 0); 
             __pyx_t_5 = PyTuple_GET_ITEM(sequence, 1); 
             __pyx_t_6 = PyTuple_GET_ITEM(sequence, 2); 
           } else {
@@ -14421,149 +14497,149 @@
             __pyx_t_5 = PyList_GET_ITEM(sequence, 1); 
             __pyx_t_6 = PyList_GET_ITEM(sequence, 2); 
           }
           __Pyx_INCREF(__pyx_t_4);
           __Pyx_INCREF(__pyx_t_5);
           __Pyx_INCREF(__pyx_t_6);
           #else
-          __pyx_t_4 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 837, __pyx_L5_error)
+          __pyx_t_4 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 841, __pyx_L5_error)
           __Pyx_GOTREF(__pyx_t_4);
-          __pyx_t_5 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 837, __pyx_L5_error)
+          __pyx_t_5 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 841, __pyx_L5_error)
           __Pyx_GOTREF(__pyx_t_5);
-          __pyx_t_6 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 837, __pyx_L5_error)
+          __pyx_t_6 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 841, __pyx_L5_error)
           __Pyx_GOTREF(__pyx_t_6);
           #endif
           __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
         } else {
           Py_ssize_t index = -1;
-          __pyx_t_7 = PyObject_GetIter(__pyx_t_3); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 837, __pyx_L5_error)
+          __pyx_t_7 = PyObject_GetIter(__pyx_t_3); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 841, __pyx_L5_error)
           __Pyx_GOTREF(__pyx_t_7);
           __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
           __pyx_t_8 = Py_TYPE(__pyx_t_7)->tp_iternext;
           index = 0; __pyx_t_4 = __pyx_t_8(__pyx_t_7); if (unlikely(!__pyx_t_4)) goto __pyx_L15_unpacking_failed;
           __Pyx_GOTREF(__pyx_t_4);
           index = 1; __pyx_t_5 = __pyx_t_8(__pyx_t_7); if (unlikely(!__pyx_t_5)) goto __pyx_L15_unpacking_failed;
           __Pyx_GOTREF(__pyx_t_5);
           index = 2; __pyx_t_6 = __pyx_t_8(__pyx_t_7); if (unlikely(!__pyx_t_6)) goto __pyx_L15_unpacking_failed;
           __Pyx_GOTREF(__pyx_t_6);
-          if (__Pyx_IternextUnpackEndCheck(__pyx_t_8(__pyx_t_7), 3) < 0) __PYX_ERR(0, 837, __pyx_L5_error)
+          if (__Pyx_IternextUnpackEndCheck(__pyx_t_8(__pyx_t_7), 3) < 0) __PYX_ERR(0, 841, __pyx_L5_error)
           __pyx_t_8 = NULL;
           __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
           goto __pyx_L16_unpacking_done;
           __pyx_L15_unpacking_failed:;
           __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
           __pyx_t_8 = NULL;
           if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
-          __PYX_ERR(0, 837, __pyx_L5_error)
+          __PYX_ERR(0, 841, __pyx_L5_error)
           __pyx_L16_unpacking_done:;
         }
-        if (!(likely(PyUnicode_CheckExact(__pyx_t_4))||((__pyx_t_4) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "unicode", Py_TYPE(__pyx_t_4)->tp_name), 0))) __PYX_ERR(0, 837, __pyx_L5_error)
-        if (!(likely(PyUnicode_CheckExact(__pyx_t_6))||((__pyx_t_6) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "unicode", Py_TYPE(__pyx_t_6)->tp_name), 0))) __PYX_ERR(0, 837, __pyx_L5_error)
+        if (!(likely(PyUnicode_CheckExact(__pyx_t_4))||((__pyx_t_4) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "unicode", Py_TYPE(__pyx_t_4)->tp_name), 0))) __PYX_ERR(0, 841, __pyx_L5_error)
+        if (!(likely(PyUnicode_CheckExact(__pyx_t_6))||((__pyx_t_6) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "unicode", Py_TYPE(__pyx_t_6)->tp_name), 0))) __PYX_ERR(0, 841, __pyx_L5_error)
         __Pyx_DECREF_SET(__pyx_v_user, ((PyObject*)__pyx_t_4));
         __pyx_t_4 = 0;
         __pyx_v_sep = __pyx_t_5;
         __pyx_t_5 = 0;
         __Pyx_DECREF_SET(__pyx_v_password, ((PyObject*)__pyx_t_6));
         __pyx_t_6 = 0;
 
-        /* "aiohttp/_http_parser.pyx":832
+        /* "aiohttp/_http_parser.pyx":836
  *                 fragment = ''
  * 
  *             if parsed.field_set & (1 << cparser.UF_USERINFO):             # <<<<<<<<<<<<<<
  *                 off = parsed.field_data[<int>cparser.UF_USERINFO].off
  *                 ln = parsed.field_data[<int>cparser.UF_USERINFO].len
  */
       }
 
-      /* "aiohttp/_http_parser.pyx":839
+      /* "aiohttp/_http_parser.pyx":843
  *                 user, sep, password = userinfo.partition(':')
  * 
  *             return URL_build(scheme=schema,             # <<<<<<<<<<<<<<
  *                              user=user, password=password, host=host, port=port,
  *                              path=path, query=query, fragment=fragment)
  */
       __Pyx_XDECREF(__pyx_r);
-      __pyx_t_3 = __Pyx_PyDict_NewPresized(8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 839, __pyx_L5_error)
+      __pyx_t_3 = __Pyx_PyDict_NewPresized(8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 843, __pyx_L5_error)
       __Pyx_GOTREF(__pyx_t_3);
-      if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_scheme, __pyx_v_schema) < 0) __PYX_ERR(0, 839, __pyx_L5_error)
+      if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_scheme, __pyx_v_schema) < 0) __PYX_ERR(0, 843, __pyx_L5_error)
 
-      /* "aiohttp/_http_parser.pyx":840
+      /* "aiohttp/_http_parser.pyx":844
  * 
  *             return URL_build(scheme=schema,
  *                              user=user, password=password, host=host, port=port,             # <<<<<<<<<<<<<<
  *                              path=path, query=query, fragment=fragment)
  *         else:
  */
-      if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_user, __pyx_v_user) < 0) __PYX_ERR(0, 839, __pyx_L5_error)
-      if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_password, __pyx_v_password) < 0) __PYX_ERR(0, 839, __pyx_L5_error)
-      if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_host, __pyx_v_host) < 0) __PYX_ERR(0, 839, __pyx_L5_error)
-      if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_port, __pyx_v_port) < 0) __PYX_ERR(0, 839, __pyx_L5_error)
+      if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_user, __pyx_v_user) < 0) __PYX_ERR(0, 843, __pyx_L5_error)
+      if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_password, __pyx_v_password) < 0) __PYX_ERR(0, 843, __pyx_L5_error)
+      if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_host, __pyx_v_host) < 0) __PYX_ERR(0, 843, __pyx_L5_error)
+      if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_port, __pyx_v_port) < 0) __PYX_ERR(0, 843, __pyx_L5_error)
 
-      /* "aiohttp/_http_parser.pyx":841
+      /* "aiohttp/_http_parser.pyx":845
  *             return URL_build(scheme=schema,
  *                              user=user, password=password, host=host, port=port,
  *                              path=path, query=query, fragment=fragment)             # <<<<<<<<<<<<<<
  *         else:
  *             raise InvalidURLError("invalid url {!r}".format(buf_data))
  */
-      if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_path, __pyx_v_path) < 0) __PYX_ERR(0, 839, __pyx_L5_error)
-      if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_query, __pyx_v_query) < 0) __PYX_ERR(0, 839, __pyx_L5_error)
-      if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_fragment, __pyx_v_fragment) < 0) __PYX_ERR(0, 839, __pyx_L5_error)
+      if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_path, __pyx_v_path) < 0) __PYX_ERR(0, 843, __pyx_L5_error)
+      if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_query, __pyx_v_query) < 0) __PYX_ERR(0, 843, __pyx_L5_error)
+      if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_fragment, __pyx_v_fragment) < 0) __PYX_ERR(0, 843, __pyx_L5_error)
 
-      /* "aiohttp/_http_parser.pyx":839
+      /* "aiohttp/_http_parser.pyx":843
  *                 user, sep, password = userinfo.partition(':')
  * 
  *             return URL_build(scheme=schema,             # <<<<<<<<<<<<<<
  *                              user=user, password=password, host=host, port=port,
  *                              path=path, query=query, fragment=fragment)
  */
-      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_v_7aiohttp_12_http_parser_URL_build, __pyx_empty_tuple, __pyx_t_3); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 839, __pyx_L5_error)
+      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_v_7aiohttp_12_http_parser_URL_build, __pyx_empty_tuple, __pyx_t_3); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 843, __pyx_L5_error)
       __Pyx_GOTREF(__pyx_t_6);
       __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
       __pyx_r = __pyx_t_6;
       __pyx_t_6 = 0;
       goto __pyx_L4_return;
 
-      /* "aiohttp/_http_parser.pyx":793
+      /* "aiohttp/_http_parser.pyx":797
  *         res = cparser.http_parser_parse_url(buf_data, length, 0, parsed)
  * 
  *         if res == 0:             # <<<<<<<<<<<<<<
  *             if parsed.field_set & (1 << cparser.UF_SCHEMA):
  *                 off = parsed.field_data[<int>cparser.UF_SCHEMA].off
  */
     }
 
-    /* "aiohttp/_http_parser.pyx":843
+    /* "aiohttp/_http_parser.pyx":847
  *                              path=path, query=query, fragment=fragment)
  *         else:
  *             raise InvalidURLError("invalid url {!r}".format(buf_data))             # <<<<<<<<<<<<<<
  *     finally:
  *         PyMem_Free(parsed)
  */
     /*else*/ {
-      __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_InvalidURLError); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 843, __pyx_L5_error)
+      __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_InvalidURLError); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 847, __pyx_L5_error)
       __Pyx_GOTREF(__pyx_t_3);
-      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_kp_u_invalid_url_r, __pyx_n_s_format); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 843, __pyx_L5_error)
+      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_kp_u_invalid_url_r, __pyx_n_s_format); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 847, __pyx_L5_error)
       __Pyx_GOTREF(__pyx_t_4);
-      __pyx_t_7 = __Pyx_PyBytes_FromString(__pyx_v_buf_data); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 843, __pyx_L5_error)
+      __pyx_t_7 = __Pyx_PyBytes_FromString(__pyx_v_buf_data); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 847, __pyx_L5_error)
       __Pyx_GOTREF(__pyx_t_7);
       __pyx_t_9 = NULL;
       if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
         __pyx_t_9 = PyMethod_GET_SELF(__pyx_t_4);
         if (likely(__pyx_t_9)) {
           PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
           __Pyx_INCREF(__pyx_t_9);
           __Pyx_INCREF(function);
           __Pyx_DECREF_SET(__pyx_t_4, function);
         }
       }
       __pyx_t_5 = (__pyx_t_9) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_9, __pyx_t_7) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_7);
       __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
       __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
-      if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 843, __pyx_L5_error)
+      if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 847, __pyx_L5_error)
       __Pyx_GOTREF(__pyx_t_5);
       __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
       __pyx_t_4 = NULL;
       if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
         __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
         if (likely(__pyx_t_4)) {
           PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
@@ -14571,40 +14647,40 @@
           __Pyx_INCREF(function);
           __Pyx_DECREF_SET(__pyx_t_3, function);
         }
       }
       __pyx_t_6 = (__pyx_t_4) ? __Pyx_PyObject_Call2Args(__pyx_t_3, __pyx_t_4, __pyx_t_5) : __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_5);
       __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
       __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
-      if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 843, __pyx_L5_error)
+      if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 847, __pyx_L5_error)
       __Pyx_GOTREF(__pyx_t_6);
       __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
       __Pyx_Raise(__pyx_t_6, 0, 0, 0);
       __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
-      __PYX_ERR(0, 843, __pyx_L5_error)
+      __PYX_ERR(0, 847, __pyx_L5_error)
     }
   }
 
-  /* "aiohttp/_http_parser.pyx":845
+  /* "aiohttp/_http_parser.pyx":849
  *             raise InvalidURLError("invalid url {!r}".format(buf_data))
  *     finally:
  *         PyMem_Free(parsed)             # <<<<<<<<<<<<<<
  */
   /*finally:*/ {
     __pyx_L5_error:;
     /*exception exit:*/{
       __Pyx_PyThreadState_declare
       __Pyx_PyThreadState_assign
       __pyx_t_13 = 0; __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0;
-      __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
-      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
+      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
       __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
       __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
-      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
       __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
+      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
+      __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
       if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_16, &__pyx_t_17, &__pyx_t_18);
       if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_13, &__pyx_t_14, &__pyx_t_15) < 0)) __Pyx_ErrFetch(&__pyx_t_13, &__pyx_t_14, &__pyx_t_15);
       __Pyx_XGOTREF(__pyx_t_13);
       __Pyx_XGOTREF(__pyx_t_14);
       __Pyx_XGOTREF(__pyx_t_15);
       __Pyx_XGOTREF(__pyx_t_16);
       __Pyx_XGOTREF(__pyx_t_17);
@@ -14633,15 +14709,15 @@
       PyMem_Free(__pyx_v_parsed);
       __pyx_r = __pyx_t_18;
       __pyx_t_18 = 0;
       goto __pyx_L0;
     }
   }
 
-  /* "aiohttp/_http_parser.pyx":768
+  /* "aiohttp/_http_parser.pyx":772
  * 
  * 
  * cdef _parse_url(char* buf_data, size_t length):             # <<<<<<<<<<<<<<
  *     cdef:
  *         cparser.http_parser_url* parsed
  */
 
@@ -15868,14 +15944,17 @@
   0, /*tp_subclasses*/
   0, /*tp_weaklist*/
   0, /*tp_del*/
   0, /*tp_version_tag*/
   #if PY_VERSION_HEX >= 0x030400a1
   0, /*tp_finalize*/
   #endif
+  #if PY_VERSION_HEX >= 0x030800b1
+  0, /*tp_vectorcall*/
+  #endif
 };
 
 static struct __pyx_obj_7aiohttp_12_http_parser_RawResponseMessage *__pyx_freelist_7aiohttp_12_http_parser_RawResponseMessage[250];
 static int __pyx_freecount_7aiohttp_12_http_parser_RawResponseMessage = 0;
 
 static PyObject *__pyx_tp_new_7aiohttp_12_http_parser_RawResponseMessage(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
   struct __pyx_obj_7aiohttp_12_http_parser_RawResponseMessage *p;
@@ -16089,14 +16168,17 @@
   0, /*tp_subclasses*/
   0, /*tp_weaklist*/
   0, /*tp_del*/
   0, /*tp_version_tag*/
   #if PY_VERSION_HEX >= 0x030400a1
   0, /*tp_finalize*/
   #endif
+  #if PY_VERSION_HEX >= 0x030800b1
+  0, /*tp_vectorcall*/
+  #endif
 };
 static struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpParser __pyx_vtable_7aiohttp_12_http_parser_HttpParser;
 
 static PyObject *__pyx_tp_new_7aiohttp_12_http_parser_HttpParser(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
   struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *p;
   PyObject *o;
   if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
@@ -16241,16 +16323,17 @@
   Py_CLEAR(p->py_buf.obj);
   return 0;
 }
 
 static PyMethodDef __pyx_methods_7aiohttp_12_http_parser_HttpParser[] = {
   {"feed_eof", (PyCFunction)__pyx_pw_7aiohttp_12_http_parser_10HttpParser_5feed_eof, METH_NOARGS, 0},
   {"feed_data", (PyCFunction)__pyx_pw_7aiohttp_12_http_parser_10HttpParser_7feed_data, METH_O, 0},
-  {"__reduce_cython__", (PyCFunction)__pyx_pw_7aiohttp_12_http_parser_10HttpParser_9__reduce_cython__, METH_NOARGS, 0},
-  {"__setstate_cython__", (PyCFunction)__pyx_pw_7aiohttp_12_http_parser_10HttpParser_11__setstate_cython__, METH_O, 0},
+  {"set_upgraded", (PyCFunction)__pyx_pw_7aiohttp_12_http_parser_10HttpParser_9set_upgraded, METH_O, 0},
+  {"__reduce_cython__", (PyCFunction)__pyx_pw_7aiohttp_12_http_parser_10HttpParser_11__reduce_cython__, METH_NOARGS, 0},
+  {"__setstate_cython__", (PyCFunction)__pyx_pw_7aiohttp_12_http_parser_10HttpParser_13__setstate_cython__, METH_O, 0},
   {0, 0, 0, 0}
 };
 
 static PyTypeObject __pyx_type_7aiohttp_12_http_parser_HttpParser = {
   PyVarObject_HEAD_INIT(0, 0)
   "aiohttp._http_parser.HttpParser", /*tp_name*/
   sizeof(struct __pyx_obj_7aiohttp_12_http_parser_HttpParser), /*tp_basicsize*/
@@ -16302,14 +16385,17 @@
   0, /*tp_subclasses*/
   0, /*tp_weaklist*/
   0, /*tp_del*/
   0, /*tp_version_tag*/
   #if PY_VERSION_HEX >= 0x030400a1
   0, /*tp_finalize*/
   #endif
+  #if PY_VERSION_HEX >= 0x030800b1
+  0, /*tp_vectorcall*/
+  #endif
 };
 static struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpRequestParser __pyx_vtable_7aiohttp_12_http_parser_HttpRequestParser;
 
 static PyObject *__pyx_tp_new_7aiohttp_12_http_parser_HttpRequestParser(PyTypeObject *t, PyObject *a, PyObject *k) {
   struct __pyx_obj_7aiohttp_12_http_parser_HttpRequestParser *p;
   PyObject *o = __pyx_tp_new_7aiohttp_12_http_parser_HttpParser(t, a, k);
   if (unlikely(!o)) return 0;
@@ -16376,14 +16462,17 @@
   0, /*tp_subclasses*/
   0, /*tp_weaklist*/
   0, /*tp_del*/
   0, /*tp_version_tag*/
   #if PY_VERSION_HEX >= 0x030400a1
   0, /*tp_finalize*/
   #endif
+  #if PY_VERSION_HEX >= 0x030800b1
+  0, /*tp_vectorcall*/
+  #endif
 };
 static struct __pyx_vtabstruct_7aiohttp_12_http_parser_HttpResponseParser __pyx_vtable_7aiohttp_12_http_parser_HttpResponseParser;
 
 static PyObject *__pyx_tp_new_7aiohttp_12_http_parser_HttpResponseParser(PyTypeObject *t, PyObject *a, PyObject *k) {
   struct __pyx_obj_7aiohttp_12_http_parser_HttpResponseParser *p;
   PyObject *o = __pyx_tp_new_7aiohttp_12_http_parser_HttpParser(t, a, k);
   if (unlikely(!o)) return 0;
@@ -16450,14 +16539,17 @@
   0, /*tp_subclasses*/
   0, /*tp_weaklist*/
   0, /*tp_del*/
   0, /*tp_version_tag*/
   #if PY_VERSION_HEX >= 0x030400a1
   0, /*tp_finalize*/
   #endif
+  #if PY_VERSION_HEX >= 0x030800b1
+  0, /*tp_vectorcall*/
+  #endif
 };
 
 static struct __pyx_obj_7aiohttp_12_http_parser___pyx_scope_struct____repr__ *__pyx_freelist_7aiohttp_12_http_parser___pyx_scope_struct____repr__[8];
 static int __pyx_freecount_7aiohttp_12_http_parser___pyx_scope_struct____repr__ = 0;
 
 static PyObject *__pyx_tp_new_7aiohttp_12_http_parser___pyx_scope_struct____repr__(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
   PyObject *o;
@@ -16554,14 +16646,17 @@
   0, /*tp_subclasses*/
   0, /*tp_weaklist*/
   0, /*tp_del*/
   0, /*tp_version_tag*/
   #if PY_VERSION_HEX >= 0x030400a1
   0, /*tp_finalize*/
   #endif
+  #if PY_VERSION_HEX >= 0x030800b1
+  0, /*tp_vectorcall*/
+  #endif
 };
 
 static struct __pyx_obj_7aiohttp_12_http_parser___pyx_scope_struct_1_genexpr *__pyx_freelist_7aiohttp_12_http_parser___pyx_scope_struct_1_genexpr[8];
 static int __pyx_freecount_7aiohttp_12_http_parser___pyx_scope_struct_1_genexpr = 0;
 
 static PyObject *__pyx_tp_new_7aiohttp_12_http_parser___pyx_scope_struct_1_genexpr(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
   PyObject *o;
@@ -16657,14 +16752,17 @@
   0, /*tp_subclasses*/
   0, /*tp_weaklist*/
   0, /*tp_del*/
   0, /*tp_version_tag*/
   #if PY_VERSION_HEX >= 0x030400a1
   0, /*tp_finalize*/
   #endif
+  #if PY_VERSION_HEX >= 0x030800b1
+  0, /*tp_vectorcall*/
+  #endif
 };
 
 static struct __pyx_obj_7aiohttp_12_http_parser___pyx_scope_struct_2___repr__ *__pyx_freelist_7aiohttp_12_http_parser___pyx_scope_struct_2___repr__[8];
 static int __pyx_freecount_7aiohttp_12_http_parser___pyx_scope_struct_2___repr__ = 0;
 
 static PyObject *__pyx_tp_new_7aiohttp_12_http_parser___pyx_scope_struct_2___repr__(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
   PyObject *o;
@@ -16761,14 +16859,17 @@
   0, /*tp_subclasses*/
   0, /*tp_weaklist*/
   0, /*tp_del*/
   0, /*tp_version_tag*/
   #if PY_VERSION_HEX >= 0x030400a1
   0, /*tp_finalize*/
   #endif
+  #if PY_VERSION_HEX >= 0x030800b1
+  0, /*tp_vectorcall*/
+  #endif
 };
 
 static struct __pyx_obj_7aiohttp_12_http_parser___pyx_scope_struct_3_genexpr *__pyx_freelist_7aiohttp_12_http_parser___pyx_scope_struct_3_genexpr[8];
 static int __pyx_freecount_7aiohttp_12_http_parser___pyx_scope_struct_3_genexpr = 0;
 
 static PyObject *__pyx_tp_new_7aiohttp_12_http_parser___pyx_scope_struct_3_genexpr(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
   PyObject *o;
@@ -16864,14 +16965,17 @@
   0, /*tp_subclasses*/
   0, /*tp_weaklist*/
   0, /*tp_del*/
   0, /*tp_version_tag*/
   #if PY_VERSION_HEX >= 0x030400a1
   0, /*tp_finalize*/
   #endif
+  #if PY_VERSION_HEX >= 0x030800b1
+  0, /*tp_vectorcall*/
+  #endif
 };
 
 static PyMethodDef __pyx_methods[] = {
   {0, 0, 0, 0}
 };
 
 #if PY_MAJOR_VERSION >= 3
@@ -17153,15 +17257,15 @@
   {&__pyx_n_s_yarl, __pyx_k_yarl, sizeof(__pyx_k_yarl), 0, 0, 1, 1},
   {0, 0, 0, 0, 0, 0, 0}
 };
 static CYTHON_SMALL_CODE int __Pyx_InitCachedBuiltins(void) {
   __pyx_builtin_range = __Pyx_GetBuiltinName(__pyx_n_s_range); if (!__pyx_builtin_range) __PYX_ERR(0, 70, __pyx_L1_error)
   __pyx_builtin_MemoryError = __Pyx_GetBuiltinName(__pyx_n_s_MemoryError); if (!__pyx_builtin_MemoryError) __PYX_ERR(0, 297, __pyx_L1_error)
   __pyx_builtin_TypeError = __Pyx_GetBuiltinName(__pyx_n_s_TypeError); if (!__pyx_builtin_TypeError) __PYX_ERR(1, 2, __pyx_L1_error)
-  __pyx_builtin_BaseException = __Pyx_GetBuiltinName(__pyx_n_s_BaseException); if (!__pyx_builtin_BaseException) __PYX_ERR(0, 601, __pyx_L1_error)
+  __pyx_builtin_BaseException = __Pyx_GetBuiltinName(__pyx_n_s_BaseException); if (!__pyx_builtin_BaseException) __PYX_ERR(0, 605, __pyx_L1_error)
   return 0;
   __pyx_L1_error:;
   return -1;
 }
 
 static CYTHON_SMALL_CODE int __Pyx_InitCachedConstants(void) {
   __Pyx_RefNannyDeclarations
@@ -17231,25 +17335,25 @@
  *            'RawRequestMessage', 'RawResponseMessage')
  * 
  */
   __pyx_tuple__12 = PyTuple_Pack(4, __pyx_n_u_HttpRequestParser, __pyx_n_u_HttpResponseParser, __pyx_n_u_RawRequestMessage_2, __pyx_n_u_RawResponseMessage_2); if (unlikely(!__pyx_tuple__12)) __PYX_ERR(0, 40, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__12);
   __Pyx_GIVEREF(__pyx_tuple__12);
 
-  /* "aiohttp/_http_parser.pyx":755
+  /* "aiohttp/_http_parser.pyx":759
  * 
  * 
  * def parse_url(url):             # <<<<<<<<<<<<<<
  *     cdef:
  *         Py_buffer py_buf
  */
-  __pyx_tuple__13 = PyTuple_Pack(3, __pyx_n_s_url, __pyx_n_s_py_buf, __pyx_n_s_buf_data); if (unlikely(!__pyx_tuple__13)) __PYX_ERR(0, 755, __pyx_L1_error)
+  __pyx_tuple__13 = PyTuple_Pack(3, __pyx_n_s_url, __pyx_n_s_py_buf, __pyx_n_s_buf_data); if (unlikely(!__pyx_tuple__13)) __PYX_ERR(0, 759, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__13);
   __Pyx_GIVEREF(__pyx_tuple__13);
-  __pyx_codeobj__14 = (PyObject*)__Pyx_PyCode_New(1, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__13, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_aiohttp__http_parser_pyx, __pyx_n_s_parse_url, 755, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__14)) __PYX_ERR(0, 755, __pyx_L1_error)
+  __pyx_codeobj__14 = (PyObject*)__Pyx_PyCode_New(1, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__13, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_aiohttp__http_parser_pyx, __pyx_n_s_parse_url, 759, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__14)) __PYX_ERR(0, 759, __pyx_L1_error)
 
   /* "(tree fragment)":1
  * def __pyx_unpickle_RawRequestMessage(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
  *     cdef object __pyx_PickleError
  *     cdef object __pyx_result
  */
   __pyx_tuple__15 = PyTuple_Pack(5, __pyx_n_s_pyx_type, __pyx_n_s_pyx_checksum, __pyx_n_s_pyx_state, __pyx_n_s_pyx_PickleError, __pyx_n_s_pyx_result); if (unlikely(!__pyx_tuple__15)) __PYX_ERR(1, 1, __pyx_L1_error)
@@ -17324,23 +17428,27 @@
 }
 
 static int __Pyx_modinit_type_init_code(void) {
   __Pyx_RefNannyDeclarations
   __Pyx_RefNannySetupContext("__Pyx_modinit_type_init_code", 0);
   /*--- Type init code ---*/
   if (PyType_Ready(&__pyx_type_7aiohttp_12_http_parser_RawRequestMessage) < 0) __PYX_ERR(0, 93, __pyx_L1_error)
+  #if PY_VERSION_HEX < 0x030800B1
   __pyx_type_7aiohttp_12_http_parser_RawRequestMessage.tp_print = 0;
+  #endif
   if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_7aiohttp_12_http_parser_RawRequestMessage.tp_dictoffset && __pyx_type_7aiohttp_12_http_parser_RawRequestMessage.tp_getattro == PyObject_GenericGetAttr)) {
     __pyx_type_7aiohttp_12_http_parser_RawRequestMessage.tp_getattro = __Pyx_PyObject_GenericGetAttr;
   }
   if (PyObject_SetAttr(__pyx_m, __pyx_n_s_RawRequestMessage_2, (PyObject *)&__pyx_type_7aiohttp_12_http_parser_RawRequestMessage) < 0) __PYX_ERR(0, 93, __pyx_L1_error)
   if (__Pyx_setup_reduce((PyObject*)&__pyx_type_7aiohttp_12_http_parser_RawRequestMessage) < 0) __PYX_ERR(0, 93, __pyx_L1_error)
   __pyx_ptype_7aiohttp_12_http_parser_RawRequestMessage = &__pyx_type_7aiohttp_12_http_parser_RawRequestMessage;
   if (PyType_Ready(&__pyx_type_7aiohttp_12_http_parser_RawResponseMessage) < 0) __PYX_ERR(0, 193, __pyx_L1_error)
+  #if PY_VERSION_HEX < 0x030800B1
   __pyx_type_7aiohttp_12_http_parser_RawResponseMessage.tp_print = 0;
+  #endif
   if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_7aiohttp_12_http_parser_RawResponseMessage.tp_dictoffset && __pyx_type_7aiohttp_12_http_parser_RawResponseMessage.tp_getattro == PyObject_GenericGetAttr)) {
     __pyx_type_7aiohttp_12_http_parser_RawResponseMessage.tp_getattro = __Pyx_PyObject_GenericGetAttr;
   }
   if (PyObject_SetAttr(__pyx_m, __pyx_n_s_RawResponseMessage_2, (PyObject *)&__pyx_type_7aiohttp_12_http_parser_RawResponseMessage) < 0) __PYX_ERR(0, 193, __pyx_L1_error)
   if (__Pyx_setup_reduce((PyObject*)&__pyx_type_7aiohttp_12_http_parser_RawResponseMessage) < 0) __PYX_ERR(0, 193, __pyx_L1_error)
   __pyx_ptype_7aiohttp_12_http_parser_RawResponseMessage = &__pyx_type_7aiohttp_12_http_parser_RawResponseMessage;
   __pyx_vtabptr_7aiohttp_12_http_parser_HttpParser = &__pyx_vtable_7aiohttp_12_http_parser_HttpParser;
@@ -17351,67 +17459,81 @@
   __pyx_vtable_7aiohttp_12_http_parser_HttpParser._on_headers_complete = (PyObject *(*)(struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *))__pyx_f_7aiohttp_12_http_parser_10HttpParser__on_headers_complete;
   __pyx_vtable_7aiohttp_12_http_parser_HttpParser._on_message_complete = (PyObject *(*)(struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *))__pyx_f_7aiohttp_12_http_parser_10HttpParser__on_message_complete;
   __pyx_vtable_7aiohttp_12_http_parser_HttpParser._on_chunk_header = (PyObject *(*)(struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *))__pyx_f_7aiohttp_12_http_parser_10HttpParser__on_chunk_header;
   __pyx_vtable_7aiohttp_12_http_parser_HttpParser._on_chunk_complete = (PyObject *(*)(struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *))__pyx_f_7aiohttp_12_http_parser_10HttpParser__on_chunk_complete;
   __pyx_vtable_7aiohttp_12_http_parser_HttpParser._on_status_complete = (PyObject *(*)(struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *))__pyx_f_7aiohttp_12_http_parser_10HttpParser__on_status_complete;
   __pyx_vtable_7aiohttp_12_http_parser_HttpParser.http_version = (PyObject *(*)(struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *))__pyx_f_7aiohttp_12_http_parser_10HttpParser_http_version;
   if (PyType_Ready(&__pyx_type_7aiohttp_12_http_parser_HttpParser) < 0) __PYX_ERR(0, 255, __pyx_L1_error)
+  #if PY_VERSION_HEX < 0x030800B1
   __pyx_type_7aiohttp_12_http_parser_HttpParser.tp_print = 0;
+  #endif
   if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_7aiohttp_12_http_parser_HttpParser.tp_dictoffset && __pyx_type_7aiohttp_12_http_parser_HttpParser.tp_getattro == PyObject_GenericGetAttr)) {
     __pyx_type_7aiohttp_12_http_parser_HttpParser.tp_getattro = __Pyx_PyObject_GenericGetAttr;
   }
   if (__Pyx_SetVtable(__pyx_type_7aiohttp_12_http_parser_HttpParser.tp_dict, __pyx_vtabptr_7aiohttp_12_http_parser_HttpParser) < 0) __PYX_ERR(0, 255, __pyx_L1_error)
   if (__Pyx_setup_reduce((PyObject*)&__pyx_type_7aiohttp_12_http_parser_HttpParser) < 0) __PYX_ERR(0, 255, __pyx_L1_error)
   __pyx_ptype_7aiohttp_12_http_parser_HttpParser = &__pyx_type_7aiohttp_12_http_parser_HttpParser;
   __pyx_vtabptr_7aiohttp_12_http_parser_HttpRequestParser = &__pyx_vtable_7aiohttp_12_http_parser_HttpRequestParser;
   __pyx_vtable_7aiohttp_12_http_parser_HttpRequestParser.__pyx_base = *__pyx_vtabptr_7aiohttp_12_http_parser_HttpParser;
   __pyx_vtable_7aiohttp_12_http_parser_HttpRequestParser.__pyx_base._on_status_complete = (PyObject *(*)(struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *))__pyx_f_7aiohttp_12_http_parser_17HttpRequestParser__on_status_complete;
   __pyx_type_7aiohttp_12_http_parser_HttpRequestParser.tp_base = __pyx_ptype_7aiohttp_12_http_parser_HttpParser;
-  if (PyType_Ready(&__pyx_type_7aiohttp_12_http_parser_HttpRequestParser) < 0) __PYX_ERR(0, 537, __pyx_L1_error)
+  if (PyType_Ready(&__pyx_type_7aiohttp_12_http_parser_HttpRequestParser) < 0) __PYX_ERR(0, 540, __pyx_L1_error)
+  #if PY_VERSION_HEX < 0x030800B1
   __pyx_type_7aiohttp_12_http_parser_HttpRequestParser.tp_print = 0;
+  #endif
   if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_7aiohttp_12_http_parser_HttpRequestParser.tp_dictoffset && __pyx_type_7aiohttp_12_http_parser_HttpRequestParser.tp_getattro == PyObject_GenericGetAttr)) {
     __pyx_type_7aiohttp_12_http_parser_HttpRequestParser.tp_getattro = __Pyx_PyObject_GenericGetAttr;
   }
-  if (__Pyx_SetVtable(__pyx_type_7aiohttp_12_http_parser_HttpRequestParser.tp_dict, __pyx_vtabptr_7aiohttp_12_http_parser_HttpRequestParser) < 0) __PYX_ERR(0, 537, __pyx_L1_error)
-  if (PyObject_SetAttr(__pyx_m, __pyx_n_s_HttpRequestParser, (PyObject *)&__pyx_type_7aiohttp_12_http_parser_HttpRequestParser) < 0) __PYX_ERR(0, 537, __pyx_L1_error)
-  if (__Pyx_setup_reduce((PyObject*)&__pyx_type_7aiohttp_12_http_parser_HttpRequestParser) < 0) __PYX_ERR(0, 537, __pyx_L1_error)
+  if (__Pyx_SetVtable(__pyx_type_7aiohttp_12_http_parser_HttpRequestParser.tp_dict, __pyx_vtabptr_7aiohttp_12_http_parser_HttpRequestParser) < 0) __PYX_ERR(0, 540, __pyx_L1_error)
+  if (PyObject_SetAttr(__pyx_m, __pyx_n_s_HttpRequestParser, (PyObject *)&__pyx_type_7aiohttp_12_http_parser_HttpRequestParser) < 0) __PYX_ERR(0, 540, __pyx_L1_error)
+  if (__Pyx_setup_reduce((PyObject*)&__pyx_type_7aiohttp_12_http_parser_HttpRequestParser) < 0) __PYX_ERR(0, 540, __pyx_L1_error)
   __pyx_ptype_7aiohttp_12_http_parser_HttpRequestParser = &__pyx_type_7aiohttp_12_http_parser_HttpRequestParser;
   __pyx_vtabptr_7aiohttp_12_http_parser_HttpResponseParser = &__pyx_vtable_7aiohttp_12_http_parser_HttpResponseParser;
   __pyx_vtable_7aiohttp_12_http_parser_HttpResponseParser.__pyx_base = *__pyx_vtabptr_7aiohttp_12_http_parser_HttpParser;
   __pyx_vtable_7aiohttp_12_http_parser_HttpResponseParser.__pyx_base._on_status_complete = (PyObject *(*)(struct __pyx_obj_7aiohttp_12_http_parser_HttpParser *))__pyx_f_7aiohttp_12_http_parser_18HttpResponseParser__on_status_complete;
   __pyx_type_7aiohttp_12_http_parser_HttpResponseParser.tp_base = __pyx_ptype_7aiohttp_12_http_parser_HttpParser;
-  if (PyType_Ready(&__pyx_type_7aiohttp_12_http_parser_HttpResponseParser) < 0) __PYX_ERR(0, 564, __pyx_L1_error)
+  if (PyType_Ready(&__pyx_type_7aiohttp_12_http_parser_HttpResponseParser) < 0) __PYX_ERR(0, 567, __pyx_L1_error)
+  #if PY_VERSION_HEX < 0x030800B1
   __pyx_type_7aiohttp_12_http_parser_HttpResponseParser.tp_print = 0;
+  #endif
   if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_7aiohttp_12_http_parser_HttpResponseParser.tp_dictoffset && __pyx_type_7aiohttp_12_http_parser_HttpResponseParser.tp_getattro == PyObject_GenericGetAttr)) {
     __pyx_type_7aiohttp_12_http_parser_HttpResponseParser.tp_getattro = __Pyx_PyObject_GenericGetAttr;
   }
-  if (__Pyx_SetVtable(__pyx_type_7aiohttp_12_http_parser_HttpResponseParser.tp_dict, __pyx_vtabptr_7aiohttp_12_http_parser_HttpResponseParser) < 0) __PYX_ERR(0, 564, __pyx_L1_error)
-  if (PyObject_SetAttr(__pyx_m, __pyx_n_s_HttpResponseParser, (PyObject *)&__pyx_type_7aiohttp_12_http_parser_HttpResponseParser) < 0) __PYX_ERR(0, 564, __pyx_L1_error)
-  if (__Pyx_setup_reduce((PyObject*)&__pyx_type_7aiohttp_12_http_parser_HttpResponseParser) < 0) __PYX_ERR(0, 564, __pyx_L1_error)
+  if (__Pyx_SetVtable(__pyx_type_7aiohttp_12_http_parser_HttpResponseParser.tp_dict, __pyx_vtabptr_7aiohttp_12_http_parser_HttpResponseParser) < 0) __PYX_ERR(0, 567, __pyx_L1_error)
+  if (PyObject_SetAttr(__pyx_m, __pyx_n_s_HttpResponseParser, (PyObject *)&__pyx_type_7aiohttp_12_http_parser_HttpResponseParser) < 0) __PYX_ERR(0, 567, __pyx_L1_error)
+  if (__Pyx_setup_reduce((PyObject*)&__pyx_type_7aiohttp_12_http_parser_HttpResponseParser) < 0) __PYX_ERR(0, 567, __pyx_L1_error)
   __pyx_ptype_7aiohttp_12_http_parser_HttpResponseParser = &__pyx_type_7aiohttp_12_http_parser_HttpResponseParser;
   if (PyType_Ready(&__pyx_type_7aiohttp_12_http_parser___pyx_scope_struct____repr__) < 0) __PYX_ERR(0, 118, __pyx_L1_error)
+  #if PY_VERSION_HEX < 0x030800B1
   __pyx_type_7aiohttp_12_http_parser___pyx_scope_struct____repr__.tp_print = 0;
+  #endif
   if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_7aiohttp_12_http_parser___pyx_scope_struct____repr__.tp_dictoffset && __pyx_type_7aiohttp_12_http_parser___pyx_scope_struct____repr__.tp_getattro == PyObject_GenericGetAttr)) {
     __pyx_type_7aiohttp_12_http_parser___pyx_scope_struct____repr__.tp_getattro = __Pyx_PyObject_GenericGetAttrNoDict;
   }
   __pyx_ptype_7aiohttp_12_http_parser___pyx_scope_struct____repr__ = &__pyx_type_7aiohttp_12_http_parser___pyx_scope_struct____repr__;
   if (PyType_Ready(&__pyx_type_7aiohttp_12_http_parser___pyx_scope_struct_1_genexpr) < 0) __PYX_ERR(0, 130, __pyx_L1_error)
+  #if PY_VERSION_HEX < 0x030800B1
   __pyx_type_7aiohttp_12_http_parser___pyx_scope_struct_1_genexpr.tp_print = 0;
+  #endif
   if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_7aiohttp_12_http_parser___pyx_scope_struct_1_genexpr.tp_dictoffset && __pyx_type_7aiohttp_12_http_parser___pyx_scope_struct_1_genexpr.tp_getattro == PyObject_GenericGetAttr)) {
     __pyx_type_7aiohttp_12_http_parser___pyx_scope_struct_1_genexpr.tp_getattro = __Pyx_PyObject_GenericGetAttrNoDict;
   }
   __pyx_ptype_7aiohttp_12_http_parser___pyx_scope_struct_1_genexpr = &__pyx_type_7aiohttp_12_http_parser___pyx_scope_struct_1_genexpr;
   if (PyType_Ready(&__pyx_type_7aiohttp_12_http_parser___pyx_scope_struct_2___repr__) < 0) __PYX_ERR(0, 216, __pyx_L1_error)
+  #if PY_VERSION_HEX < 0x030800B1
   __pyx_type_7aiohttp_12_http_parser___pyx_scope_struct_2___repr__.tp_print = 0;
+  #endif
   if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_7aiohttp_12_http_parser___pyx_scope_struct_2___repr__.tp_dictoffset && __pyx_type_7aiohttp_12_http_parser___pyx_scope_struct_2___repr__.tp_getattro == PyObject_GenericGetAttr)) {
     __pyx_type_7aiohttp_12_http_parser___pyx_scope_struct_2___repr__.tp_getattro = __Pyx_PyObject_GenericGetAttrNoDict;
   }
   __pyx_ptype_7aiohttp_12_http_parser___pyx_scope_struct_2___repr__ = &__pyx_type_7aiohttp_12_http_parser___pyx_scope_struct_2___repr__;
   if (PyType_Ready(&__pyx_type_7aiohttp_12_http_parser___pyx_scope_struct_3_genexpr) < 0) __PYX_ERR(0, 227, __pyx_L1_error)
+  #if PY_VERSION_HEX < 0x030800B1
   __pyx_type_7aiohttp_12_http_parser___pyx_scope_struct_3_genexpr.tp_print = 0;
+  #endif
   if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_7aiohttp_12_http_parser___pyx_scope_struct_3_genexpr.tp_dictoffset && __pyx_type_7aiohttp_12_http_parser___pyx_scope_struct_3_genexpr.tp_getattro == PyObject_GenericGetAttr)) {
     __pyx_type_7aiohttp_12_http_parser___pyx_scope_struct_3_genexpr.tp_getattro = __Pyx_PyObject_GenericGetAttrNoDict;
   }
   __pyx_ptype_7aiohttp_12_http_parser___pyx_scope_struct_3_genexpr = &__pyx_type_7aiohttp_12_http_parser___pyx_scope_struct_3_genexpr;
   __Pyx_RefNannyFinishContext();
   return 0;
   __pyx_L1_error:;
@@ -17707,18 +17829,17 @@
   __pyx_m = PyModule_Create(&__pyx_moduledef);
   #endif
   if (unlikely(!__pyx_m)) __PYX_ERR(0, 1, __pyx_L1_error)
   #endif
   __pyx_d = PyModule_GetDict(__pyx_m); if (unlikely(!__pyx_d)) __PYX_ERR(0, 1, __pyx_L1_error)
   Py_INCREF(__pyx_d);
   __pyx_b = PyImport_AddModule(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_b)) __PYX_ERR(0, 1, __pyx_L1_error)
-  __pyx_cython_runtime = PyImport_AddModule((char *) "cython_runtime"); if (unlikely(!__pyx_cython_runtime)) __PYX_ERR(0, 1, __pyx_L1_error)
-  #if CYTHON_COMPILING_IN_PYPY
   Py_INCREF(__pyx_b);
-  #endif
+  __pyx_cython_runtime = PyImport_AddModule((char *) "cython_runtime"); if (unlikely(!__pyx_cython_runtime)) __PYX_ERR(0, 1, __pyx_L1_error)
+  Py_INCREF(__pyx_cython_runtime);
   if (PyObject_SetAttrString(__pyx_m, "__builtins__", __pyx_b) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
   /*--- Initialize various global constants etc. ---*/
   if (__Pyx_InitGlobals() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
   #if PY_MAJOR_VERSION < 3 && (__PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT)
   if (__Pyx_init_sys_getdefaultencoding_params() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
   #endif
   if (__pyx_module_is_main_aiohttp___http_parser) {
@@ -17729,17 +17850,17 @@
     PyObject *modules = PyImport_GetModuleDict(); if (unlikely(!modules)) __PYX_ERR(0, 1, __pyx_L1_error)
     if (!PyDict_GetItemString(modules, "aiohttp._http_parser")) {
       if (unlikely(PyDict_SetItemString(modules, "aiohttp._http_parser", __pyx_m) < 0)) __PYX_ERR(0, 1, __pyx_L1_error)
     }
   }
   #endif
   /*--- Builtin init code ---*/
-  if (__Pyx_InitCachedBuiltins() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
+  if (__Pyx_InitCachedBuiltins() < 0) goto __pyx_L1_error;
   /*--- Constants init code ---*/
-  if (__Pyx_InitCachedConstants() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
+  if (__Pyx_InitCachedConstants() < 0) goto __pyx_L1_error;
   /*--- Global type/function init code ---*/
   (void)__Pyx_modinit_global_init_code();
   (void)__Pyx_modinit_variable_export_code();
   (void)__Pyx_modinit_function_export_code();
   if (unlikely(__Pyx_modinit_type_init_code() != 0)) goto __pyx_L1_error;
   if (unlikely(__Pyx_modinit_type_import_code() != 0)) goto __pyx_L1_error;
   (void)__Pyx_modinit_variable_import_code();
@@ -19507,24 +19628,24 @@
  *         cparser.http_method_str(<cparser.http_method> i).decode('ascii'))
  * 
  */
     __pyx_t_83 = __Pyx_PyList_Append(__pyx_v_7aiohttp_12_http_parser__http_method, __pyx_t_1); if (unlikely(__pyx_t_83 == ((int)-1))) __PYX_ERR(0, 71, __pyx_L1_error)
     __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
   }
 
-  /* "aiohttp/_http_parser.pyx":755
+  /* "aiohttp/_http_parser.pyx":759
  * 
  * 
  * def parse_url(url):             # <<<<<<<<<<<<<<
  *     cdef:
  *         Py_buffer py_buf
  */
-  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_7aiohttp_12_http_parser_1parse_url, NULL, __pyx_n_s_aiohttp__http_parser); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 755, __pyx_L1_error)
+  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_7aiohttp_12_http_parser_1parse_url, NULL, __pyx_n_s_aiohttp__http_parser); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 759, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
-  if (PyDict_SetItem(__pyx_d, __pyx_n_s_parse_url, __pyx_t_1) < 0) __PYX_ERR(0, 755, __pyx_L1_error)
+  if (PyDict_SetItem(__pyx_d, __pyx_n_s_parse_url, __pyx_t_1) < 0) __PYX_ERR(0, 759, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
 
   /* "(tree fragment)":1
  * def __pyx_unpickle_RawRequestMessage(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
  *     cdef object __pyx_PickleError
  *     cdef object __pyx_result
  */
@@ -20174,14 +20295,40 @@
     return d;
 }
 static CYTHON_INLINE PyObject *__Pyx_GetAttr3(PyObject *o, PyObject *n, PyObject *d) {
     PyObject *r = __Pyx_GetAttr(o, n);
     return (likely(r)) ? r : __Pyx_GetAttr3Default(d);
 }
 
+/* PyDictVersioning */
+#if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_TYPE_SLOTS
+static CYTHON_INLINE PY_UINT64_T __Pyx_get_tp_dict_version(PyObject *obj) {
+    PyObject *dict = Py_TYPE(obj)->tp_dict;
+    return likely(dict) ? __PYX_GET_DICT_VERSION(dict) : 0;
+}
+static CYTHON_INLINE PY_UINT64_T __Pyx_get_object_dict_version(PyObject *obj) {
+    PyObject **dictptr = NULL;
+    Py_ssize_t offset = Py_TYPE(obj)->tp_dictoffset;
+    if (offset) {
+#if CYTHON_COMPILING_IN_CPYTHON
+        dictptr = (likely(offset > 0)) ? (PyObject **) ((char *)obj + offset) : _PyObject_GetDictPtr(obj);
+#else
+        dictptr = _PyObject_GetDictPtr(obj);
+#endif
+    }
+    return (dictptr && *dictptr) ? __PYX_GET_DICT_VERSION(*dictptr) : 0;
+}
+static CYTHON_INLINE int __Pyx_object_dict_version_matches(PyObject* obj, PY_UINT64_T tp_dict_version, PY_UINT64_T obj_dict_version) {
+    PyObject *dict = Py_TYPE(obj)->tp_dict;
+    if (unlikely(!dict) || unlikely(tp_dict_version != __PYX_GET_DICT_VERSION(dict)))
+        return 0;
+    return obj_dict_version == __Pyx_get_object_dict_version(obj);
+}
+#endif
+
 /* GetModuleGlobalName */
 #if CYTHON_USE_DICT_VERSIONS
 static PyObject *__Pyx__GetModuleGlobalName(PyObject *name, PY_UINT64_T *dict_version, PyObject **dict_cached_value)
 #else
 static CYTHON_INLINE PyObject *__Pyx__GetModuleGlobalName(PyObject *name)
 #endif
 {
@@ -20240,15 +20387,15 @@
     result = PyEval_EvalFrameEx(f,0);
     ++tstate->recursion_depth;
     Py_DECREF(f);
     --tstate->recursion_depth;
     return result;
 }
 #if 1 || PY_VERSION_HEX < 0x030600B1
-static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs) {
+static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, Py_ssize_t nargs, PyObject *kwargs) {
     PyCodeObject *co = (PyCodeObject *)PyFunction_GET_CODE(func);
     PyObject *globals = PyFunction_GET_GLOBALS(func);
     PyObject *argdefs = PyFunction_GET_DEFAULTS(func);
     PyObject *closure;
 #if PY_MAJOR_VERSION >= 3
     PyObject *kwdefs;
 #endif
@@ -20311,20 +20458,20 @@
     }
     else {
         d = NULL;
         nd = 0;
     }
 #if PY_MAJOR_VERSION >= 3
     result = PyEval_EvalCodeEx((PyObject*)co, globals, (PyObject *)NULL,
-                               args, nargs,
+                               args, (int)nargs,
                                k, (int)nk,
                                d, (int)nd, kwdefs, closure);
 #else
     result = PyEval_EvalCodeEx(co, globals, (PyObject *)NULL,
-                               args, nargs,
+                               args, (int)nargs,
                                k, (int)nk,
                                d, (int)nd, closure);
 #endif
     Py_XDECREF(kwtuple);
 done:
     Py_LeaveRecursiveCall();
     return result;
@@ -23767,14 +23914,17 @@
 #endif
     0,
 #if CYTHON_USE_TP_FINALIZE
     __Pyx_Coroutine_del,
 #elif PY_VERSION_HEX >= 0x030400a1
     0,
 #endif
+#if PY_VERSION_HEX >= 0x030800b1
+    0,
+#endif
 };
 static int __pyx_Generator_init(void) {
     __pyx_GeneratorType_type.tp_getattro = __Pyx_PyObject_GenericGetAttrNoDict;
     __pyx_GeneratorType_type.tp_iter = PyObject_SelfIter;
     __pyx_GeneratorType = __Pyx_FetchCommonType(&__pyx_GeneratorType_type);
     if (unlikely(!__pyx_GeneratorType)) {
         return -1;
```

### Comparing `aiohttp-4.0.0a0/aiohttp/_http_parser.pyx` & `aiohttp-4.0.0a1/aiohttp/_http_parser.pyx`

 * *Files 1% similar despite different names*

```diff
@@ -529,14 +529,17 @@
             messages = ()
 
         if self._upgraded:
             return messages, True, data[nb:]
         else:
             return messages, False, b''
 
+    def set_upgraded(self, val):
+        self._upgraded = val
+
 
 cdef class HttpRequestParser(HttpParser):
 
     def __init__(self, protocol, loop, timer=None,
                  size_t max_line_size=8190, size_t max_headers=32768,
                  size_t max_field_size=8190, payload_exception=None,
                  bint response_with_body=True, bint read_until_eof=False):
@@ -572,15 +575,16 @@
                    max_line_size, max_headers, max_field_size,
                    payload_exception, response_with_body, auto_decompress)
 
     cdef object _on_status_complete(self):
         if self._buf:
             self._reason = self._buf.decode('utf-8', 'surrogateescape')
             PyByteArray_Resize(self._buf, 0)
-
+        else:
+            self._reason = self._reason or ''
 
 cdef int cb_on_message_begin(cparser.http_parser* parser) except -1:
     cdef HttpParser pyparser = <HttpParser>parser.data
 
     pyparser._started = True
     pyparser._headers = CIMultiDict()
     pyparser._raw_headers = []
```

### Comparing `aiohttp-4.0.0a0/aiohttp/_http_writer.c` & `aiohttp-4.0.0a1/aiohttp/_http_writer.c`

 * *Files 6% similar despite different names*

```diff
@@ -1,32 +1,19 @@
-/* Generated by Cython 0.29.2 */
-
-/* BEGIN: Cython Metadata
-{
-    "distutils": {
-        "depends": [],
-        "name": "aiohttp._http_writer",
-        "sources": [
-            "aiohttp/_http_writer.pyx"
-        ]
-    },
-    "module_name": "aiohttp._http_writer"
-}
-END: Cython Metadata */
+/* Generated by Cython 0.29.13 */
 
 #define PY_SSIZE_T_CLEAN
 #include "Python.h"
 #ifndef Py_PYTHON_H
     #error Python headers needed to compile C extensions, please install development version of Python.
 #elif PY_VERSION_HEX < 0x02060000 || (0x03000000 <= PY_VERSION_HEX && PY_VERSION_HEX < 0x03030000)
     #error Cython requires Python 2.6+ or Python 3.3+.
 #else
-#define CYTHON_ABI "0_29_2"
-#define CYTHON_HEX_VERSION 0x001D02F0
-#define CYTHON_FUTURE_DIVISION 0
+#define CYTHON_ABI "0_29_13"
+#define CYTHON_HEX_VERSION 0x001D0DF0
+#define CYTHON_FUTURE_DIVISION 1
 #include <stddef.h>
 #ifndef offsetof
   #define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
 #endif
 #if !defined(WIN32) && !defined(MS_WINDOWS)
   #ifndef __stdcall
     #define __stdcall
@@ -319,16 +306,21 @@
 #if PY_MAJOR_VERSION < 3
   #define __Pyx_BUILTIN_MODULE_NAME "__builtin__"
   #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
           PyCode_New(a+k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
   #define __Pyx_DefaultClassType PyClass_Type
 #else
   #define __Pyx_BUILTIN_MODULE_NAME "builtins"
+#if PY_VERSION_HEX >= 0x030800A4 && PY_VERSION_HEX < 0x030800B2
+  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
+          PyCode_New(a, 0, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
+#else
   #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
           PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
+#endif
   #define __Pyx_DefaultClassType PyType_Type
 #endif
 #ifndef Py_TPFLAGS_CHECKTYPES
   #define Py_TPFLAGS_CHECKTYPES 0
 #endif
 #ifndef Py_TPFLAGS_HAVE_INDEX
   #define Py_TPFLAGS_HAVE_INDEX 0
@@ -355,34 +347,14 @@
 #endif
 #if CYTHON_FAST_PYCCALL
 #define __Pyx_PyFastCFunction_Check(func)\
     ((PyCFunction_Check(func) && (METH_FASTCALL == (PyCFunction_GET_FLAGS(func) & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS | METH_STACKLESS)))))
 #else
 #define __Pyx_PyFastCFunction_Check(func) 0
 #endif
-#if CYTHON_USE_DICT_VERSIONS
-#define __PYX_GET_DICT_VERSION(dict)  (((PyDictObject*)(dict))->ma_version_tag)
-#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)\
-    (version_var) = __PYX_GET_DICT_VERSION(dict);\
-    (cache_var) = (value);
-#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP) {\
-        static PY_UINT64_T __pyx_dict_version = 0;\
-        static PyObject *__pyx_dict_cached_value = NULL;\
-        if (likely(__PYX_GET_DICT_VERSION(DICT) == __pyx_dict_version)) {\
-            (VAR) = __pyx_dict_cached_value;\
-        } else {\
-            (VAR) = __pyx_dict_cached_value = (LOOKUP);\
-            __pyx_dict_version = __PYX_GET_DICT_VERSION(DICT);\
-        }\
-    }
-#else
-#define __PYX_GET_DICT_VERSION(dict)  (0)
-#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)
-#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP)  (VAR) = (LOOKUP);
-#endif
 #if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Malloc)
   #define PyObject_Malloc(s)   PyMem_Malloc(s)
   #define PyObject_Free(p)     PyMem_Free(p)
   #define PyObject_Realloc(p)  PyMem_Realloc(p)
 #endif
 #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x030400A1
   #define PyMem_RawMalloc(n)           PyMem_Malloc(n)
@@ -407,15 +379,15 @@
 #endif
 #if PY_VERSION_HEX < 0x030700A2 && !defined(PyThread_tss_create) && !defined(Py_tss_NEEDS_INIT)
 #include "pythread.h"
 #define Py_tss_NEEDS_INIT 0
 typedef int Py_tss_t;
 static CYTHON_INLINE int PyThread_tss_create(Py_tss_t *key) {
   *key = PyThread_create_key();
-  return 0; // PyThread_create_key reports success always
+  return 0;
 }
 static CYTHON_INLINE Py_tss_t * PyThread_tss_alloc(void) {
   Py_tss_t *key = (Py_tss_t *)PyObject_Malloc(sizeof(Py_tss_t));
   *key = Py_tss_NEEDS_INIT;
   return key;
 }
 static CYTHON_INLINE void PyThread_tss_free(Py_tss_t *key) {
@@ -430,15 +402,15 @@
 }
 static CYTHON_INLINE int PyThread_tss_set(Py_tss_t *key, void *value) {
   return PyThread_set_key_value(*key, value);
 }
 static CYTHON_INLINE void * PyThread_tss_get(Py_tss_t *key) {
   return PyThread_get_key_value(*key);
 }
-#endif // TSS (Thread Specific Storage) API
+#endif
 #if CYTHON_COMPILING_IN_CPYTHON || defined(_PyDict_NewPresized)
 #define __Pyx_PyDict_NewPresized(n)  ((n <= 8) ? PyDict_New() : _PyDict_NewPresized(n))
 #else
 #define __Pyx_PyDict_NewPresized(n)  PyDict_New()
 #endif
 #if PY_MAJOR_VERSION >= 3 || CYTHON_FUTURE_DIVISION
   #define __Pyx_PyNumber_Divide(x,y)         PyNumber_TrueDivide(x,y)
@@ -632,15 +604,16 @@
 #define CYTHON_WITHOUT_ASSERTIONS
 #endif
 
 typedef struct {PyObject **p; const char *s; const Py_ssize_t n; const char* encoding;
                 const char is_unicode; const char is_str; const char intern; } __Pyx_StringTabEntry;
 
 #define __PYX_DEFAULT_STRING_ENCODING_IS_ASCII 0
-#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT 0
+#define __PYX_DEFAULT_STRING_ENCODING_IS_UTF8 0
+#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT (PY_MAJOR_VERSION >= 3 && __PYX_DEFAULT_STRING_ENCODING_IS_UTF8)
 #define __PYX_DEFAULT_STRING_ENCODING ""
 #define __Pyx_PyObject_FromString __Pyx_PyBytes_FromString
 #define __Pyx_PyObject_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
 #define __Pyx_uchar_cast(c) ((unsigned char)c)
 #define __Pyx_long_cast(x) ((long)x)
 #define __Pyx_fits_Py_ssize_t(v, type, is_signed)  (\
     (sizeof(type) < sizeof(Py_ssize_t))  ||\
@@ -827,15 +800,15 @@
 static int __pyx_lineno;
 static int __pyx_clineno = 0;
 static const char * __pyx_cfilenm= __FILE__;
 static const char *__pyx_filename;
 
 
 static const char *__pyx_f[] = {
-  "aiohttp\\_http_writer.pyx",
+  "aiohttp/_http_writer.pyx",
   "type.pxd",
 };
 
 /*--- Type declarations ---*/
 struct __pyx_t_7aiohttp_12_http_writer_Writer;
 
 /* "aiohttp/_http_writer.pyx":19
@@ -962,27 +935,31 @@
 #endif
 
 /* WriteUnraisableException.proto */
 static void __Pyx_WriteUnraisable(const char *name, int clineno,
                                   int lineno, const char *filename,
                                   int full_traceback, int nogil);
 
+/* unicode_iter.proto */
+static CYTHON_INLINE int __Pyx_init_unicode_iteration(
+    PyObject* ustring, Py_ssize_t *length, void** data, int *kind);
+
 /* PyCFunctionFastCall.proto */
 #if CYTHON_FAST_PYCCALL
 static CYTHON_INLINE PyObject *__Pyx_PyCFunction_FastCall(PyObject *func, PyObject **args, Py_ssize_t nargs);
 #else
 #define __Pyx_PyCFunction_FastCall(func, args, nargs)  (assert(0), NULL)
 #endif
 
 /* PyFunctionFastCall.proto */
 #if CYTHON_FAST_PYCALL
 #define __Pyx_PyFunction_FastCall(func, args, nargs)\
     __Pyx_PyFunction_FastCallDict((func), (args), (nargs), NULL)
 #if 1 || PY_VERSION_HEX < 0x030600B1
-static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs);
+static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, Py_ssize_t nargs, PyObject *kwargs);
 #else
 #define __Pyx_PyFunction_FastCallDict(func, args, nargs, kwargs) _PyFunction_FastCallDict(func, args, nargs, kwargs)
 #endif
 #define __Pyx_BUILD_ASSERT_EXPR(cond)\
     (sizeof(char [1 - 2*!(cond)]) - 1)
 #ifndef Py_MEMBER_SIZE
 #define Py_MEMBER_SIZE(type, member) sizeof(((type *)0)->member)
@@ -1039,33 +1016,63 @@
 #if CYTHON_USE_EXC_INFO_STACK
 static _PyErr_StackItem * __Pyx_PyErr_GetTopmostException(PyThreadState *tstate);
 #endif
 
 /* ReRaiseException.proto */
 static CYTHON_INLINE void __Pyx_ReraiseException(void);
 
+/* IterFinish.proto */
+static CYTHON_INLINE int __Pyx_IterFinish(void);
+
 /* PyObjectCallNoArg.proto */
 #if CYTHON_COMPILING_IN_CPYTHON
 static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func);
 #else
 #define __Pyx_PyObject_CallNoArg(func) __Pyx_PyObject_Call(func, __pyx_empty_tuple, NULL)
 #endif
 
-/* RaiseTooManyValuesToUnpack.proto */
-static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected);
+/* PyObjectGetMethod.proto */
+static int __Pyx_PyObject_GetMethod(PyObject *obj, PyObject *name, PyObject **method);
+
+/* PyObjectCallMethod0.proto */
+static PyObject* __Pyx_PyObject_CallMethod0(PyObject* obj, PyObject* method_name);
 
 /* RaiseNeedMoreValuesToUnpack.proto */
 static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index);
 
-/* IterFinish.proto */
-static CYTHON_INLINE int __Pyx_IterFinish(void);
+/* RaiseTooManyValuesToUnpack.proto */
+static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected);
 
 /* UnpackItemEndCheck.proto */
 static int __Pyx_IternextUnpackEndCheck(PyObject *retval, Py_ssize_t expected);
 
+/* RaiseNoneIterError.proto */
+static CYTHON_INLINE void __Pyx_RaiseNoneNotIterableError(void);
+
+/* UnpackTupleError.proto */
+static void __Pyx_UnpackTupleError(PyObject *, Py_ssize_t index);
+
+/* UnpackTuple2.proto */
+#define __Pyx_unpack_tuple2(tuple, value1, value2, is_tuple, has_known_size, decref_tuple)\
+    (likely(is_tuple || PyTuple_Check(tuple)) ?\
+        (likely(has_known_size || PyTuple_GET_SIZE(tuple) == 2) ?\
+            __Pyx_unpack_tuple2_exact(tuple, value1, value2, decref_tuple) :\
+            (__Pyx_UnpackTupleError(tuple, 2), -1)) :\
+        __Pyx_unpack_tuple2_generic(tuple, value1, value2, has_known_size, decref_tuple))
+static CYTHON_INLINE int __Pyx_unpack_tuple2_exact(
+    PyObject* tuple, PyObject** value1, PyObject** value2, int decref_tuple);
+static int __Pyx_unpack_tuple2_generic(
+    PyObject* tuple, PyObject** value1, PyObject** value2, int has_known_size, int decref_tuple);
+
+/* dict_iter.proto */
+static CYTHON_INLINE PyObject* __Pyx_dict_iterator(PyObject* dict, int is_dict, PyObject* method_name,
+                                                   Py_ssize_t* p_orig_length, int* p_is_dict);
+static CYTHON_INLINE int __Pyx_dict_iter_next(PyObject* dict_or_iter, Py_ssize_t orig_length, Py_ssize_t* ppos,
+                                              PyObject** pkey, PyObject** pvalue, PyObject** pitem, int is_dict);
+
 /* GetException.proto */
 #if CYTHON_FAST_THREAD_STATE
 #define __Pyx_GetException(type, value, tb)  __Pyx__GetException(__pyx_tstate, type, value, tb)
 static int __Pyx__GetException(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
 #else
 static int __Pyx_GetException(PyObject **type, PyObject **value, PyObject **tb);
 #endif
@@ -1102,14 +1109,40 @@
 
 /* Import.proto */
 static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level);
 
 /* ImportFrom.proto */
 static PyObject* __Pyx_ImportFrom(PyObject* module, PyObject* name);
 
+/* PyDictVersioning.proto */
+#if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_TYPE_SLOTS
+#define __PYX_DICT_VERSION_INIT  ((PY_UINT64_T) -1)
+#define __PYX_GET_DICT_VERSION(dict)  (((PyDictObject*)(dict))->ma_version_tag)
+#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)\
+    (version_var) = __PYX_GET_DICT_VERSION(dict);\
+    (cache_var) = (value);
+#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP) {\
+    static PY_UINT64_T __pyx_dict_version = 0;\
+    static PyObject *__pyx_dict_cached_value = NULL;\
+    if (likely(__PYX_GET_DICT_VERSION(DICT) == __pyx_dict_version)) {\
+        (VAR) = __pyx_dict_cached_value;\
+    } else {\
+        (VAR) = __pyx_dict_cached_value = (LOOKUP);\
+        __pyx_dict_version = __PYX_GET_DICT_VERSION(DICT);\
+    }\
+}
+static CYTHON_INLINE PY_UINT64_T __Pyx_get_tp_dict_version(PyObject *obj);
+static CYTHON_INLINE PY_UINT64_T __Pyx_get_object_dict_version(PyObject *obj);
+static CYTHON_INLINE int __Pyx_object_dict_version_matches(PyObject* obj, PY_UINT64_T tp_dict_version, PY_UINT64_T obj_dict_version);
+#else
+#define __PYX_GET_DICT_VERSION(dict)  (0)
+#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)
+#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP)  (VAR) = (LOOKUP);
+#endif
+
 /* GetModuleGlobalName.proto */
 #if CYTHON_USE_DICT_VERSIONS
 #define __Pyx_GetModuleGlobalName(var, name)  {\
     static PY_UINT64_T __pyx_dict_version = 0;\
     static PyObject *__pyx_dict_cached_value = NULL;\
     (var) = (likely(__pyx_dict_version == __PYX_GET_DICT_VERSION(__pyx_d))) ?\
         (likely(__pyx_dict_cached_value) ? __Pyx_NewRef(__pyx_dict_cached_value) : __Pyx_GetBuiltinName(name)) :\
@@ -1149,22 +1182,14 @@
 static PyCodeObject *__pyx_find_code_object(int code_line);
 static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object);
 
 /* AddTraceback.proto */
 static void __Pyx_AddTraceback(const char *funcname, int c_line,
                                int py_line, const char *filename);
 
-/* UnicodeAsUCS4.proto */
-static CYTHON_INLINE Py_UCS4 __Pyx_PyUnicode_AsPy_UCS4(PyObject*);
-
-/* ObjectAsUCS4.proto */
-#define __Pyx_PyObject_AsPy_UCS4(x)\
-    (likely(PyUnicode_Check(x)) ? __Pyx_PyUnicode_AsPy_UCS4(x) : __Pyx__PyObject_AsPy_UCS4(x))
-static Py_UCS4 __Pyx__PyObject_AsPy_UCS4(PyObject*);
-
 /* CIntToPy.proto */
 static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value);
 
 /* CIntFromPy.proto */
 static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *);
 
 /* CIntFromPy.proto */
@@ -1240,17 +1265,17 @@
 static const char __pyx_k_headers[] = "headers";
 static const char __pyx_k_TypeError[] = "TypeError";
 static const char __pyx_k_multidict[] = "multidict";
 static const char __pyx_k_status_line[] = "status_line";
 static const char __pyx_k_serialize_headers[] = "_serialize_headers";
 static const char __pyx_k_cline_in_traceback[] = "cline_in_traceback";
 static const char __pyx_k_aiohttp__http_writer[] = "aiohttp._http_writer";
-static const char __pyx_k_aiohttp__http_writer_pyx[] = "aiohttp\\_http_writer.pyx";
+static const char __pyx_k_aiohttp__http_writer_pyx[] = "aiohttp/_http_writer.pyx";
 static const char __pyx_k_Cannot_serialize_non_str_key_r[] = "Cannot serialize non-str key {!r}";
-static PyObject *__pyx_kp_s_Cannot_serialize_non_str_key_r;
+static PyObject *__pyx_kp_u_Cannot_serialize_non_str_key_r;
 static PyObject *__pyx_n_s_TypeError;
 static PyObject *__pyx_n_s_aiohttp__http_writer;
 static PyObject *__pyx_kp_s_aiohttp__http_writer_pyx;
 static PyObject *__pyx_n_s_cline_in_traceback;
 static PyObject *__pyx_n_s_format;
 static PyObject *__pyx_n_s_headers;
 static PyObject *__pyx_n_s_import;
@@ -2008,56 +2033,50 @@
  */
 
 static CYTHON_INLINE int __pyx_f_7aiohttp_12_http_writer__write_str(struct __pyx_t_7aiohttp_12_http_writer_Writer *__pyx_v_writer, PyObject *__pyx_v_s) {
   Py_UCS4 __pyx_v_ch;
   int __pyx_r;
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
-  PyObject *(*__pyx_t_2)(PyObject *);
-  PyObject *__pyx_t_3 = NULL;
-  Py_UCS4 __pyx_t_4;
+  Py_ssize_t __pyx_t_2;
+  Py_ssize_t __pyx_t_3;
+  void *__pyx_t_4;
   int __pyx_t_5;
+  int __pyx_t_6;
+  Py_ssize_t __pyx_t_7;
+  int __pyx_t_8;
   __Pyx_RefNannySetupContext("_write_str", 0);
 
   /* "aiohttp/_http_writer.pyx":96
  * cdef inline int _write_str(Writer* writer, str s):
  *     cdef Py_UCS4 ch
  *     for ch in s:             # <<<<<<<<<<<<<<
  *         if _write_utf8(writer, ch) < 0:
  *             return -1
  */
-  __pyx_t_1 = PyObject_GetIter(__pyx_v_s); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 96, __pyx_L1_error)
-  __Pyx_GOTREF(__pyx_t_1);
-  __pyx_t_2 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 96, __pyx_L1_error)
-  for (;;) {
-    {
-      __pyx_t_3 = __pyx_t_2(__pyx_t_1);
-      if (unlikely(!__pyx_t_3)) {
-        PyObject* exc_type = PyErr_Occurred();
-        if (exc_type) {
-          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
-          else __PYX_ERR(0, 96, __pyx_L1_error)
-        }
-        break;
-      }
-      __Pyx_GOTREF(__pyx_t_3);
-    }
-    __pyx_t_4 = __Pyx_PyObject_AsPy_UCS4(__pyx_t_3); if (unlikely((__pyx_t_4 == (Py_UCS4)-1) && PyErr_Occurred())) __PYX_ERR(0, 96, __pyx_L1_error)
-    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
-    __pyx_v_ch = __pyx_t_4;
+  if (unlikely(__pyx_v_s == Py_None)) {
+    PyErr_SetString(PyExc_TypeError, "'NoneType' is not iterable");
+    __PYX_ERR(0, 96, __pyx_L1_error)
+  }
+  __Pyx_INCREF(__pyx_v_s);
+  __pyx_t_1 = __pyx_v_s;
+  __pyx_t_6 = __Pyx_init_unicode_iteration(__pyx_t_1, (&__pyx_t_3), (&__pyx_t_4), (&__pyx_t_5)); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(0, 96, __pyx_L1_error)
+  for (__pyx_t_7 = 0; __pyx_t_7 < __pyx_t_3; __pyx_t_7++) {
+    __pyx_t_2 = __pyx_t_7;
+    __pyx_v_ch = __Pyx_PyUnicode_READ(__pyx_t_5, __pyx_t_4, __pyx_t_2);
 
     /* "aiohttp/_http_writer.pyx":97
  *     cdef Py_UCS4 ch
  *     for ch in s:
  *         if _write_utf8(writer, ch) < 0:             # <<<<<<<<<<<<<<
  *             return -1
  * 
  */
-    __pyx_t_5 = ((__pyx_f_7aiohttp_12_http_writer__write_utf8(__pyx_v_writer, __pyx_v_ch) < 0) != 0);
-    if (__pyx_t_5) {
+    __pyx_t_8 = ((__pyx_f_7aiohttp_12_http_writer__write_utf8(__pyx_v_writer, __pyx_v_ch) < 0) != 0);
+    if (__pyx_t_8) {
 
       /* "aiohttp/_http_writer.pyx":98
  *     for ch in s:
  *         if _write_utf8(writer, ch) < 0:
  *             return -1             # <<<<<<<<<<<<<<
  * 
  * 
@@ -2070,22 +2089,14 @@
  *     cdef Py_UCS4 ch
  *     for ch in s:
  *         if _write_utf8(writer, ch) < 0:             # <<<<<<<<<<<<<<
  *             return -1
  * 
  */
     }
-
-    /* "aiohttp/_http_writer.pyx":96
- * cdef inline int _write_str(Writer* writer, str s):
- *     cdef Py_UCS4 ch
- *     for ch in s:             # <<<<<<<<<<<<<<
- *         if _write_utf8(writer, ch) < 0:
- *             return -1
- */
   }
   __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
 
   /* "aiohttp/_http_writer.pyx":94
  * 
  * 
  * cdef inline int _write_str(Writer* writer, str s):             # <<<<<<<<<<<<<<
@@ -2094,15 +2105,14 @@
  */
 
   /* function exit code */
   __pyx_r = 0;
   goto __pyx_L0;
   __pyx_L1_error:;
   __Pyx_XDECREF(__pyx_t_1);
-  __Pyx_XDECREF(__pyx_t_3);
   __Pyx_WriteUnraisable("aiohttp._http_writer._write_str", __pyx_clineno, __pyx_lineno, __pyx_filename, 1, 0);
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
@@ -2138,15 +2148,15 @@
   /* "aiohttp/_http_writer.pyx":105
  * cdef str to_str(object s):
  *     typ = type(s)
  *     if typ is str:             # <<<<<<<<<<<<<<
  *         return <str>s
  *     elif typ is _istr:
  */
-  __pyx_t_1 = (__pyx_v_typ == (&PyString_Type));
+  __pyx_t_1 = (__pyx_v_typ == (&PyUnicode_Type));
   __pyx_t_2 = (__pyx_t_1 != 0);
   if (__pyx_t_2) {
 
     /* "aiohttp/_http_writer.pyx":106
  *     typ = type(s)
  *     if typ is str:
  *         return <str>s             # <<<<<<<<<<<<<<
@@ -2184,15 +2194,15 @@
  *         return PyObject_Str(s)             # <<<<<<<<<<<<<<
  *     elif not isinstance(s, str):
  *         raise TypeError("Cannot serialize non-str key {!r}".format(s))
  */
     __Pyx_XDECREF(__pyx_r);
     __pyx_t_3 = PyObject_Str(__pyx_v_s); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 108, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
-    if (!(likely(PyString_CheckExact(__pyx_t_3))||((__pyx_t_3) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "str", Py_TYPE(__pyx_t_3)->tp_name), 0))) __PYX_ERR(0, 108, __pyx_L1_error)
+    if (!(likely(PyUnicode_CheckExact(__pyx_t_3))||((__pyx_t_3) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "unicode", Py_TYPE(__pyx_t_3)->tp_name), 0))) __PYX_ERR(0, 108, __pyx_L1_error)
     __pyx_r = ((PyObject*)__pyx_t_3);
     __pyx_t_3 = 0;
     goto __pyx_L0;
 
     /* "aiohttp/_http_writer.pyx":107
  *     if typ is str:
  *         return <str>s
@@ -2205,26 +2215,26 @@
   /* "aiohttp/_http_writer.pyx":109
  *     elif typ is _istr:
  *         return PyObject_Str(s)
  *     elif not isinstance(s, str):             # <<<<<<<<<<<<<<
  *         raise TypeError("Cannot serialize non-str key {!r}".format(s))
  *     else:
  */
-  __pyx_t_1 = PyString_Check(__pyx_v_s); 
+  __pyx_t_1 = PyUnicode_Check(__pyx_v_s); 
   __pyx_t_2 = ((!(__pyx_t_1 != 0)) != 0);
   if (unlikely(__pyx_t_2)) {
 
     /* "aiohttp/_http_writer.pyx":110
  *         return PyObject_Str(s)
  *     elif not isinstance(s, str):
  *         raise TypeError("Cannot serialize non-str key {!r}".format(s))             # <<<<<<<<<<<<<<
  *     else:
  *         return str(s)
  */
-    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_Cannot_serialize_non_str_key_r, __pyx_n_s_format); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 110, __pyx_L1_error)
+    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_kp_u_Cannot_serialize_non_str_key_r, __pyx_n_s_format); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 110, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_4);
     __pyx_t_5 = NULL;
     if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
       __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
       if (likely(__pyx_t_5)) {
         PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
         __Pyx_INCREF(__pyx_t_5);
@@ -2258,17 +2268,16 @@
  *     else:
  *         return str(s)             # <<<<<<<<<<<<<<
  * 
  * 
  */
   /*else*/ {
     __Pyx_XDECREF(__pyx_r);
-    __pyx_t_4 = __Pyx_PyObject_CallOneArg(((PyObject *)(&PyString_Type)), __pyx_v_s); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 112, __pyx_L1_error)
+    __pyx_t_4 = __Pyx_PyObject_CallOneArg(((PyObject *)(&PyUnicode_Type)), __pyx_v_s); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 112, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_4);
-    if (!(likely(PyString_CheckExact(__pyx_t_4))||((__pyx_t_4) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "str", Py_TYPE(__pyx_t_4)->tp_name), 0))) __PYX_ERR(0, 112, __pyx_L1_error)
     __pyx_r = ((PyObject*)__pyx_t_4);
     __pyx_t_4 = 0;
     goto __pyx_L0;
   }
 
   /* "aiohttp/_http_writer.pyx":103
  * # --------------- _serialize_headers ----------------------
@@ -2351,15 +2360,15 @@
   __pyx_L5_argtuple_error:;
   __Pyx_RaiseArgtupleInvalid("_serialize_headers", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 115, __pyx_L3_error)
   __pyx_L3_error:;
   __Pyx_AddTraceback("aiohttp._http_writer._serialize_headers", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __Pyx_RefNannyFinishContext();
   return NULL;
   __pyx_L4_argument_unpacking_done:;
-  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_status_line), (&PyString_Type), 1, "status_line", 1))) __PYX_ERR(0, 115, __pyx_L1_error)
+  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_status_line), (&PyUnicode_Type), 1, "status_line", 1))) __PYX_ERR(0, 115, __pyx_L1_error)
   __pyx_r = __pyx_pf_7aiohttp_12_http_writer__serialize_headers(__pyx_self, __pyx_v_status_line, __pyx_v_headers);
 
   /* function exit code */
   goto __pyx_L0;
   __pyx_L1_error:;
   __pyx_r = NULL;
   __pyx_L0:;
@@ -2371,30 +2380,27 @@
   struct __pyx_t_7aiohttp_12_http_writer_Writer __pyx_v_writer;
   PyObject *__pyx_v_key = 0;
   PyObject *__pyx_v_val = 0;
   PyObject *__pyx_r = NULL;
   __Pyx_RefNannyDeclarations
   int __pyx_t_1;
   PyObject *__pyx_t_2 = NULL;
-  PyObject *__pyx_t_3 = NULL;
-  PyObject *__pyx_t_4 = NULL;
-  Py_ssize_t __pyx_t_5;
-  PyObject *(*__pyx_t_6)(PyObject *);
+  Py_ssize_t __pyx_t_3;
+  Py_ssize_t __pyx_t_4;
+  int __pyx_t_5;
+  PyObject *__pyx_t_6 = NULL;
   PyObject *__pyx_t_7 = NULL;
-  PyObject *__pyx_t_8 = NULL;
-  PyObject *(*__pyx_t_9)(PyObject *);
-  int __pyx_t_10;
-  int __pyx_t_11;
-  char const *__pyx_t_12;
+  int __pyx_t_8;
+  char const *__pyx_t_9;
+  PyObject *__pyx_t_10 = NULL;
+  PyObject *__pyx_t_11 = NULL;
+  PyObject *__pyx_t_12 = NULL;
   PyObject *__pyx_t_13 = NULL;
   PyObject *__pyx_t_14 = NULL;
   PyObject *__pyx_t_15 = NULL;
-  PyObject *__pyx_t_16 = NULL;
-  PyObject *__pyx_t_17 = NULL;
-  PyObject *__pyx_t_18 = NULL;
   __Pyx_RefNannySetupContext("_serialize_headers", 0);
 
   /* "aiohttp/_http_writer.pyx":121
  *     cdef bytes ret
  * 
  *     _init_writer(&writer)             # <<<<<<<<<<<<<<
  * 
@@ -2412,511 +2418,414 @@
   /*try:*/ {
 
     /* "aiohttp/_http_writer.pyx":124
  * 
  *     try:
  *         if _write_str(&writer, status_line) < 0:             # <<<<<<<<<<<<<<
  *             raise
- *         if _write_byte(&writer, '\r') < 0:
+ *         if _write_byte(&writer, b'\r') < 0:
  */
     __pyx_t_1 = ((__pyx_f_7aiohttp_12_http_writer__write_str((&__pyx_v_writer), __pyx_v_status_line) < 0) != 0);
     if (unlikely(__pyx_t_1)) {
 
       /* "aiohttp/_http_writer.pyx":125
  *     try:
  *         if _write_str(&writer, status_line) < 0:
  *             raise             # <<<<<<<<<<<<<<
- *         if _write_byte(&writer, '\r') < 0:
+ *         if _write_byte(&writer, b'\r') < 0:
  *             raise
  */
       __Pyx_ReraiseException(); __PYX_ERR(0, 125, __pyx_L4_error)
 
       /* "aiohttp/_http_writer.pyx":124
  * 
  *     try:
  *         if _write_str(&writer, status_line) < 0:             # <<<<<<<<<<<<<<
  *             raise
- *         if _write_byte(&writer, '\r') < 0:
+ *         if _write_byte(&writer, b'\r') < 0:
  */
     }
 
     /* "aiohttp/_http_writer.pyx":126
  *         if _write_str(&writer, status_line) < 0:
  *             raise
- *         if _write_byte(&writer, '\r') < 0:             # <<<<<<<<<<<<<<
+ *         if _write_byte(&writer, b'\r') < 0:             # <<<<<<<<<<<<<<
  *             raise
- *         if _write_byte(&writer, '\n') < 0:
+ *         if _write_byte(&writer, b'\n') < 0:
  */
     __pyx_t_1 = ((__pyx_f_7aiohttp_12_http_writer__write_byte((&__pyx_v_writer), '\r') < 0) != 0);
     if (unlikely(__pyx_t_1)) {
 
       /* "aiohttp/_http_writer.pyx":127
  *             raise
- *         if _write_byte(&writer, '\r') < 0:
+ *         if _write_byte(&writer, b'\r') < 0:
  *             raise             # <<<<<<<<<<<<<<
- *         if _write_byte(&writer, '\n') < 0:
+ *         if _write_byte(&writer, b'\n') < 0:
  *             raise
  */
       __Pyx_ReraiseException(); __PYX_ERR(0, 127, __pyx_L4_error)
 
       /* "aiohttp/_http_writer.pyx":126
  *         if _write_str(&writer, status_line) < 0:
  *             raise
- *         if _write_byte(&writer, '\r') < 0:             # <<<<<<<<<<<<<<
+ *         if _write_byte(&writer, b'\r') < 0:             # <<<<<<<<<<<<<<
  *             raise
- *         if _write_byte(&writer, '\n') < 0:
+ *         if _write_byte(&writer, b'\n') < 0:
  */
     }
 
     /* "aiohttp/_http_writer.pyx":128
- *         if _write_byte(&writer, '\r') < 0:
+ *         if _write_byte(&writer, b'\r') < 0:
  *             raise
- *         if _write_byte(&writer, '\n') < 0:             # <<<<<<<<<<<<<<
+ *         if _write_byte(&writer, b'\n') < 0:             # <<<<<<<<<<<<<<
  *             raise
  * 
  */
     __pyx_t_1 = ((__pyx_f_7aiohttp_12_http_writer__write_byte((&__pyx_v_writer), '\n') < 0) != 0);
     if (unlikely(__pyx_t_1)) {
 
       /* "aiohttp/_http_writer.pyx":129
  *             raise
- *         if _write_byte(&writer, '\n') < 0:
+ *         if _write_byte(&writer, b'\n') < 0:
  *             raise             # <<<<<<<<<<<<<<
  * 
  *         for key, val in headers.items():
  */
       __Pyx_ReraiseException(); __PYX_ERR(0, 129, __pyx_L4_error)
 
       /* "aiohttp/_http_writer.pyx":128
- *         if _write_byte(&writer, '\r') < 0:
+ *         if _write_byte(&writer, b'\r') < 0:
  *             raise
- *         if _write_byte(&writer, '\n') < 0:             # <<<<<<<<<<<<<<
+ *         if _write_byte(&writer, b'\n') < 0:             # <<<<<<<<<<<<<<
  *             raise
  * 
  */
     }
 
     /* "aiohttp/_http_writer.pyx":131
  *             raise
  * 
  *         for key, val in headers.items():             # <<<<<<<<<<<<<<
  *             if _write_str(&writer, to_str(key)) < 0:
  *                 raise
  */
-    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_headers, __pyx_n_s_items); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 131, __pyx_L4_error)
-    __Pyx_GOTREF(__pyx_t_3);
-    __pyx_t_4 = NULL;
-    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_3))) {
-      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
-      if (likely(__pyx_t_4)) {
-        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
-        __Pyx_INCREF(__pyx_t_4);
-        __Pyx_INCREF(function);
-        __Pyx_DECREF_SET(__pyx_t_3, function);
-      }
-    }
-    __pyx_t_2 = (__pyx_t_4) ? __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4) : __Pyx_PyObject_CallNoArg(__pyx_t_3);
-    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
-    if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 131, __pyx_L4_error)
-    __Pyx_GOTREF(__pyx_t_2);
-    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
-    if (likely(PyList_CheckExact(__pyx_t_2)) || PyTuple_CheckExact(__pyx_t_2)) {
-      __pyx_t_3 = __pyx_t_2; __Pyx_INCREF(__pyx_t_3); __pyx_t_5 = 0;
-      __pyx_t_6 = NULL;
-    } else {
-      __pyx_t_5 = -1; __pyx_t_3 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 131, __pyx_L4_error)
-      __Pyx_GOTREF(__pyx_t_3);
-      __pyx_t_6 = Py_TYPE(__pyx_t_3)->tp_iternext; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 131, __pyx_L4_error)
-    }
-    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
-    for (;;) {
-      if (likely(!__pyx_t_6)) {
-        if (likely(PyList_CheckExact(__pyx_t_3))) {
-          if (__pyx_t_5 >= PyList_GET_SIZE(__pyx_t_3)) break;
-          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
-          __pyx_t_2 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_5); __Pyx_INCREF(__pyx_t_2); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 131, __pyx_L4_error)
-          #else
-          __pyx_t_2 = PySequence_ITEM(__pyx_t_3, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 131, __pyx_L4_error)
-          __Pyx_GOTREF(__pyx_t_2);
-          #endif
-        } else {
-          if (__pyx_t_5 >= PyTuple_GET_SIZE(__pyx_t_3)) break;
-          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
-          __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_5); __Pyx_INCREF(__pyx_t_2); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 131, __pyx_L4_error)
-          #else
-          __pyx_t_2 = PySequence_ITEM(__pyx_t_3, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 131, __pyx_L4_error)
-          __Pyx_GOTREF(__pyx_t_2);
-          #endif
-        }
-      } else {
-        __pyx_t_2 = __pyx_t_6(__pyx_t_3);
-        if (unlikely(!__pyx_t_2)) {
-          PyObject* exc_type = PyErr_Occurred();
-          if (exc_type) {
-            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
-            else __PYX_ERR(0, 131, __pyx_L4_error)
-          }
-          break;
-        }
-        __Pyx_GOTREF(__pyx_t_2);
-      }
-      if ((likely(PyTuple_CheckExact(__pyx_t_2))) || (PyList_CheckExact(__pyx_t_2))) {
-        PyObject* sequence = __pyx_t_2;
-        Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
-        if (unlikely(size != 2)) {
-          if (size > 2) __Pyx_RaiseTooManyValuesError(2);
-          else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
-          __PYX_ERR(0, 131, __pyx_L4_error)
-        }
-        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
-        if (likely(PyTuple_CheckExact(sequence))) {
-          __pyx_t_4 = PyTuple_GET_ITEM(sequence, 0); 
-          __pyx_t_7 = PyTuple_GET_ITEM(sequence, 1); 
-        } else {
-          __pyx_t_4 = PyList_GET_ITEM(sequence, 0); 
-          __pyx_t_7 = PyList_GET_ITEM(sequence, 1); 
-        }
-        __Pyx_INCREF(__pyx_t_4);
-        __Pyx_INCREF(__pyx_t_7);
-        #else
-        __pyx_t_4 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 131, __pyx_L4_error)
-        __Pyx_GOTREF(__pyx_t_4);
-        __pyx_t_7 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 131, __pyx_L4_error)
-        __Pyx_GOTREF(__pyx_t_7);
-        #endif
-        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
-      } else {
-        Py_ssize_t index = -1;
-        __pyx_t_8 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 131, __pyx_L4_error)
-        __Pyx_GOTREF(__pyx_t_8);
-        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
-        __pyx_t_9 = Py_TYPE(__pyx_t_8)->tp_iternext;
-        index = 0; __pyx_t_4 = __pyx_t_9(__pyx_t_8); if (unlikely(!__pyx_t_4)) goto __pyx_L11_unpacking_failed;
-        __Pyx_GOTREF(__pyx_t_4);
-        index = 1; __pyx_t_7 = __pyx_t_9(__pyx_t_8); if (unlikely(!__pyx_t_7)) goto __pyx_L11_unpacking_failed;
-        __Pyx_GOTREF(__pyx_t_7);
-        if (__Pyx_IternextUnpackEndCheck(__pyx_t_9(__pyx_t_8), 2) < 0) __PYX_ERR(0, 131, __pyx_L4_error)
-        __pyx_t_9 = NULL;
-        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
-        goto __pyx_L12_unpacking_done;
-        __pyx_L11_unpacking_failed:;
-        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
-        __pyx_t_9 = NULL;
-        if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
-        __PYX_ERR(0, 131, __pyx_L4_error)
-        __pyx_L12_unpacking_done:;
-      }
-      __Pyx_XDECREF_SET(__pyx_v_key, __pyx_t_4);
-      __pyx_t_4 = 0;
+    __pyx_t_3 = 0;
+    if (unlikely(__pyx_v_headers == Py_None)) {
+      PyErr_Format(PyExc_AttributeError, "'NoneType' object has no attribute '%.30s'", "items");
+      __PYX_ERR(0, 131, __pyx_L4_error)
+    }
+    __pyx_t_6 = __Pyx_dict_iterator(__pyx_v_headers, 0, __pyx_n_s_items, (&__pyx_t_4), (&__pyx_t_5)); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 131, __pyx_L4_error)
+    __Pyx_GOTREF(__pyx_t_6);
+    __Pyx_XDECREF(__pyx_t_2);
+    __pyx_t_2 = __pyx_t_6;
+    __pyx_t_6 = 0;
+    while (1) {
+      __pyx_t_8 = __Pyx_dict_iter_next(__pyx_t_2, __pyx_t_4, &__pyx_t_3, &__pyx_t_6, &__pyx_t_7, NULL, __pyx_t_5);
+      if (unlikely(__pyx_t_8 == 0)) break;
+      if (unlikely(__pyx_t_8 == -1)) __PYX_ERR(0, 131, __pyx_L4_error)
+      __Pyx_GOTREF(__pyx_t_6);
+      __Pyx_GOTREF(__pyx_t_7);
+      __Pyx_XDECREF_SET(__pyx_v_key, __pyx_t_6);
+      __pyx_t_6 = 0;
       __Pyx_XDECREF_SET(__pyx_v_val, __pyx_t_7);
       __pyx_t_7 = 0;
 
       /* "aiohttp/_http_writer.pyx":132
  * 
  *         for key, val in headers.items():
  *             if _write_str(&writer, to_str(key)) < 0:             # <<<<<<<<<<<<<<
  *                 raise
- *             if _write_byte(&writer, ':') < 0:
+ *             if _write_byte(&writer, b':') < 0:
  */
-      __pyx_t_2 = __pyx_f_7aiohttp_12_http_writer_to_str(__pyx_v_key); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 132, __pyx_L4_error)
-      __Pyx_GOTREF(__pyx_t_2);
-      __pyx_t_1 = ((__pyx_f_7aiohttp_12_http_writer__write_str((&__pyx_v_writer), ((PyObject*)__pyx_t_2)) < 0) != 0);
-      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
+      __pyx_t_7 = __pyx_f_7aiohttp_12_http_writer_to_str(__pyx_v_key); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 132, __pyx_L4_error)
+      __Pyx_GOTREF(__pyx_t_7);
+      __pyx_t_1 = ((__pyx_f_7aiohttp_12_http_writer__write_str((&__pyx_v_writer), ((PyObject*)__pyx_t_7)) < 0) != 0);
+      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
       if (unlikely(__pyx_t_1)) {
 
         /* "aiohttp/_http_writer.pyx":133
  *         for key, val in headers.items():
  *             if _write_str(&writer, to_str(key)) < 0:
  *                 raise             # <<<<<<<<<<<<<<
- *             if _write_byte(&writer, ':') < 0:
+ *             if _write_byte(&writer, b':') < 0:
  *                 raise
  */
         __Pyx_ReraiseException(); __PYX_ERR(0, 133, __pyx_L4_error)
 
         /* "aiohttp/_http_writer.pyx":132
  * 
  *         for key, val in headers.items():
  *             if _write_str(&writer, to_str(key)) < 0:             # <<<<<<<<<<<<<<
  *                 raise
- *             if _write_byte(&writer, ':') < 0:
+ *             if _write_byte(&writer, b':') < 0:
  */
       }
 
       /* "aiohttp/_http_writer.pyx":134
  *             if _write_str(&writer, to_str(key)) < 0:
  *                 raise
- *             if _write_byte(&writer, ':') < 0:             # <<<<<<<<<<<<<<
+ *             if _write_byte(&writer, b':') < 0:             # <<<<<<<<<<<<<<
  *                 raise
- *             if _write_byte(&writer, ' ') < 0:
+ *             if _write_byte(&writer, b' ') < 0:
  */
       __pyx_t_1 = ((__pyx_f_7aiohttp_12_http_writer__write_byte((&__pyx_v_writer), ':') < 0) != 0);
       if (unlikely(__pyx_t_1)) {
 
         /* "aiohttp/_http_writer.pyx":135
  *                 raise
- *             if _write_byte(&writer, ':') < 0:
+ *             if _write_byte(&writer, b':') < 0:
  *                 raise             # <<<<<<<<<<<<<<
- *             if _write_byte(&writer, ' ') < 0:
+ *             if _write_byte(&writer, b' ') < 0:
  *                 raise
  */
         __Pyx_ReraiseException(); __PYX_ERR(0, 135, __pyx_L4_error)
 
         /* "aiohttp/_http_writer.pyx":134
  *             if _write_str(&writer, to_str(key)) < 0:
  *                 raise
- *             if _write_byte(&writer, ':') < 0:             # <<<<<<<<<<<<<<
+ *             if _write_byte(&writer, b':') < 0:             # <<<<<<<<<<<<<<
  *                 raise
- *             if _write_byte(&writer, ' ') < 0:
+ *             if _write_byte(&writer, b' ') < 0:
  */
       }
 
       /* "aiohttp/_http_writer.pyx":136
- *             if _write_byte(&writer, ':') < 0:
+ *             if _write_byte(&writer, b':') < 0:
  *                 raise
- *             if _write_byte(&writer, ' ') < 0:             # <<<<<<<<<<<<<<
+ *             if _write_byte(&writer, b' ') < 0:             # <<<<<<<<<<<<<<
  *                 raise
  *             if _write_str(&writer, to_str(val)) < 0:
  */
       __pyx_t_1 = ((__pyx_f_7aiohttp_12_http_writer__write_byte((&__pyx_v_writer), ' ') < 0) != 0);
       if (unlikely(__pyx_t_1)) {
 
         /* "aiohttp/_http_writer.pyx":137
  *                 raise
- *             if _write_byte(&writer, ' ') < 0:
+ *             if _write_byte(&writer, b' ') < 0:
  *                 raise             # <<<<<<<<<<<<<<
  *             if _write_str(&writer, to_str(val)) < 0:
  *                 raise
  */
         __Pyx_ReraiseException(); __PYX_ERR(0, 137, __pyx_L4_error)
 
         /* "aiohttp/_http_writer.pyx":136
- *             if _write_byte(&writer, ':') < 0:
+ *             if _write_byte(&writer, b':') < 0:
  *                 raise
- *             if _write_byte(&writer, ' ') < 0:             # <<<<<<<<<<<<<<
+ *             if _write_byte(&writer, b' ') < 0:             # <<<<<<<<<<<<<<
  *                 raise
  *             if _write_str(&writer, to_str(val)) < 0:
  */
       }
 
       /* "aiohttp/_http_writer.pyx":138
- *             if _write_byte(&writer, ' ') < 0:
+ *             if _write_byte(&writer, b' ') < 0:
  *                 raise
  *             if _write_str(&writer, to_str(val)) < 0:             # <<<<<<<<<<<<<<
  *                 raise
- *             if _write_byte(&writer, '\r') < 0:
+ *             if _write_byte(&writer, b'\r') < 0:
  */
-      __pyx_t_2 = __pyx_f_7aiohttp_12_http_writer_to_str(__pyx_v_val); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 138, __pyx_L4_error)
-      __Pyx_GOTREF(__pyx_t_2);
-      __pyx_t_1 = ((__pyx_f_7aiohttp_12_http_writer__write_str((&__pyx_v_writer), ((PyObject*)__pyx_t_2)) < 0) != 0);
-      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
+      __pyx_t_7 = __pyx_f_7aiohttp_12_http_writer_to_str(__pyx_v_val); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 138, __pyx_L4_error)
+      __Pyx_GOTREF(__pyx_t_7);
+      __pyx_t_1 = ((__pyx_f_7aiohttp_12_http_writer__write_str((&__pyx_v_writer), ((PyObject*)__pyx_t_7)) < 0) != 0);
+      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
       if (unlikely(__pyx_t_1)) {
 
         /* "aiohttp/_http_writer.pyx":139
  *                 raise
  *             if _write_str(&writer, to_str(val)) < 0:
  *                 raise             # <<<<<<<<<<<<<<
- *             if _write_byte(&writer, '\r') < 0:
+ *             if _write_byte(&writer, b'\r') < 0:
  *                 raise
  */
         __Pyx_ReraiseException(); __PYX_ERR(0, 139, __pyx_L4_error)
 
         /* "aiohttp/_http_writer.pyx":138
- *             if _write_byte(&writer, ' ') < 0:
+ *             if _write_byte(&writer, b' ') < 0:
  *                 raise
  *             if _write_str(&writer, to_str(val)) < 0:             # <<<<<<<<<<<<<<
  *                 raise
- *             if _write_byte(&writer, '\r') < 0:
+ *             if _write_byte(&writer, b'\r') < 0:
  */
       }
 
       /* "aiohttp/_http_writer.pyx":140
  *             if _write_str(&writer, to_str(val)) < 0:
  *                 raise
- *             if _write_byte(&writer, '\r') < 0:             # <<<<<<<<<<<<<<
+ *             if _write_byte(&writer, b'\r') < 0:             # <<<<<<<<<<<<<<
  *                 raise
- *             if _write_byte(&writer, '\n') < 0:
+ *             if _write_byte(&writer, b'\n') < 0:
  */
       __pyx_t_1 = ((__pyx_f_7aiohttp_12_http_writer__write_byte((&__pyx_v_writer), '\r') < 0) != 0);
       if (unlikely(__pyx_t_1)) {
 
         /* "aiohttp/_http_writer.pyx":141
  *                 raise
- *             if _write_byte(&writer, '\r') < 0:
+ *             if _write_byte(&writer, b'\r') < 0:
  *                 raise             # <<<<<<<<<<<<<<
- *             if _write_byte(&writer, '\n') < 0:
+ *             if _write_byte(&writer, b'\n') < 0:
  *                 raise
  */
         __Pyx_ReraiseException(); __PYX_ERR(0, 141, __pyx_L4_error)
 
         /* "aiohttp/_http_writer.pyx":140
  *             if _write_str(&writer, to_str(val)) < 0:
  *                 raise
- *             if _write_byte(&writer, '\r') < 0:             # <<<<<<<<<<<<<<
+ *             if _write_byte(&writer, b'\r') < 0:             # <<<<<<<<<<<<<<
  *                 raise
- *             if _write_byte(&writer, '\n') < 0:
+ *             if _write_byte(&writer, b'\n') < 0:
  */
       }
 
       /* "aiohttp/_http_writer.pyx":142
- *             if _write_byte(&writer, '\r') < 0:
+ *             if _write_byte(&writer, b'\r') < 0:
  *                 raise
- *             if _write_byte(&writer, '\n') < 0:             # <<<<<<<<<<<<<<
+ *             if _write_byte(&writer, b'\n') < 0:             # <<<<<<<<<<<<<<
  *                 raise
  * 
  */
       __pyx_t_1 = ((__pyx_f_7aiohttp_12_http_writer__write_byte((&__pyx_v_writer), '\n') < 0) != 0);
       if (unlikely(__pyx_t_1)) {
 
         /* "aiohttp/_http_writer.pyx":143
  *                 raise
- *             if _write_byte(&writer, '\n') < 0:
+ *             if _write_byte(&writer, b'\n') < 0:
  *                 raise             # <<<<<<<<<<<<<<
  * 
- *         if _write_byte(&writer, '\r') < 0:
+ *         if _write_byte(&writer, b'\r') < 0:
  */
         __Pyx_ReraiseException(); __PYX_ERR(0, 143, __pyx_L4_error)
 
         /* "aiohttp/_http_writer.pyx":142
- *             if _write_byte(&writer, '\r') < 0:
+ *             if _write_byte(&writer, b'\r') < 0:
  *                 raise
- *             if _write_byte(&writer, '\n') < 0:             # <<<<<<<<<<<<<<
+ *             if _write_byte(&writer, b'\n') < 0:             # <<<<<<<<<<<<<<
  *                 raise
  * 
  */
       }
-
-      /* "aiohttp/_http_writer.pyx":131
- *             raise
- * 
- *         for key, val in headers.items():             # <<<<<<<<<<<<<<
- *             if _write_str(&writer, to_str(key)) < 0:
- *                 raise
- */
     }
-    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
+    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
 
     /* "aiohttp/_http_writer.pyx":145
  *                 raise
  * 
- *         if _write_byte(&writer, '\r') < 0:             # <<<<<<<<<<<<<<
+ *         if _write_byte(&writer, b'\r') < 0:             # <<<<<<<<<<<<<<
  *             raise
- *         if _write_byte(&writer, '\n') < 0:
+ *         if _write_byte(&writer, b'\n') < 0:
  */
     __pyx_t_1 = ((__pyx_f_7aiohttp_12_http_writer__write_byte((&__pyx_v_writer), '\r') < 0) != 0);
     if (unlikely(__pyx_t_1)) {
 
       /* "aiohttp/_http_writer.pyx":146
  * 
- *         if _write_byte(&writer, '\r') < 0:
+ *         if _write_byte(&writer, b'\r') < 0:
  *             raise             # <<<<<<<<<<<<<<
- *         if _write_byte(&writer, '\n') < 0:
+ *         if _write_byte(&writer, b'\n') < 0:
  *             raise
  */
       __Pyx_ReraiseException(); __PYX_ERR(0, 146, __pyx_L4_error)
 
       /* "aiohttp/_http_writer.pyx":145
  *                 raise
  * 
- *         if _write_byte(&writer, '\r') < 0:             # <<<<<<<<<<<<<<
+ *         if _write_byte(&writer, b'\r') < 0:             # <<<<<<<<<<<<<<
  *             raise
- *         if _write_byte(&writer, '\n') < 0:
+ *         if _write_byte(&writer, b'\n') < 0:
  */
     }
 
     /* "aiohttp/_http_writer.pyx":147
- *         if _write_byte(&writer, '\r') < 0:
+ *         if _write_byte(&writer, b'\r') < 0:
  *             raise
- *         if _write_byte(&writer, '\n') < 0:             # <<<<<<<<<<<<<<
+ *         if _write_byte(&writer, b'\n') < 0:             # <<<<<<<<<<<<<<
  *             raise
  * 
  */
     __pyx_t_1 = ((__pyx_f_7aiohttp_12_http_writer__write_byte((&__pyx_v_writer), '\n') < 0) != 0);
     if (unlikely(__pyx_t_1)) {
 
       /* "aiohttp/_http_writer.pyx":148
  *             raise
- *         if _write_byte(&writer, '\n') < 0:
+ *         if _write_byte(&writer, b'\n') < 0:
  *             raise             # <<<<<<<<<<<<<<
  * 
  *         return PyBytes_FromStringAndSize(writer.buf, writer.pos)
  */
       __Pyx_ReraiseException(); __PYX_ERR(0, 148, __pyx_L4_error)
 
       /* "aiohttp/_http_writer.pyx":147
- *         if _write_byte(&writer, '\r') < 0:
+ *         if _write_byte(&writer, b'\r') < 0:
  *             raise
- *         if _write_byte(&writer, '\n') < 0:             # <<<<<<<<<<<<<<
+ *         if _write_byte(&writer, b'\n') < 0:             # <<<<<<<<<<<<<<
  *             raise
  * 
  */
     }
 
     /* "aiohttp/_http_writer.pyx":150
  *             raise
  * 
  *         return PyBytes_FromStringAndSize(writer.buf, writer.pos)             # <<<<<<<<<<<<<<
  *     finally:
  *         _release_writer(&writer)
  */
     __Pyx_XDECREF(__pyx_r);
-    __pyx_t_3 = PyBytes_FromStringAndSize(__pyx_v_writer.buf, __pyx_v_writer.pos); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 150, __pyx_L4_error)
-    __Pyx_GOTREF(__pyx_t_3);
-    __pyx_r = __pyx_t_3;
-    __pyx_t_3 = 0;
+    __pyx_t_2 = PyBytes_FromStringAndSize(__pyx_v_writer.buf, __pyx_v_writer.pos); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 150, __pyx_L4_error)
+    __Pyx_GOTREF(__pyx_t_2);
+    __pyx_r = __pyx_t_2;
+    __pyx_t_2 = 0;
     goto __pyx_L3_return;
   }
 
   /* "aiohttp/_http_writer.pyx":152
  *         return PyBytes_FromStringAndSize(writer.buf, writer.pos)
  *     finally:
  *         _release_writer(&writer)             # <<<<<<<<<<<<<<
  */
   /*finally:*/ {
     __pyx_L4_error:;
     /*exception exit:*/{
       __Pyx_PyThreadState_declare
       __Pyx_PyThreadState_assign
-      __pyx_t_13 = 0; __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0;
-      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
-      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
-      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
+      __pyx_t_10 = 0; __pyx_t_11 = 0; __pyx_t_12 = 0; __pyx_t_13 = 0; __pyx_t_14 = 0; __pyx_t_15 = 0;
       __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
-      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
-      if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_16, &__pyx_t_17, &__pyx_t_18);
-      if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_13, &__pyx_t_14, &__pyx_t_15) < 0)) __Pyx_ErrFetch(&__pyx_t_13, &__pyx_t_14, &__pyx_t_15);
+      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
+      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
+      if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_13, &__pyx_t_14, &__pyx_t_15);
+      if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_10, &__pyx_t_11, &__pyx_t_12) < 0)) __Pyx_ErrFetch(&__pyx_t_10, &__pyx_t_11, &__pyx_t_12);
+      __Pyx_XGOTREF(__pyx_t_10);
+      __Pyx_XGOTREF(__pyx_t_11);
+      __Pyx_XGOTREF(__pyx_t_12);
       __Pyx_XGOTREF(__pyx_t_13);
       __Pyx_XGOTREF(__pyx_t_14);
       __Pyx_XGOTREF(__pyx_t_15);
-      __Pyx_XGOTREF(__pyx_t_16);
-      __Pyx_XGOTREF(__pyx_t_17);
-      __Pyx_XGOTREF(__pyx_t_18);
-      __pyx_t_10 = __pyx_lineno; __pyx_t_11 = __pyx_clineno; __pyx_t_12 = __pyx_filename;
+      __pyx_t_5 = __pyx_lineno; __pyx_t_8 = __pyx_clineno; __pyx_t_9 = __pyx_filename;
       {
         __pyx_f_7aiohttp_12_http_writer__release_writer((&__pyx_v_writer));
       }
       if (PY_MAJOR_VERSION >= 3) {
-        __Pyx_XGIVEREF(__pyx_t_16);
-        __Pyx_XGIVEREF(__pyx_t_17);
-        __Pyx_XGIVEREF(__pyx_t_18);
-        __Pyx_ExceptionReset(__pyx_t_16, __pyx_t_17, __pyx_t_18);
+        __Pyx_XGIVEREF(__pyx_t_13);
+        __Pyx_XGIVEREF(__pyx_t_14);
+        __Pyx_XGIVEREF(__pyx_t_15);
+        __Pyx_ExceptionReset(__pyx_t_13, __pyx_t_14, __pyx_t_15);
       }
-      __Pyx_XGIVEREF(__pyx_t_13);
-      __Pyx_XGIVEREF(__pyx_t_14);
-      __Pyx_XGIVEREF(__pyx_t_15);
-      __Pyx_ErrRestore(__pyx_t_13, __pyx_t_14, __pyx_t_15);
-      __pyx_t_13 = 0; __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0;
-      __pyx_lineno = __pyx_t_10; __pyx_clineno = __pyx_t_11; __pyx_filename = __pyx_t_12;
+      __Pyx_XGIVEREF(__pyx_t_10);
+      __Pyx_XGIVEREF(__pyx_t_11);
+      __Pyx_XGIVEREF(__pyx_t_12);
+      __Pyx_ErrRestore(__pyx_t_10, __pyx_t_11, __pyx_t_12);
+      __pyx_t_10 = 0; __pyx_t_11 = 0; __pyx_t_12 = 0; __pyx_t_13 = 0; __pyx_t_14 = 0; __pyx_t_15 = 0;
+      __pyx_lineno = __pyx_t_5; __pyx_clineno = __pyx_t_8; __pyx_filename = __pyx_t_9;
       goto __pyx_L1_error;
     }
     __pyx_L3_return: {
-      __pyx_t_18 = __pyx_r;
+      __pyx_t_15 = __pyx_r;
       __pyx_r = 0;
       __pyx_f_7aiohttp_12_http_writer__release_writer((&__pyx_v_writer));
-      __pyx_r = __pyx_t_18;
-      __pyx_t_18 = 0;
+      __pyx_r = __pyx_t_15;
+      __pyx_t_15 = 0;
       goto __pyx_L0;
     }
   }
 
   /* "aiohttp/_http_writer.pyx":115
  * 
  * 
@@ -2924,18 +2833,16 @@
  *     cdef Writer writer
  *     cdef object key
  */
 
   /* function exit code */
   __pyx_L1_error:;
   __Pyx_XDECREF(__pyx_t_2);
-  __Pyx_XDECREF(__pyx_t_3);
-  __Pyx_XDECREF(__pyx_t_4);
+  __Pyx_XDECREF(__pyx_t_6);
   __Pyx_XDECREF(__pyx_t_7);
-  __Pyx_XDECREF(__pyx_t_8);
   __Pyx_AddTraceback("aiohttp._http_writer._serialize_headers", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XDECREF(__pyx_v_key);
   __Pyx_XDECREF(__pyx_v_val);
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
@@ -2984,15 +2891,15 @@
     #define CYTHON_SMALL_CODE __attribute__((cold))
 #else
     #define CYTHON_SMALL_CODE
 #endif
 #endif
 
 static __Pyx_StringTabEntry __pyx_string_tab[] = {
-  {&__pyx_kp_s_Cannot_serialize_non_str_key_r, __pyx_k_Cannot_serialize_non_str_key_r, sizeof(__pyx_k_Cannot_serialize_non_str_key_r), 0, 0, 1, 0},
+  {&__pyx_kp_u_Cannot_serialize_non_str_key_r, __pyx_k_Cannot_serialize_non_str_key_r, sizeof(__pyx_k_Cannot_serialize_non_str_key_r), 0, 1, 0, 0},
   {&__pyx_n_s_TypeError, __pyx_k_TypeError, sizeof(__pyx_k_TypeError), 0, 0, 1, 1},
   {&__pyx_n_s_aiohttp__http_writer, __pyx_k_aiohttp__http_writer, sizeof(__pyx_k_aiohttp__http_writer), 0, 0, 1, 1},
   {&__pyx_kp_s_aiohttp__http_writer_pyx, __pyx_k_aiohttp__http_writer_pyx, sizeof(__pyx_k_aiohttp__http_writer_pyx), 0, 0, 1, 0},
   {&__pyx_n_s_cline_in_traceback, __pyx_k_cline_in_traceback, sizeof(__pyx_k_cline_in_traceback), 0, 0, 1, 1},
   {&__pyx_n_s_format, __pyx_k_format, sizeof(__pyx_k_format), 0, 0, 1, 1},
   {&__pyx_n_s_headers, __pyx_k_headers, sizeof(__pyx_k_headers), 0, 0, 1, 1},
   {&__pyx_n_s_import, __pyx_k_import, sizeof(__pyx_k_import), 0, 0, 1, 1},
@@ -3284,18 +3191,17 @@
   __pyx_m = PyModule_Create(&__pyx_moduledef);
   #endif
   if (unlikely(!__pyx_m)) __PYX_ERR(0, 1, __pyx_L1_error)
   #endif
   __pyx_d = PyModule_GetDict(__pyx_m); if (unlikely(!__pyx_d)) __PYX_ERR(0, 1, __pyx_L1_error)
   Py_INCREF(__pyx_d);
   __pyx_b = PyImport_AddModule(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_b)) __PYX_ERR(0, 1, __pyx_L1_error)
-  __pyx_cython_runtime = PyImport_AddModule((char *) "cython_runtime"); if (unlikely(!__pyx_cython_runtime)) __PYX_ERR(0, 1, __pyx_L1_error)
-  #if CYTHON_COMPILING_IN_PYPY
   Py_INCREF(__pyx_b);
-  #endif
+  __pyx_cython_runtime = PyImport_AddModule((char *) "cython_runtime"); if (unlikely(!__pyx_cython_runtime)) __PYX_ERR(0, 1, __pyx_L1_error)
+  Py_INCREF(__pyx_cython_runtime);
   if (PyObject_SetAttrString(__pyx_m, "__builtins__", __pyx_b) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
   /*--- Initialize various global constants etc. ---*/
   if (__Pyx_InitGlobals() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
   #if PY_MAJOR_VERSION < 3 && (__PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT)
   if (__Pyx_init_sys_getdefaultencoding_params() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
   #endif
   if (__pyx_module_is_main_aiohttp___http_writer) {
@@ -3306,17 +3212,17 @@
     PyObject *modules = PyImport_GetModuleDict(); if (unlikely(!modules)) __PYX_ERR(0, 1, __pyx_L1_error)
     if (!PyDict_GetItemString(modules, "aiohttp._http_writer")) {
       if (unlikely(PyDict_SetItemString(modules, "aiohttp._http_writer", __pyx_m) < 0)) __PYX_ERR(0, 1, __pyx_L1_error)
     }
   }
   #endif
   /*--- Builtin init code ---*/
-  if (__Pyx_InitCachedBuiltins() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
+  if (__Pyx_InitCachedBuiltins() < 0) goto __pyx_L1_error;
   /*--- Constants init code ---*/
-  if (__Pyx_InitCachedConstants() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
+  if (__Pyx_InitCachedConstants() < 0) goto __pyx_L1_error;
   /*--- Global type/function init code ---*/
   (void)__Pyx_modinit_global_init_code();
   (void)__Pyx_modinit_variable_export_code();
   (void)__Pyx_modinit_function_export_code();
   (void)__Pyx_modinit_type_init_code();
   if (unlikely(__Pyx_modinit_type_import_code() != 0)) goto __pyx_L1_error;
   (void)__Pyx_modinit_variable_import_code();
@@ -3334,15 +3240,15 @@
  * DEF BUF_SIZE = 16 * 1024  # 16KiB
  */
   __pyx_t_1 = PyList_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 9, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __Pyx_INCREF(__pyx_n_s_istr);
   __Pyx_GIVEREF(__pyx_n_s_istr);
   PyList_SET_ITEM(__pyx_t_1, 0, __pyx_n_s_istr);
-  __pyx_t_2 = __Pyx_Import(__pyx_n_s_multidict, __pyx_t_1, -1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 9, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_Import(__pyx_n_s_multidict, __pyx_t_1, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 9, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
   __pyx_t_1 = __Pyx_ImportFrom(__pyx_t_2, __pyx_n_s_istr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 9, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   if (PyDict_SetItem(__pyx_d, __pyx_n_s_istr, __pyx_t_1) < 0) __PYX_ERR(0, 9, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
   __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
@@ -3516,14 +3422,30 @@
     }
 #ifdef WITH_THREAD
     if (nogil)
         PyGILState_Release(state);
 #endif
 }
 
+/* unicode_iter */
+static CYTHON_INLINE int __Pyx_init_unicode_iteration(
+    PyObject* ustring, Py_ssize_t *length, void** data, int *kind) {
+#if CYTHON_PEP393_ENABLED
+    if (unlikely(__Pyx_PyUnicode_READY(ustring) < 0)) return -1;
+    *kind   = PyUnicode_KIND(ustring);
+    *length = PyUnicode_GET_LENGTH(ustring);
+    *data   = PyUnicode_DATA(ustring);
+#else
+    *kind   = 0;
+    *length = PyUnicode_GET_SIZE(ustring);
+    *data   = (void*)PyUnicode_AS_UNICODE(ustring);
+#endif
+    return 0;
+}
+
 /* PyCFunctionFastCall */
 #if CYTHON_FAST_PYCCALL
 static CYTHON_INLINE PyObject * __Pyx_PyCFunction_FastCall(PyObject *func_obj, PyObject **args, Py_ssize_t nargs) {
     PyCFunctionObject *func = (PyCFunctionObject*)func_obj;
     PyCFunction meth = PyCFunction_GET_FUNCTION(func);
     PyObject *self = PyCFunction_GET_SELF(func);
     int flags = PyCFunction_GET_FLAGS(func);
@@ -3570,15 +3492,15 @@
     result = PyEval_EvalFrameEx(f,0);
     ++tstate->recursion_depth;
     Py_DECREF(f);
     --tstate->recursion_depth;
     return result;
 }
 #if 1 || PY_VERSION_HEX < 0x030600B1
-static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs) {
+static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, Py_ssize_t nargs, PyObject *kwargs) {
     PyCodeObject *co = (PyCodeObject *)PyFunction_GET_CODE(func);
     PyObject *globals = PyFunction_GET_GLOBALS(func);
     PyObject *argdefs = PyFunction_GET_DEFAULTS(func);
     PyObject *closure;
 #if PY_MAJOR_VERSION >= 3
     PyObject *kwdefs;
 #endif
@@ -3641,20 +3563,20 @@
     }
     else {
         d = NULL;
         nd = 0;
     }
 #if PY_MAJOR_VERSION >= 3
     result = PyEval_EvalCodeEx((PyObject*)co, globals, (PyObject *)NULL,
-                               args, nargs,
+                               args, (int)nargs,
                                k, (int)nk,
                                d, (int)nd, kwdefs, closure);
 #else
     result = PyEval_EvalCodeEx(co, globals, (PyObject *)NULL,
-                               args, nargs,
+                               args, (int)nargs,
                                k, (int)nk,
                                d, (int)nd, closure);
 #endif
     Py_XDECREF(kwtuple);
 done:
     Py_LeaveRecursiveCall();
     return result;
@@ -4140,49 +4062,14 @@
         Py_XINCREF(value);
         Py_XINCREF(tb);
 #endif
         PyErr_Restore(type, value, tb);
     }
 }
 
-/* PyObjectCallNoArg */
-#if CYTHON_COMPILING_IN_CPYTHON
-static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func) {
-#if CYTHON_FAST_PYCALL
-    if (PyFunction_Check(func)) {
-        return __Pyx_PyFunction_FastCall(func, NULL, 0);
-    }
-#endif
-#ifdef __Pyx_CyFunction_USED
-    if (likely(PyCFunction_Check(func) || __Pyx_CyFunction_Check(func)))
-#else
-    if (likely(PyCFunction_Check(func)))
-#endif
-    {
-        if (likely(PyCFunction_GET_FLAGS(func) & METH_NOARGS)) {
-            return __Pyx_PyObject_CallMethO(func, NULL);
-        }
-    }
-    return __Pyx_PyObject_Call(func, __pyx_empty_tuple, NULL);
-}
-#endif
-
-/* RaiseTooManyValuesToUnpack */
-static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected) {
-    PyErr_Format(PyExc_ValueError,
-                 "too many values to unpack (expected %" CYTHON_FORMAT_SSIZE_T "d)", expected);
-}
-
-/* RaiseNeedMoreValuesToUnpack */
-static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index) {
-    PyErr_Format(PyExc_ValueError,
-                 "need more than %" CYTHON_FORMAT_SSIZE_T "d value%.1s to unpack",
-                 index, (index == 1) ? "" : "s");
-}
-
 /* IterFinish */
 static CYTHON_INLINE int __Pyx_IterFinish(void) {
 #if CYTHON_FAST_THREAD_STATE
     PyThreadState *tstate = __Pyx_PyThreadState_Current;
     PyObject* exc_type = tstate->curexc_type;
     if (unlikely(exc_type)) {
         if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) {
@@ -4210,26 +4097,354 @@
             return -1;
         }
     }
     return 0;
 #endif
 }
 
+/* PyObjectCallNoArg */
+#if CYTHON_COMPILING_IN_CPYTHON
+static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func) {
+#if CYTHON_FAST_PYCALL
+    if (PyFunction_Check(func)) {
+        return __Pyx_PyFunction_FastCall(func, NULL, 0);
+    }
+#endif
+#ifdef __Pyx_CyFunction_USED
+    if (likely(PyCFunction_Check(func) || __Pyx_CyFunction_Check(func)))
+#else
+    if (likely(PyCFunction_Check(func)))
+#endif
+    {
+        if (likely(PyCFunction_GET_FLAGS(func) & METH_NOARGS)) {
+            return __Pyx_PyObject_CallMethO(func, NULL);
+        }
+    }
+    return __Pyx_PyObject_Call(func, __pyx_empty_tuple, NULL);
+}
+#endif
+
+/* PyObjectGetMethod */
+static int __Pyx_PyObject_GetMethod(PyObject *obj, PyObject *name, PyObject **method) {
+    PyObject *attr;
+#if CYTHON_UNPACK_METHODS && CYTHON_COMPILING_IN_CPYTHON && CYTHON_USE_PYTYPE_LOOKUP
+    PyTypeObject *tp = Py_TYPE(obj);
+    PyObject *descr;
+    descrgetfunc f = NULL;
+    PyObject **dictptr, *dict;
+    int meth_found = 0;
+    assert (*method == NULL);
+    if (unlikely(tp->tp_getattro != PyObject_GenericGetAttr)) {
+        attr = __Pyx_PyObject_GetAttrStr(obj, name);
+        goto try_unpack;
+    }
+    if (unlikely(tp->tp_dict == NULL) && unlikely(PyType_Ready(tp) < 0)) {
+        return 0;
+    }
+    descr = _PyType_Lookup(tp, name);
+    if (likely(descr != NULL)) {
+        Py_INCREF(descr);
+#if PY_MAJOR_VERSION >= 3
+        #ifdef __Pyx_CyFunction_USED
+        if (likely(PyFunction_Check(descr) || (Py_TYPE(descr) == &PyMethodDescr_Type) || __Pyx_CyFunction_Check(descr)))
+        #else
+        if (likely(PyFunction_Check(descr) || (Py_TYPE(descr) == &PyMethodDescr_Type)))
+        #endif
+#else
+        #ifdef __Pyx_CyFunction_USED
+        if (likely(PyFunction_Check(descr) || __Pyx_CyFunction_Check(descr)))
+        #else
+        if (likely(PyFunction_Check(descr)))
+        #endif
+#endif
+        {
+            meth_found = 1;
+        } else {
+            f = Py_TYPE(descr)->tp_descr_get;
+            if (f != NULL && PyDescr_IsData(descr)) {
+                attr = f(descr, obj, (PyObject *)Py_TYPE(obj));
+                Py_DECREF(descr);
+                goto try_unpack;
+            }
+        }
+    }
+    dictptr = _PyObject_GetDictPtr(obj);
+    if (dictptr != NULL && (dict = *dictptr) != NULL) {
+        Py_INCREF(dict);
+        attr = __Pyx_PyDict_GetItemStr(dict, name);
+        if (attr != NULL) {
+            Py_INCREF(attr);
+            Py_DECREF(dict);
+            Py_XDECREF(descr);
+            goto try_unpack;
+        }
+        Py_DECREF(dict);
+    }
+    if (meth_found) {
+        *method = descr;
+        return 1;
+    }
+    if (f != NULL) {
+        attr = f(descr, obj, (PyObject *)Py_TYPE(obj));
+        Py_DECREF(descr);
+        goto try_unpack;
+    }
+    if (descr != NULL) {
+        *method = descr;
+        return 0;
+    }
+    PyErr_Format(PyExc_AttributeError,
+#if PY_MAJOR_VERSION >= 3
+                 "'%.50s' object has no attribute '%U'",
+                 tp->tp_name, name);
+#else
+                 "'%.50s' object has no attribute '%.400s'",
+                 tp->tp_name, PyString_AS_STRING(name));
+#endif
+    return 0;
+#else
+    attr = __Pyx_PyObject_GetAttrStr(obj, name);
+    goto try_unpack;
+#endif
+try_unpack:
+#if CYTHON_UNPACK_METHODS
+    if (likely(attr) && PyMethod_Check(attr) && likely(PyMethod_GET_SELF(attr) == obj)) {
+        PyObject *function = PyMethod_GET_FUNCTION(attr);
+        Py_INCREF(function);
+        Py_DECREF(attr);
+        *method = function;
+        return 1;
+    }
+#endif
+    *method = attr;
+    return 0;
+}
+
+/* PyObjectCallMethod0 */
+static PyObject* __Pyx_PyObject_CallMethod0(PyObject* obj, PyObject* method_name) {
+    PyObject *method = NULL, *result = NULL;
+    int is_method = __Pyx_PyObject_GetMethod(obj, method_name, &method);
+    if (likely(is_method)) {
+        result = __Pyx_PyObject_CallOneArg(method, obj);
+        Py_DECREF(method);
+        return result;
+    }
+    if (unlikely(!method)) goto bad;
+    result = __Pyx_PyObject_CallNoArg(method);
+    Py_DECREF(method);
+bad:
+    return result;
+}
+
+/* RaiseNeedMoreValuesToUnpack */
+static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index) {
+    PyErr_Format(PyExc_ValueError,
+                 "need more than %" CYTHON_FORMAT_SSIZE_T "d value%.1s to unpack",
+                 index, (index == 1) ? "" : "s");
+}
+
+/* RaiseTooManyValuesToUnpack */
+static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected) {
+    PyErr_Format(PyExc_ValueError,
+                 "too many values to unpack (expected %" CYTHON_FORMAT_SSIZE_T "d)", expected);
+}
+
 /* UnpackItemEndCheck */
 static int __Pyx_IternextUnpackEndCheck(PyObject *retval, Py_ssize_t expected) {
     if (unlikely(retval)) {
         Py_DECREF(retval);
         __Pyx_RaiseTooManyValuesError(expected);
         return -1;
     } else {
         return __Pyx_IterFinish();
     }
     return 0;
 }
 
+/* RaiseNoneIterError */
+static CYTHON_INLINE void __Pyx_RaiseNoneNotIterableError(void) {
+    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not iterable");
+}
+
+/* UnpackTupleError */
+static void __Pyx_UnpackTupleError(PyObject *t, Py_ssize_t index) {
+    if (t == Py_None) {
+      __Pyx_RaiseNoneNotIterableError();
+    } else if (PyTuple_GET_SIZE(t) < index) {
+      __Pyx_RaiseNeedMoreValuesError(PyTuple_GET_SIZE(t));
+    } else {
+      __Pyx_RaiseTooManyValuesError(index);
+    }
+}
+
+/* UnpackTuple2 */
+static CYTHON_INLINE int __Pyx_unpack_tuple2_exact(
+        PyObject* tuple, PyObject** pvalue1, PyObject** pvalue2, int decref_tuple) {
+    PyObject *value1 = NULL, *value2 = NULL;
+#if CYTHON_COMPILING_IN_PYPY
+    value1 = PySequence_ITEM(tuple, 0);  if (unlikely(!value1)) goto bad;
+    value2 = PySequence_ITEM(tuple, 1);  if (unlikely(!value2)) goto bad;
+#else
+    value1 = PyTuple_GET_ITEM(tuple, 0);  Py_INCREF(value1);
+    value2 = PyTuple_GET_ITEM(tuple, 1);  Py_INCREF(value2);
+#endif
+    if (decref_tuple) {
+        Py_DECREF(tuple);
+    }
+    *pvalue1 = value1;
+    *pvalue2 = value2;
+    return 0;
+#if CYTHON_COMPILING_IN_PYPY
+bad:
+    Py_XDECREF(value1);
+    Py_XDECREF(value2);
+    if (decref_tuple) { Py_XDECREF(tuple); }
+    return -1;
+#endif
+}
+static int __Pyx_unpack_tuple2_generic(PyObject* tuple, PyObject** pvalue1, PyObject** pvalue2,
+                                       int has_known_size, int decref_tuple) {
+    Py_ssize_t index;
+    PyObject *value1 = NULL, *value2 = NULL, *iter = NULL;
+    iternextfunc iternext;
+    iter = PyObject_GetIter(tuple);
+    if (unlikely(!iter)) goto bad;
+    if (decref_tuple) { Py_DECREF(tuple); tuple = NULL; }
+    iternext = Py_TYPE(iter)->tp_iternext;
+    value1 = iternext(iter); if (unlikely(!value1)) { index = 0; goto unpacking_failed; }
+    value2 = iternext(iter); if (unlikely(!value2)) { index = 1; goto unpacking_failed; }
+    if (!has_known_size && unlikely(__Pyx_IternextUnpackEndCheck(iternext(iter), 2))) goto bad;
+    Py_DECREF(iter);
+    *pvalue1 = value1;
+    *pvalue2 = value2;
+    return 0;
+unpacking_failed:
+    if (!has_known_size && __Pyx_IterFinish() == 0)
+        __Pyx_RaiseNeedMoreValuesError(index);
+bad:
+    Py_XDECREF(iter);
+    Py_XDECREF(value1);
+    Py_XDECREF(value2);
+    if (decref_tuple) { Py_XDECREF(tuple); }
+    return -1;
+}
+
+/* dict_iter */
+static CYTHON_INLINE PyObject* __Pyx_dict_iterator(PyObject* iterable, int is_dict, PyObject* method_name,
+                                                   Py_ssize_t* p_orig_length, int* p_source_is_dict) {
+    is_dict = is_dict || likely(PyDict_CheckExact(iterable));
+    *p_source_is_dict = is_dict;
+    if (is_dict) {
+#if !CYTHON_COMPILING_IN_PYPY
+        *p_orig_length = PyDict_Size(iterable);
+        Py_INCREF(iterable);
+        return iterable;
+#elif PY_MAJOR_VERSION >= 3
+        static PyObject *py_items = NULL, *py_keys = NULL, *py_values = NULL;
+        PyObject **pp = NULL;
+        if (method_name) {
+            const char *name = PyUnicode_AsUTF8(method_name);
+            if (strcmp(name, "iteritems") == 0) pp = &py_items;
+            else if (strcmp(name, "iterkeys") == 0) pp = &py_keys;
+            else if (strcmp(name, "itervalues") == 0) pp = &py_values;
+            if (pp) {
+                if (!*pp) {
+                    *pp = PyUnicode_FromString(name + 4);
+                    if (!*pp)
+                        return NULL;
+                }
+                method_name = *pp;
+            }
+        }
+#endif
+    }
+    *p_orig_length = 0;
+    if (method_name) {
+        PyObject* iter;
+        iterable = __Pyx_PyObject_CallMethod0(iterable, method_name);
+        if (!iterable)
+            return NULL;
+#if !CYTHON_COMPILING_IN_PYPY
+        if (PyTuple_CheckExact(iterable) || PyList_CheckExact(iterable))
+            return iterable;
+#endif
+        iter = PyObject_GetIter(iterable);
+        Py_DECREF(iterable);
+        return iter;
+    }
+    return PyObject_GetIter(iterable);
+}
+static CYTHON_INLINE int __Pyx_dict_iter_next(
+        PyObject* iter_obj, CYTHON_NCP_UNUSED Py_ssize_t orig_length, CYTHON_NCP_UNUSED Py_ssize_t* ppos,
+        PyObject** pkey, PyObject** pvalue, PyObject** pitem, int source_is_dict) {
+    PyObject* next_item;
+#if !CYTHON_COMPILING_IN_PYPY
+    if (source_is_dict) {
+        PyObject *key, *value;
+        if (unlikely(orig_length != PyDict_Size(iter_obj))) {
+            PyErr_SetString(PyExc_RuntimeError, "dictionary changed size during iteration");
+            return -1;
+        }
+        if (unlikely(!PyDict_Next(iter_obj, ppos, &key, &value))) {
+            return 0;
+        }
+        if (pitem) {
+            PyObject* tuple = PyTuple_New(2);
+            if (unlikely(!tuple)) {
+                return -1;
+            }
+            Py_INCREF(key);
+            Py_INCREF(value);
+            PyTuple_SET_ITEM(tuple, 0, key);
+            PyTuple_SET_ITEM(tuple, 1, value);
+            *pitem = tuple;
+        } else {
+            if (pkey) {
+                Py_INCREF(key);
+                *pkey = key;
+            }
+            if (pvalue) {
+                Py_INCREF(value);
+                *pvalue = value;
+            }
+        }
+        return 1;
+    } else if (PyTuple_CheckExact(iter_obj)) {
+        Py_ssize_t pos = *ppos;
+        if (unlikely(pos >= PyTuple_GET_SIZE(iter_obj))) return 0;
+        *ppos = pos + 1;
+        next_item = PyTuple_GET_ITEM(iter_obj, pos);
+        Py_INCREF(next_item);
+    } else if (PyList_CheckExact(iter_obj)) {
+        Py_ssize_t pos = *ppos;
+        if (unlikely(pos >= PyList_GET_SIZE(iter_obj))) return 0;
+        *ppos = pos + 1;
+        next_item = PyList_GET_ITEM(iter_obj, pos);
+        Py_INCREF(next_item);
+    } else
+#endif
+    {
+        next_item = PyIter_Next(iter_obj);
+        if (unlikely(!next_item)) {
+            return __Pyx_IterFinish();
+        }
+    }
+    if (pitem) {
+        *pitem = next_item;
+    } else if (pkey && pvalue) {
+        if (__Pyx_unpack_tuple2(next_item, pkey, pvalue, source_is_dict, source_is_dict, 1))
+            return -1;
+    } else if (pkey) {
+        *pkey = next_item;
+    } else {
+        *pvalue = next_item;
+    }
+    return 1;
+}
+
 /* GetException */
 #if CYTHON_FAST_THREAD_STATE
 static int __Pyx__GetException(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb)
 #else
 static int __Pyx_GetException(PyObject **type, PyObject **value, PyObject **tb)
 #endif
 {
@@ -4512,14 +4727,40 @@
         #else
             "cannot import name %S", name);
         #endif
     }
     return value;
 }
 
+/* PyDictVersioning */
+#if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_TYPE_SLOTS
+static CYTHON_INLINE PY_UINT64_T __Pyx_get_tp_dict_version(PyObject *obj) {
+    PyObject *dict = Py_TYPE(obj)->tp_dict;
+    return likely(dict) ? __PYX_GET_DICT_VERSION(dict) : 0;
+}
+static CYTHON_INLINE PY_UINT64_T __Pyx_get_object_dict_version(PyObject *obj) {
+    PyObject **dictptr = NULL;
+    Py_ssize_t offset = Py_TYPE(obj)->tp_dictoffset;
+    if (offset) {
+#if CYTHON_COMPILING_IN_CPYTHON
+        dictptr = (likely(offset > 0)) ? (PyObject **) ((char *)obj + offset) : _PyObject_GetDictPtr(obj);
+#else
+        dictptr = _PyObject_GetDictPtr(obj);
+#endif
+    }
+    return (dictptr && *dictptr) ? __PYX_GET_DICT_VERSION(*dictptr) : 0;
+}
+static CYTHON_INLINE int __Pyx_object_dict_version_matches(PyObject* obj, PY_UINT64_T tp_dict_version, PY_UINT64_T obj_dict_version) {
+    PyObject *dict = Py_TYPE(obj)->tp_dict;
+    if (unlikely(!dict) || unlikely(tp_dict_version != __PYX_GET_DICT_VERSION(dict)))
+        return 0;
+    return obj_dict_version == __Pyx_get_object_dict_version(obj);
+}
+#endif
+
 /* GetModuleGlobalName */
 #if CYTHON_USE_DICT_VERSIONS
 static PyObject *__Pyx__GetModuleGlobalName(PyObject *name, PY_UINT64_T *dict_version, PyObject **dict_cached_value)
 #else
 static CYTHON_INLINE PyObject *__Pyx__GetModuleGlobalName(PyObject *name)
 #endif
 {
@@ -4754,66 +4995,14 @@
     __Pyx_PyFrame_SetLineNumber(py_frame, py_line);
     PyTraceBack_Here(py_frame);
 bad:
     Py_XDECREF(py_code);
     Py_XDECREF(py_frame);
 }
 
-/* UnicodeAsUCS4 */
-static CYTHON_INLINE Py_UCS4 __Pyx_PyUnicode_AsPy_UCS4(PyObject* x) {
-   Py_ssize_t length;
-   #if CYTHON_PEP393_ENABLED
-   length = PyUnicode_GET_LENGTH(x);
-   if (likely(length == 1)) {
-       return PyUnicode_READ_CHAR(x, 0);
-   }
-   #else
-   length = PyUnicode_GET_SIZE(x);
-   if (likely(length == 1)) {
-       return PyUnicode_AS_UNICODE(x)[0];
-   }
-   #if Py_UNICODE_SIZE == 2
-   else if (PyUnicode_GET_SIZE(x) == 2) {
-       Py_UCS4 high_val = PyUnicode_AS_UNICODE(x)[0];
-       if (high_val >= 0xD800 && high_val <= 0xDBFF) {
-           Py_UCS4 low_val = PyUnicode_AS_UNICODE(x)[1];
-           if (low_val >= 0xDC00 && low_val <= 0xDFFF) {
-               return 0x10000 + (((high_val & ((1<<10)-1)) << 10) | (low_val & ((1<<10)-1)));
-           }
-       }
-   }
-   #endif
-   #endif
-   PyErr_Format(PyExc_ValueError,
-                "only single character unicode strings can be converted to Py_UCS4, "
-                "got length %" CYTHON_FORMAT_SSIZE_T "d", length);
-   return (Py_UCS4)-1;
-}
-
-/* ObjectAsUCS4 */
-static Py_UCS4 __Pyx__PyObject_AsPy_UCS4_raise_error(long ival) {
-   if (ival < 0) {
-       if (!PyErr_Occurred())
-           PyErr_SetString(PyExc_OverflowError,
-                           "cannot convert negative value to Py_UCS4");
-   } else {
-       PyErr_SetString(PyExc_OverflowError,
-                       "value too large to convert to Py_UCS4");
-   }
-   return (Py_UCS4)-1;
-}
-static Py_UCS4 __Pyx__PyObject_AsPy_UCS4(PyObject* x) {
-   long ival;
-   ival = __Pyx_PyInt_As_long(x);
-   if (unlikely(!__Pyx_is_valid_index(ival, 1114111 + 1))) {
-       return __Pyx__PyObject_AsPy_UCS4_raise_error(ival);
-   }
-   return (Py_UCS4)ival;
-}
-
 /* CIntToPy */
 static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value) {
     const long neg_one = (long) ((long) 0 - (long) 1), const_zero = (long) 0;
     const int is_unsigned = neg_one > const_zero;
     if (is_unsigned) {
         if (sizeof(long) < sizeof(long)) {
             return PyInt_FromLong((long) value);
```

### Comparing `aiohttp-4.0.0a0/aiohttp/_http_writer.pyx` & `aiohttp-4.0.0a1/aiohttp/_http_writer.pyx`

 * *Files 2% similar despite different names*

```diff
@@ -119,34 +119,34 @@
     cdef bytes ret
 
     _init_writer(&writer)
 
     try:
         if _write_str(&writer, status_line) < 0:
             raise
-        if _write_byte(&writer, '\r') < 0:
+        if _write_byte(&writer, b'\r') < 0:
             raise
-        if _write_byte(&writer, '\n') < 0:
+        if _write_byte(&writer, b'\n') < 0:
             raise
 
         for key, val in headers.items():
             if _write_str(&writer, to_str(key)) < 0:
                 raise
-            if _write_byte(&writer, ':') < 0:
+            if _write_byte(&writer, b':') < 0:
                 raise
-            if _write_byte(&writer, ' ') < 0:
+            if _write_byte(&writer, b' ') < 0:
                 raise
             if _write_str(&writer, to_str(val)) < 0:
                 raise
-            if _write_byte(&writer, '\r') < 0:
+            if _write_byte(&writer, b'\r') < 0:
                 raise
-            if _write_byte(&writer, '\n') < 0:
+            if _write_byte(&writer, b'\n') < 0:
                 raise
 
-        if _write_byte(&writer, '\r') < 0:
+        if _write_byte(&writer, b'\r') < 0:
             raise
-        if _write_byte(&writer, '\n') < 0:
+        if _write_byte(&writer, b'\n') < 0:
             raise
 
         return PyBytes_FromStringAndSize(writer.buf, writer.pos)
     finally:
         _release_writer(&writer)
```

### Comparing `aiohttp-4.0.0a0/aiohttp/_websocket.c` & `aiohttp-4.0.0a1/aiohttp/_websocket.c`

 * *Files 0% similar despite different names*

```diff
@@ -1,32 +1,19 @@
-/* Generated by Cython 0.29.2 */
-
-/* BEGIN: Cython Metadata
-{
-    "distutils": {
-        "depends": [],
-        "name": "aiohttp._websocket",
-        "sources": [
-            "aiohttp/_websocket.pyx"
-        ]
-    },
-    "module_name": "aiohttp._websocket"
-}
-END: Cython Metadata */
+/* Generated by Cython 0.29.13 */
 
 #define PY_SSIZE_T_CLEAN
 #include "Python.h"
 #ifndef Py_PYTHON_H
     #error Python headers needed to compile C extensions, please install development version of Python.
 #elif PY_VERSION_HEX < 0x02060000 || (0x03000000 <= PY_VERSION_HEX && PY_VERSION_HEX < 0x03030000)
     #error Cython requires Python 2.6+ or Python 3.3+.
 #else
-#define CYTHON_ABI "0_29_2"
-#define CYTHON_HEX_VERSION 0x001D02F0
-#define CYTHON_FUTURE_DIVISION 0
+#define CYTHON_ABI "0_29_13"
+#define CYTHON_HEX_VERSION 0x001D0DF0
+#define CYTHON_FUTURE_DIVISION 1
 #include <stddef.h>
 #ifndef offsetof
   #define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
 #endif
 #if !defined(WIN32) && !defined(MS_WINDOWS)
   #ifndef __stdcall
     #define __stdcall
@@ -319,16 +306,21 @@
 #if PY_MAJOR_VERSION < 3
   #define __Pyx_BUILTIN_MODULE_NAME "__builtin__"
   #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
           PyCode_New(a+k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
   #define __Pyx_DefaultClassType PyClass_Type
 #else
   #define __Pyx_BUILTIN_MODULE_NAME "builtins"
+#if PY_VERSION_HEX >= 0x030800A4 && PY_VERSION_HEX < 0x030800B2
+  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
+          PyCode_New(a, 0, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
+#else
   #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
           PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
+#endif
   #define __Pyx_DefaultClassType PyType_Type
 #endif
 #ifndef Py_TPFLAGS_CHECKTYPES
   #define Py_TPFLAGS_CHECKTYPES 0
 #endif
 #ifndef Py_TPFLAGS_HAVE_INDEX
   #define Py_TPFLAGS_HAVE_INDEX 0
@@ -355,34 +347,14 @@
 #endif
 #if CYTHON_FAST_PYCCALL
 #define __Pyx_PyFastCFunction_Check(func)\
     ((PyCFunction_Check(func) && (METH_FASTCALL == (PyCFunction_GET_FLAGS(func) & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS | METH_STACKLESS)))))
 #else
 #define __Pyx_PyFastCFunction_Check(func) 0
 #endif
-#if CYTHON_USE_DICT_VERSIONS
-#define __PYX_GET_DICT_VERSION(dict)  (((PyDictObject*)(dict))->ma_version_tag)
-#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)\
-    (version_var) = __PYX_GET_DICT_VERSION(dict);\
-    (cache_var) = (value);
-#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP) {\
-        static PY_UINT64_T __pyx_dict_version = 0;\
-        static PyObject *__pyx_dict_cached_value = NULL;\
-        if (likely(__PYX_GET_DICT_VERSION(DICT) == __pyx_dict_version)) {\
-            (VAR) = __pyx_dict_cached_value;\
-        } else {\
-            (VAR) = __pyx_dict_cached_value = (LOOKUP);\
-            __pyx_dict_version = __PYX_GET_DICT_VERSION(DICT);\
-        }\
-    }
-#else
-#define __PYX_GET_DICT_VERSION(dict)  (0)
-#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)
-#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP)  (VAR) = (LOOKUP);
-#endif
 #if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Malloc)
   #define PyObject_Malloc(s)   PyMem_Malloc(s)
   #define PyObject_Free(p)     PyMem_Free(p)
   #define PyObject_Realloc(p)  PyMem_Realloc(p)
 #endif
 #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x030400A1
   #define PyMem_RawMalloc(n)           PyMem_Malloc(n)
@@ -407,15 +379,15 @@
 #endif
 #if PY_VERSION_HEX < 0x030700A2 && !defined(PyThread_tss_create) && !defined(Py_tss_NEEDS_INIT)
 #include "pythread.h"
 #define Py_tss_NEEDS_INIT 0
 typedef int Py_tss_t;
 static CYTHON_INLINE int PyThread_tss_create(Py_tss_t *key) {
   *key = PyThread_create_key();
-  return 0; // PyThread_create_key reports success always
+  return 0;
 }
 static CYTHON_INLINE Py_tss_t * PyThread_tss_alloc(void) {
   Py_tss_t *key = (Py_tss_t *)PyObject_Malloc(sizeof(Py_tss_t));
   *key = Py_tss_NEEDS_INIT;
   return key;
 }
 static CYTHON_INLINE void PyThread_tss_free(Py_tss_t *key) {
@@ -430,15 +402,15 @@
 }
 static CYTHON_INLINE int PyThread_tss_set(Py_tss_t *key, void *value) {
   return PyThread_set_key_value(*key, value);
 }
 static CYTHON_INLINE void * PyThread_tss_get(Py_tss_t *key) {
   return PyThread_get_key_value(*key);
 }
-#endif // TSS (Thread Specific Storage) API
+#endif
 #if CYTHON_COMPILING_IN_CPYTHON || defined(_PyDict_NewPresized)
 #define __Pyx_PyDict_NewPresized(n)  ((n <= 8) ? PyDict_New() : _PyDict_NewPresized(n))
 #else
 #define __Pyx_PyDict_NewPresized(n)  PyDict_New()
 #endif
 #if PY_MAJOR_VERSION >= 3 || CYTHON_FUTURE_DIVISION
   #define __Pyx_PyNumber_Divide(x,y)         PyNumber_TrueDivide(x,y)
@@ -633,15 +605,16 @@
 #define CYTHON_WITHOUT_ASSERTIONS
 #endif
 
 typedef struct {PyObject **p; const char *s; const Py_ssize_t n; const char* encoding;
                 const char is_unicode; const char is_str; const char intern; } __Pyx_StringTabEntry;
 
 #define __PYX_DEFAULT_STRING_ENCODING_IS_ASCII 0
-#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT 0
+#define __PYX_DEFAULT_STRING_ENCODING_IS_UTF8 0
+#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT (PY_MAJOR_VERSION >= 3 && __PYX_DEFAULT_STRING_ENCODING_IS_UTF8)
 #define __PYX_DEFAULT_STRING_ENCODING ""
 #define __Pyx_PyObject_FromString __Pyx_PyBytes_FromString
 #define __Pyx_PyObject_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
 #define __Pyx_uchar_cast(c) ((unsigned char)c)
 #define __Pyx_long_cast(x) ((long)x)
 #define __Pyx_fits_Py_ssize_t(v, type, is_signed)  (\
     (sizeof(type) < sizeof(Py_ssize_t))  ||\
@@ -828,15 +801,15 @@
 static int __pyx_lineno;
 static int __pyx_clineno = 0;
 static const char * __pyx_cfilenm= __FILE__;
 static const char *__pyx_filename;
 
 
 static const char *__pyx_f[] = {
-  "aiohttp\\_websocket.pyx",
+  "aiohttp/_websocket.pyx",
   "type.pxd",
   "bool.pxd",
   "complex.pxd",
 };
 
 /*--- Type declarations ---*/
 
@@ -934,15 +907,15 @@
 #endif
 
 /* PyFunctionFastCall.proto */
 #if CYTHON_FAST_PYCALL
 #define __Pyx_PyFunction_FastCall(func, args, nargs)\
     __Pyx_PyFunction_FastCallDict((func), (args), (nargs), NULL)
 #if 1 || PY_VERSION_HEX < 0x030600B1
-static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs);
+static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, Py_ssize_t nargs, PyObject *kwargs);
 #else
 #define __Pyx_PyFunction_FastCallDict(func, args, nargs, kwargs) _PyFunction_FastCallDict(func, args, nargs, kwargs)
 #endif
 #define __Pyx_BUILD_ASSERT_EXPR(cond)\
     (sizeof(char [1 - 2*!(cond)]) - 1)
 #ifndef Py_MEMBER_SIZE
 #define Py_MEMBER_SIZE(type, member) sizeof(((type *)0)->member)
@@ -978,14 +951,40 @@
    __Pyx_ImportType_CheckSize_Error = 0,
    __Pyx_ImportType_CheckSize_Warn = 1,
    __Pyx_ImportType_CheckSize_Ignore = 2
 };
 static PyTypeObject *__Pyx_ImportType(PyObject* module, const char *module_name, const char *class_name, size_t size, enum __Pyx_ImportType_CheckSize check_size);
 #endif
 
+/* PyDictVersioning.proto */
+#if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_TYPE_SLOTS
+#define __PYX_DICT_VERSION_INIT  ((PY_UINT64_T) -1)
+#define __PYX_GET_DICT_VERSION(dict)  (((PyDictObject*)(dict))->ma_version_tag)
+#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)\
+    (version_var) = __PYX_GET_DICT_VERSION(dict);\
+    (cache_var) = (value);
+#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP) {\
+    static PY_UINT64_T __pyx_dict_version = 0;\
+    static PyObject *__pyx_dict_cached_value = NULL;\
+    if (likely(__PYX_GET_DICT_VERSION(DICT) == __pyx_dict_version)) {\
+        (VAR) = __pyx_dict_cached_value;\
+    } else {\
+        (VAR) = __pyx_dict_cached_value = (LOOKUP);\
+        __pyx_dict_version = __PYX_GET_DICT_VERSION(DICT);\
+    }\
+}
+static CYTHON_INLINE PY_UINT64_T __Pyx_get_tp_dict_version(PyObject *obj);
+static CYTHON_INLINE PY_UINT64_T __Pyx_get_object_dict_version(PyObject *obj);
+static CYTHON_INLINE int __Pyx_object_dict_version_matches(PyObject* obj, PY_UINT64_T tp_dict_version, PY_UINT64_T obj_dict_version);
+#else
+#define __PYX_GET_DICT_VERSION(dict)  (0)
+#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)
+#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP)  (VAR) = (LOOKUP);
+#endif
+
 /* PyThreadStateGet.proto */
 #if CYTHON_FAST_THREAD_STATE
 #define __Pyx_PyThreadState_declare  PyThreadState *__pyx_tstate;
 #define __Pyx_PyThreadState_assign  __pyx_tstate = __Pyx_PyThreadState_Current;
 #define __Pyx_PyErr_Occurred()  __pyx_tstate->curexc_type
 #else
 #define __Pyx_PyThreadState_declare
@@ -1176,15 +1175,15 @@
 static const char __pyx_k_data_len[] = "data_len";
 static const char __pyx_k_mask_buf[] = "mask_buf";
 static const char __pyx_k_uint32_msk[] = "uint32_msk";
 static const char __pyx_k_uint64_msk[] = "uint64_msk";
 static const char __pyx_k_aiohttp__websocket[] = "aiohttp._websocket";
 static const char __pyx_k_cline_in_traceback[] = "cline_in_traceback";
 static const char __pyx_k_websocket_mask_cython[] = "_websocket_mask_cython";
-static const char __pyx_k_aiohttp__websocket_pyx[] = "aiohttp\\_websocket.pyx";
+static const char __pyx_k_aiohttp__websocket_pyx[] = "aiohttp/_websocket.pyx";
 static PyObject *__pyx_n_s_aiohttp__websocket;
 static PyObject *__pyx_kp_s_aiohttp__websocket_pyx;
 static PyObject *__pyx_n_s_cline_in_traceback;
 static PyObject *__pyx_n_s_data;
 static PyObject *__pyx_n_s_data_len;
 static PyObject *__pyx_n_s_i;
 static PyObject *__pyx_n_s_in_buf;
@@ -1942,18 +1941,17 @@
   __pyx_m = PyModule_Create(&__pyx_moduledef);
   #endif
   if (unlikely(!__pyx_m)) __PYX_ERR(0, 1, __pyx_L1_error)
   #endif
   __pyx_d = PyModule_GetDict(__pyx_m); if (unlikely(!__pyx_d)) __PYX_ERR(0, 1, __pyx_L1_error)
   Py_INCREF(__pyx_d);
   __pyx_b = PyImport_AddModule(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_b)) __PYX_ERR(0, 1, __pyx_L1_error)
-  __pyx_cython_runtime = PyImport_AddModule((char *) "cython_runtime"); if (unlikely(!__pyx_cython_runtime)) __PYX_ERR(0, 1, __pyx_L1_error)
-  #if CYTHON_COMPILING_IN_PYPY
   Py_INCREF(__pyx_b);
-  #endif
+  __pyx_cython_runtime = PyImport_AddModule((char *) "cython_runtime"); if (unlikely(!__pyx_cython_runtime)) __PYX_ERR(0, 1, __pyx_L1_error)
+  Py_INCREF(__pyx_cython_runtime);
   if (PyObject_SetAttrString(__pyx_m, "__builtins__", __pyx_b) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
   /*--- Initialize various global constants etc. ---*/
   if (__Pyx_InitGlobals() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
   #if PY_MAJOR_VERSION < 3 && (__PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT)
   if (__Pyx_init_sys_getdefaultencoding_params() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
   #endif
   if (__pyx_module_is_main_aiohttp___websocket) {
@@ -1964,17 +1962,17 @@
     PyObject *modules = PyImport_GetModuleDict(); if (unlikely(!modules)) __PYX_ERR(0, 1, __pyx_L1_error)
     if (!PyDict_GetItemString(modules, "aiohttp._websocket")) {
       if (unlikely(PyDict_SetItemString(modules, "aiohttp._websocket", __pyx_m) < 0)) __PYX_ERR(0, 1, __pyx_L1_error)
     }
   }
   #endif
   /*--- Builtin init code ---*/
-  if (__Pyx_InitCachedBuiltins() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
+  if (__Pyx_InitCachedBuiltins() < 0) goto __pyx_L1_error;
   /*--- Constants init code ---*/
-  if (__Pyx_InitCachedConstants() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
+  if (__Pyx_InitCachedConstants() < 0) goto __pyx_L1_error;
   /*--- Global type/function init code ---*/
   (void)__Pyx_modinit_global_init_code();
   (void)__Pyx_modinit_variable_export_code();
   (void)__Pyx_modinit_function_export_code();
   (void)__Pyx_modinit_type_init_code();
   if (unlikely(__Pyx_modinit_type_import_code() != 0)) goto __pyx_L1_error;
   (void)__Pyx_modinit_variable_import_code();
@@ -2268,15 +2266,15 @@
     result = PyEval_EvalFrameEx(f,0);
     ++tstate->recursion_depth;
     Py_DECREF(f);
     --tstate->recursion_depth;
     return result;
 }
 #if 1 || PY_VERSION_HEX < 0x030600B1
-static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs) {
+static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, Py_ssize_t nargs, PyObject *kwargs) {
     PyCodeObject *co = (PyCodeObject *)PyFunction_GET_CODE(func);
     PyObject *globals = PyFunction_GET_GLOBALS(func);
     PyObject *argdefs = PyFunction_GET_DEFAULTS(func);
     PyObject *closure;
 #if PY_MAJOR_VERSION >= 3
     PyObject *kwdefs;
 #endif
@@ -2339,20 +2337,20 @@
     }
     else {
         d = NULL;
         nd = 0;
     }
 #if PY_MAJOR_VERSION >= 3
     result = PyEval_EvalCodeEx((PyObject*)co, globals, (PyObject *)NULL,
-                               args, nargs,
+                               args, (int)nargs,
                                k, (int)nk,
                                d, (int)nd, kwdefs, closure);
 #else
     result = PyEval_EvalCodeEx(co, globals, (PyObject *)NULL,
-                               args, nargs,
+                               args, (int)nargs,
                                k, (int)nk,
                                d, (int)nd, closure);
 #endif
     Py_XDECREF(kwtuple);
 done:
     Py_LeaveRecursiveCall();
     return result;
@@ -2497,14 +2495,40 @@
     return (PyTypeObject *)result;
 bad:
     Py_XDECREF(result);
     return NULL;
 }
 #endif
 
+/* PyDictVersioning */
+#if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_TYPE_SLOTS
+static CYTHON_INLINE PY_UINT64_T __Pyx_get_tp_dict_version(PyObject *obj) {
+    PyObject *dict = Py_TYPE(obj)->tp_dict;
+    return likely(dict) ? __PYX_GET_DICT_VERSION(dict) : 0;
+}
+static CYTHON_INLINE PY_UINT64_T __Pyx_get_object_dict_version(PyObject *obj) {
+    PyObject **dictptr = NULL;
+    Py_ssize_t offset = Py_TYPE(obj)->tp_dictoffset;
+    if (offset) {
+#if CYTHON_COMPILING_IN_CPYTHON
+        dictptr = (likely(offset > 0)) ? (PyObject **) ((char *)obj + offset) : _PyObject_GetDictPtr(obj);
+#else
+        dictptr = _PyObject_GetDictPtr(obj);
+#endif
+    }
+    return (dictptr && *dictptr) ? __PYX_GET_DICT_VERSION(*dictptr) : 0;
+}
+static CYTHON_INLINE int __Pyx_object_dict_version_matches(PyObject* obj, PY_UINT64_T tp_dict_version, PY_UINT64_T obj_dict_version) {
+    PyObject *dict = Py_TYPE(obj)->tp_dict;
+    if (unlikely(!dict) || unlikely(tp_dict_version != __PYX_GET_DICT_VERSION(dict)))
+        return 0;
+    return obj_dict_version == __Pyx_get_object_dict_version(obj);
+}
+#endif
+
 /* PyErrFetchRestore */
 #if CYTHON_FAST_THREAD_STATE
 static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb) {
     PyObject *tmp_type, *tmp_value, *tmp_tb;
     tmp_type = tstate->curexc_type;
     tmp_value = tstate->curexc_value;
     tmp_tb = tstate->curexc_traceback;
```

### Comparing `aiohttp-4.0.0a0/aiohttp/_websocket.pyx` & `aiohttp-4.0.0a1/aiohttp/_websocket.pyx`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/aiohttp.egg-info/PKG-INFO` & `aiohttp-4.0.0a1/PKG-INFO`

 * *Files 24% similar despite different names*

```diff
@@ -1,393 +1,549 @@
-Metadata-Version: 2.1
-Name: aiohttp
-Version: 4.0.0a0
-Summary: Async http client/server framework (asyncio)
-Home-page: https://github.com/aio-libs/aiohttp
-Author: Nikolay Kim
-Author-email: fafhrd91@gmail.com
-Maintainer: Nikolay Kim <fafhrd91@gmail.com>, Andrew Svetlov <andrew.svetlov@gmail.com>
-Maintainer-email: aio-libs@googlegroups.com
-License: Apache 2
-Project-URL: CI: AppVeyor, https://ci.appveyor.com/project/aio-libs/aiohttp
-Project-URL: Coverage: codecov, https://codecov.io/github/aio-libs/aiohttp
-Project-URL: CI: Circle, https://circleci.com/gh/aio-libs/aiohttp
-Project-URL: Chat: Gitter, https://gitter.im/aio-libs/Lobby
-Project-URL: CI: Travis, https://travis-ci.com/aio-libs/aiohttp
-Project-URL: GitHub: issues, https://github.com/aio-libs/aiohttp/issues
-Project-URL: Docs: RTD, https://docs.aiohttp.org
-Project-URL: GitHub: repo, https://github.com/aio-libs/aiohttp
-Project-URL: CI: Shippable, https://app.shippable.com/github/aio-libs/aiohttp
-Description: ==================================
-        Async http client/server framework
-        ==================================
-        
-        .. image:: https://raw.githubusercontent.com/aio-libs/aiohttp/master/docs/_static/aiohttp-icon-128x128.png
-           :height: 64px
-           :width: 64px
-           :alt: aiohttp logo
-        
-        |
-        
-        .. image:: https://travis-ci.com/aio-libs/aiohttp.svg?branch=master
-           :target: https://travis-ci.com/aio-libs/aiohttp
-           :align: right
-           :alt: Travis status for master branch
-        
-        .. image:: https://ci.appveyor.com/api/projects/status/tnddy9k6pphl8w7k/branch/master?svg=true
-           :target: https://ci.appveyor.com/project/aio-libs/aiohttp
-           :align: right
-           :alt: AppVeyor status for master branch
-        
-        .. image:: https://codecov.io/gh/aio-libs/aiohttp/branch/master/graph/badge.svg
-           :target: https://codecov.io/gh/aio-libs/aiohttp
-           :alt: codecov.io status for master branch
-        
-        .. image:: https://badge.fury.io/py/aiohttp.svg
-           :target: https://pypi.org/project/aiohttp
-           :alt: Latest PyPI package version
-        
-        .. image:: https://readthedocs.org/projects/aiohttp/badge/?version=latest
-           :target: https://docs.aiohttp.org/
-           :alt: Latest Read The Docs
-        
-        .. image:: https://badges.gitter.im/Join%20Chat.svg
-            :target: https://gitter.im/aio-libs/Lobby
-            :alt: Chat on Gitter
-        
-        Key Features
-        ============
-        
-        - Supports both client and server side of HTTP protocol.
-        - Supports both client and server Web-Sockets out-of-the-box and avoids
-          Callback Hell.
-        - Provides Web-server with middlewares and pluggable routing.
-        
-        
-        Getting started
-        ===============
-        
-        Client
-        ------
-        
-        To get something from the web:
-        
-        .. code-block:: python
-        
-          import aiohttp
-          import asyncio
-        
-          async def fetch(session, url):
-              async with session.get(url) as response:
-                  return await response.text()
-        
-          async def main():
-              async with aiohttp.ClientSession() as session:
-                  html = await fetch(session, 'http://python.org')
-                  print(html)
-        
-          if __name__ == '__main__':
-              loop = asyncio.get_event_loop()
-              loop.run_until_complete(main())
-        
-        
-        Server
-        ------
-        
-        An example using a simple server:
-        
-        .. code-block:: python
-        
-            # examples/server_simple.py
-            from aiohttp import web
-        
-            async def handle(request):
-                name = request.match_info.get('name', "Anonymous")
-                text = "Hello, " + name
-                return web.Response(text=text)
-        
-            async def wshandle(request):
-                ws = web.WebSocketResponse()
-                await ws.prepare(request)
-        
-                async for msg in ws:
-                    if msg.type == web.WSMsgType.text:
-                        await ws.send_str("Hello, {}".format(msg.data))
-                    elif msg.type == web.WSMsgType.binary:
-                        await ws.send_bytes(msg.data)
-                    elif msg.type == web.WSMsgType.close:
-                        break
-        
-                return ws
-        
-        
-            app = web.Application()
-            app.add_routes([web.get('/', handle),
-                            web.get('/echo', wshandle),
-                            web.get('/{name}', handle)])
-        
-            web.run_app(app)
-        
-        
-        Documentation
-        =============
-        
-        https://aiohttp.readthedocs.io/
-        
-        
-        Demos
-        =====
-        
-        https://github.com/aio-libs/aiohttp-demos
-        
-        
-        External links
-        ==============
-        
-        * `Third party libraries
-          <http://aiohttp.readthedocs.io/en/latest/third_party.html>`_
-        * `Built with aiohttp
-          <http://aiohttp.readthedocs.io/en/latest/built_with.html>`_
-        * `Powered by aiohttp
-          <http://aiohttp.readthedocs.io/en/latest/powered_by.html>`_
-        
-        Feel free to make a Pull Request for adding your link to these pages!
-        
-        
-        Communication channels
-        ======================
-        
-        *aio-libs* google group: https://groups.google.com/forum/#!forum/aio-libs
-        
-        Feel free to post your questions and ideas here.
-        
-        *gitter chat* https://gitter.im/aio-libs/Lobby
-        
-        We support `Stack Overflow
-        <https://stackoverflow.com/questions/tagged/aiohttp>`_.
-        Please add *aiohttp* tag to your question there.
-        
-        Requirements
-        ============
-        
-        - Python >= 3.5.3
-        - async-timeout_
-        - attrs_
-        - chardet_
-        - multidict_
-        - yarl_
-        
-        Optionally you may install the cChardet_ and aiodns_ libraries (highly
-        recommended for sake of speed).
-        
-        .. _chardet: https://pypi.python.org/pypi/chardet
-        .. _aiodns: https://pypi.python.org/pypi/aiodns
-        .. _attrs: https://github.com/python-attrs/attrs
-        .. _multidict: https://pypi.python.org/pypi/multidict
-        .. _yarl: https://pypi.python.org/pypi/yarl
-        .. _async-timeout: https://pypi.python.org/pypi/async_timeout
-        .. _cChardet: https://pypi.python.org/pypi/cchardet
-        
-        License
-        =======
-        
-        ``aiohttp`` is offered under the Apache 2 license.
-        
-        
-        Keepsafe
-        ========
-        
-        The aiohttp community would like to thank Keepsafe
-        (https://www.getkeepsafe.com) for its support in the early days of
-        the project.
-        
-        
-        Source code
-        ===========
-        
-        The latest developer version is available in a GitHub repository:
-        https://github.com/aio-libs/aiohttp
-        
-        Benchmarks
-        ==========
-        
-        If you are interested in efficiency, the AsyncIO community maintains a
-        list of benchmarks on the official wiki:
-        https://github.com/python/asyncio/wiki/Benchmarks
-        
-        =========
-        Changelog
-        =========
-        
-        ..
-            You should *NOT* be adding new change log entries to this file, this
-            file is managed by towncrier. You *may* edit previous change logs to
-            fix problems like typo corrections or such.
-            To add a new change log entry, please see
-            https://pip.pypa.io/en/latest/development/#adding-a-news-entry
-            we named the news folder "changes".
-        
-            WARNING: Don't drop the next directive!
-        
-        .. towncrier release notes start
-        
-        3.5.2 (2019-01-08)
-        ==================
-        
-        Features
-        --------
-        
-        - ``FileResponse`` from ``web_fileresponse.py`` uses a ``ThreadPoolExecutor`` to work with files asynchronously.
-          I/O based payloads from ``payload.py`` uses a ``ThreadPoolExecutor`` to work with I/O objects asynchronously.
-          `#3313 <https://github.com/aio-libs/aiohttp/issues/3313>`_
-        - Internal Server Errors in plain text if the browser does not support HTML.
-          `#3483 <https://github.com/aio-libs/aiohttp/issues/3483>`_
-        
-        
-        Bugfixes
-        --------
-        
-        - Preserve MultipartWriter parts headers on write.
-        
-          Refactor the way how ``Payload.headers`` are handled. Payload instances now always
-          have headers and Content-Type defined.
-        
-          Fix Payload Content-Disposition header reset after initial creation.
-          `#3035 <https://github.com/aio-libs/aiohttp/issues/3035>`_
-        - Log suppressed exceptions in ``GunicornWebWorker``.
-          `#3464 <https://github.com/aio-libs/aiohttp/issues/3464>`_
-        - Remove wildcard imports.
-          `#3468 <https://github.com/aio-libs/aiohttp/issues/3468>`_
-        - Use the same task for app initialization and web server handling in gunicorn workers.
-          It allows to use Python3.7 context vars smoothly.
-          `#3471 <https://github.com/aio-libs/aiohttp/issues/3471>`_
-        - Fix handling of chunked+gzipped response when first chunk does not give uncompressed data
-          `#3477 <https://github.com/aio-libs/aiohttp/issues/3477>`_
-        - Replace ``collections.MutableMapping`` with ``collections.abc.MutableMapping`` to avoid a deprecation warning.
-          `#3480 <https://github.com/aio-libs/aiohttp/issues/3480>`_
-        - ``Payload.size`` type annotation changed from `Optional[float]` to `Optional[int]`.
-          `#3484 <https://github.com/aio-libs/aiohttp/issues/3484>`_
-        - Ignore done tasks when cancels pending activities on ``web.run_app`` finalization.
-          `#3497 <https://github.com/aio-libs/aiohttp/issues/3497>`_
-        
-        
-        Improved Documentation
-        ----------------------
-        
-        - Add documentation for ``aiohttp.web.HTTPException``.
-          `#3490 <https://github.com/aio-libs/aiohttp/issues/3490>`_
-        
-        
-        Misc
-        ----
-        
-        - `#3487 <https://github.com/aio-libs/aiohttp/issues/3487>`_
-        
-        
-        ----
-        
-        
-        3.5.1 (2018-12-24)
-        ====================
-        
-        - Fix a regression about ``ClientSession._requote_redirect_url`` modification in debug
-          mode.
-        
-        3.5.0 (2018-12-22)
-        ====================
-        
-        Features
-        --------
-        
-        - The library type annotations are checked in strict mode now.
-        - Add support for setting cookies for individual request (`#2387 <https://github.com/aio-libs/aiohttp/pull/2387>`_)
-        - Application.add_domain implementation (`#2809 <https://github.com/aio-libs/aiohttp/pull/2809>`_)
-        - The default ``app`` in the request returned by ``test_utils.make_mocked_request``
-          can now have objects assigned to it and retrieved using the ``[]`` operator. (`#3174 <https://github.com/aio-libs/aiohttp/pull/3174>`_)
-        - Make ``request.url`` accessible when transport is closed. (`#3177 <https://github.com/aio-libs/aiohttp/pull/3177>`_)
-        - Add ``zlib_executor_size`` argument to ``Response`` constructor to allow compression to run in a background executor to avoid blocking the main thread and potentially triggering health check failures. (`#3205 <https://github.com/aio-libs/aiohttp/pull/3205>`_)
-        - Enable users to set `ClientTimeout` in `aiohttp.request` (`#3213 <https://github.com/aio-libs/aiohttp/pull/3213>`_)
-        - Don't raise a warning if ``NETRC`` environment variable is not set and ``~/.netrc`` file
-          doesn't exist. (`#3267 <https://github.com/aio-libs/aiohttp/pull/3267>`_)
-        - Add default logging handler to web.run_app
-        
-          If the `Application.debug` flag is set and the default logger `aiohttp.access` is used, access logs will now be output using a `stderr` `StreamHandler` if no handlers are attached. Furthermore, if the default logger has no log level set, the log level will be set to `DEBUG`. (`#3324 <https://github.com/aio-libs/aiohttp/pull/3324>`_)
-        - Add method argument to ``session.ws_connect()``.
-        
-          Sometimes server API requires a different HTTP method for WebSocket connection establishment.
-        
-          For example, ``Docker exec`` needs POST. (`#3378 <https://github.com/aio-libs/aiohttp/pull/3378>`_)
-        - Create a task per request handling. (`#3406 <https://github.com/aio-libs/aiohttp/pull/3406>`_)
-        
-        
-        Bugfixes
-        --------
-        
-        - Enable passing `access_log_class` via `handler_args` (`#3158 <https://github.com/aio-libs/aiohttp/pull/3158>`_)
-        - Return empty bytes with end-of-chunk marker in empty stream reader. (`#3186 <https://github.com/aio-libs/aiohttp/pull/3186>`_)
-        - Accept ``CIMultiDictProxy`` instances for ``headers`` argument in ``web.Response``
-          constructor. (`#3207 <https://github.com/aio-libs/aiohttp/pull/3207>`_)
-        - Don't uppercase HTTP method in parser (`#3233 <https://github.com/aio-libs/aiohttp/pull/3233>`_)
-        - Make method match regexp RFC-7230 compliant (`#3235 <https://github.com/aio-libs/aiohttp/pull/3235>`_)
-        - Add ``app.pre_frozen`` state to properly handle startup signals in sub-applications. (`#3237 <https://github.com/aio-libs/aiohttp/pull/3237>`_)
-        - Enhanced parsing and validation of helpers.BasicAuth.decode. (`#3239 <https://github.com/aio-libs/aiohttp/pull/3239>`_)
-        - Change imports from collections module in preparation for 3.8. (`#3258 <https://github.com/aio-libs/aiohttp/pull/3258>`_)
-        - Ensure Host header is added first to ClientRequest to better replicate browser (`#3265 <https://github.com/aio-libs/aiohttp/pull/3265>`_)
-        - Fix forward compatibility with Python 3.8: importing ABCs directly from the collections module will not be supported anymore. (`#3273 <https://github.com/aio-libs/aiohttp/pull/3273>`_)
-        - Keep the query string by `normalize_path_middleware`. (`#3278 <https://github.com/aio-libs/aiohttp/pull/3278>`_)
-        - Fix missing parameter ``raise_for_status`` for aiohttp.request() (`#3290 <https://github.com/aio-libs/aiohttp/pull/3290>`_)
-        - Bracket IPv6 addresses in the HOST header (`#3304 <https://github.com/aio-libs/aiohttp/pull/3304>`_)
-        - Fix default message for server ping and pong frames. (`#3308 <https://github.com/aio-libs/aiohttp/pull/3308>`_)
-        - Fix tests/test_connector.py typo and tests/autobahn/server.py duplicate loop def. (`#3337 <https://github.com/aio-libs/aiohttp/pull/3337>`_)
-        - Fix false-negative indicator end_of_HTTP_chunk in StreamReader.readchunk function (`#3361 <https://github.com/aio-libs/aiohttp/pull/3361>`_)
-        - Release HTTP response before raising status exception (`#3364 <https://github.com/aio-libs/aiohttp/pull/3364>`_)
-        - Fix task cancellation when ``sendfile()`` syscall is used by static file handling. (`#3383 <https://github.com/aio-libs/aiohttp/pull/3383>`_)
-        - Fix stack trace for ``asyncio.TimeoutError`` which was not logged, when it is caught
-          in the handler. (`#3414 <https://github.com/aio-libs/aiohttp/pull/3414>`_)
-        
-        
-        Improved Documentation
-        ----------------------
-        
-        - Improve documentation of ``Application.make_handler`` parameters. (`#3152 <https://github.com/aio-libs/aiohttp/pull/3152>`_)
-        - Fix BaseRequest.raw_headers doc. (`#3215 <https://github.com/aio-libs/aiohttp/pull/3215>`_)
-        - Fix typo in TypeError exception reason in ``web.Application._handle`` (`#3229 <https://github.com/aio-libs/aiohttp/pull/3229>`_)
-        - Make server access log format placeholder %b documentation reflect
-          behavior and docstring. (`#3307 <https://github.com/aio-libs/aiohttp/pull/3307>`_)
-        
-        
-        Deprecations and Removals
-        -------------------------
-        
-        - Deprecate modification of ``session.requote_redirect_url`` (`#2278 <https://github.com/aio-libs/aiohttp/pull/2278>`_)
-        - Deprecate ``stream.unread_data()`` (`#3260 <https://github.com/aio-libs/aiohttp/pull/3260>`_)
-        - Deprecated use of boolean in ``resp.enable_compression()`` (`#3318 <https://github.com/aio-libs/aiohttp/pull/3318>`_)
-        - Encourage creation of aiohttp public objects inside a coroutine (`#3331 <https://github.com/aio-libs/aiohttp/pull/3331>`_)
-        - Drop dead ``Connection.detach()`` and ``Connection.writer``. Both methods were broken
-          for more than 2 years. (`#3358 <https://github.com/aio-libs/aiohttp/pull/3358>`_)
-        - Deprecate ``app.loop``, ``request.loop``, ``client.loop`` and ``connector.loop`` properties. (`#3374 <https://github.com/aio-libs/aiohttp/pull/3374>`_)
-        - Deprecate explicit debug argument. Use asyncio debug mode instead. (`#3381 <https://github.com/aio-libs/aiohttp/pull/3381>`_)
-        - Deprecate body parameter in HTTPException (and derived classes) constructor. (`#3385 <https://github.com/aio-libs/aiohttp/pull/3385>`_)
-        - Deprecate bare connector close, use ``async with connector:`` and ``await connector.close()`` instead. (`#3417 <https://github.com/aio-libs/aiohttp/pull/3417>`_)
-        - Deprecate obsolete ``read_timeout`` and ``conn_timeout`` in ``ClientSession`` constructor. (`#3438 <https://github.com/aio-libs/aiohttp/pull/3438>`_)
-        
-        
-        Misc
-        ----
-        
-        - #3341, #3351
-Platform: UNKNOWN
-Classifier: License :: OSI Approved :: Apache Software License
-Classifier: Intended Audience :: Developers
-Classifier: Programming Language :: Python
-Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.5
-Classifier: Programming Language :: Python :: 3.6
-Classifier: Programming Language :: Python :: 3.7
-Classifier: Development Status :: 5 - Production/Stable
-Classifier: Operating System :: POSIX
-Classifier: Operating System :: MacOS :: MacOS X
-Classifier: Operating System :: Microsoft :: Windows
-Classifier: Topic :: Internet :: WWW/HTTP
-Classifier: Framework :: AsyncIO
-Requires-Python: >=3.5.3
-Provides-Extra: speedups
+Metadata-Version: 2.1
+Name: aiohttp
+Version: 4.0.0a1
+Summary: Async http client/server framework (asyncio)
+Home-page: https://github.com/aio-libs/aiohttp
+Author: Nikolay Kim
+Author-email: fafhrd91@gmail.com
+Maintainer: Nikolay Kim <fafhrd91@gmail.com>, Andrew Svetlov <andrew.svetlov@gmail.com>
+Maintainer-email: aio-libs@googlegroups.com
+License: Apache 2
+Project-URL: Chat: Gitter, https://gitter.im/aio-libs/Lobby
+Project-URL: CI: AppVeyor, https://ci.appveyor.com/project/aio-libs/aiohttp
+Project-URL: CI: Circle, https://circleci.com/gh/aio-libs/aiohttp
+Project-URL: CI: Shippable, https://app.shippable.com/github/aio-libs/aiohttp
+Project-URL: CI: Travis, https://travis-ci.com/aio-libs/aiohttp
+Project-URL: Coverage: codecov, https://codecov.io/github/aio-libs/aiohttp
+Project-URL: Docs: RTD, https://docs.aiohttp.org
+Project-URL: GitHub: issues, https://github.com/aio-libs/aiohttp/issues
+Project-URL: GitHub: repo, https://github.com/aio-libs/aiohttp
+Description: ==================================
+        Async http client/server framework
+        ==================================
+        
+        .. image:: https://raw.githubusercontent.com/aio-libs/aiohttp/master/docs/_static/aiohttp-icon-128x128.png
+           :height: 64px
+           :width: 64px
+           :alt: aiohttp logo
+        
+        |
+        
+        .. image:: https://travis-ci.com/aio-libs/aiohttp.svg?branch=master
+           :target: https://travis-ci.com/aio-libs/aiohttp
+           :align: right
+           :alt: Travis status for master branch
+        
+        .. image:: https://ci.appveyor.com/api/projects/status/tnddy9k6pphl8w7k/branch/master?svg=true
+           :target: https://ci.appveyor.com/project/aio-libs/aiohttp
+           :align: right
+           :alt: AppVeyor status for master branch
+        
+        .. image:: https://codecov.io/gh/aio-libs/aiohttp/branch/master/graph/badge.svg
+           :target: https://codecov.io/gh/aio-libs/aiohttp
+           :alt: codecov.io status for master branch
+        
+        .. image:: https://badge.fury.io/py/aiohttp.svg
+           :target: https://pypi.org/project/aiohttp
+           :alt: Latest PyPI package version
+        
+        .. image:: https://readthedocs.org/projects/aiohttp/badge/?version=latest
+           :target: https://docs.aiohttp.org/
+           :alt: Latest Read The Docs
+        
+        .. image:: https://badges.gitter.im/Join%20Chat.svg
+            :target: https://gitter.im/aio-libs/Lobby
+            :alt: Chat on Gitter
+        
+        Key Features
+        ============
+        
+        - Supports both client and server side of HTTP protocol.
+        - Supports both client and server Web-Sockets out-of-the-box and avoids
+          Callback Hell.
+        - Provides Web-server with middlewares and pluggable routing.
+        
+        
+        Getting started
+        ===============
+        
+        Client
+        ------
+        
+        To get something from the web:
+        
+        .. code-block:: python
+        
+          import aiohttp
+          import asyncio
+        
+          async def fetch(session, url):
+              async with session.get(url) as response:
+                  return await response.text()
+        
+          async def main():
+              async with aiohttp.ClientSession() as session:
+                  html = await fetch(session, 'http://python.org')
+                  print(html)
+        
+          if __name__ == '__main__':
+              loop = asyncio.get_event_loop()
+              loop.run_until_complete(main())
+        
+        
+        Server
+        ------
+        
+        An example using a simple server:
+        
+        .. code-block:: python
+        
+            # examples/server_simple.py
+            from aiohttp import web
+        
+            async def handle(request):
+                name = request.match_info.get('name', "Anonymous")
+                text = "Hello, " + name
+                return web.Response(text=text)
+        
+            async def wshandle(request):
+                ws = web.WebSocketResponse()
+                await ws.prepare(request)
+        
+                async for msg in ws:
+                    if msg.type == web.WSMsgType.text:
+                        await ws.send_str("Hello, {}".format(msg.data))
+                    elif msg.type == web.WSMsgType.binary:
+                        await ws.send_bytes(msg.data)
+                    elif msg.type == web.WSMsgType.close:
+                        break
+        
+                return ws
+        
+        
+            app = web.Application()
+            app.add_routes([web.get('/', handle),
+                            web.get('/echo', wshandle),
+                            web.get('/{name}', handle)])
+        
+            if __name__ == '__main__':
+                web.run_app(app)
+        
+        
+        Documentation
+        =============
+        
+        https://aiohttp.readthedocs.io/
+        
+        
+        Demos
+        =====
+        
+        https://github.com/aio-libs/aiohttp-demos
+        
+        
+        External links
+        ==============
+        
+        * `Third party libraries
+          <http://aiohttp.readthedocs.io/en/latest/third_party.html>`_
+        * `Built with aiohttp
+          <http://aiohttp.readthedocs.io/en/latest/built_with.html>`_
+        * `Powered by aiohttp
+          <http://aiohttp.readthedocs.io/en/latest/powered_by.html>`_
+        
+        Feel free to make a Pull Request for adding your link to these pages!
+        
+        
+        Communication channels
+        ======================
+        
+        *aio-libs* google group: https://groups.google.com/forum/#!forum/aio-libs
+        
+        Feel free to post your questions and ideas here.
+        
+        *gitter chat* https://gitter.im/aio-libs/Lobby
+        
+        We support `Stack Overflow
+        <https://stackoverflow.com/questions/tagged/aiohttp>`_.
+        Please add *aiohttp* tag to your question there.
+        
+        Requirements
+        ============
+        
+        - Python >= 3.5.3
+        - async-timeout_
+        - attrs_
+        - chardet_
+        - multidict_
+        - yarl_
+        
+        Optionally you may install the cChardet_ and aiodns_ libraries (highly
+        recommended for sake of speed).
+        
+        .. _chardet: https://pypi.python.org/pypi/chardet
+        .. _aiodns: https://pypi.python.org/pypi/aiodns
+        .. _attrs: https://github.com/python-attrs/attrs
+        .. _multidict: https://pypi.python.org/pypi/multidict
+        .. _yarl: https://pypi.python.org/pypi/yarl
+        .. _async-timeout: https://pypi.python.org/pypi/async_timeout
+        .. _cChardet: https://pypi.python.org/pypi/cchardet
+        
+        License
+        =======
+        
+        ``aiohttp`` is offered under the Apache 2 license.
+        
+        
+        Keepsafe
+        ========
+        
+        The aiohttp community would like to thank Keepsafe
+        (https://www.getkeepsafe.com) for its support in the early days of
+        the project.
+        
+        
+        Source code
+        ===========
+        
+        The latest developer version is available in a GitHub repository:
+        https://github.com/aio-libs/aiohttp
+        
+        Benchmarks
+        ==========
+        
+        If you are interested in efficiency, the AsyncIO community maintains a
+        list of benchmarks on the official wiki:
+        https://github.com/python/asyncio/wiki/Benchmarks
+        
+        =========
+        Changelog
+        =========
+        
+        ..
+            You should *NOT* be adding new change log entries to this file, this
+            file is managed by towncrier. You *may* edit previous change logs to
+            fix problems like typo corrections or such.
+            To add a new change log entry, please see
+            https://pip.pypa.io/en/latest/development/#adding-a-news-entry
+            we named the news folder "changes".
+        
+            WARNING: Don't drop the next directive!
+        
+        .. towncrier release notes start
+        
+        3.6.1 (2019-09-19)
+        ==================
+        
+        Features
+        --------
+        
+        - Compatibility with Python 3.8.
+          `#4056 <https://github.com/aio-libs/aiohttp/issues/4056>`_
+        
+        
+        Bugfixes
+        --------
+        
+        - correct some exception string format
+          `#4068 <https://github.com/aio-libs/aiohttp/issues/4068>`_
+        - Emit a warning when ``ssl.OP_NO_COMPRESSION`` is
+          unavailable because the runtime is built against
+          an outdated OpenSSL.
+          `#4052 <https://github.com/aio-libs/aiohttp/issues/4052>`_
+        - Update multidict requirement to >= 4.5
+          `#4057 <https://github.com/aio-libs/aiohttp/issues/4057>`_
+        
+        
+        Improved Documentation
+        ----------------------
+        
+        - Provide pytest-aiohttp namespace for pytest fixtures in docs.
+          `#3723 <https://github.com/aio-libs/aiohttp/issues/3723>`_
+        
+        
+        ----
+        
+        
+        3.6.0 (2019-09-06)
+        ==================
+        
+        Features
+        --------
+        
+        - Add support for Named Pipes (Site and Connector) under Windows. This feature requires Proactor event loop to work.
+          `#3629 <https://github.com/aio-libs/aiohttp/issues/3629>`_
+        - Removed `Transfer-Encoding: chunked` header from websocket responses to be compatible with more http proxy servers.
+          `#3798 <https://github.com/aio-libs/aiohttp/issues/3798>`_
+        - Accept non-GET request for starting websocket handshake on server side.
+          `#3980 <https://github.com/aio-libs/aiohttp/issues/3980>`_
+        
+        
+        Bugfixes
+        --------
+        
+        - Raise a ClientResponseError instead of an AssertionError for a blank
+          HTTP Reason Phrase.
+          `#3532 <https://github.com/aio-libs/aiohttp/issues/3532>`_
+        - Fix an issue where cookies would sometimes not be set during a redirect.
+          `#3576 <https://github.com/aio-libs/aiohttp/issues/3576>`_
+        - Change normalize_path_middleware to use 308 redirect instead of 301.
+        
+          This behavior should prevent clients from being unable to use PUT/POST
+          methods on endpoints that are redirected because of a trailing slash.
+          `#3579 <https://github.com/aio-libs/aiohttp/issues/3579>`_
+        - Drop the processed task from ``all_tasks()`` list early. It prevents logging about a task with unhandled exception when the server is used in conjunction with ``asyncio.run()``.
+          `#3587 <https://github.com/aio-libs/aiohttp/issues/3587>`_
+        - ``Signal`` type annotation changed from `Signal[Callable[['TraceConfig'], Awaitable[None]]]` to `Signal[Callable[ClientSession, SimpleNamespace, ...]`.
+          `#3595 <https://github.com/aio-libs/aiohttp/issues/3595>`_
+        - Use sanitized URL as Location header in redirects
+          `#3614 <https://github.com/aio-libs/aiohttp/issues/3614>`_
+        - Improve typing annotations for multipart.py along with changes required
+          by mypy in files that references multipart.py.
+          `#3621 <https://github.com/aio-libs/aiohttp/issues/3621>`_
+        - Close session created inside ``aiohttp.request`` when unhandled exception occurs
+          `#3628 <https://github.com/aio-libs/aiohttp/issues/3628>`_
+        - Cleanup per-chunk data in generic data read. Memory leak fixed.
+          `#3631 <https://github.com/aio-libs/aiohttp/issues/3631>`_
+        - Use correct type for add_view and family
+          `#3633 <https://github.com/aio-libs/aiohttp/issues/3633>`_
+        - Fix _keepalive field in __slots__ of ``RequestHandler``.
+          `#3644 <https://github.com/aio-libs/aiohttp/issues/3644>`_
+        - Properly handle ConnectionResetError, to silence the "Cannot write to closing
+          transport" exception when clients disconnect uncleanly.
+          `#3648 <https://github.com/aio-libs/aiohttp/issues/3648>`_
+        - Suppress pytest warnings due to ``test_utils`` classes
+          `#3660 <https://github.com/aio-libs/aiohttp/issues/3660>`_
+        - Fix overshadowing of overlapped sub-application prefixes.
+          `#3701 <https://github.com/aio-libs/aiohttp/issues/3701>`_
+        - Fixed return type annotation for WSMessage.json()
+          `#3720 <https://github.com/aio-libs/aiohttp/issues/3720>`_
+        - Properly expose TooManyRedirects publicly as documented.
+          `#3818 <https://github.com/aio-libs/aiohttp/issues/3818>`_
+        - Fix missing brackets for IPv6 in proxy CONNECT request
+          `#3841 <https://github.com/aio-libs/aiohttp/issues/3841>`_
+        - Make the signature of `aiohttp.test_utils.TestClient.request` match `asyncio.ClientSession.request` according to the docs
+          `#3852 <https://github.com/aio-libs/aiohttp/issues/3852>`_
+        - Use correct style for re-exported imports, makes mypy ``--strict`` mode happy.
+          `#3868 <https://github.com/aio-libs/aiohttp/issues/3868>`_
+        - Fixed type annotation for add_view method of UrlDispatcher to accept any subclass of View
+          `#3880 <https://github.com/aio-libs/aiohttp/issues/3880>`_
+        - Made cython HTTP parser set Reason-Phrase of the response to an empty string if it is missing.
+          `#3906 <https://github.com/aio-libs/aiohttp/issues/3906>`_
+        - Add URL to the string representation of ClientResponseError.
+          `#3959 <https://github.com/aio-libs/aiohttp/issues/3959>`_
+        - Accept ``istr`` keys in ``LooseHeaders`` type hints.
+          `#3976 <https://github.com/aio-libs/aiohttp/issues/3976>`_
+        - Fixed race conditions in _resolve_host caching and throttling when tracing is enabled.
+          `#4013 <https://github.com/aio-libs/aiohttp/issues/4013>`_
+        - For URLs like "unix://localhost/..." set Host HTTP header to "localhost" instead of "localhost:None".
+          `#4039 <https://github.com/aio-libs/aiohttp/issues/4039>`_
+        
+        
+        Improved Documentation
+        ----------------------
+        
+        - Modify documentation for Background Tasks to remove deprecated usage of event loop.
+          `#3526 <https://github.com/aio-libs/aiohttp/issues/3526>`_
+        - use ``if __name__ == '__main__':`` in server examples.
+          `#3775 <https://github.com/aio-libs/aiohttp/issues/3775>`_
+        - Update documentation reference to the default access logger.
+          `#3783 <https://github.com/aio-libs/aiohttp/issues/3783>`_
+        - Improve documentation for ``web.BaseRequest.path`` and ``web.BaseRequest.raw_path``.
+          `#3791 <https://github.com/aio-libs/aiohttp/issues/3791>`_
+        - Removed deprecation warning in tracing example docs
+          `#3964 <https://github.com/aio-libs/aiohttp/issues/3964>`_
+        
+        
+        ----
+        
+        
+        3.5.4 (2019-01-12)
+        ==================
+        
+        Bugfixes
+        --------
+        
+        - Fix stream ``.read()`` / ``.readany()`` / ``.iter_any()`` which used to return a
+          partial content only in case of compressed content
+          `#3525 <https://github.com/aio-libs/aiohttp/issues/3525>`_
+        
+        
+        3.5.3 (2019-01-10)
+        ==================
+        
+        Bugfixes
+        --------
+        
+        - Fix type stubs for ``aiohttp.web.run_app(access_log=True)`` and fix edge case of ``access_log=True`` and the event loop being in debug mode.
+          `#3504 <https://github.com/aio-libs/aiohttp/issues/3504>`_
+        - Fix ``aiohttp.ClientTimeout`` type annotations to accept ``None`` for fields
+          `#3511 <https://github.com/aio-libs/aiohttp/issues/3511>`_
+        - Send custom per-request cookies even if session jar is empty
+          `#3515 <https://github.com/aio-libs/aiohttp/issues/3515>`_
+        - Restore Linux binary wheels publishing on PyPI
+        
+        ----
+        
+        
+        3.5.2 (2019-01-08)
+        ==================
+        
+        Features
+        --------
+        
+        - ``FileResponse`` from ``web_fileresponse.py`` uses a ``ThreadPoolExecutor`` to work with files asynchronously.
+          I/O based payloads from ``payload.py`` uses a ``ThreadPoolExecutor`` to work with I/O objects asynchronously.
+          `#3313 <https://github.com/aio-libs/aiohttp/issues/3313>`_
+        - Internal Server Errors in plain text if the browser does not support HTML.
+          `#3483 <https://github.com/aio-libs/aiohttp/issues/3483>`_
+        
+        
+        Bugfixes
+        --------
+        
+        - Preserve MultipartWriter parts headers on write.
+        
+          Refactor the way how ``Payload.headers`` are handled. Payload instances now always
+          have headers and Content-Type defined.
+        
+          Fix Payload Content-Disposition header reset after initial creation.
+          `#3035 <https://github.com/aio-libs/aiohttp/issues/3035>`_
+        - Log suppressed exceptions in ``GunicornWebWorker``.
+          `#3464 <https://github.com/aio-libs/aiohttp/issues/3464>`_
+        - Remove wildcard imports.
+          `#3468 <https://github.com/aio-libs/aiohttp/issues/3468>`_
+        - Use the same task for app initialization and web server handling in gunicorn workers.
+          It allows to use Python3.7 context vars smoothly.
+          `#3471 <https://github.com/aio-libs/aiohttp/issues/3471>`_
+        - Fix handling of chunked+gzipped response when first chunk does not give uncompressed data
+          `#3477 <https://github.com/aio-libs/aiohttp/issues/3477>`_
+        - Replace ``collections.MutableMapping`` with ``collections.abc.MutableMapping`` to avoid a deprecation warning.
+          `#3480 <https://github.com/aio-libs/aiohttp/issues/3480>`_
+        - ``Payload.size`` type annotation changed from `Optional[float]` to `Optional[int]`.
+          `#3484 <https://github.com/aio-libs/aiohttp/issues/3484>`_
+        - Ignore done tasks when cancels pending activities on ``web.run_app`` finalization.
+          `#3497 <https://github.com/aio-libs/aiohttp/issues/3497>`_
+        
+        
+        Improved Documentation
+        ----------------------
+        
+        - Add documentation for ``aiohttp.web.HTTPException``.
+          `#3490 <https://github.com/aio-libs/aiohttp/issues/3490>`_
+        
+        
+        Misc
+        ----
+        
+        - `#3487 <https://github.com/aio-libs/aiohttp/issues/3487>`_
+        
+        
+        ----
+        
+        
+        3.5.1 (2018-12-24)
+        ====================
+        
+        - Fix a regression about ``ClientSession._requote_redirect_url`` modification in debug
+          mode.
+        
+        3.5.0 (2018-12-22)
+        ====================
+        
+        Features
+        --------
+        
+        - The library type annotations are checked in strict mode now.
+        - Add support for setting cookies for individual request (`#2387 <https://github.com/aio-libs/aiohttp/pull/2387>`_)
+        - Application.add_domain implementation (`#2809 <https://github.com/aio-libs/aiohttp/pull/2809>`_)
+        - The default ``app`` in the request returned by ``test_utils.make_mocked_request``
+          can now have objects assigned to it and retrieved using the ``[]`` operator. (`#3174 <https://github.com/aio-libs/aiohttp/pull/3174>`_)
+        - Make ``request.url`` accessible when transport is closed. (`#3177 <https://github.com/aio-libs/aiohttp/pull/3177>`_)
+        - Add ``zlib_executor_size`` argument to ``Response`` constructor to allow compression to run in a background executor to avoid blocking the main thread and potentially triggering health check failures. (`#3205 <https://github.com/aio-libs/aiohttp/pull/3205>`_)
+        - Enable users to set `ClientTimeout` in `aiohttp.request` (`#3213 <https://github.com/aio-libs/aiohttp/pull/3213>`_)
+        - Don't raise a warning if ``NETRC`` environment variable is not set and ``~/.netrc`` file
+          doesn't exist. (`#3267 <https://github.com/aio-libs/aiohttp/pull/3267>`_)
+        - Add default logging handler to web.run_app
+        
+          If the `Application.debug` flag is set and the default logger `aiohttp.access` is used, access logs will now be output using a `stderr` `StreamHandler` if no handlers are attached. Furthermore, if the default logger has no log level set, the log level will be set to `DEBUG`. (`#3324 <https://github.com/aio-libs/aiohttp/pull/3324>`_)
+        - Add method argument to ``session.ws_connect()``.
+        
+          Sometimes server API requires a different HTTP method for WebSocket connection establishment.
+        
+          For example, ``Docker exec`` needs POST. (`#3378 <https://github.com/aio-libs/aiohttp/pull/3378>`_)
+        - Create a task per request handling. (`#3406 <https://github.com/aio-libs/aiohttp/pull/3406>`_)
+        
+        
+        Bugfixes
+        --------
+        
+        - Enable passing `access_log_class` via `handler_args` (`#3158 <https://github.com/aio-libs/aiohttp/pull/3158>`_)
+        - Return empty bytes with end-of-chunk marker in empty stream reader. (`#3186 <https://github.com/aio-libs/aiohttp/pull/3186>`_)
+        - Accept ``CIMultiDictProxy`` instances for ``headers`` argument in ``web.Response``
+          constructor. (`#3207 <https://github.com/aio-libs/aiohttp/pull/3207>`_)
+        - Don't uppercase HTTP method in parser (`#3233 <https://github.com/aio-libs/aiohttp/pull/3233>`_)
+        - Make method match regexp RFC-7230 compliant (`#3235 <https://github.com/aio-libs/aiohttp/pull/3235>`_)
+        - Add ``app.pre_frozen`` state to properly handle startup signals in sub-applications. (`#3237 <https://github.com/aio-libs/aiohttp/pull/3237>`_)
+        - Enhanced parsing and validation of helpers.BasicAuth.decode. (`#3239 <https://github.com/aio-libs/aiohttp/pull/3239>`_)
+        - Change imports from collections module in preparation for 3.8. (`#3258 <https://github.com/aio-libs/aiohttp/pull/3258>`_)
+        - Ensure Host header is added first to ClientRequest to better replicate browser (`#3265 <https://github.com/aio-libs/aiohttp/pull/3265>`_)
+        - Fix forward compatibility with Python 3.8: importing ABCs directly from the collections module will not be supported anymore. (`#3273 <https://github.com/aio-libs/aiohttp/pull/3273>`_)
+        - Keep the query string by `normalize_path_middleware`. (`#3278 <https://github.com/aio-libs/aiohttp/pull/3278>`_)
+        - Fix missing parameter ``raise_for_status`` for aiohttp.request() (`#3290 <https://github.com/aio-libs/aiohttp/pull/3290>`_)
+        - Bracket IPv6 addresses in the HOST header (`#3304 <https://github.com/aio-libs/aiohttp/pull/3304>`_)
+        - Fix default message for server ping and pong frames. (`#3308 <https://github.com/aio-libs/aiohttp/pull/3308>`_)
+        - Fix tests/test_connector.py typo and tests/autobahn/server.py duplicate loop def. (`#3337 <https://github.com/aio-libs/aiohttp/pull/3337>`_)
+        - Fix false-negative indicator end_of_HTTP_chunk in StreamReader.readchunk function (`#3361 <https://github.com/aio-libs/aiohttp/pull/3361>`_)
+        - Release HTTP response before raising status exception (`#3364 <https://github.com/aio-libs/aiohttp/pull/3364>`_)
+        - Fix task cancellation when ``sendfile()`` syscall is used by static file handling. (`#3383 <https://github.com/aio-libs/aiohttp/pull/3383>`_)
+        - Fix stack trace for ``asyncio.TimeoutError`` which was not logged, when it is caught
+          in the handler. (`#3414 <https://github.com/aio-libs/aiohttp/pull/3414>`_)
+        
+        
+        Improved Documentation
+        ----------------------
+        
+        - Improve documentation of ``Application.make_handler`` parameters. (`#3152 <https://github.com/aio-libs/aiohttp/pull/3152>`_)
+        - Fix BaseRequest.raw_headers doc. (`#3215 <https://github.com/aio-libs/aiohttp/pull/3215>`_)
+        - Fix typo in TypeError exception reason in ``web.Application._handle`` (`#3229 <https://github.com/aio-libs/aiohttp/pull/3229>`_)
+        - Make server access log format placeholder %b documentation reflect
+          behavior and docstring. (`#3307 <https://github.com/aio-libs/aiohttp/pull/3307>`_)
+        
+        
+        Deprecations and Removals
+        -------------------------
+        
+        - Deprecate modification of ``session.requote_redirect_url`` (`#2278 <https://github.com/aio-libs/aiohttp/pull/2278>`_)
+        - Deprecate ``stream.unread_data()`` (`#3260 <https://github.com/aio-libs/aiohttp/pull/3260>`_)
+        - Deprecated use of boolean in ``resp.enable_compression()`` (`#3318 <https://github.com/aio-libs/aiohttp/pull/3318>`_)
+        - Encourage creation of aiohttp public objects inside a coroutine (`#3331 <https://github.com/aio-libs/aiohttp/pull/3331>`_)
+        - Drop dead ``Connection.detach()`` and ``Connection.writer``. Both methods were broken
+          for more than 2 years. (`#3358 <https://github.com/aio-libs/aiohttp/pull/3358>`_)
+        - Deprecate ``app.loop``, ``request.loop``, ``client.loop`` and ``connector.loop`` properties. (`#3374 <https://github.com/aio-libs/aiohttp/pull/3374>`_)
+        - Deprecate explicit debug argument. Use asyncio debug mode instead. (`#3381 <https://github.com/aio-libs/aiohttp/pull/3381>`_)
+        - Deprecate body parameter in HTTPException (and derived classes) constructor. (`#3385 <https://github.com/aio-libs/aiohttp/pull/3385>`_)
+        - Deprecate bare connector close, use ``async with connector:`` and ``await connector.close()`` instead. (`#3417 <https://github.com/aio-libs/aiohttp/pull/3417>`_)
+        - Deprecate obsolete ``read_timeout`` and ``conn_timeout`` in ``ClientSession`` constructor. (`#3438 <https://github.com/aio-libs/aiohttp/pull/3438>`_)
+        
+        
+        Misc
+        ----
+        
+        - #3341, #3351
+Platform: UNKNOWN
+Classifier: License :: OSI Approved :: Apache Software License
+Classifier: Intended Audience :: Developers
+Classifier: Programming Language :: Python
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.6
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Operating System :: POSIX
+Classifier: Operating System :: MacOS :: MacOS X
+Classifier: Operating System :: Microsoft :: Windows
+Classifier: Topic :: Internet :: WWW/HTTP
+Classifier: Framework :: AsyncIO
+Requires-Python: >=3.6
+Description-Content-Type: text/x-rst
+Provides-Extra: speedups
```

### Comparing `aiohttp-4.0.0a0/aiohttp.egg-info/SOURCES.txt` & `aiohttp-4.0.0a1/aiohttp.egg-info/SOURCES.txt`

 * *Files 16% similar despite different names*

```diff
@@ -1,52 +1,15 @@
-.appveyor.yml
-.cherry_picker.toml
-.editorconfig
-.gitattributes
-.gitignore
-.gitmodules
-.pyup.yml
-.readthedocs.yml
-.travis.yml
 CHANGES.rst
-CODE_OF_CONDUCT.md
-CONTRIBUTING.rst
 CONTRIBUTORS.txt
-HISTORY.rst
 LICENSE.txt
 MANIFEST.in
 Makefile
 README.rst
-codecov.yml
-pyproject.toml
-pytest.ci.ini
-pytest.ini
 setup.cfg
 setup.py
-tox.ini
-.github/CODEOWNERS
-.github/ISSUE_TEMPLATE.md
-.github/PULL_REQUEST_TEMPLATE.md
-.github/main.workflow
-CHANGES/.TEMPLATE.rst
-CHANGES/.gitignore
-CHANGES/3035.bugfix
-CHANGES/3313.feature
-CHANGES/3463.removal
-CHANGES/3464.bugfix
-CHANGES/3468.bugfix
-CHANGES/3471.bugfix
-CHANGES/3477.bugfix
-CHANGES/3480.bugfix
-CHANGES/3482.bugfix
-CHANGES/3483.feature
-CHANGES/3484.bugfix
-CHANGES/3487.misc
-CHANGES/3490.doc
-CHANGES/3497.bugfix
 aiohttp/__init__.py
 aiohttp/_cparser.pxd
 aiohttp/_find_header.c
 aiohttp/_find_header.h
 aiohttp/_find_header.pxd
 aiohttp/_frozenlist.c
 aiohttp/_frozenlist.pyx
@@ -79,15 +42,14 @@
 aiohttp/http_parser.py
 aiohttp/http_websocket.py
 aiohttp/http_writer.py
 aiohttp/locks.py
 aiohttp/log.py
 aiohttp/multipart.py
 aiohttp/payload.py
-aiohttp/payload_streamer.py
 aiohttp/py.typed
 aiohttp/pytest_plugin.py
 aiohttp/resolver.py
 aiohttp/signals.py
 aiohttp/signals.pyi
 aiohttp/streams.py
 aiohttp/tcp_helpers.py
@@ -149,14 +111,15 @@
 docs/structures.rst
 docs/testing.rst
 docs/third_party.rst
 docs/tracing_reference.rst
 docs/utilities.rst
 docs/web.rst
 docs/web_advanced.rst
+docs/web_exceptions.rst
 docs/web_lowlevel.rst
 docs/web_quickstart.rst
 docs/web_reference.rst
 docs/websocket_utilities.rst
 docs/whats_new_1_1.rst
 docs/whats_new_3_0.rst
 docs/_static/aiohttp-icon-128x128.png
@@ -180,23 +143,14 @@
 examples/web_srv_route_deco.py
 examples/web_srv_route_table.py
 examples/web_ws.py
 examples/websocket.html
 examples/legacy/crawl.py
 examples/legacy/srv.py
 examples/legacy/tcp_protocol_parser.py
-requirements/ci-wheel.txt
-requirements/ci.txt
-requirements/cython.txt
-requirements/dev.txt
-requirements/doc-spelling.txt
-requirements/doc.txt
-requirements/flake.txt
-requirements/towncrier.txt
-requirements/wheel.txt
 tests/aiohttp.jpg
 tests/aiohttp.png
 tests/conftest.py
 tests/data.unknown_mime_type
 tests/hello.txt.gz
 tests/test_base_protocol.py
 tests/test_classbasedview.py
@@ -257,21 +211,14 @@
 tests/test_websocket_parser.py
 tests/test_websocket_writer.py
 tests/test_worker.py
 tests/autobahn/client.py
 tests/autobahn/fuzzingclient.json
 tests/autobahn/fuzzingserver.json
 tests/autobahn/server.py
-tools/build-wheels.sh
-tools/build.cmd
-tools/check_changes.py
-tools/drop_merged_branches.sh
-tools/gen.py
-tools/run_docker.sh
-vendor/http-parser/http_parser.c
 vendor/http-parser/.git
 vendor/http-parser/.gitignore
 vendor/http-parser/.mailmap
 vendor/http-parser/.travis.yml
 vendor/http-parser/AUTHORS
 vendor/http-parser/LICENSE-MIT
 vendor/http-parser/Makefile
```

### Comparing `aiohttp-4.0.0a0/CONTRIBUTORS.txt` & `aiohttp-4.0.0a1/CONTRIBUTORS.txt`

 * *Files 9% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 - Contributors -
 ----------------
 A. Jesse Jiryu Davis
 Adam Cooper
 Adam Mills
 Adrin Chaves
+Alan Tse
 Alec Hanefeld
 Alejandro Gmez
 Aleksandr Danshyn
 Aleksey Kutepov
 Alex Hayes
 Alex Key
 Alex Khomchenko
@@ -21,148 +22,173 @@
 Alexander Shorin
 Alexander Travov
 Alexandru Mihai
 Alexey Firsov
 Alexey Popravka
 Alexey Stepanov
 Amin Etesamian
+Amit Tulshyan
 Amy Boyle
+Anders Melchiorsen
 Andrei Ursulenko
 Andrej Antonov
 Andrew Leech
 Andrew Lytvyn
 Andrew Svetlov
 Andrew Zhou
 Andrii Soldatenko
 Antoine Pietri
 Anton Kasyanov
 Anton Zhdan-Pushkin
+Artem Yushkovskiy
 Arthur Darcet
 Ben Bader
+Ben Timby
 Benedikt Reinartz
 Boris Feld
 Boyi Chen
 Brett Cannon
 Brian C. Lane
 Brian Muller
+Bryan Kok
 Bryce Drennan
 Carl George
 Cecile Tonglet
 Chien-Wei Huang
 Chih-Yuan Chen
 Chris AtLee
 Chris Laws
 Chris Moore
 Christopher Schmitt
 Claudiu Popa
 Colin Dunklau
+Cong Xu
 Damien Nad
 Dan Xu
 Daniel Garca
+Daniel Grossmann-Kavanagh
 Daniel Nelson
 Danny Song
 David Bibb
 David Michael Brown
 Denilson Amorim
 Denis Matiychuk
+Dennis Kliban
 Dima Veselov
 Dimitar Dimitrov
+Diogo Dutra da Mata
 Dmitriy Safonov
 Dmitry Doroshev
 Dmitry Lukashin
+Dmitry Marakasov
 Dmitry Shamov
 Dmitry Trofimov
 Dmytro Bohomiakov
 Dmytro Kuznetsov
 Dustin J. Mitchell
 Eduard Iskandarov
 Eli Ribble
 Elizabeth Leddy
+Emil Melnikov
 Enrique Saez
 Eric Sheng
 Erich Healy
 Eugene Chernyshov
 Eugene Naydenov
+Eugene Nikolaiev
 Eugene Tolmachev
 Evert Lammerts
+Felix Yan
 FichteFoll
+Florian Scheffler
 Frederik Gladhorn
 Frederik Peter Aalund
 Gabriel Tremblay
 Gennady Andreyev
 Georges Dubus
 Greg Holt
 Gregory Haynes
 Gus Goulart
 Gustavo Carneiro
 Gnther Jena
 Hans Adema
 Harmon Y.
 Hu Bo
+Hugh Young
 Hugo Herter
 Hynek Schlawack
 Igor Alexandrov
 Igor Davydenko
 Igor Mozharovsky
 Igor Pavlov
+Ilya Chichak
 Ingmar Steen
+Ivan Larin
 Jacob Champion
 Jaesung Lee
 Jake Davis
 Jakob Ackermann
 Jakub Wilk
 Jashandeep Sohi
 Jeongkyu Shin
 Jeroen van der Heijden
 Jesus Cea
 Jian Zeng
 Jinkyu Yi
 Joel Watts
 Jon Nabozny
+Jonas Obrist
 Joongi Kim
 Josep Cugat
+Joshu Coats
 Julia Tsemusheva
 Julien Duponchelle
 Jungkook Park
 Junjie Tao
 Justas Trimailovas
 Justin Foo
 Justin Turner Arthur
 Kay Zheng
 Kimmo Parviainen-Jalanko
 Kirill Klenov
 Kirill Malovitsa
+Konstantin Valetov
 Kyrylo Perevozchikov
 Lars P. Sndergaard
 Louis-Philippe Huberdeau
 Loc Lajeanne
 Lu Gong
 Lubomir Gelo
 Ludovic Gasc
 Luis Pedrosa
 Lukasz Marcin Dobrzanski
 Makc Belousow
 Manuel Miranda
 Marat Sharafutdinov
 Marco Paolini
 Mariano Anaya
+Martijn Pieters
 Martin Melka
 Martin Richard
 Mathias Frjdman
+Mathieu Dugr
+Matt VanEseltine
 Matthieu Hauglustaine
 Matthieu Rigal
 Michael Ihnatenko
+Mikhail Burshteyn
 Mikhail Kashkin
 Mikhail Lukyanchenko
 Mikhail Nacharov
 Misha Behersky
 Mitchell Ferree
 Morgan Delahaye-Prat
 Moss Collum
 Mun Gwan-gyeong
+Navid Sheikhol
 Nicolas Braem
 Nikolay Kim
 Nikolay Novik
 Oisin Aylward
 Olaf Conradi
 Pahaz Blinov
 Panagiotis Kolokotronis
@@ -178,14 +204,15 @@
 Pepe Osca
 Philipp A.
 Pieter van Beek
 Rafael Viotti
 Ral Cumplido
 Required Field
 Robert Lu
+Robert Nikolich
 Roman Podoliaka
 Samuel Colvin
 Sean Hunt
 Sebastian Acuna
 Sebastian Hanula
 Sebastian Hther
 Sebastien Geffroy
@@ -193,14 +220,16 @@
 Sergey Ninua
 Sergey Skripnick
 Serhii Kostel
 Simon Kennedy
 Sin-Woo Bang
 Stanislas Plum
 Stanislav Prokop
+Stefan Tjarks
+Stepan Pletnev
 Stephen Granade
 Steven Seguin
 Sunghyun Hwang
 Sviatoslav Bulbakha
 Sviatoslav Sydorenko
 Taha Jahangir
 Taras Voinarovskyi
```

### Comparing `aiohttp-4.0.0a0/docs/abc.rst` & `aiohttp-4.0.0a1/docs/abc.rst`

 * *Files 1% similar despite different names*

```diff
@@ -1,16 +1,14 @@
+.. module:: aiohttp.abc
+
 .. _aiohttp-abc:
 
 Abstract Base Classes
 =====================
 
-.. module:: aiohttp
-
-.. currentmodule:: aiohttp
-
 Abstract routing
 ----------------
 
 aiohttp has abstract classes for managing web interfaces.
 
 The most part of :mod:`aiohttp.web` is not intended to be inherited
 but few of them are.
```

### Comparing `aiohttp-4.0.0a0/docs/aiohttp-icon.svg` & `aiohttp-4.0.0a1/docs/aiohttp-icon.svg`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/docs/aiohttp-plain.svg` & `aiohttp-4.0.0a1/docs/aiohttp-plain.svg`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/docs/built_with.rst` & `aiohttp-4.0.0a1/docs/built_with.rst`

 * *Files 8% similar despite different names*

```diff
@@ -19,7 +19,8 @@
 
 
 * `Molotov <http://molotov.readthedocs.io>`_ Load testing tool.
 * `Arsenic <https://github.com/hde/arsenic>`_ Async WebDriver.
 * `Home Assistant <https://home-assistant.io>`_ Home Automation Platform.
 * `Backend.AI <https://backend.ai>`_ Code execution API service.
 * `doh-proxy <https://github.com/facebookexperimental/doh-proxy>`_ DNS Over HTTPS Proxy.
+* `Mariner <https://gitlab.com/radek-sprta/mariner>`_ Command-line torrent searcher.
```

### Comparing `aiohttp-4.0.0a0/docs/client_advanced.rst` & `aiohttp-4.0.0a1/docs/client_advanced.rst`

 * *Files 6% similar despite different names*

```diff
@@ -1,14 +1,14 @@
+.. currentmodule:: aiohttp
+
 .. _aiohttp-client-advanced:
 
 Advanced Client Usage
 =====================
 
-.. currentmodule:: aiohttp
-
 .. _aiohttp-client-session:
 
 Client Session
 --------------
 
 :class:`ClientSession` is the heart and the main entry point for all
 client API operations.
@@ -77,15 +77,15 @@
 :class:`~aiohttp.ClientSession` may be used for sharing cookies
 between multiple requests::
 
     async with aiohttp.ClientSession() as session:
         await session.get(
             'http://httpbin.org/cookies/set?my_cookie=my_value')
         filtered = session.cookie_jar.filter_cookies(
-            'http://httpbin.org')
+            URL('http://httpbin.org'))
         assert filtered['my_cookie'].value == 'my_value'
         async with session.get('http://httpbin.org/cookies') as r:
             json_body = await r.json()
             assert json_body['cookies']['my_cookie'] == 'my_value'
 
 Response Headers and Cookies
 ----------------------------
@@ -276,18 +276,18 @@
 second, a :class:`SimpleNamespace` instance called
 ``trace_config_ctx``. The ``trace_config_ctx`` object can be used to
 share the state through to the different signals that belong to the
 same request and to the same :class:`TraceConfig` class, perhaps::
 
     async def on_request_start(
             session, trace_config_ctx, params):
-        trace_config_ctx.start = session.loop.time()
+        trace_config_ctx.start = asyncio.get_event_loop().time()
 
     async def on_request_end(session, trace_config_ctx, params):
-        elapsed = session.loop.time() - trace_config_ctx.start
+        elapsed = asyncio.get_event_loop().time() - trace_config_ctx.start
         print("Request took {}".format(elapsed))
 
 
 The ``trace_config_ctx`` param is by default a
 :class:`SimpleNampespace` that is initialized at the beginning of the
 request flow. However, the factory used to create this object can be
 overwritten using the ``trace_config_ctx_factory`` constructor param of
@@ -393,14 +393,25 @@
 If your HTTP server uses UNIX domain sockets you can use
 :class:`~aiohttp.UnixConnector`::
 
   conn = aiohttp.UnixConnector(path='/path/to/socket')
   session = aiohttp.ClientSession(connector=conn)
 
 
+Named pipes in Windows
+^^^^^^^^^^^^^^^^^^^^^^
+
+If your HTTP server uses Named pipes you can use
+:class:`~aiohttp.NamedPipeConnector`::
+
+  conn = aiohttp.NamedPipeConnector(path=r'\\.\pipe\<name-of-pipe>')
+  session = aiohttp.ClientSession(connector=conn)
+
+It will only work with the ProactorEventLoop
+
 SSL control for TCP sockets
 ---------------------------
 
 By default *aiohttp* uses strict checks for HTTPS protocol. Certification
 checks can be relaxed by setting *ssl* to ``False``::
 
   r = await session.get('https://example.com', ssl=False)
@@ -485,16 +496,17 @@
    *ssl* parameter could be passed
    to :class:`TCPConnector` as default, the value from
    :meth:`ClientSession.get` and others override default.
 
 Proxy support
 -------------
 
-aiohttp supports HTTP/HTTPS proxies. You have to use
-*proxy* parameter::
+aiohttp supports plain HTTP proxies and HTTP proxies that can be upgraded to HTTPS
+via the HTTP CONNECT method. aiohttp does not support proxies that must be
+connected to via ``https://``. To connect, use the *proxy* parameter::
 
    async with aiohttp.ClientSession() as session:
        async with session.get("http://python.org",
                               proxy="http://proxy.com") as resp:
            print(resp.status)
 
 It also supports proxy authorization::
@@ -521,14 +533,60 @@
    async with aiohttp.ClientSession(trust_env=True) as session:
        async with session.get("http://python.org") as resp:
            print(resp.status)
 
 Proxy credentials are given from ``~/.netrc`` file if present (see
 :class:`aiohttp.ClientSession` for more details).
 
+.. _aiohttp-persistent-session:
+
+Persistent session
+------------------
+
+Even though creating a session on demand seems like tempting idea, we
+advise against it. :class:`aiohttp.ClientSession` maintains a
+connection pool. Contained connections can be reused if necessary to gain some
+performance improvements. If you plan on reusing the session, a.k.a. creating
+**persistent session**, you can use either :ref:`aiohttp-web-signals` or
+:ref:`aiohttp-web-cleanup-ctx`. If possible we advise using :ref:`aiohttp-web-cleanup-ctx`,
+as it results in more compact code::
+
+    app.cleanup_ctx.append(persistent_session)
+
+    async def persistent_session(app):
+       app['PERSISTENT_SESSION'] = session = aiohttp.ClientSession()
+       yield
+       await session.close()
+
+    async def my_request_handler(request):
+       session = request.app['PERSISTENT_SESSION']
+       async with session.get("http://python.org") as resp:
+           print(resp.status)
+
+
+This approach can be successfully used to define numerous of session given certain
+requirements. It benefits from having a single location where :class:`aiohttp.ClientSession`
+instances are created and where artifacts such as :class:`aiohttp.connector.BaseConnector`
+can be safely shared between sessions if needed.
+
+In the end all you have to do is to close all sessions after `yield` statement::
+
+    async def multiple_sessions(app):
+       app['PERSISTENT_SESSION_1'] = session_1 = aiohttp.ClientSession()
+       app['PERSISTENT_SESSION_2'] = session_2 = aiohttp.ClientSession()
+       app['PERSISTENT_SESSION_3'] = session_3 = aiohttp.ClientSession()
+
+       yield
+
+       await asyncio.gather(*[
+           session_1.close(),
+           session_2.close(),
+           session_3.close(),
+       ])
+
 Graceful Shutdown
 -----------------
 
 When :class:`ClientSession` closes at the end of an ``async with``
 block (or through a direct :meth:`ClientSession.close()` call), the
 underlying connection remains open due to asyncio internal details. In
 practice, the underlying connection will close after a short
@@ -560,12 +618,17 @@
     # Wait 250 ms for the underlying SSL connections to close
     loop.run_until_complete(asyncio.sleep(0.250))
     loop.close()
 
 Note that the appropriate amount of time to wait will vary from
 application to application.
 
-All if this will eventually become obsolete when the asyncio internals
+All of this will eventually become obsolete when the asyncio internals
 are changed so that aiohttp itself can wait on the underlying
 connection to close. Please follow issue `#1925
 <https://github.com/aio-libs/aiohttp/issues/1925>`_ for the progress
 on this.
+
+HTTP Pipelining
+---------------
+
+aiohttp does not support HTTP/HTTPS pipelining.
```

### Comparing `aiohttp-4.0.0a0/docs/client_quickstart.rst` & `aiohttp-4.0.0a1/docs/client_quickstart.rst`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,15 @@
+.. currentmodule:: aiohttp
+
 .. _aiohttp-client-quickstart:
 
 ===================
  Client Quickstart
 ===================
 
-.. currentmodule:: aiohttp
-
 Eager to get started? This page gives a good introduction in how to
 get started with aiohttp client API.
 
 First, make sure that aiohttp is :ref:`installed
 <aiohttp-installation>` and *up-to-date*
 
 Let's get started with some simple examples.
@@ -57,14 +57,17 @@
    More complex cases may require a session per site, e.g. one for
    Github and other one for Facebook APIs. Anyway making a session for
    every request is a **very bad** idea.
 
    A session contains a connection pool inside. Connection reusage and
    keep-alives (both are on by default) may speed up total performance.
 
+   You may find more information about creating persistent sessions
+   in :ref:`aiohttp-persistent-session`.
+
 A session context manager usage is not mandatory
 but ``await session.close()`` method
 should be called in this case, e.g.::
 
     session = aiohttp.ClientSession()
     async with session.get('...'):
         # ...
@@ -164,25 +167,25 @@
 
     b'[{"created_at":"2015-06-12T14:06:22Z","public":true,"actor":{...
 
 The ``gzip`` and ``deflate`` transfer-encodings are automatically
 decoded for you.
 
 You can enable ``brotli`` transfer-encodings support,
-just install  `brotlipy <https://github.com/python-hyper/brotlipy>`_.
+just install  `Brotli <https://pypi.org/project/Brotli>`_.
 
 JSON Request
 ============
 
 Any of session's request methods like :func:`request`,
 :meth:`ClientSession.get`, :meth:`ClientSesssion.post` etc. accept
 `json` parameter::
 
   async with aiohttp.ClientSession() as session:
-      async with session.post(url, json={'test': 'object'})
+      await session.post(url, json={'test': 'object'})
 
 
 By default session uses python's standard :mod:`json` module for
 serialization.  But it is possible to use different
 ``serializer``. :class:`ClientSession` accepts ``json_serialize``
 parameter::
 
@@ -347,26 +350,14 @@
 :class:`~aiohttp.StreamReader` (provides async iterator protocol), you
 can chain get and post requests together::
 
    resp = await session.get('http://python.org')
    await session.post('http://httpbin.org/post',
                       data=resp.content)
 
-.. note::
-
-   Python 3.5 has no native support for asynchronous generators, use
-   ``async_generator`` library as workaround.
-
-.. deprecated:: 3.1
-
-   ``aiohttp`` still supports ``aiohttp.streamer`` decorator but this
-   approach is deprecated in favor of *asynchronous generators* as
-   shown above.
-
-
 .. _aiohttp-client-websockets:
 
 
 WebSockets
 ==========
 
 :mod:`aiohttp` works with client websockets out-of-the-box.
@@ -396,15 +387,15 @@
 
 
 .. _aiohttp-client-timeouts:
 
 Timeouts
 ========
 
-Timeout settings a stored in :class:`ClientTimeout` data structure.
+Timeout settings are stored in :class:`ClientTimeout` data structure.
 
 By default *aiohttp* uses a *total* 5min timeout, it means that the
 whole operation should finish in 5 minutes.
 
 The value could be overridden by *timeout* parameter for the session::
 
     timeout = aiohttp.ClientTimeout(total=60)
```

### Comparing `aiohttp-4.0.0a0/docs/client_reference.rst` & `aiohttp-4.0.0a1/docs/client_reference.rst`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,14 @@
+.. currentmodule:: aiohttp
+
 .. _aiohttp-client-reference:
 
 Client Reference
 ================
 
-.. module:: aiohttp
-.. currentmodule:: aiohttp
-
-
 Client Session
 --------------
 
 Client session is the recommended interface for making HTTP requests.
 
 Session encapsulates a *connection pool* (*connector* instance) and
 supports keepalives by default. Unless you are connecting to a large,
@@ -35,45 +33,33 @@
 
      loop = asyncio.get_event_loop()
      loop.run_until_complete(main())
 
 
 The client session supports the context manager protocol for self closing.
 
-.. class:: ClientSession(*, connector=None, loop=None, cookies=None, \
+.. class:: ClientSession(*, connector=None, cookies=None, \
                          headers=None, skip_auto_headers=None, \
                          auth=None, json_serialize=json.dumps, \
                          version=aiohttp.HttpVersion11, \
-                         cookie_jar=None, read_timeout=None, \
-                         conn_timeout=None, \
+                         cookie_jar=None,
                          timeout=sentinel, \
                          raise_for_status=False, \
                          connector_owner=True, \
                          auto_decompress=True, \
                          requote_redirect_url=False, \
                          trust_env=False, \
                          trace_configs=None)
 
    The class for creating client sessions and making requests.
 
 
    :param aiohttp.connector.BaseConnector connector: BaseConnector
       sub-class instance to support connection pooling.
 
-   :param loop: :ref:`event loop<asyncio-event-loop>` used for
-      processing HTTP requests.
-
-      If *loop* is ``None`` the constructor
-      borrows it from *connector* if specified.
-
-      :func:`asyncio.get_event_loop` is used for getting default event
-      loop otherwise.
-
-      .. deprecated:: 2.0
-
    :param dict cookies: Cookies to send with the request (optional)
 
    :param headers: HTTP Headers to send with every request (optional).
 
                    May be either *iterable of key-value pairs* or
                    :class:`~collections.abc.Mapping`
                    (e.g. :class:`dict`,
@@ -108,15 +94,15 @@
       :class:`aiohttp.DummyCookieJar` instance can be
       provided.
 
    :param callable json_serialize: Json *serializer* callable.
 
       By default :func:`json.dumps` function.
 
-   :param bool raise_for_status:
+   :param ~typing.Union[bool, callable] raise_for_status:
 
       Automatically call :meth:`ClientResponse.raise_for_status()` for
       each response, ``False`` by default.
 
       This parameter can be overridden when you making a request, e.g.::
 
           client_session = aiohttp.ClientSession(raise_for_status=True)
@@ -125,34 +111,38 @@
               assert resp.status == 200
 
       Set the parameter to ``True`` if you need ``raise_for_status``
       for most of cases but override ``raise_for_status`` for those
       requests where you need to handle responses with status 400 or
       higher.
 
-   :param timeout: a :class:`ClientTimeout` settings structure, 5min
-        total timeout by default.
+      You can also provide a coroutine which takes the response as an
+      argument and can raise an exception based on custom logic, e.g.::
 
-      .. versionadded:: 3.3
+          async def custom_check(response):
+              if response.status not in {201, 202}:
+                  raise RuntimeError('expected either 201 or 202')
+              text = await response.text()
+              if 'apple pie' not in text:
+                  raise RuntimeError('I wanted to see "apple pie" in response')
 
-   :param float read_timeout: Request operations timeout. ``read_timeout`` is
-      cumulative for all request operations (request, redirects, responses,
-      data consuming). By default, the read timeout is 5*60 seconds.
-      Use ``None`` or ``0`` to disable timeout checks.
+          client_session = aiohttp.ClientSession(raise_for_status=custom_check)
+          ...
 
-      .. deprecated:: 3.3
+      As with boolean values, you're free to set this on the session and/or
+      overwrite it on a per-request basis.
 
-         Use ``timeout`` parameter instead.
+      .. versionchanged:: 4.0
 
-   :param float conn_timeout: timeout for connection establishing
-      (optional). Values ``0`` or ``None`` mean no timeout.
+         Async callback support is added.
 
-      .. deprecated:: 3.3
+   :param timeout: a :class:`ClientTimeout` settings structure, 5min
+        total timeout by default.
 
-         Use ``timeout`` parameter instead.
+      .. versionadded:: 3.3
 
    :param bool connector_owner:
 
       Close connector instance on session closing.
 
       Setting the parameter to ``False`` allows to share
       connection pool between sessions without sharing session state:
@@ -211,41 +201,25 @@
 
       A read-only property.
 
    .. attribute:: requote_redirect_url
 
       aiohttp re quote's redirect urls by default, but some servers
       require exact url from location header. To disable *re-quote* system
-      set :attr:`requote_redirect_url` attribute to ``False``.
-
-      .. versionadded:: 2.1
+      create ``ClientSession`` with ``requote_redirect_url=False``.
 
-      .. note:: This parameter affects all subsequent requests.
-
-      .. deprecated:: 3.5
-
-         The attribute modification is deprecated.
-
-   .. attribute:: loop
-
-      A loop instance used for session creation.
-
-      A read-only property.
-
-      .. deprecated:: 3.5
 
    .. comethod:: request(method, url, *, params=None, data=None, json=None,\
                          cookies=None, headers=None, skip_auto_headers=None, \
                          auth=None, allow_redirects=True,\
                          max_redirects=10,\
                          compress=None, chunked=None, expect100=False, raise_for_status=None,\
                          read_until_eof=True, proxy=None, proxy_auth=None,\
                          timeout=sentinel, ssl=None, \
-                         verify_ssl=None, fingerprint=None, \
-                         ssl_context=None, proxy_headers=None)
+                         proxy_headers=None)
       :async-with:
       :coroutine:
 
       Performs an asynchronous HTTP request. Returns a response object.
 
       :param str method: HTTP method
 
@@ -262,16 +236,18 @@
                        :class:`aiohttp.MultiDict` or
                        :class:`aiohttp.MultiDictProxy`
                      - :class:`collections.abc.Iterable` e.g. :class:`tuple` or
                        :class:`list`
                      - :class:`str` with preferably url-encoded content
                        (**Warning:** content will not be encoded by *aiohttp*)
 
-      :param data: Dictionary, bytes, or file-like object to
-                   send in the body of the request (optional)
+      :param data: The data to send in the body of the request. This can be a
+                   :class:`FormData` object or anything that can be passed into
+                   :class:`FormData`, e.g. a dictionary, bytes, or file-like object.
+                   (optional)
 
       :param json: Any json compatible python object
                    (optional). *json* and *data* parameters could not
                    be used at the same time.
 
       :param dict cookies: HTTP Cookies to send with
                            the request (optional)
@@ -305,30 +281,58 @@
                                 ``10`` by default.
 
       :param bool compress: Set to ``True`` if request has to be compressed
          with deflate encoding. If `compress` can not be combined
          with a *Content-Encoding* and *Content-Length* headers.
          ``None`` by default (optional).
 
-      :param int chunked: Enable chunked transfer encoding.
+      :param bool chunked: Enable chunked transfer encoding.
          It is up to the developer
          to decide how to chunk data streams. If chunking is enabled, aiohttp
          encodes the provided chunks in the "Transfer-encoding: chunked" format.
          If *chunked* is set, then the *Transfer-encoding* and *content-length*
          headers are disallowed. ``None`` by default (optional).
 
       :param bool expect100: Expect 100-continue response from server.
                              ``False`` by default (optional).
 
-      :param bool raise_for_status: Automatically call :meth:`ClientResponse.raise_for_status()` for
-                                    response if set to ``True``.
-                                    If set to ``None`` value from ``ClientSession`` will be used.
-                                    ``None`` by default (optional).
+      :param ~typing.Union[bool, callable] raise_for_status:
+
+         Automatically apply a check for failed status codes (usually a code
+         that is greater than or equal to ``400``).
 
-          .. versionadded:: 3.4
+         ``None`` (default) means that ``raise_for_status`` argument of
+         :class:`ClientSession` constructor controls this behavior.
+
+         Set the parameter to ``True`` if you need to enforce
+         :meth:`ClientResponse.raise_for_status` call.
+
+         Set the argument to ``False`` to suppress a HTTP status checker even if
+         :class:`ClientSession` enables it.
+
+         Use an *async callback* to call user code that accepts a
+         :class:`ClientResponse` and raises an exception to prevent future
+         processing.
+
+         The following callback example is a functional equivalent of
+         ``raise_for_status=True``::
+
+             async def custom_check(response):
+                 if 400 <= response.status:
+                     raise aiohttp.ClientResponseError(
+                     response.request_info,
+                     response.history,
+                     status=response.status,
+                     message=response.reason,
+                     headers=response.headers)
+
+             client_session = aiohttp.ClientSession(raise_for_status=custom_check)
+             ...
+
+         .. versionchanged:: 4.0
 
       :param bool read_until_eof: Read response until EOF if response
                                   does not have Content-Length header.
                                   ``True`` by default (optional).
 
       :param proxy: Proxy URL, :class:`str` or :class:`~yarl.URL` (optional)
 
@@ -348,54 +352,16 @@
       :param ssl: SSL validation mode. ``None`` for default SSL check
                   (:func:`ssl.create_default_context` is used),
                   ``False`` for skip SSL certificate validation,
                   :class:`aiohttp.Fingerprint` for fingerprint
                   validation, :class:`ssl.SSLContext` for custom SSL
                   certificate validation.
 
-                  Supersedes *verify_ssl*, *ssl_context* and
-                  *fingerprint* parameters.
-
          .. versionadded:: 3.0
 
-      :param bool verify_ssl: Perform SSL certificate validation for
-         *HTTPS* requests (enabled by default). May be disabled to
-         skip validation for sites with invalid certificates.
-
-         .. versionadded:: 2.3
-
-         .. deprecated:: 3.0
-
-            Use ``ssl=False``
-
-      :param bytes fingerprint: Pass the SHA256 digest of the expected
-         certificate in DER format to verify that the certificate the
-         server presents matches. Useful for `certificate pinning
-         <https://en.wikipedia.org/wiki/Transport_Layer_Security#Certificate_pinning>`_.
-
-         Warning: use of MD5 or SHA1 digests is insecure and removed.
-
-         .. versionadded:: 2.3
-
-         .. deprecated:: 3.0
-
-            Use ``ssl=aiohttp.Fingerprint(digest)``
-
-      :param ssl.SSLContext ssl_context: ssl context used for processing
-         *HTTPS* requests (optional).
-
-         *ssl_context* may be used for configuring certification
-         authority channel, supported SSL options etc.
-
-         .. versionadded:: 2.3
-
-         .. deprecated:: 3.0
-
-            Use ``ssl=ssl_context``
-
       :param abc.Mapping proxy_headers: HTTP headers to send to the proxy if the
          parameter proxy has been provided.
 
          .. versionadded:: 2.3
 
       :param trace_request_ctx: Object used to give as a kw param for each new
         :class:`TraceConfig` object instantiated,
@@ -434,16 +400,17 @@
       In order to modify inner
       :meth:`request<aiohttp.ClientSession.request>`
       parameters, provide `kwargs`.
 
 
       :param url: Request URL, :class:`str` or :class:`~yarl.URL`
 
-      :param data: Dictionary, bytes, or file-like object to
-                   send in the body of the request (optional)
+      :param data: Data to send in the body of the request; see
+                   :meth:`request<aiohttp.ClientSession.request>`
+                   for details (optional)
 
       :return ClientResponse: a :class:`client response
                               <ClientResponse>` object.
 
    .. comethod:: put(url, *, data=None, **kwargs)
       :async-with:
       :coroutine:
@@ -453,16 +420,17 @@
       In order to modify inner
       :meth:`request<aiohttp.ClientSession.request>`
       parameters, provide `kwargs`.
 
 
       :param url: Request URL, :class:`str` or :class:`~yarl.URL`
 
-      :param data: Dictionary, bytes, or file-like object to
-                   send in the body of the request (optional)
+      :param data: Data to send in the body of the request; see
+                   :meth:`request<aiohttp.ClientSession.request>`
+                   for details (optional)
 
       :return ClientResponse: a :class:`client response
                               <ClientResponse>` object.
 
    .. comethod:: delete(url, **kwargs)
       :async-with:
       :coroutine:
@@ -523,50 +491,48 @@
 
       In order to modify inner
       :meth:`request<aiohttp.ClientSession.request>`
       parameters, provide `kwargs`.
 
       :param url: Request URL, :class:`str` or :class:`~yarl.URL`
 
-      :param data: Dictionary, bytes, or file-like object to
-                   send in the body of the request (optional)
-
+      :param data: Data to send in the body of the request; see
+                   :meth:`request<aiohttp.ClientSession.request>`
+                   for details (optional)
 
       :return ClientResponse: a :class:`client response
                               <ClientResponse>` object.
 
    .. comethod:: ws_connect(url, *, method='GET', \
-                            protocols=(), timeout=10.0,\
-                            receive_timeout=None,\
+                            protocols=(), \
+                            timeout=sentinel,\
                             auth=None,\
                             autoclose=True,\
                             autoping=True,\
                             heartbeat=None,\
                             origin=None, \
                             headers=None, \
                             proxy=None, proxy_auth=None, ssl=None, \
-                            verify_ssl=None, fingerprint=None, \
-                            ssl_context=None, proxy_headers=None, \
+                            proxy_headers=None, \
                             compress=0, max_msg_size=4194304)
       :async-with:
       :coroutine:
 
       Create a websocket connection. Returns a
       :class:`ClientWebSocketResponse` object.
 
       :param url: Websocket server url, :class:`str` or :class:`~yarl.URL`
 
       :param tuple protocols: Websocket protocols
 
-      :param float timeout: Timeout for websocket to close. ``10`` seconds
-                            by default
-
-      :param float receive_timeout: Timeout for websocket to receive
-                                    complete message.  ``None`` (unlimited)
-                                    seconds by default
+      :param timeout: a :class:`ClientWSTimeout` timeout for websocket.
+                      By default, the value
+                      `ClientWSTimeout(ws_receive=None, ws_close=10.0)` is used
+                      (``10.0`` seconds for the websocket to close).
+                      ``None`` means no timeout will be used.
 
       :param aiohttp.BasicAuth auth: an object that represents HTTP
                                      Basic Authorization (optional)
 
       :param bool autoclose: Automatically close websocket connection on close
                              message from server. If *autoclose* is False
                              then close procedure has to be handled manually.
@@ -594,54 +560,16 @@
       :param ssl: SSL validation mode. ``None`` for default SSL check
                   (:func:`ssl.create_default_context` is used),
                   ``False`` for skip SSL certificate validation,
                   :class:`aiohttp.Fingerprint` for fingerprint
                   validation, :class:`ssl.SSLContext` for custom SSL
                   certificate validation.
 
-                  Supersedes *verify_ssl*, *ssl_context* and
-                  *fingerprint* parameters.
-
          .. versionadded:: 3.0
 
-      :param bool verify_ssl: Perform SSL certificate validation for
-         *HTTPS* requests (enabled by default). May be disabled to
-         skip validation for sites with invalid certificates.
-
-         .. versionadded:: 2.3
-
-         .. deprecated:: 3.0
-
-            Use ``ssl=False``
-
-      :param bytes fingerprint: Pass the SHA256 digest of the expected
-         certificate in DER format to verify that the certificate the
-         server presents matches. Useful for `certificate pinning
-         <https://en.wikipedia.org/wiki/Transport_Layer_Security#Certificate_pinning>`_.
-
-         Note: use of MD5 or SHA1 digests is insecure and deprecated.
-
-         .. versionadded:: 2.3
-
-         .. deprecated:: 3.0
-
-            Use ``ssl=aiohttp.Fingerprint(digest)``
-
-      :param ssl.SSLContext ssl_context: ssl context used for processing
-         *HTTPS* requests (optional).
-
-         *ssl_context* may be used for configuring certification
-         authority channel, supported SSL options etc.
-
-         .. versionadded:: 2.3
-
-         .. deprecated:: 3.0
-
-            Use ``ssl=ssl_context``
-
       :param dict proxy_headers: HTTP headers to send to the proxy if the
          parameter proxy has been provided.
 
          .. versionadded:: 2.3
 
       :param int compress: Enable Per-Message Compress Extension support.
                            0 for disable, 9 to 15 for window bit support.
@@ -689,31 +617,33 @@
 .. cofunction:: request(method, url, *, params=None, data=None, \
                         json=None,\
                         headers=None, cookies=None, auth=None, \
                         allow_redirects=True, max_redirects=10, \
                         encoding='utf-8', \
                         version=HttpVersion(major=1, minor=1), \
                         compress=None, chunked=None, expect100=False, raise_for_status=False, \
-                        connector=None, loop=None,\
+                        connector=None, \
                         read_until_eof=True, timeout=sentinel)
 
    :async-with:
 
    Asynchronous context manager for performing an asynchronous HTTP
    request. Returns a :class:`ClientResponse` response object.
 
    :param str method: HTTP method
 
    :param url: Requested URL, :class:`str` or :class:`~yarl.URL`
 
    :param dict params: Parameters to be sent in the query
                        string of the new request (optional)
 
-   :param data: Dictionary, bytes, or file-like object to
-                send in the body of the request (optional)
+   :param data: The data to send in the body of the request. This can be a
+                :class:`FormData` object or anything that can be passed into
+                :class:`FormData`, e.g. a dictionary, bytes, or file-like object.
+                (optional)
 
    :param json: Any json compatible python object (optional). *json* and *data*
                 parameters could not be used at the same time.
 
    :param dict headers: HTTP Headers to send with the request (optional)
 
    :param dict cookies: Cookies to send with the request (optional)
@@ -752,22 +682,14 @@
    :param bool read_until_eof: Read response until EOF if response
                                does not have Content-Length header.
                                ``True`` by default (optional).
 
    :param timeout: a :class:`ClientTimeout` settings structure, 5min
         total timeout by default.
 
-   :param loop: :ref:`event loop<asyncio-event-loop>`
-                used for processing HTTP requests.
-                If param is ``None``, :func:`asyncio.get_event_loop`
-                is used for getting default event loop.
-
-      .. deprecated:: 2.0
-
-   :return ClientResponse: a :class:`client response <ClientResponse>` object.
 
    Usage::
 
       import aiohttp
 
       async def fetch():
           async with aiohttp.request('GET',
@@ -797,15 +719,15 @@
 
 
 BaseConnector
 ^^^^^^^^^^^^^
 
 .. class:: BaseConnector(*, keepalive_timeout=15, \
                          force_close=False, limit=100, limit_per_host=0, \
-                         enable_cleanup_closed=False, loop=None)
+                         enable_cleanup_closed=False)
 
    Base class for all connectors.
 
    :param float keepalive_timeout: timeout for connection reusing
                                    after releasing (optional). Values
                                    ``0``. For disabling *keep-alive*
                                    feature use ``force_close=True``
@@ -823,22 +745,14 @@
                             connection releasing (optional).
 
    :param bool enable_cleanup_closed: some SSL servers do not properly complete
       SSL shutdown process, in that case asyncio leaks ssl connections.
       If this parameter is set to True, aiohttp additionally aborts underlining
       transport after 2 seconds. It is off by default.
 
-
-   :param loop: :ref:`event loop<asyncio-event-loop>`
-      used for handling connections.
-      If param is ``None``, :func:`asyncio.get_event_loop`
-      is used for getting default event loop.
-
-      .. deprecated:: 2.0
-
    .. attribute:: closed
 
       Read-only property, ``True`` if connector is closed.
 
    .. attribute:: force_close
 
       Read-only property, ``True`` if connector should ultimately
@@ -859,15 +773,15 @@
 
       If *limit_per_host* is ``None`` the connector has no limit per host.
 
       Read-only property.
 
    .. comethod:: close()
 
-      Close all opened connections.
+      Close all open connections (and await them to close).
 
    .. comethod:: connect(request)
 
       Get a free connection from pool or create new one if connection
       is absent in the pool.
 
       The call may be paused if :attr:`limit` is exhausted until used
@@ -886,20 +800,20 @@
 
 
 
 
 TCPConnector
 ^^^^^^^^^^^^
 
-.. class:: TCPConnector(*, ssl=None, verify_ssl=True, fingerprint=None, \
+.. class:: TCPConnector(*, ssl=None, \
                  use_dns_cache=True, ttl_dns_cache=10, \
-                 family=0, ssl_context=None, local_addr=None, \
+                 family=0, local_addr=None, \
                  resolver=None, keepalive_timeout=sentinel, \
                  force_close=False, limit=100, limit_per_host=0, \
-                 enable_cleanup_closed=False, loop=None)
+                 enable_cleanup_closed=False)
 
    Connector for working with *HTTP* and *HTTPS* via *TCP* sockets.
 
    The most common transport. When you don't know what connector type
    to use, use a :class:`TCPConnector` instance.
 
    :class:`TCPConnector` inherits from :class:`BaseConnector`.
@@ -910,38 +824,16 @@
       :param ssl: SSL validation mode. ``None`` for default SSL check
                   (:func:`ssl.create_default_context` is used),
                   ``False`` for skip SSL certificate validation,
                   :class:`aiohttp.Fingerprint` for fingerprint
                   validation, :class:`ssl.SSLContext` for custom SSL
                   certificate validation.
 
-                  Supersedes *verify_ssl*, *ssl_context* and
-                  *fingerprint* parameters.
-
          .. versionadded:: 3.0
 
-   :param bool verify_ssl: perform SSL certificate validation for
-      *HTTPS* requests (enabled by default). May be disabled to
-      skip validation for sites with invalid certificates.
-
-      .. deprecated:: 2.3
-
-         Pass *verify_ssl* to ``ClientSession.get()`` etc.
-
-   :param bytes fingerprint: pass the SHA256 digest of the expected
-      certificate in DER format to verify that the certificate the
-      server presents matches. Useful for `certificate pinning
-      <https://en.wikipedia.org/wiki/Transport_Layer_Security#Certificate_pinning>`_.
-
-      Note: use of MD5 or SHA1 digests is insecure and deprecated.
-
-      .. deprecated:: 2.3
-
-         Pass *verify_ssl* to ``ClientSession.get()`` etc.
-
    :param bool use_dns_cache: use internal cache for DNS lookups, ``True``
       by default.
 
       Enabling an option *may* speedup connection
       establishing a bit but may introduce some
       *side effects* also.
 
@@ -958,40 +850,33 @@
 
    :param int limit_per_host: limit simultaneous connections to the same
       endpoint.  Endpoints are the same if they are
       have equal ``(host, port, is_ssl)`` triple.
       If *limit* is ``0`` the connector has no limit (default: 0).
 
    :param aiohttp.abc.AbstractResolver resolver: custom resolver
-      instance to use.  ``aiohttp.DefaultResolver`` by
-      default (asynchronous if ``aiodns>=1.1`` is installed).
+      instance to use. ``aiohttp.DefaultResolver`` by default.
 
       Custom resolvers allow to resolve hostnames differently than the
       way the host is configured.
 
-      The resolver is ``aiohttp.ThreadedResolver`` by default,
-      asynchronous version is pretty robust but might fail in
-      very rare cases.
+      The resolver is ``aiohttp.ThreadedResolver`` by default. Asynchronous
+      version ``aiohttp.AsyncResolver`` (requires ``aiodns>=1.1``) is pretty
+      robust but might fail in very rare cases.
 
    :param int family: TCP socket family, both IPv4 and IPv6 by default.
                       For *IPv4* only use :const:`socket.AF_INET`,
                       for  *IPv6* only -- :const:`socket.AF_INET6`.
 
                       *family* is ``0`` by default, that means both
                       IPv4 and IPv6 are accepted. To specify only
                       concrete version please pass
                       :const:`socket.AF_INET` or
                       :const:`socket.AF_INET6` explicitly.
 
-   :param ssl.SSLContext ssl_context: SSL context used for processing
-      *HTTPS* requests (optional).
-
-      *ssl_context* may be used for configuring certification
-      authority channel, supported SSL options etc.
-
    :param tuple local_addr: tuple of ``(local_host, local_port)`` used to bind
       socket locally if specified.
 
    :param bool force_close: close underlying sockets after
                             connection releasing (optional).
 
    :param bool enable_cleanup_closed: Some ssl servers do not properly complete
@@ -1027,15 +912,15 @@
 
 
 UnixConnector
 ^^^^^^^^^^^^^
 
 .. class:: UnixConnector(path, *, conn_timeout=None, \
                          keepalive_timeout=30, limit=100, \
-                         force_close=False, loop=None)
+                         force_close=False)
 
    Unix socket connector.
 
    Use :class:`UnixConnector` for sending *HTTP/HTTPS* requests
    through *UNIX Sockets* as underlying transport.
 
    UNIX sockets are handy for writing tests and making very fast
@@ -1072,20 +957,14 @@
    but get it by :meth:`BaseConnector.connect` coroutine.
 
    .. attribute:: closed
 
       :class:`bool` read-only property, ``True`` if connection was
       closed, released or detached.
 
-   .. attribute:: loop
-
-      Event loop used for connection
-
-      .. deprecated:: 3.5
-
    .. attribute:: transport
 
       Connection transport
 
    .. method:: close()
 
       Close connection with forcibly closing underlying socket.
@@ -1250,15 +1129,15 @@
    .. method:: raise_for_status()
 
       Raise an :exc:`aiohttp.ClientResponseError` if the response
       status is 400 or higher.
 
       Do nothing for success responses (less than 400).
 
-   .. comethod:: text(encoding=None)
+   .. comethod:: text(encoding=None, errors='strict')
 
       Read response's body and return decoded :class:`str` using
       specified *encoding* parameter.
 
       If *encoding* is ``None`` content encoding is autocalculated
       using ``Content-Type`` HTTP header and *chardet* tool if the
       header is not provided by server.
@@ -1269,14 +1148,17 @@
       Close underlying connection if data reading gets an error,
       release connection otherwise.
 
       :param str encoding: text encoding used for *BODY* decoding, or
                            ``None`` for encoding autodetection
                            (default).
 
+      :param str errors: error handling scheme, see :ref:`error-handlers` for
+                         more details.  ``'strict'`` by default.
+
       :return str: decoded *BODY*
 
       :raise LookupError: if the encoding detected by chardet or cchardet is
                           unknown by Python (e.g. VISCII).
 
       .. note::
 
@@ -1565,15 +1447,32 @@
 
    .. attribute:: sock_read
 
       A timeout for reading a portion of data from a peer.
 
       :class:`float`, ``None`` by default.
 
-   .. versionadded:: 3.3
+
+.. class:: ClientWSTimeout(*, ws_receive=None, ws_close=None)
+
+   A data class for websocket client timeout settings.
+
+   .. attribute:: ws_receive
+
+      A timeout for websocket to receive a complete message.
+
+      :class:`float`, ``None`` by default.
+
+   .. attribute:: ws_close
+
+      A timeout for the websocket to close.
+
+      :class:`float`, ``10.0`` by default.
+
+   .. versionadded:: 4.0
 
 RequestInfo
 ^^^^^^^^^^^
 
 .. class:: RequestInfo()
 
    A data class with request URL and headers from :class:`ClientRequest`
@@ -1640,15 +1539,15 @@
 
       :return: encoded authentication data, :class:`str`.
 
 
 CookieJar
 ^^^^^^^^^
 
-.. class:: CookieJar(*, unsafe=False, loop=None)
+.. class:: CookieJar(*, unsafe=False)
 
    The cookie jar instance is available as :attr:`ClientSession.cookie_jar`.
 
    The jar contains :class:`~http.cookies.Morsel` items for storing
    internal cookie data.
 
    API provides a count of saved cookies::
@@ -1665,19 +1564,14 @@
    :class:`collections.abc.Sized` and
    :class:`aiohttp.AbstractCookieJar` interfaces.
 
    Implements cookie storage adhering to RFC 6265.
 
    :param bool unsafe: (optional) Whether to accept cookies from IPs.
 
-   :param bool loop: an :ref:`event loop<asyncio-event-loop>` instance.
-      See :class:`aiohttp.abc.AbstractCookieJar`
-
-      .. deprecated:: 2.0
-
    .. method:: update_cookies(cookies, response_url=None)
 
       Update cookies returned by server in ``Set-Cookie`` header.
 
       :param cookies: a :class:`collections.abc.Mapping`
          (e.g. :class:`dict`, :class:`~http.cookies.SimpleCookie`) or
          *iterable* of *pairs* with cookies returned by server's
@@ -1712,15 +1606,15 @@
       at provided path.
 
       :param file_path: Path to file from where cookies will be
            imported, :class:`str` or :class:`pathlib.Path` instance.
 
 
 
-.. class:: DummyCookieJar(*, loop=None)
+.. class:: DummyCookieJar()
 
    Dummy cookie jar which does not store cookies but ignores them.
 
    Could be useful e.g. for web crawlers to iterate over Internet
    without blowing up with saved cookies information.
 
    To install dummy cookie jar pass it into session instance::
@@ -1729,14 +1623,17 @@
       session = aiohttp.ClientSession(cookie_jar=DummyCookieJar())
 
 
 .. class:: Fingerprint(digest)
 
    Fingerprint helper for checking SSL certificates by *SHA256* digest.
 
+   Useful for `certificate pinning
+   <https://en.wikipedia.org/wiki/Transport_Layer_Security#Certificate_pinning>`_.
+
    :param bytes digest: *SHA256* digest for certificate in DER-encoded
                         binary form (see
                         :meth:`ssl.SSLSocket.getpeercert`).
 
    To check fingerprint pass the object into :meth:`ClientSession.get`
    call, e.g.::
 
@@ -1745,14 +1642,87 @@
       with open(path_to_cert, 'rb') as f:
           digest = hashlib.sha256(f.read()).digest()
 
       await session.get(url, ssl=aiohttp.Fingerprint(digest))
 
    .. versionadded:: 3.0
 
+FormData
+^^^^^^^^
+
+A :class:`FormData` object contains the form data and also handles
+encoding it into a body that is either ``multipart/form-data`` or
+``application/x-www-form-urlencoded``. ``multipart/form-data`` is
+used if at least one field is an :class:`io.IOBase` object or was
+added with at least one optional argument to :meth:`add_field<aiohttp.FormData.add_field>`
+(``content_type``, ``filename``, or ``content_transfer_encoding``).
+Otherwise, ``application/x-www-form-urlencoded`` is used.
+
+:class:`FormData` instances are callable and return a :class:`Payload`
+on being called.
+
+.. class:: FormData(fields, quote_fields=True, charset=None)
+
+   Helper class for multipart/form-data and application/x-www-form-urlencoded body generation.
+
+   :param fields: A container for the key/value pairs of this form.
+
+                  Possible types are:
+
+                  - :class:`dict`
+                  - :class:`tuple` or :class:`list`
+                  - :class:`io.IOBase`, e.g. a file-like object
+                  - :class:`multidict.MultiDict` or :class:`multidict.MultiDictProxy`
+
+                  If it is a :class:`tuple` or :class:`list`, it must be a valid argument
+                  for :meth:`add_fields<aiohttp.FormData.add_fields>`.
+
+                  For :class:`dict`, :class:`multidict.MultiDict`, and :class:`multidict.MultiDictProxy`,
+                  the keys and values must be valid `name` and `value` arguments to
+                  :meth:`add_field<aiohttp.FormData.add_field>`, respectively.
+
+   .. method:: add_field(name, value, content_type=None, filename=None,\
+                         content_transfer_encoding=None)
+
+      Add a field to the form.
+
+      :param str name: Name of the field
+
+      :param value: Value of the field
+
+                    Possible types are:
+
+                    - :class:`str`
+                    - :class:`bytes`, :class:`bytesarray`, or :class:`memoryview`
+                    - :class:`io.IOBase`, e.g. a file-like object
+
+      :param str content_type: The field's content-type header (optional)
+
+      :param str filename: The field's filename (optional)
+
+                           If this is not set and ``value`` is a :class:`bytes`, :class:`bytesarray`,
+                           or :class:`memoryview` object, the `name` argument is used as the filename
+                           unless ``content_transfer_encoding`` is specified.
+
+                           If ``filename`` is not set and ``value`` is an :class:`io.IOBase`
+                           object, the filename is extracted from the object if possible.
+
+      :param str content_transfer_encoding: The field's content-transfer-encoding
+                                            header (optional)
+
+   .. method:: add_fields(fields)
+
+      Add one or more fields to the form.
+
+      :param fields: An iterable containing:
+
+                     - :class:`io.IOBase`, e.g. a file-like object
+                     - :class:`multidict.MultiDict` or :class:`multidict.MultiDictProxy`
+                     - :class:`tuple` or :class:`list` of length two, containing a name-value pair
+
 Client exceptions
 -----------------
 
 Exception hierarchy has been significantly modified in version
 2.0. aiohttp defines only exceptions that covers connection handling
 and server response misbehaviors.  For developer specific mistakes,
 aiohttp uses python standard exceptions like :exc:`ValueError` or
```

### Comparing `aiohttp-4.0.0a0/docs/conf.py` & `aiohttp-4.0.0a1/docs/conf.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/docs/contributing.rst` & `aiohttp-4.0.0a1/docs/contributing.rst`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/docs/deployment.rst` & `aiohttp-4.0.0a1/docs/deployment.rst`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/docs/faq.rst` & `aiohttp-4.0.0a1/docs/faq.rst`

 * *Files 4% similar despite different names*

```diff
@@ -65,47 +65,22 @@
         db = request.app['db']
         cursor = await db.cursor()
         await cursor.execute('SELECT 42')
         # ...
         return web.Response(status=200, text='ok')
 
 
-    async def init_app(loop):
-        app = Application(loop=loop)
+    async def init_app():
+        app = Application()
         db = await create_connection(user='user', password='123')
         app['db'] = db
         app.router.add_get('/', go)
         return app
 
 
-Why is Python 3.5.3 the lowest supported version?
--------------------------------------------------
-
-Python 3.5.2 fixes the protocol for async iterators: ``__aiter__()`` is
-not a coroutine but a regular function.
-
-Python 3.5.3 has a more important change: :func:`asyncio.get_event_loop`
-returns the running loop instance if called from a coroutine.
-Previously it returned a *default* loop, set by
-:func:`asyncio.set_event_loop`.
-
-Previous to Python 3.5.3,
-:func:`asyncio.get_event_loop` was not reliable, so users were
-forced to explicitly pass the event loop instance everywhere.
-If a future object were created for one event loop
-(e.g. the default loop) but a coroutine was run by another loop, the coroutine
-was never awaited. As a result, the task would hang.
-
-Keep in mind that every internal ``await`` expression either passed
-instantly or paused, waiting for a future.
-
-It's extremely important that all tasks (coroutine runners) and
-futures use the same event loop.
-
-
 How can middleware store data for web handlers to use?
 ------------------------------------------------------
 
 Both :class:`aiohttp.web.Request`  and :class:`aiohttp.web.Application`
 support the :class:`dict` interface.
 
 Therefore, data may be stored inside a request object. ::
@@ -142,15 +117,15 @@
 However, other tasks may use the same WebSocket object for sending data to
 peers. ::
 
     async def handler(request):
 
         ws = web.WebSocketResponse()
         await ws.prepare(request)
-        task = request.app.loop.create_task(
+        task = asyncio.create_task(
             read_subscription(ws,
                               request.app['redis']))
         try:
             async for msg in ws:
                 # handle incoming messages
                 # use ws.send_str() to send data back
                 ...
@@ -214,28 +189,28 @@
         ws_closers and await asyncio.gather(*ws_closers)
 
         return web.Response(text='OK')
 
 
     def main():
         loop = asyncio.get_event_loop()
-        app = web.Application(loop=loop)
+        app = web.Application()
         app.router.add_route('GET', '/echo', echo_handler)
         app.router.add_route('POST', '/logout', logout_handler)
         app['websockets'] = defaultdict(set)
         web.run_app(app, host='localhost', port=8080)
 
 
 How do I make a request from a specific IP address?
 ---------------------------------------------------
 
 If your system has several IP interfaces, you may choose one which will
 be used used to bind a socket locally::
 
-    conn = aiohttp.TCPConnector(local_addr=('127.0.0.1', 0), loop=loop)
+    conn = aiohttp.TCPConnector(local_addr=('127.0.0.1', 0))
     async with aiohttp.ClientSession(connector=conn) as session:
         ...
 
 .. seealso:: :class:`aiohttp.TCPConnector` and ``local_addr`` parameter.
 
 
 What is the API stability and deprecation policy?
@@ -269,15 +244,15 @@
 All backward incompatible changes are explicitly marked in
 :ref:`the changelog <aiohttp_changes>`.
 
 
 How do I enable gzip compression globally for my entire application?
 --------------------------------------------------------------------
 
-It's impossible. Choosing what to compress and what not to compress is
+It's impossible. Choosing what to compress and what not to compress
 is a tricky matter.
 
 If you need global compression, write a custom middleware. Or
 enable compression in NGINX (you are deploying aiohttp behind reverse
 proxy, right?).
 
 
@@ -349,15 +324,14 @@
 
     from aiohttp import web
 
     def misbehaved_middleware():
         # don't do this!
         cached = web.Response(status=200, text='Hi, I am cached!')
 
-        @web.middleware
         async def middleware(request, handler):
             # ignoring response for the sake of this example
             _res = handler(request)
             return cached
 
         return middleware
```

### Comparing `aiohttp-4.0.0a0/docs/favicon.ico` & `aiohttp-4.0.0a1/docs/favicon.ico`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/docs/glossary.rst` & `aiohttp-4.0.0a1/docs/glossary.rst`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/docs/index.rst` & `aiohttp-4.0.0a1/docs/index.rst`

 * *Files 6% similar despite different names*

```diff
@@ -44,14 +44,25 @@
 :term:`aiodns` as well.
 This option is highly recommended:
 
 .. code-block:: bash
 
    $ pip install aiodns
 
+Installing speedups altogether
+------------------------------
+
+The following will get you ``aiohttp`` along with :term:`chardet`,
+:term:`aiodns` and ``Brotli`` in one bundle. No need to type
+separate commands anymore!
+
+.. code-block:: bash
+
+   $ pip install aiohttp[speedups]
+
 Getting Started
 ===============
 
 Client example::
 
     import aiohttp
     import asyncio
@@ -61,31 +72,33 @@
             return await response.text()
 
     async def main():
         async with aiohttp.ClientSession() as session:
             html = await fetch(session, 'http://python.org')
             print(html)
 
-    loop = asyncio.get_event_loop()
-    loop.run_until_complete(main())
+    if __name__ == '__main__':
+        loop = asyncio.get_event_loop()
+        loop.run_until_complete(main())
 
 Server example::
 
     from aiohttp import web
 
     async def handle(request):
         name = request.match_info.get('name', "Anonymous")
         text = "Hello, " + name
         return web.Response(text=text)
 
     app = web.Application()
     app.add_routes([web.get('/', handle),
                     web.get('/{name}', handle)])
 
-    web.run_app(app)
+    if __name__ == '__main__':
+        web.run_app(app)
 
 
 For more information please visit :ref:`aiohttp-client` and
 :ref:`aiohttp-web` pages.
 
 
 What's new in aiohttp 3?
@@ -113,15 +126,15 @@
 The library uses `Travis <https://travis-ci.com/aio-libs/aiohttp>`_ for
 Continuous Integration.
 
 
 Dependencies
 ============
 
-- Python 3.5.3+
+- Python 3.6+
 - *async_timeout*
 - *attrs*
 - *chardet*
 - *multidict*
 - *yarl*
 - *Optional* :term:`cchardet` as faster replacement for
   :term:`chardet`.
@@ -174,22 +187,22 @@
 
 Policy for Backward Incompatible Changes
 ========================================
 
 *aiohttp* keeps backward compatibility.
 
 After deprecating some *Public API* (method, class, function argument,
-etc.) the library guaranties the usage of *deprecated API* is still
+etc.) the library guarantees the usage of *deprecated API* is still
 allowed at least for a year and half after publishing new release with
 deprecation.
 
 All deprecations are reflected in documentation and raises
 :exc:`DeprecationWarning`.
 
-Sometimes we are forced to break the own rule for sake of very strong
+Sometimes we are forced to break our own rule for the sake of very strong
 reason.  Most likely the reason is a critical bug which cannot be
 solved without major API change, but we are working hard for keeping
 these changes as rare as possible.
 
 
 Table Of Contents
 =================
```

### Comparing `aiohttp-4.0.0a0/docs/logging.rst` & `aiohttp-4.0.0a1/docs/logging.rst`

 * *Files 17% similar despite different names*

```diff
@@ -1,15 +1,14 @@
+.. currentmodule:: aiohttp
+
 .. _aiohttp-logging:
 
 Logging
 =======
 
-.. currentmodule:: aiohttp
-
-
 *aiohttp* uses standard :mod:`logging` for tracking the
 library activity.
 
 We have the following loggers enumerated by names:
 
 - ``'aiohttp.access'``
 - ``'aiohttp.client'``
@@ -19,15 +18,26 @@
 - ``'aiohttp.websocket'``
 
 You may subscribe to these loggers for getting logging messages.  The
 page does not provide instructions for logging subscribing while the
 most friendly method is :func:`logging.config.dictConfig` for
 configuring whole loggers in your application.
 
+Logging does not work out of the box. It requires at least minimal ``'logging'``
+configuration.
+Example of minimal working logger setup::
+
+  import logging
+  from aiohttp import web
+
+  app = web.Application()
+  logging.basicConfig(level=logging.DEBUG)
+  web.run_app(app, port=5000)
 
+.. versionadded:: 4.0.0
 
 Access logs
 -----------
 
 Access logs are enabled by default. If the `debug` flag is set, and the default
 logger ``'aiohttp.access'`` is used, access logs will be output to
 :obj:`~sys.stderr` if no handlers are attached.
@@ -89,26 +99,54 @@
 
    '%a %t "%r" %s %b "%{Referer}i" "%{User-Agent}i"'
 
 .. versionadded:: 2.3.0
 
 *access_log_class* introduced.
 
-Example of a drop-in replacement for :class:`aiohttp.helpers.AccessLogger`::
+Example of a drop-in replacement for the default access logger::
 
   from aiohttp.abc import AbstractAccessLogger
 
   class AccessLogger(AbstractAccessLogger):
 
       def log(self, request, response, time):
           self.logger.info(f'{request.remote} '
                            f'"{request.method} {request.path} '
                            f'done in {time}s: {response.status}')
 
 
+.. versionadded:: 4.0.0
+
+
+``AccessLogger.log()`` can now access any exception raised while processing
+the request with ``sys.exc_info()``.
+
+
+.. versionadded:: 4.0.0
+
+
+If your logging needs to perform IO you can instead inherit from
+:class:`aiohttp.abc.AbstractAsyncAccessLogger`::
+
+
+  from aiohttp.abc import AbstractAsyncAccessLogger
+
+  class AccessLogger(AbstractAsyncAccessLogger):
+
+      async def log(self, request, response, time):
+          logging_service = request.app['logging_service']
+          await logging_service.log(f'{request.remote} '
+                                    f'"{request.method} {request.path} '
+                                    f'done in {time}s: {response.status}')
+
+
+This also allows access to the results of coroutines on the ``request`` and
+``response``, e.g. ``request.text()``.
+
 .. _gunicorn-accesslog:
 
 Gunicorn access logs
 ^^^^^^^^^^^^^^^^^^^^
 When `Gunicorn <http://docs.gunicorn.org/en/latest/index.html>`_ is used for
 :ref:`deployment <aiohttp-deployment-gunicorn>`, its default access log format
 will be automatically replaced with the default aiohttp's access log format.
@@ -119,17 +157,14 @@
 Gunicorn's access log works only if accesslog_ is specified explicitly in your
 config or as a command line option.
 This configuration can be either a path or ``'-'``. If the application uses
 a custom logging setup intercepting the ``'gunicorn.access'`` logger,
 accesslog_ should be set to ``'-'`` to prevent Gunicorn to create an empty
 access log file upon every startup.
 
-
-
-
 Error logs
 ----------
 
 :mod:`aiohttp.web` uses a logger named ``'aiohttp.server'`` to store errors
 given on web requests handling.
 
 This log is enabled by default.
```

### Comparing `aiohttp-4.0.0a0/docs/make.bat` & `aiohttp-4.0.0a1/docs/make.bat`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/docs/Makefile` & `aiohttp-4.0.0a1/docs/Makefile`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/docs/migration_to_2xx.rst` & `aiohttp-4.0.0a1/docs/migration_to_2xx.rst`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/docs/multipart.rst` & `aiohttp-4.0.0a1/docs/multipart.rst`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-.. module:: aiohttp
+.. currentmodule:: aiohttp
 
 .. _aiohttp-multipart:
 
 Working with Multipart
 ======================
 
 ``aiohttp`` supports a full featured multipart reader and writer. Both
@@ -192,15 +192,15 @@
 content. Providing `close_boundary = False` prevents this.::
 
     my_boundary = 'some-boundary'
     response = web.StreamResponse(
         status=200,
         reason='OK',
         headers={
-            'Content-Type': 'multipart/x-mixed-replace;boundary=--%s' % my_boundary
+            'Content-Type': 'multipart/x-mixed-replace;boundary={}'.format(my_boundary)
         }
     )
     while True:
         frame = get_jpeg_frame()
         with MultipartWriter('image/jpeg', boundary=my_boundary) as mpwriter:
             mpwriter.append(frame, {
                 'Content-Type': 'image/jpeg'
```

### Comparing `aiohttp-4.0.0a0/docs/multipart_reference.rst` & `aiohttp-4.0.0a1/docs/multipart_reference.rst`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-.. module:: aiohttp
+.. currentmodule:: aiohttp
 
 .. _aiohttp-multipart-reference:
 
 Multipart reference
 ===================
 
 .. class:: MultipartResponseWrapper(resp, stream)
@@ -115,15 +115,15 @@
    .. attribute:: name
 
       A field *name* specified in ``Content-Disposition`` header or ``None``
       if missed or header is malformed.
 
       Readonly :class:`str` property.
 
-   .. attribute:: name
+   .. attribute:: filename
 
       A field *filename* specified in ``Content-Disposition`` header or ``None``
       if missed or header is malformed.
 
       Readonly :class:`str` property.
 
 
@@ -196,9 +196,9 @@
       Write body.
 
       :param bool close_boundary: The (:class:`bool`) that will emit
                                   boundary closing. You may want to disable
                                   when streaming (``multipart/x-mixed-replace``)
 
       .. versionadded:: 3.4
-         
+
          Support ``close_boundary`` argument.
```

### Comparing `aiohttp-4.0.0a0/docs/new_router.rst` & `aiohttp-4.0.0a1/docs/new_router.rst`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/docs/old-logo.png` & `aiohttp-4.0.0a1/docs/old-logo.png`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/docs/old-logo.svg` & `aiohttp-4.0.0a1/docs/old-logo.svg`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/docs/powered_by.rst` & `aiohttp-4.0.0a1/docs/powered_by.rst`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/docs/signals.rst` & `aiohttp-4.0.0a1/docs/signals.rst`

 * *Ordering differences only*

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,12 @@
+.. currentmodule:: aiohttp
+
 Signals
 =======
 
-.. currentmodule:: aiohttp
-
 Signal is a list of registered asynchronous callbacks.
 
 The signal's life-cycle has two stages: after creation its content
 could be filled by using standard list operations: ``sig.append()``
 etc.
 
 After ``sig.freeze()`` call the signal is *frozen*: adding, removing
```

### Comparing `aiohttp-4.0.0a0/docs/spelling_wordlist.txt` & `aiohttp-4.0.0a1/docs/spelling_wordlist.txt`

 * *Files 5% similar despite different names*

```diff
@@ -5,41 +5,41 @@
 aiohttpdemo
 aiohttps
 aiopg
 alives
 api
 apis
 app
-apps
 apps
+apps
 arg
 Arsenic
 async
 asyncio
 auth
 autocalculated
 autodetection
 autogenerates
 autogeneration
 awaitable
 backend
 backends
+backport
 Backport
 Backporting
-backport
 backports
 BaseEventLoop
 basename
 BasicAuth
 BodyPartReader
 boolean
 botocore
+bugfix
 Bugfixes
 builtin
-bugfix
 BytesIO
 cchardet
 cChardet
 Changelog
 charset
 charsetdetect
 chunked
@@ -62,17 +62,18 @@
 Coroutine
 coroutines
 cpu
 CPython
 css
 ctor
 Ctrl
+cython
 Cython
-cythonized
 Cythonize
+cythonized
 de
 deduplicate
 # de-facto:
 deprecations
 DER
 Dev
 dict
@@ -147,24 +148,26 @@
 metadata
 microservice
 middleware
 middlewares
 miltidict
 misbehaviors
 misformed
+Mixcloud
 Mongo
 msg
 MsgType
 multi
 multidict
-multidicts
 multidicts
+multidicts
 Multidicts
 multipart
 Multipart
+mypy
 Nagle
 Nagles
 namedtuple
 nameservers
 namespace
 nginx
 Nginx
@@ -186,33 +189,34 @@
 pipelining
 pluggable
 plugin
 poller
 pong
 Postgres
 pre
+proactor
 programmatically
 proxied
 PRs
 pubsub
 Punycode
 py
 pyenv
 pyflakes
 pytest
 Pytest
 Quickstart
 quotes
+readline
 readonly
 readpayload
 rebase
 redirections
 Redis
 refactor
-Refactor
 refactored
 refactoring
 regex
 regexps
 regexs
 reloader
 renderer
@@ -226,14 +230,15 @@
 requote
 requoting
 resolvehost
 resolvers
 reusage
 reuseconn
 Runit
+runtime
 sa
 Satisfiable
 schemas
 sendfile
 serializable
 shourtcuts
 skipuntil
@@ -255,51 +260,52 @@
 symlink
 symlinks
 syscall
 syscalls
 Systemd
 tarball
 TCP
-TLS
 teardown
 Teardown
 TestClient
 Testsuite
 Tf
 timestamps
+TLS
 toolbar
 toplevel
 towncrier
 tp
 tuples
 UI
 un
 unawaited
 unclosed
+unhandled
 unicode
 unittest
 Unittest
 unix
 unsets
 unstripped
 upstr
 url
 urldispatcher
 urlencoded
-urls
 urls
+urls
 utf
 utils
 uvloop
 vcvarsall
 waituntil
 webapp
 websocket
-websockets
 websockets
+websockets
 Websockets
 wildcard
 Workflow
 ws
 wsgi
 WSMessage
 WSMsgType
```

### Comparing `aiohttp-4.0.0a0/docs/streams.rst` & `aiohttp-4.0.0a1/docs/streams.rst`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,14 @@
+.. currentmodule:: aiohttp
+
 .. _aiohttp-streams:
 
 Streaming API
 =============
 
-.. module:: aiohttp
-.. currentmodule:: aiohttp
-
 
 ``aiohttp`` uses streams for retrieving *BODIES*:
 :attr:`aiohttp.web.Request.content` and
 :attr:`aiohttp.ClientResponse.content` are properties with stream API.
 
 
 .. class:: StreamReader
```

### Comparing `aiohttp-4.0.0a0/docs/structures.rst` & `aiohttp-4.0.0a1/docs/structures.rst`

 * *Files 1% similar despite different names*

```diff
@@ -1,18 +1,16 @@
+.. currentmodule:: aiohttp
+
+
 .. _aiohttp-structures:
 
 
 Common data structures
 ======================
 
-.. module:: aiohttp
-
-.. currentmodule:: aiohttp
-
-
 Common data structures used by *aiohttp* internally.
 
 
 FrozenList
 ----------
 
 A list-like structure which implements
```

### Comparing `aiohttp-4.0.0a0/docs/testing.rst` & `aiohttp-4.0.0a1/docs/testing.rst`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,14 @@
+.. module:: aiohttp.test_utils
+
 .. _aiohttp-testing:
 
 Testing
 =======
 
-.. currentmodule:: aiohttp.test_utils
-
 Testing aiohttp web servers
 ---------------------------
 
 aiohttp provides plugin for *pytest* making writing web server tests
 extremely easy, it also provides :ref:`test framework agnostic
 utilities <aiohttp-testing-framework-agnostic-utilities>` for testing
 with other frameworks such as :ref:`unittest
@@ -48,15 +48,15 @@
 
 The Test Client and Servers
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 *aiohttp* test utils provides a scaffolding for testing aiohttp-based
 web servers.
 
-They are consist of two parts: running test server and making HTTP
+They consist of two parts: running test server and making HTTP
 requests to this server.
 
 :class:`~aiohttp.test_utils.TestServer` runs :class:`aiohttp.web.Application`
 based server, :class:`~aiohttp.test_utils.RawTestServer` starts
 :class:`aiohttp.web.WebServer` low level server.
 
 For performing HTTP requests to these servers you have to create a
@@ -67,25 +67,27 @@
 *ws_connect*, *get*, *post*, etc.
 
 
 
 Pytest
 ~~~~~~
 
+.. currentmodule:: pytest_aiohttp
+
 The :data:`aiohttp_client` fixture available from pytest-aiohttp_ plugin
 allows you to create a client to make requests to test your app.
 
 A simple would be::
 
     from aiohttp import web
 
     async def hello(request):
         return web.Response(text='Hello, world')
 
-    async def test_hello(aiohttp_client, loop):
+    async def test_hello(aiohttp_client):
         app = web.Application()
         app.router.add_get('/', hello)
         client = await aiohttp_client(app)
         resp = await client.get('/')
         assert resp.status == 200
         text = await resp.text()
         assert 'Hello, world' in text
@@ -146,15 +148,15 @@
 
    *port* optional, port the server is run at, if
    not provided a random unused port is used.
 
    .. versionadded:: 3.0
 
    *kwargs* are parameters passed to
-                  :meth:`aiohttp.web.Application.make_handler`
+                  :meth:`aiohttp.web.AppRunner`
 
    .. versionchanged:: 3.0
    .. deprecated:: 3.2
 
       The fixture was renamed from ``test_server`` to ``aiohttp_server``.
 
 
@@ -231,14 +233,17 @@
 .. _aiohttp-testing-unittest-example:
 
 .. _aiohttp-testing-unittest-style:
 
 Unittest
 ~~~~~~~~
 
+.. currentmodule:: aiohttp.test_utils
+
+
 To test applications with the standard library's unittest or unittest-based
 functionality, the AioHTTPTestCase is provided::
 
     from aiohttp.test_utils import AioHTTPTestCase, unittest_run_loop
     from aiohttp import web
 
     class MyAppTestCase(AioHTTPTestCase):
@@ -503,15 +508,15 @@
 If it's preferred to handle the creation / teardown on a more granular
 basis, the TestClient object can be used directly::
 
     from aiohttp.test_utils import TestClient, TestServer
 
     with loop_context() as loop:
         app = _create_example_app()
-        client = TestClient(TestSever(app), loop=loop)
+        client = TestClient(TestServer(app), loop=loop)
         loop.run_until_complete(client.start_server())
         root = "http://127.0.0.1:{}".format(port)
 
         async def test_get_route():
             resp = await client.get("/")
             assert resp.status == 200
             text = await resp.text()
@@ -573,18 +578,15 @@
 
       :class:`aiohttp.web.WebServer` used for HTTP requests serving.
 
    .. attribute:: server
 
       :class:`asyncio.AbstractServer` used for managing accepted connections.
 
-   .. comethod:: start_server(loop=None, **kwargs)
-
-      :param loop: the event_loop to use
-      :type loop: asyncio.AbstractEventLoop
+   .. comethod:: start_server(**kwargs)
 
       Start a test server.
 
    .. comethod:: close()
 
       Stop and finish executed test server.
 
@@ -640,35 +642,33 @@
 
       :class:`aiohttp.web.Application` instance to run.
 
 
 Test Client
 ~~~~~~~~~~~
 
-.. class:: TestClient(app_or_server, *, loop=None, \
+.. class:: TestClient(app_or_server, *, \
                       scheme='http', host='127.0.0.1', \
                       cookie_jar=None, **kwargs)
 
    A test client used for making calls to tested server.
 
    :param app_or_server: :class:`BaseTestServer` instance for making
                          client requests to it.
 
-                         In order to pass a :class:`aiohttp.web.Application`
+                         In order to pass an :class:`aiohttp.web.Application`
                          you need to convert it first to :class:`TestServer`
                          first with ``TestServer(app)``.
 
    :param cookie_jar: an optional :class:`aiohttp.CookieJar` instance,
                       may be useful with ``CookieJar(unsafe=True)``
                       option.
 
    :param str scheme: HTTP scheme, non-protected ``"http"`` by default.
 
-   :param asyncio.AbstractEventLoop loop: the event_loop to use
-
    :param str host: a host for TCP socket, IPv4 *local host*
       (``'127.0.0.1'``) by default.
 
    .. attribute:: scheme
 
       A *scheme* for tested application, ``'http'`` for non-protected
       run and ``'https'`` for TLS encrypted server.
```

### Comparing `aiohttp-4.0.0a0/docs/third_party.rst` & `aiohttp-4.0.0a1/docs/third_party.rst`

 * *Files 6% similar despite different names*

```diff
@@ -105,26 +105,35 @@
 The list of libraries which are exists but not enlisted in former categories.
 
 They may be perfect or not -- we don't know.
 
 Please add your library reference here first and after some time
 period ask to raise the status.
 
+- `octomachinery <https://octomachinery.dev>`_ A framework for developing
+  GitHub Apps and GitHub Actions. Python 3.7+ is required.
+
+- `aiomixcloud <https://github.com/amikrop/aiomixcloud>`_
+  Mixcloud API wrapper for Python and Async IO.
+
 - `aiohttp-cache <https://github.com/cr0hn/aiohttp-cache>`_ A cache
   system for aiohttp server.
 
 - `aiocache <https://github.com/argaen/aiocache>`_ Caching for asyncio
   with multiple backends (framework agnostic)
 
 - `gain <https://github.com/gaojiuli/gain>`_ Web crawling framework
   based on asyncio for everyone.
 
 - `aiohttp-swagger <https://github.com/cr0hn/aiohttp-swagger>`_
   Swagger API Documentation builder for aiohttp server.
 
+- `aiohttp-swagger3 <https://github.com/hh-h/aiohttp-swagger3>`_
+  Library for Swagger documentation builder and validating aiohttp requests using swagger specification 3.0.
+
 - `aiohttp-swaggerify <https://github.com/dchaplinsky/aiohttp_swaggerify>`_
   Library to automatically generate swagger2.0 definition for aiohttp endpoints.
 
 - `aiohttp-validate <https://github.com/dchaplinsky/aiohttp_validate>`_
   Simple library that helps you validate your API endpoints requests/responses with json schema.
 
 - `raven-aiohttp <https://github.com/getsentry/raven-aiohttp>`_ An
@@ -196,14 +205,20 @@
   algorithm based on aiohttp.
 
 - `home-assistant <https://github.com/home-assistant/home-assistant>`_
   Open-source home automation platform running on Python 3.
 
 - `discord.py <https://github.com/Rapptz/discord.py>`_ Discord client library.
 
+- `aiogram <https://github.com/aiogram/aiogram>`_
+  A fully asynchronous library for Telegram Bot API written with asyncio and aiohttp.
+  
+- `vk.py <https://github.com/prostomarkeloff/vk.py>`_
+  Extremely-fast Python 3.6+ toolkit for create applications work`s with VKAPI.
+
 - `aiohttp-graphql <https://github.com/graphql-python/aiohttp-graphql>`_
   GraphQL and GraphIQL interface for aiohttp.
 
 - `aiohttp-sentry <https://github.com/underyx/aiohttp-sentry>`_
   An aiohttp middleware for reporting errors to Sentry. Python 3.5+ is required.
 
 - `aiohttp-datadog <https://github.com/underyx/aiohttp-datadog>`_
@@ -230,7 +245,10 @@
 - `asynapplicationinsights <https://github.com/RobertoPrevato/asynapplicationinsights>`_ A client 
   for `Azure Application Insights <https://azure.microsoft.com/en-us/services/application-insights/>`_
   implemented using ``aiohttp`` client, including a middleware for ``aiohttp`` servers to collect web apps
   telemetry.
 
 - `aiogmaps <https://github.com/hzlmn/aiogmaps>`_
   Asynchronous client for Google Maps API Web Services. Python 3.6+ required.
+
+- `DBGR <https://github.com/JakubTesarek/dbgr>`_
+  Terminal based tool to test and debug HTTP APIs with ``aiohttp``.
```

### Comparing `aiohttp-4.0.0a0/docs/tracing_reference.rst` & `aiohttp-4.0.0a1/docs/tracing_reference.rst`

 * *Ordering differences only*

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,14 @@
+.. currentmodule:: aiohttp
+
 .. _aiohttp-client-tracing-reference:
 
 Tracing Reference
 =================
 
-.. currentmodule:: aiohttp
-
 .. versionadded:: 3.0
 
 A reference for client tracing API.
 
 .. seealso:: :ref:`aiohttp-client-tracing` for tracing usage instructions.
```

### Comparing `aiohttp-4.0.0a0/docs/websocket_utilities.rst` & `aiohttp-4.0.0a1/docs/websocket_utilities.rst`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,13 @@
+.. currentmodule:: aiohttp
+
+
 WebSocket utilities
 ===================
 
-.. currentmodule:: aiohttp
-
 .. class:: WSCloseCode
 
     An :class:`~enum.IntEnum` for keeping close message code.
 
     .. attribute:: OK
 
        A normal closure, meaning that the purpose for
@@ -150,9 +151,7 @@
       optional message description.
 
    .. method:: json(*, loads=json.loads)
 
       Returns parsed JSON data.
 
       :param loads: optional JSON decoder function.
-
-
```

### Comparing `aiohttp-4.0.0a0/docs/web_advanced.rst` & `aiohttp-4.0.0a1/docs/web_advanced.rst`

 * *Files 6% similar despite different names*

```diff
@@ -1,126 +1,44 @@
+.. currentmodule:: aiohttp.web
+
 .. _aiohttp-web-advanced:
 
 Web Server Advanced
 ===================
 
-.. currentmodule:: aiohttp.web
-
-
 Unicode support
 ---------------
 
 *aiohttp* does :term:`requoting` of incoming request path.
 
 Unicode (non-ASCII) symbols are processed transparently on both *route
 adding* and *resolving* (internally everything is converted to
 :term:`percent-encoding` form by :term:`yarl` library).
 
 But in case of custom regular expressions for
 :ref:`aiohttp-web-variable-handler` please take care that URL is
 *percent encoded*: if you pass Unicode patterns they don't match to
 *requoted* path.
 
+Peer disconnection
+------------------
 
-Web Handler Cancellation
-------------------------
-
-.. warning::
-
-   :term:`web-handler` execution could be canceled on every ``await``
-   if client drops connection without reading entire response's BODY.
-
-   The behavior is very different from classic WSGI frameworks like
-   Flask and Django.
-
-Sometimes it is a desirable behavior: on processing ``GET`` request the
-code might fetch data from database or other web resource, the
-fetching is potentially slow.
-
-Canceling this fetch is very good: the peer dropped connection
-already, there is no reason to waste time and resources (memory etc) by
-getting data from DB without any chance to send it back to peer.
-
-But sometimes the cancellation is bad: on ``POST`` request very often
-is needed to save data to DB regardless to peer closing.
-
-Cancellation prevention could be implemented in several ways:
-
-* Applying :func:`asyncio.shield` to coroutine that saves data into DB.
-* Spawning a new task for DB saving
-* Using aiojobs_ or other third party library.
-
-:func:`asyncio.shield` works pretty good. The only disadvantage is you
-need to split web handler into exactly two async functions: one
-for handler itself and other for protected code.
-
-For example the following snippet is not safe::
-
-   async def handler(request):
-       await asyncio.shield(write_to_redis(request))
-       await asyncio.shield(write_to_postgres(request))
-       return web.Response(text='OK')
-
-Cancellation might be occurred just after saving data in REDIS,
-``write_to_postgres`` will be not called.
-
-Spawning a new task is much worse: there is no place to ``await``
-spawned tasks::
-
-   async def handler(request):
-       request.loop.create_task(write_to_redis(request))
-       return web.Response(text='OK')
-
-In this case errors from ``write_to_redis`` are not awaited, it leads
-to many asyncio log messages *Future exception was never retrieved*
-and *Task was destroyed but it is pending!*.
-
-Moreover on :ref:`aiohttp-web-graceful-shutdown` phase *aiohttp* don't
-wait for these tasks, you have a great chance to loose very important
-data.
-
-On other hand aiojobs_ provides an API for spawning new jobs and
-awaiting their results etc. It stores all scheduled activity in
-internal data structures and could terminate them gracefully::
-
-   from aiojobs.aiohttp import setup, spawn
-
-   async def coro(timeout):
-       await asyncio.sleep(timeout)  # do something in background
-
-   async def handler(request):
-       await spawn(request, coro())
-       return web.Response()
-
-   app = web.Application()
-   setup(app)
-   app.router.add_get('/', handler)
-
-All not finished jobs will be terminated on
-:attr:`Application.on_cleanup` signal.
+When a client peer is gone a subsequent reading or writing raises :exc:`OSError`
+or more specific exception like :exc:`ConnectionResetError`.
 
-To prevent cancellation of the whole :term:`web-handler` use
-``@atomic`` decorator::
+The reason for disconnection is vary; it can be a network issue or explicit
+socket closing on the peer side without reading the whole server response.
 
-   from aiojobs.aiohttp import atomic
+*aiohttp* handles disconnection properly but you can handle it explicitly, e.g.::
 
-   @atomic
    async def handler(request):
-       await write_to_db()
-       return web.Response()
-
-   app = web.Application()
-   setup(app)
-   app.router.add_post('/', handler)
-
-It prevents all ``handler`` async function from cancellation,
-``write_to_db`` will be never interrupted.
-
-.. _aiojobs: http://aiojobs.readthedocs.io/en/latest/
-
+       try:
+           text = await request.text()
+       except OSError:
+           # disconnected
 
 Passing a coroutine into run_app and Gunicorn
 ---------------------------------------------
 
 :func:`run_app` accepts either application instance or a coroutine for
 making an application. The coroutine based approach allows to perform
 async IO before making an app::
@@ -479,20 +397,26 @@
 
 A *middleware* is a coroutine that can modify either the request or
 response. For example, here's a simple *middleware* which appends
 ``' wink'`` to the response::
 
     from aiohttp.web import middleware
 
-    @middleware
     async def middleware(request, handler):
         resp = await handler(request)
         resp.text = resp.text + ' wink'
         return resp
 
+.. warning::
+
+   As of version ``4.0.0`` "new-style" middleware is default and the
+   ``@middleware`` decorator is not required (and is deprecated), you can
+   simply remove the decorator. "Old-style" middleware (a coroutine which
+   returned a coroutine) is no longer supported.
+
 .. note::
 
    The example won't work with streamed responses or websockets
 
 Every *middleware* should accept two parameters, a :class:`request
 <Request>` instance and a *handler*, and return the response or raise
 an exception. If the exception is not an instance of
@@ -527,22 +451,20 @@
 
    from aiohttp import web
 
    async def test(request):
        print('Handler function called')
        return web.Response(text="Hello")
 
-   @web.middleware
    async def middleware1(request, handler):
        print('Middleware 1 called')
        response = await handler(request)
        print('Middleware 1 finished')
        return response
 
-   @web.middleware
    async def middleware2(request, handler):
        print('Middleware 2 called')
        response = await handler(request)
        print('Middleware 2 finished')
        return response
 
 
@@ -563,15 +485,14 @@
 
 A common use of middlewares is to implement custom error pages.  The following
 example will render 404 errors using a JSON response, as might be appropriate
 a JSON REST service::
 
     from aiohttp import web
 
-    @web.middleware
     async def error_middleware(request, handler):
         try:
             response = await handler(request)
             if response.status != 404:
                 return response
             message = response.message
         except web.HTTPException as ex:
@@ -582,25 +503,27 @@
 
     app = web.Application(middlewares=[error_middleware])
 
 
 Middleware Factory
 ^^^^^^^^^^^^^^^^^^
 
-A *middleware factory* is a function that creates a middleware with passed arguments. For example, here's a trivial *middleware factory*::
+A *middleware factory* is a function that creates a middleware with passed
+arguments. For example, here's a trivial *middleware factory*::
 
     def middleware_factory(text):
-        @middleware
         async def sample_middleware(request, handler):
             resp = await handler(request)
             resp.text = resp.text + text
             return resp
         return sample_middleware
 
-Remember that contrary to regular middlewares you need the result of a middleware factory not the function itself. So when passing a middleware factory to an app you actually need to call it::
+Note that in contrast to regular middlewares, a middleware factory should
+return the function, not the value. So when passing a middleware factory
+to the app you actually need to call it::
 
     app = web.Application(middlewares=[middleware_factory(' wink')])
 
 .. _aiohttp-web-signals:
 
 Signals
 -------
@@ -691,18 +614,14 @@
 ``yield`` is an initialization stage (called on *startup*), a code
 *after* ``yield`` is executed on *cleanup*. The generator must have only
 one ``yield``.
 
 *aiohttp* guarantees that *cleanup code* is called if and only if
 *startup code* was successfully finished.
 
-Asynchronous generators are supported by Python 3.6+, on Python 3.5
-please use `async_generator <https://pypi.org/project/async_generator/>`_
-library.
-
 .. versionadded:: 3.1
 
 .. _aiohttp-web-nested-applications:
 
 Nested applications
 -------------------
 
@@ -938,29 +857,29 @@
 tasks that will live till the application is alive. The appropriate
 background tasks could be registered as an :attr:`Application.on_startup`
 signal handlers as shown in the example below::
 
 
   async def listen_to_redis(app):
       try:
-          sub = await aioredis.create_redis(('localhost', 6379), loop=app.loop)
+          sub = await aioredis.create_redis(('localhost', 6379))
           ch, *_ = await sub.subscribe('news')
           async for msg in ch.iter(encoding='utf-8'):
               # Forward message to all connected websockets:
               for ws in app['websockets']:
                   ws.send_str('{}: {}'.format(ch.name, msg))
       except asyncio.CancelledError:
           pass
       finally:
           await sub.unsubscribe(ch.name)
           await sub.quit()
 
 
   async def start_background_tasks(app):
-      app['redis_listener'] = app.loop.create_task(listen_to_redis(app))
+      app['redis_listener'] = asyncio.create_task(listen_to_redis(app))
 
 
   async def cleanup_background_tasks(app):
       app['redis_listener'].cancel()
       await app['redis_listener']
```

### Comparing `aiohttp-4.0.0a0/docs/web_lowlevel.rst` & `aiohttp-4.0.0a1/docs/web_lowlevel.rst`

 * *Ordering differences only*

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
+.. currentmodule:: aiohttp.web
+
 .. _aiohttp-web-lowlevel:
 
 Low Level Server
 ================
 
-.. currentmodule:: aiohttp.web
-
 
 This topic describes :mod:`aiohttp.web` based *low level* API.
 
 Abstract
 --------
 
 Sometimes user don't need high-level concepts introduced in
```

### Comparing `aiohttp-4.0.0a0/docs/web_quickstart.rst` & `aiohttp-4.0.0a1/docs/web_quickstart.rst`

 * *Files 9% similar despite different names*

```diff
@@ -1,15 +1,14 @@
+.. currentmodule:: aiohttp.web
+
 .. _aiohttp-web-quickstart:
 
 Web Server Quickstart
 =====================
 
-.. currentmodule:: aiohttp.web
-
-
 Run a Simple Web Server
 -----------------------
 
 In order to implement a web server, first create a
 :ref:`request handler <aiohttp-web-handler>`.
 
 A request handler must be a :ref:`coroutine <coroutine>` that
@@ -50,14 +49,20 @@
 taste: do you prefer *Django style* with famous ``urls.py`` or *Flask*
 with shiny route decorators.
 
 *aiohttp* server documentation uses both ways in code snippets to
 emphasize their equality, switching from one style to another is very
 trivial.
 
+.. note::
+   You can get a powerful aiohttp template by running one command.
+   To do this, simply use our `boilerplate for quick start with aiohttp
+   <https://create-aio-app.readthedocs.io/pages/aiohttp_quick_start.html>`_.
+
+
 .. seealso::
 
    :ref:`aiohttp-web-graceful-shutdown` section explains what :func:`run_app`
    does and how to implement complex server initialization/finalization
    from scratch.
 
    :ref:`aiohttp-web-app-runners` for more handling more complex cases
@@ -155,15 +160,15 @@
 
 Resource is an entry in *route table* which corresponds to requested URL.
 
 Resource in turn has at least one *route*.
 
 Route corresponds to handling *HTTP method* by calling *web handler*.
 
-Thus when you add a *route* the *resouce* object is created under the hood.
+Thus when you add a *route* the *resource* object is created under the hood.
 
 The library implementation **merges** all subsequent route additions
 for the same path adding the only resource for all HTTP methods.
 
 Consider two examples::
 
    app.add_routes([web.get('/path1', get_1),
@@ -292,22 +297,26 @@
 Handlers should be coroutines accepting *self* only and returning
 response object as regular :term:`web-handler`. Request object can be
 retrieved by :attr:`View.request` property.
 
 After implementing the view (``MyView`` from example above) should be
 registered in application's router::
 
-   web.view('/path/to', MyView)
+   app.add_routes([web.view('/path/to', MyView)]) 
 
 or::
 
    @routes.view('/path/to')
    class MyView(web.View):
        ...
 
+or::
+
+   app.router.add_route('*', '/path/to', MyView)
+
 Example will process GET and POST requests for */path/to* but raise
 *405 Method not allowed* exception for unimplemented HTTP methods.
 
 Resource Views
 ^^^^^^^^^^^^^^
 
 *All* registered resources in a router can be viewed using the
@@ -590,14 +599,16 @@
 
     async def websocket_handler(request):
 
         ws = web.WebSocketResponse()
         await ws.prepare(request)
 
         async for msg in ws:
+            # ws.__next__() automatically terminates the loop
+            # after ws.close() or ws.exception() is called
             if msg.type == aiohttp.WSMsgType.TEXT:
                 if msg.data == 'close':
                     await ws.close()
                 else:
                     await ws.send_str(msg.data + '/answer')
             elif msg.type == aiohttp.WSMsgType.ERROR:
                 print('ws connection closed with exception %s' %
@@ -646,114 +657,7 @@
                 raise web.HTTPFound(location=location)
 
         return {}
 
     app.router.add_get('/', index, name='index')
     app.router.add_get('/login', login, name='login')
     app.router.add_post('/login', login, name='login')
-
-.. _aiohttp-web-exceptions:
-
-Exceptions
-----------
-
-:mod:`aiohttp.web` defines a set of exceptions for every *HTTP status code*.
-
-Each exception is a subclass of :class:`~HTTPException` and relates to a single
-HTTP status code::
-
-    async def handler(request):
-        raise aiohttp.web.HTTPFound('/redirect')
-
-.. warning::
-
-   Returning :class:`~HTTPException` or its subclasses is deprecated and will
-   be removed in subsequent aiohttp versions.
-
-Each exception class has a status code according to :rfc:`2068`:
-codes with 100-300 are not really errors; 400s are client errors,
-and 500s are server errors.
-
-HTTP Exception hierarchy chart::
-
-   Exception
-     HTTPException
-       HTTPSuccessful
-         * 200 - HTTPOk
-         * 201 - HTTPCreated
-         * 202 - HTTPAccepted
-         * 203 - HTTPNonAuthoritativeInformation
-         * 204 - HTTPNoContent
-         * 205 - HTTPResetContent
-         * 206 - HTTPPartialContent
-       HTTPRedirection
-         * 300 - HTTPMultipleChoices
-         * 301 - HTTPMovedPermanently
-         * 302 - HTTPFound
-         * 303 - HTTPSeeOther
-         * 304 - HTTPNotModified
-         * 305 - HTTPUseProxy
-         * 307 - HTTPTemporaryRedirect
-         * 308 - HTTPPermanentRedirect
-       HTTPError
-         HTTPClientError
-           * 400 - HTTPBadRequest
-           * 401 - HTTPUnauthorized
-           * 402 - HTTPPaymentRequired
-           * 403 - HTTPForbidden
-           * 404 - HTTPNotFound
-           * 405 - HTTPMethodNotAllowed
-           * 406 - HTTPNotAcceptable
-           * 407 - HTTPProxyAuthenticationRequired
-           * 408 - HTTPRequestTimeout
-           * 409 - HTTPConflict
-           * 410 - HTTPGone
-           * 411 - HTTPLengthRequired
-           * 412 - HTTPPreconditionFailed
-           * 413 - HTTPRequestEntityTooLarge
-           * 414 - HTTPRequestURITooLong
-           * 415 - HTTPUnsupportedMediaType
-           * 416 - HTTPRequestRangeNotSatisfiable
-           * 417 - HTTPExpectationFailed
-           * 421 - HTTPMisdirectedRequest
-           * 422 - HTTPUnprocessableEntity
-           * 424 - HTTPFailedDependency
-           * 426 - HTTPUpgradeRequired
-           * 428 - HTTPPreconditionRequired
-           * 429 - HTTPTooManyRequests
-           * 431 - HTTPRequestHeaderFieldsTooLarge
-           * 451 - HTTPUnavailableForLegalReasons
-         HTTPServerError
-           * 500 - HTTPInternalServerError
-           * 501 - HTTPNotImplemented
-           * 502 - HTTPBadGateway
-           * 503 - HTTPServiceUnavailable
-           * 504 - HTTPGatewayTimeout
-           * 505 - HTTPVersionNotSupported
-           * 506 - HTTPVariantAlsoNegotiates
-           * 507 - HTTPInsufficientStorage
-           * 510 - HTTPNotExtended
-           * 511 - HTTPNetworkAuthenticationRequired
-
-All HTTP exceptions have the same constructor signature::
-
-    HTTPNotFound(*, headers=None, reason=None,
-                 body=None, text=None, content_type=None)
-
-If not directly specified, *headers* will be added to the *default
-response headers*.
-
-Classes :class:`HTTPMultipleChoices`, :class:`HTTPMovedPermanently`,
-:class:`HTTPFound`, :class:`HTTPSeeOther`, :class:`HTTPUseProxy`,
-:class:`HTTPTemporaryRedirect` have the following constructor signature::
-
-    HTTPFound(location, *, headers=None, reason=None,
-              body=None, text=None, content_type=None)
-
-where *location* is value for *Location HTTP header*.
-
-:class:`HTTPMethodNotAllowed` is constructed by providing the incoming
-unsupported method and list of allowed methods::
-
-    HTTPMethodNotAllowed(method, allowed_methods, *,
-                         headers=None, reason=None,
-                         body=None, text=None, content_type=None)
```

### Comparing `aiohttp-4.0.0a0/docs/web_reference.rst` & `aiohttp-4.0.0a1/docs/web_reference.rst`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,14 @@
+.. currentmodule:: aiohttp.web
+
 .. _aiohttp-web-reference:
 
 Server Reference
 ================
 
-.. module:: aiohttp.web
-
-.. currentmodule:: aiohttp.web
-
 .. _aiohttp-web-request:
 
 
 Request and Base Request
 ------------------------
 
 The Request object contains all the information about an incoming HTTP request.
@@ -157,27 +155,27 @@
       ``/app/blog?id=10``
 
       Read-only :class:`str` property.
 
    .. attribute:: path
 
       The URL including *PATH INFO* without the host or scheme. e.g.,
-      ``/app/blog``. The path is URL-unquoted. For raw path info see
+      ``/app/blog``. The path is URL-decoded. For raw path info see
       :attr:`raw_path`.
 
       Read-only :class:`str` property.
 
    .. attribute:: raw_path
 
       The URL including raw *PATH INFO* without the host or scheme.
-      Warning, the path may be quoted and may contains non valid URL
+      Warning, the path may be URL-encoded and may contain invalid URL
       characters, e.g.
       ``/my%2Fpath%7Cwith%21some%25strange%24characters``.
 
-      For unquoted version please take a look on :attr:`path`.
+      For URL-decoded version please take a look on :attr:`path`.
 
       Read-only :class:`str` property.
 
    .. attribute:: query
 
       A multidict with all the variables in the query string.
 
@@ -215,22 +213,14 @@
       The property can be used, for example, for getting IP address of
       client's peer::
 
          peername = request.transport.get_extra_info('peername')
          if peername is not None:
              host, port = peername
 
-   .. attribute:: loop
-
-      An event loop instance used by HTTP request handling.
-
-      Read-only :class:`asyncio.AbstractEventLoop` property.
-
-      .. deprecated:: 3.5
-
    .. attribute:: cookies
 
       A multidict of all request's cookies.
 
       Read-only :class:`~multidict.MultiDictProxy` lazy property.
 
    .. attribute:: content
@@ -252,24 +242,14 @@
 
       Return ``True`` if request's *HTTP BODY* can be read, ``False`` otherwise.
 
       Read-only :class:`bool` property.
 
       .. versionadded:: 2.3
 
-   .. attribute:: has_body
-
-      Return ``True`` if request's *HTTP BODY* can be read, ``False`` otherwise.
-
-      Read-only :class:`bool` property.
-
-      .. deprecated:: 2.3
-
-         Use :meth:`can_read_body` instead.
-
    .. attribute:: content_type
 
       Read-only property with *content* part of *Content-Type* header.
 
       Returns :class:`str` like ``'text/html'``
 
       .. note::
@@ -383,29 +363,27 @@
       Returns :class:`str` with body content.
 
       .. note::
 
          The method **does** store read data internally, subsequent
          :meth:`~Request.text` call will return the same value.
 
-   .. comethod:: json(*, loads=json.loads)
-
-      Read request body decoded as *json*.
-
-      The method is just a boilerplate :ref:`coroutine <coroutine>`
-      implemented as::
+   .. comethod:: json(*, loads=json.loads, \
+                    content_type='application/json')
 
-         async def json(self, *, loads=json.loads):
-             body = await self.text()
-             return loads(body)
+      Read request body decoded as *json*. If request's content-type does not
+      match `content_type` parameter, :class:`web.HTTPBadRequest` get raised.
+      To disable content type check pass ``None`` value.
 
       :param callable loads: any :term:`callable` that accepts
                               :class:`str` and returns :class:`dict`
                               with parsed JSON (:func:`json.loads` by
                               default).
+      :param str content_type: expected value of Content-Type header or ``None``
+                              ('application/json' by default)
 
       .. note::
 
          The method **does** store read data internally, subsequent
          :meth:`~Request.json` call will return the same value.
 
 
@@ -642,15 +620,15 @@
 
       Read-only property, indicates if chunked encoding is on.
 
       Can be enabled by :meth:`enable_chunked_encoding` call.
 
       .. seealso:: :attr:`enable_chunked_encoding`
 
-   .. method:: enable_chunked_encoding
+   .. method:: enable_chunked_encoding()
 
       Enables :attr:`chunked` encoding for response. There are no ways to
       disable it back. With enabled :attr:`chunked` encoding each :meth:`write`
       operation encoded in separate chunk.
 
       .. warning:: chunked encoding can be enabled for ``HTTP/1.1`` only.
 
@@ -868,14 +846,41 @@
       :attr:`~StreamResponse.body` value
 
       Resetting :attr:`text` (assigning ``None``) sets
       :attr:`~StreamResponse.content_length` to ``None`` too, dropping
       *Content-Length* HTTP header.
 
 
+FileResponse
+^^^^^^^^^^^^^^
+
+.. class:: FileResponse(*, path, chunk_size=256*1024, status=200, reason=None, headers=None)
+
+   The response class used to send files, inherited from :class:`StreamResponse`.
+
+   Supports the ``Content-Range`` and ``If-Range`` HTTP Headers in requests.
+
+   The actual :attr:`body` sending happens in overridden :meth:`~StreamResponse.prepare`.
+
+   :param path: Path to file. Accepts both :class:`str` and :class:`pathlib.Path`.
+   :param int chunk_size: Chunk size in bytes which will be passed into
+                          :meth:`io.RawIOBase.read` in the event that the
+                          ``sendfile`` system call is not supported.
+
+   :param int status: HTTP status code, ``200`` by default.
+
+   :param str reason: HTTP reason. If param is ``None`` reason will be
+                      calculated basing on *status*
+                      parameter. Otherwise pass :class:`str` with
+                      arbitrary *status* explanation..
+
+   :param collections.abc.Mapping headers: HTTP headers that should be added to
+                           response's ones. The ``Content-Type`` response header
+                           will be overridden if provided.
+
 WebSocketResponse
 ^^^^^^^^^^^^^^^^^
 
 .. class:: WebSocketResponse(*, timeout=10.0, receive_timeout=None, \
                              autoclose=True, autoping=True, heartbeat=None, \
                              protocols=(), compress=True, max_msg_size=4194304)
 
@@ -1214,48 +1219,14 @@
                             content_type='application/json', \
                             dumps=json.dumps)
 
 Return :class:`Response` with predefined ``'application/json'``
 content type and *data* encoded by ``dumps`` parameter
 (:func:`json.dumps` by default).
 
-HTTP Exceptions
-^^^^^^^^^^^^^^^
-Errors can also be returned by raising a HTTP exception instance from within
-the handler.
-
-.. class:: HTTPException(*, headers=None, reason=None, text=None, content_type=None)
-
-   Low-level HTTP failure.
-
-   :param headers: headers for the response
-   :type headers: dict or multidict.CIMultiDict
-
-   :param str reason: reason included in the response
-
-   :param str text: response's body
-
-   :param str content_type: response's content type.  This is passed through
-      to the :class:`Response` initializer.
-
-   Sub-classes of ``HTTPException`` exist for the standard HTTP response codes
-   as described in :ref:`aiohttp-web-exceptions` and the expected usage is to
-   simply raise the appropriate exception type to respond with a specific HTTP
-   response code.
-
-   Since ``HTTPException`` is a sub-class of :class:`Response`, it contains the
-   methods and properties that allow you to directly manipulate details of the
-   response.
-
-   .. attribute:: status_code
-
-      HTTP status code for this exception class.  This attribute is usually
-      defined at the class level.  ``self.status_code`` is passed to the
-      :class:`Response` initializer.
-
 
 .. _aiohttp-web-app-and-router:
 
 Application and Router
 ----------------------
 
 
@@ -1282,71 +1253,51 @@
    async def handler(request):
        with (await request.app['database']) as conn:
            conn.execute("DELETE * FROM table")
 
 Although :class:`Application` is a :obj:`dict`-like object, it can't be
 duplicated like one using :meth:`Application.copy`.
 
-.. class:: Application(*, logger=<default>, router=None,middlewares=(), \
+.. class:: Application(*, logger=<default>, middlewares=(), \
                        handler_args=None, client_max_size=1024**2, \
-                       loop=None, debug=...)
+                       debug=...)
 
    The class inherits :class:`dict`.
 
    :param logger: :class:`logging.Logger` instance for storing application logs.
 
                   By default the value is ``logging.getLogger("aiohttp.web")``
 
-   :param router: :class:`aiohttp.abc.AbstractRouter` instance, the system
-                  creates :class:`UrlDispatcher` by default if
-                  *router* is ``None``.
-
-      .. deprecated:: 3.3
-
-         The custom routers support is deprecated, the parameter will
-         be removed in 4.0.
-
    :param middlewares: :class:`list` of middleware factories, see
                        :ref:`aiohttp-web-middlewares` for details.
 
    :param handler_args: dict-like object that overrides keyword arguments of
-                        :meth:`Application.make_handler`
+                        :class:`AppRunner` constructor.
 
    :param client_max_size: client's maximum size in a request, in
                            bytes.  If a POST request exceeds this
                            value, it raises an
                            `HTTPRequestEntityTooLarge` exception.
 
-   :param loop: event loop
-
-      .. deprecated:: 2.0
-
-         The parameter is deprecated. Loop is get set during freeze
-         stage.
-
    :param debug: Switches debug mode.
 
       .. deprecated:: 3.5
 
-         Use asyncio :ref:`asyncio-debug-mode` instead.
+         The argument does nothing starting from 4.0,
+         use asyncio :ref:`asyncio-debug-mode` instead.
+
 
    .. attribute:: router
 
       Read-only property that returns *router instance*.
 
    .. attribute:: logger
 
       :class:`logging.Logger` instance for storing application logs.
 
-   .. attribute:: loop
-
-      :ref:`event loop<asyncio-event-loop>` used for processing HTTP requests.
-
-      .. deprecated:: 3.5
-
    .. attribute:: debug
 
       Boolean value indicating whether the debug mode is turned on or off.
 
       .. deprecated:: 3.5
 
          Use asyncio :ref:`asyncio-debug-mode` instead.
@@ -1464,67 +1415,14 @@
 
       The method is a shortcut for
       ``app.router.add_routes(routes_table)``, see also
       :meth:`UrlDispatcher.add_routes`.
 
       .. versionadded:: 3.1
 
-   .. method:: make_handler(loop=None, **kwargs)
-
-      Creates HTTP protocol factory for handling requests.
-
-      :param loop: :ref:`event loop<asyncio-event-loop>` used
-        for processing HTTP requests.
-
-        If param is ``None`` :func:`asyncio.get_event_loop`
-        used for getting default event loop.
-
-        .. deprecated:: 2.0
-
-      :param bool tcp_keepalive: Enable TCP Keep-Alive. Default: ``True``.
-      :param int keepalive_timeout: Number of seconds before closing Keep-Alive
-        connection. Default: ``75`` seconds (NGINX's default value).
-      :param logger: Custom logger object. Default:
-        :data:`aiohttp.log.server_logger`.
-      :param access_log: Custom logging object. Default:
-        :data:`aiohttp.log.access_logger`.
-      :param access_log_class: Class for `access_logger`. Default:
-        :data:`aiohttp.helpers.AccessLogger`.
-        Must to be a subclass of :class:`aiohttp.abc.AbstractAccessLogger`.
-      :param str access_log_format: Access log format string. Default:
-        :attr:`helpers.AccessLogger.LOG_FORMAT`.
-      :param int max_line_size: Optional maximum header line size. Default:
-        ``8190``.
-      :param int max_headers: Optional maximum header size. Default: ``32768``.
-      :param int max_field_size: Optional maximum header field size. Default:
-        ``8190``.
-
-      :param float lingering_time: Maximum time during which the server
-        reads and ignores additional data coming from the client when
-        lingering close is on.  Use ``0`` to disable lingering on
-        server channel closing.
-
-      You should pass result of the method as *protocol_factory* to
-      :meth:`~asyncio.AbstractEventLoop.create_server`, e.g.::
-
-         loop = asyncio.get_event_loop()
-
-         app = Application()
-
-         # setup route table
-         # app.router.add_route(...)
-
-         await loop.create_server(app.make_handler(),
-                                  '0.0.0.0', 8080)
-
-      .. deprecated:: 3.2
-
-         The method is deprecated and will be removed in future
-         aiohttp versions.  Please use :ref:`aiohttp-web-app-runners` instead.
-
    .. comethod:: startup()
 
       A :ref:`coroutine<coroutine>` that will be called along with the
       application's request handler.
 
       The purpose of the method is calling :attr:`on_startup` signal
       handlers.
@@ -2535,15 +2433,15 @@
       See :meth:`socket.getsockname` for items type.
 
       .. versionadded:: 3.3
 
    .. attribute:: sites
 
       A read-only :class:`set` of served sites (:class:`TCPSite` /
-      :class:`UnixSite` / :class:`SockSite` instances).
+      :class:`UnixSite` / :class:`NamedPipeSite` / :class:`SockSite` instances).
 
    .. comethod:: setup()
 
       Initialize the server. Should be called before adding sites.
 
    .. comethod:: cleanup()
 
@@ -2563,14 +2461,40 @@
                                :data:`signal.SIGINT` and
                                :data:`signal.SIGTERM` (``False`` by
                                default).
 
    :param kwargs: named parameters to pass into
                   web protocol.
 
+   Supported *kwargs*:
+
+   :param bool tcp_keepalive: Enable TCP Keep-Alive. Default: ``True``.
+   :param int keepalive_timeout: Number of seconds before closing Keep-Alive
+        connection. Default: ``75`` seconds (NGINX's default value).
+   :param logger: Custom logger object. Default:
+        :data:`aiohttp.log.server_logger`.
+   :param access_log: Custom logging object. Default:
+        :data:`aiohttp.log.access_logger`.
+   :param access_log_class: Class for `access_logger`. Default:
+        :data:`aiohttp.helpers.AccessLogger`.
+        Must to be a subclass of :class:`aiohttp.abc.AbstractAccessLogger`.
+   :param str access_log_format: Access log format string. Default:
+        :attr:`helpers.AccessLogger.LOG_FORMAT`.
+   :param int max_line_size: Optional maximum header line size. Default:
+        ``8190``.
+   :param int max_headers: Optional maximum header size. Default: ``32768``.
+   :param int max_field_size: Optional maximum header field size. Default:
+        ``8190``.
+
+   :param float lingering_time: Maximum time during which the server
+        reads and ignores additional data coming from the client when
+        lingering close is on.  Use ``0`` to disable lingering on
+        server channel closing.
+
+
    .. attribute:: app
 
       Read-only attribute for accessing to :class:`Application` served
       instance.
 
    .. comethod:: setup()
 
@@ -2683,14 +2607,26 @@
 
    :param int backlog: a number of unaccepted connections that the
                        system will allow before refusing new
                        connections, see :meth:`socket.listen` for details.
 
                        ``128`` by default.
 
+.. class:: NamedPipeSite(runner, path, *, shutdown_timeout=60.0)
+
+   Serve a runner on Named Pipe in Windows.
+
+   :param runner: a runner to serve.
+
+   :param str path: PATH of named pipe to listen.
+
+   :param float shutdown_timeout: a timeout for closing opened
+                                  connections on :meth:`BaseSite.stop`
+                                  call.
+
 .. class:: SockSite(runner, sock, *, \
                    shutdown_timeout=60.0, ssl_context=None, \
                    backlog=128)
 
    Serve a runner on UNIX socket.
 
    :param runner: a runner to serve.
@@ -2867,15 +2803,15 @@
 Normalize path middleware
 ^^^^^^^^^^^^^^^^^^^^^^^^^
 
 .. function:: normalize_path_middleware(*, \
                                         append_slash=True, \
                                         remove_slash=False, \
                                         merge_slashes=True, \
-                                        redirect_class=HTTPMovedPermanently)
+                                        redirect_class=HTTPPermanentRedirect)
 
    Middleware factory which produces a middleware that normalizes
    the path of a request. By normalizing it means:
 
      - Add or remove a trailing slash to the path.
      - Double slashes are replaced by one.
```

### Comparing `aiohttp-4.0.0a0/docs/whats_new_1_1.rst` & `aiohttp-4.0.0a1/docs/whats_new_1_1.rst`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/docs/whats_new_3_0.rst` & `aiohttp-4.0.0a1/docs/whats_new_3_0.rst`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/docs/_static/aiohttp-icon-128x128.png` & `aiohttp-4.0.0a1/docs/_static/aiohttp-icon-128x128.png`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/examples/background_tasks.py` & `aiohttp-4.0.0a1/examples/background_tasks.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/examples/client_auth.py` & `aiohttp-4.0.0a1/examples/client_auth.py`

 * *Files 18% similar despite different names*

```diff
@@ -8,16 +8,15 @@
     async with session.get(
             'http://httpbin.org/basic-auth/andrew/password') as resp:
         print(resp.status)
         body = await resp.text()
         print(body)
 
 
-async def go(loop):
+async def go():
     async with aiohttp.ClientSession(
-            auth=aiohttp.BasicAuth('andrew', 'password'),
-            loop=loop) as session:
+            auth=aiohttp.BasicAuth('andrew', 'password')) as session:
         await fetch(session)
 
 
 loop = asyncio.get_event_loop()
-loop.run_until_complete(go(loop))
+loop.run_until_complete(go())
```

### Comparing `aiohttp-4.0.0a0/examples/client_ws.py` & `aiohttp-4.0.0a1/examples/client_ws.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/examples/cli_app.py` & `aiohttp-4.0.0a1/examples/cli_app.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/examples/curl.py` & `aiohttp-4.0.0a1/examples/curl.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/examples/fake_server.py` & `aiohttp-4.0.0a1/examples/fake_server.py`

 * *Files 8% similar despite different names*

```diff
@@ -10,18 +10,18 @@
 
 
 class FakeResolver:
     _LOCAL_HOST = {0: '127.0.0.1',
                    socket.AF_INET: '127.0.0.1',
                    socket.AF_INET6: '::1'}
 
-    def __init__(self, fakes, *, loop):
+    def __init__(self, fakes):
         """fakes -- dns -> port dict"""
         self._fakes = fakes
-        self._resolver = DefaultResolver(loop=loop)
+        self._resolver = DefaultResolver()
 
     async def resolve(self, host, port=0, family=socket.AF_INET):
         fake_port = self._fakes.get(host)
         if fake_port is not None:
             return [{'hostname': host,
                      'host': self._LOCAL_HOST[family], 'port': fake_port,
                      'family': family, 'proto': 0,
@@ -30,15 +30,15 @@
             return await self._resolver.resolve(host, port, family)
 
 
 class FakeFacebook:
 
     def __init__(self, *, loop):
         self.loop = loop
-        self.app = web.Application(loop=loop)
+        self.app = web.Application()
         self.app.router.add_routes(
             [web.get('/v2.7/me', self.on_me),
              web.get('/v2.7/me/friends', self.on_my_friends)])
         self.runner = None
         here = pathlib.Path(__file__)
         ssl_cert = here.parent / 'server.crt'
         ssl_key = here.parent / 'server.key'
@@ -91,22 +91,20 @@
                 "total_count": 3
             }})
 
 
 async def main(loop):
     token = "ER34gsSGGS34XCBKd7u"
 
-    fake_facebook = FakeFacebook(loop=loop)
+    fake_facebook = FakeFacebook()
     info = await fake_facebook.start()
-    resolver = FakeResolver(info, loop=loop)
-    connector = aiohttp.TCPConnector(loop=loop, resolver=resolver,
-                                     verify_ssl=False)
+    resolver = FakeResolver(info)
+    connector = aiohttp.TCPConnector(resolver=resolver, ssl=False)
 
-    async with aiohttp.ClientSession(connector=connector,
-                                     loop=loop) as session:
+    async with aiohttp.ClientSession(connector=connector) as session:
         async with session.get('https://graph.facebook.com/v2.7/me',
                                params={'access_token': token}) as resp:
             print(await resp.json())
 
         async with session.get('https://graph.facebook.com/v2.7/me/friends',
                                params={'access_token': token}) as resp:
             print(await resp.json())
```

### Comparing `aiohttp-4.0.0a0/examples/legacy/crawl.py` & `aiohttp-4.0.0a1/examples/legacy/crawl.py`

 * *Files 6% similar despite different names*

```diff
@@ -8,48 +8,45 @@
 import urllib.parse
 
 import aiohttp
 
 
 class Crawler:
 
-    def __init__(self, rooturl, loop, maxtasks=100):
+    def __init__(self, rooturl, maxtasks=100):
         self.rooturl = rooturl
-        self.loop = loop
         self.todo = set()
         self.busy = set()
         self.done = {}
         self.tasks = set()
-        self.sem = asyncio.Semaphore(maxtasks, loop=loop)
+        self.sem = asyncio.Semaphore(maxtasks)
 
         # connector stores cookies between requests and uses connection pool
-        self.session = aiohttp.ClientSession(loop=loop)
+        self.session = aiohttp.ClientSession()
 
     async def run(self):
-        t = asyncio.ensure_future(self.addurls([(self.rooturl, '')]),
-                                  loop=self.loop)
-        await asyncio.sleep(1, loop=self.loop)
+        t = asyncio.ensure_future(self.addurls([(self.rooturl, '')]))
+        await asyncio.sleep(1)
         while self.busy:
-            await asyncio.sleep(1, loop=self.loop)
+            await asyncio.sleep(1)
 
         await t
         await self.session.close()
-        self.loop.stop()
 
     async def addurls(self, urls):
         for url, parenturl in urls:
             url = urllib.parse.urljoin(parenturl, url)
             url, frag = urllib.parse.urldefrag(url)
             if (url.startswith(self.rooturl) and
                     url not in self.busy and
                     url not in self.done and
                     url not in self.todo):
                 self.todo.add(url)
                 await self.sem.acquire()
-                task = asyncio.ensure_future(self.process(url), loop=self.loop)
+                task = asyncio.ensure_future(self.process(url))
                 task.add_done_callback(lambda t: self.sem.release())
                 task.add_done_callback(self.tasks.remove)
                 self.tasks.add(task)
 
     async def process(self, url):
         print('processing:', url)
 
@@ -74,16 +71,16 @@
         print(len(self.done), 'completed tasks,', len(self.tasks),
               'still pending, todo', len(self.todo))
 
 
 def main():
     loop = asyncio.get_event_loop()
 
-    c = Crawler(sys.argv[1], loop)
-    asyncio.ensure_future(c.run(), loop=loop)
+    c = Crawler(sys.argv[1])
+    asyncio.ensure_future(c.run())
 
     try:
         loop.add_signal_handler(signal.SIGINT, loop.stop)
     except RuntimeError:
         pass
     loop.run_forever()
     print('todo:', len(c.todo))
```

### Comparing `aiohttp-4.0.0a0/examples/legacy/srv.py` & `aiohttp-4.0.0a1/examples/legacy/srv.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/examples/legacy/tcp_protocol_parser.py` & `aiohttp-4.0.0a1/examples/legacy/tcp_protocol_parser.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/examples/lowlevel_srv.py` & `aiohttp-4.0.0a1/examples/lowlevel_srv.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/examples/server.crt` & `aiohttp-4.0.0a1/examples/server.crt`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/examples/server.csr` & `aiohttp-4.0.0a1/examples/server.csr`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/examples/server.key` & `aiohttp-4.0.0a1/examples/server.key`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/examples/server_simple.py` & `aiohttp-4.0.0a1/examples/server_simple.py`

 * *Files 19% similar despite different names*

```diff
@@ -9,19 +9,19 @@
 
 
 async def wshandle(request):
     ws = web.WebSocketResponse()
     await ws.prepare(request)
 
     async for msg in ws:
-        if msg.type == web.WSMsgType.text:
+        if msg.type == web.WSMsgType.TEXT:
             await ws.send_str("Hello, {}".format(msg.data))
-        elif msg.type == web.WSMsgType.binary:
+        elif msg.type == web.WSMsgType.BINARY:
             await ws.send_bytes(msg.data)
-        elif msg.type == web.WSMsgType.close:
+        elif msg.type == web.WSMsgType.CLOSE:
             break
 
     return ws
 
 
 app = web.Application()
 app.add_routes([web.get("/", handle),
```

### Comparing `aiohttp-4.0.0a0/examples/websocket.html` & `aiohttp-4.0.0a1/examples/websocket.html`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/examples/web_classview.py` & `aiohttp-4.0.0a1/examples/web_classview.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/examples/web_cookies.py` & `aiohttp-4.0.0a1/examples/web_cookies.py`

 * *Files 23% similar despite different names*

```diff
@@ -30,16 +30,16 @@
 
 async def logout(request):
     resp = web.HTTPFound(location='/')
     resp.del_cookie('AUTH')
     return resp
 
 
-def init(loop):
-    app = web.Application(loop=loop)
+def init():
+    app = web.Application()
     app.router.add_get('/', root)
     app.router.add_get('/login', login)
     app.router.add_get('/logout', logout)
     return app
 
 
 web.run_app(init())
```

### Comparing `aiohttp-4.0.0a0/examples/web_rewrite_headers_middleware.py` & `aiohttp-4.0.0a1/examples/web_rewrite_headers_middleware.py`

 * *Files 20% similar despite different names*

```diff
@@ -6,15 +6,14 @@
 from aiohttp import web
 
 
 async def handler(request):
     return web.Response(text="Everything is fine")
 
 
-@web.middleware
 async def middleware(request, handler):
     try:
         response = await handler(request)
     except web.HTTPException as exc:
         raise exc
     if not response.prepared:
         response.headers['SERVER'] = "Secured Server Software"
```

### Comparing `aiohttp-4.0.0a0/examples/web_srv.py` & `aiohttp-4.0.0a1/examples/web_srv.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/examples/web_srv_route_deco.py` & `aiohttp-4.0.0a1/examples/web_srv_route_deco.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/examples/web_srv_route_table.py` & `aiohttp-4.0.0a1/examples/web_srv_route_table.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/examples/web_ws.py` & `aiohttp-4.0.0a1/examples/web_ws.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/LICENSE.txt` & `aiohttp-4.0.0a1/LICENSE.txt`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/Makefile` & `aiohttp-4.0.0a1/Makefile`

 * *Files 10% similar despite different names*

```diff
@@ -1,20 +1,30 @@
 # Some simple testing tasks (sorry, UNIX only).
 
+PYXS = $(wildcard aiohttp/*.pyx)
+SRC = aiohttp examples tests setup.py
+
 all: test
 
-.install-deps: $(shell find requirements -type f)
+.install-cython:
 	pip install -r requirements/cython.txt
+	touch .install-cython
+
+aiohttp/%.c: aiohttp/%.pyx
+	cython -3 -o $@ $< -I aiohttp
+
+cythonize: .install-cython $(PYXS:.pyx=.c)
+
+.install-deps: cythonize $(shell find requirements -type f)
 	pip install -r requirements/dev.txt
 	@touch .install-deps
 
+
 isort:
-	isort -rc aiohttp
-	isort -rc tests
-	isort -rc examples
+	isort -rc $(SRC)
 
 flake: .flake
 
 .flake: .install-deps $(shell find aiohttp -type f) \
                       $(shell find tests -type f) \
                       $(shell find examples -type f)
 	flake8 aiohttp examples tests
@@ -25,22 +35,31 @@
             false; \
 	fi
 	@if ! LC_ALL=C sort -c CONTRIBUTORS.txt; then \
             echo "CONTRIBUTORS.txt sort error"; \
 	fi
 	@touch .flake
 
-check_changes:
-	./tools/check_changes.py
+
+flake8:
+	flake8 $(SRC)
 
 mypy: .flake
-	if python -c "import sys; sys.exit(sys.implementation.name!='cpython')"; then \
-            mypy aiohttp; \
+	mypy aiohttp
+
+isort-check:
+	@if ! isort -rc --check-only $(SRC); then \
+            echo "Import sort errors, run 'make isort' to fix them!!!"; \
+            isort --diff -rc $(SRC); \
+            false; \
 	fi
 
+check_changes:
+	./tools/check_changes.py
+
 .develop: .install-deps $(shell find aiohttp -type f) .flake check_changes mypy
 	# pip install -e .
 	@touch .develop
 
 test: .develop
 	@pytest -c pytest.ci.ini -q
 
@@ -106,11 +125,11 @@
 	@make -C docs html SPHINXOPTS="-W -E"
 	@echo "open file://`pwd`/docs/_build/html/index.html"
 
 doc-spelling:
 	@make -C docs spelling SPHINXOPTS="-W -E"
 
 install:
-	@pip install -U pip
+	@pip install -U 'pip<19'
 	@pip install -Ur requirements/dev.txt
 
 .PHONY: all build flake test vtest cov clean doc
```

### Comparing `aiohttp-4.0.0a0/PKG-INFO` & `aiohttp-4.0.0a1/aiohttp.egg-info/PKG-INFO`

 * *Files 24% similar despite different names*

```diff
@@ -1,393 +1,549 @@
-Metadata-Version: 2.1
-Name: aiohttp
-Version: 4.0.0a0
-Summary: Async http client/server framework (asyncio)
-Home-page: https://github.com/aio-libs/aiohttp
-Author: Nikolay Kim
-Author-email: fafhrd91@gmail.com
-Maintainer: Nikolay Kim <fafhrd91@gmail.com>, Andrew Svetlov <andrew.svetlov@gmail.com>
-Maintainer-email: aio-libs@googlegroups.com
-License: Apache 2
-Project-URL: CI: AppVeyor, https://ci.appveyor.com/project/aio-libs/aiohttp
-Project-URL: Coverage: codecov, https://codecov.io/github/aio-libs/aiohttp
-Project-URL: CI: Circle, https://circleci.com/gh/aio-libs/aiohttp
-Project-URL: Chat: Gitter, https://gitter.im/aio-libs/Lobby
-Project-URL: CI: Travis, https://travis-ci.com/aio-libs/aiohttp
-Project-URL: GitHub: issues, https://github.com/aio-libs/aiohttp/issues
-Project-URL: Docs: RTD, https://docs.aiohttp.org
-Project-URL: GitHub: repo, https://github.com/aio-libs/aiohttp
-Project-URL: CI: Shippable, https://app.shippable.com/github/aio-libs/aiohttp
-Description: ==================================
-        Async http client/server framework
-        ==================================
-        
-        .. image:: https://raw.githubusercontent.com/aio-libs/aiohttp/master/docs/_static/aiohttp-icon-128x128.png
-           :height: 64px
-           :width: 64px
-           :alt: aiohttp logo
-        
-        |
-        
-        .. image:: https://travis-ci.com/aio-libs/aiohttp.svg?branch=master
-           :target: https://travis-ci.com/aio-libs/aiohttp
-           :align: right
-           :alt: Travis status for master branch
-        
-        .. image:: https://ci.appveyor.com/api/projects/status/tnddy9k6pphl8w7k/branch/master?svg=true
-           :target: https://ci.appveyor.com/project/aio-libs/aiohttp
-           :align: right
-           :alt: AppVeyor status for master branch
-        
-        .. image:: https://codecov.io/gh/aio-libs/aiohttp/branch/master/graph/badge.svg
-           :target: https://codecov.io/gh/aio-libs/aiohttp
-           :alt: codecov.io status for master branch
-        
-        .. image:: https://badge.fury.io/py/aiohttp.svg
-           :target: https://pypi.org/project/aiohttp
-           :alt: Latest PyPI package version
-        
-        .. image:: https://readthedocs.org/projects/aiohttp/badge/?version=latest
-           :target: https://docs.aiohttp.org/
-           :alt: Latest Read The Docs
-        
-        .. image:: https://badges.gitter.im/Join%20Chat.svg
-            :target: https://gitter.im/aio-libs/Lobby
-            :alt: Chat on Gitter
-        
-        Key Features
-        ============
-        
-        - Supports both client and server side of HTTP protocol.
-        - Supports both client and server Web-Sockets out-of-the-box and avoids
-          Callback Hell.
-        - Provides Web-server with middlewares and pluggable routing.
-        
-        
-        Getting started
-        ===============
-        
-        Client
-        ------
-        
-        To get something from the web:
-        
-        .. code-block:: python
-        
-          import aiohttp
-          import asyncio
-        
-          async def fetch(session, url):
-              async with session.get(url) as response:
-                  return await response.text()
-        
-          async def main():
-              async with aiohttp.ClientSession() as session:
-                  html = await fetch(session, 'http://python.org')
-                  print(html)
-        
-          if __name__ == '__main__':
-              loop = asyncio.get_event_loop()
-              loop.run_until_complete(main())
-        
-        
-        Server
-        ------
-        
-        An example using a simple server:
-        
-        .. code-block:: python
-        
-            # examples/server_simple.py
-            from aiohttp import web
-        
-            async def handle(request):
-                name = request.match_info.get('name', "Anonymous")
-                text = "Hello, " + name
-                return web.Response(text=text)
-        
-            async def wshandle(request):
-                ws = web.WebSocketResponse()
-                await ws.prepare(request)
-        
-                async for msg in ws:
-                    if msg.type == web.WSMsgType.text:
-                        await ws.send_str("Hello, {}".format(msg.data))
-                    elif msg.type == web.WSMsgType.binary:
-                        await ws.send_bytes(msg.data)
-                    elif msg.type == web.WSMsgType.close:
-                        break
-        
-                return ws
-        
-        
-            app = web.Application()
-            app.add_routes([web.get('/', handle),
-                            web.get('/echo', wshandle),
-                            web.get('/{name}', handle)])
-        
-            web.run_app(app)
-        
-        
-        Documentation
-        =============
-        
-        https://aiohttp.readthedocs.io/
-        
-        
-        Demos
-        =====
-        
-        https://github.com/aio-libs/aiohttp-demos
-        
-        
-        External links
-        ==============
-        
-        * `Third party libraries
-          <http://aiohttp.readthedocs.io/en/latest/third_party.html>`_
-        * `Built with aiohttp
-          <http://aiohttp.readthedocs.io/en/latest/built_with.html>`_
-        * `Powered by aiohttp
-          <http://aiohttp.readthedocs.io/en/latest/powered_by.html>`_
-        
-        Feel free to make a Pull Request for adding your link to these pages!
-        
-        
-        Communication channels
-        ======================
-        
-        *aio-libs* google group: https://groups.google.com/forum/#!forum/aio-libs
-        
-        Feel free to post your questions and ideas here.
-        
-        *gitter chat* https://gitter.im/aio-libs/Lobby
-        
-        We support `Stack Overflow
-        <https://stackoverflow.com/questions/tagged/aiohttp>`_.
-        Please add *aiohttp* tag to your question there.
-        
-        Requirements
-        ============
-        
-        - Python >= 3.5.3
-        - async-timeout_
-        - attrs_
-        - chardet_
-        - multidict_
-        - yarl_
-        
-        Optionally you may install the cChardet_ and aiodns_ libraries (highly
-        recommended for sake of speed).
-        
-        .. _chardet: https://pypi.python.org/pypi/chardet
-        .. _aiodns: https://pypi.python.org/pypi/aiodns
-        .. _attrs: https://github.com/python-attrs/attrs
-        .. _multidict: https://pypi.python.org/pypi/multidict
-        .. _yarl: https://pypi.python.org/pypi/yarl
-        .. _async-timeout: https://pypi.python.org/pypi/async_timeout
-        .. _cChardet: https://pypi.python.org/pypi/cchardet
-        
-        License
-        =======
-        
-        ``aiohttp`` is offered under the Apache 2 license.
-        
-        
-        Keepsafe
-        ========
-        
-        The aiohttp community would like to thank Keepsafe
-        (https://www.getkeepsafe.com) for its support in the early days of
-        the project.
-        
-        
-        Source code
-        ===========
-        
-        The latest developer version is available in a GitHub repository:
-        https://github.com/aio-libs/aiohttp
-        
-        Benchmarks
-        ==========
-        
-        If you are interested in efficiency, the AsyncIO community maintains a
-        list of benchmarks on the official wiki:
-        https://github.com/python/asyncio/wiki/Benchmarks
-        
-        =========
-        Changelog
-        =========
-        
-        ..
-            You should *NOT* be adding new change log entries to this file, this
-            file is managed by towncrier. You *may* edit previous change logs to
-            fix problems like typo corrections or such.
-            To add a new change log entry, please see
-            https://pip.pypa.io/en/latest/development/#adding-a-news-entry
-            we named the news folder "changes".
-        
-            WARNING: Don't drop the next directive!
-        
-        .. towncrier release notes start
-        
-        3.5.2 (2019-01-08)
-        ==================
-        
-        Features
-        --------
-        
-        - ``FileResponse`` from ``web_fileresponse.py`` uses a ``ThreadPoolExecutor`` to work with files asynchronously.
-          I/O based payloads from ``payload.py`` uses a ``ThreadPoolExecutor`` to work with I/O objects asynchronously.
-          `#3313 <https://github.com/aio-libs/aiohttp/issues/3313>`_
-        - Internal Server Errors in plain text if the browser does not support HTML.
-          `#3483 <https://github.com/aio-libs/aiohttp/issues/3483>`_
-        
-        
-        Bugfixes
-        --------
-        
-        - Preserve MultipartWriter parts headers on write.
-        
-          Refactor the way how ``Payload.headers`` are handled. Payload instances now always
-          have headers and Content-Type defined.
-        
-          Fix Payload Content-Disposition header reset after initial creation.
-          `#3035 <https://github.com/aio-libs/aiohttp/issues/3035>`_
-        - Log suppressed exceptions in ``GunicornWebWorker``.
-          `#3464 <https://github.com/aio-libs/aiohttp/issues/3464>`_
-        - Remove wildcard imports.
-          `#3468 <https://github.com/aio-libs/aiohttp/issues/3468>`_
-        - Use the same task for app initialization and web server handling in gunicorn workers.
-          It allows to use Python3.7 context vars smoothly.
-          `#3471 <https://github.com/aio-libs/aiohttp/issues/3471>`_
-        - Fix handling of chunked+gzipped response when first chunk does not give uncompressed data
-          `#3477 <https://github.com/aio-libs/aiohttp/issues/3477>`_
-        - Replace ``collections.MutableMapping`` with ``collections.abc.MutableMapping`` to avoid a deprecation warning.
-          `#3480 <https://github.com/aio-libs/aiohttp/issues/3480>`_
-        - ``Payload.size`` type annotation changed from `Optional[float]` to `Optional[int]`.
-          `#3484 <https://github.com/aio-libs/aiohttp/issues/3484>`_
-        - Ignore done tasks when cancels pending activities on ``web.run_app`` finalization.
-          `#3497 <https://github.com/aio-libs/aiohttp/issues/3497>`_
-        
-        
-        Improved Documentation
-        ----------------------
-        
-        - Add documentation for ``aiohttp.web.HTTPException``.
-          `#3490 <https://github.com/aio-libs/aiohttp/issues/3490>`_
-        
-        
-        Misc
-        ----
-        
-        - `#3487 <https://github.com/aio-libs/aiohttp/issues/3487>`_
-        
-        
-        ----
-        
-        
-        3.5.1 (2018-12-24)
-        ====================
-        
-        - Fix a regression about ``ClientSession._requote_redirect_url`` modification in debug
-          mode.
-        
-        3.5.0 (2018-12-22)
-        ====================
-        
-        Features
-        --------
-        
-        - The library type annotations are checked in strict mode now.
-        - Add support for setting cookies for individual request (`#2387 <https://github.com/aio-libs/aiohttp/pull/2387>`_)
-        - Application.add_domain implementation (`#2809 <https://github.com/aio-libs/aiohttp/pull/2809>`_)
-        - The default ``app`` in the request returned by ``test_utils.make_mocked_request``
-          can now have objects assigned to it and retrieved using the ``[]`` operator. (`#3174 <https://github.com/aio-libs/aiohttp/pull/3174>`_)
-        - Make ``request.url`` accessible when transport is closed. (`#3177 <https://github.com/aio-libs/aiohttp/pull/3177>`_)
-        - Add ``zlib_executor_size`` argument to ``Response`` constructor to allow compression to run in a background executor to avoid blocking the main thread and potentially triggering health check failures. (`#3205 <https://github.com/aio-libs/aiohttp/pull/3205>`_)
-        - Enable users to set `ClientTimeout` in `aiohttp.request` (`#3213 <https://github.com/aio-libs/aiohttp/pull/3213>`_)
-        - Don't raise a warning if ``NETRC`` environment variable is not set and ``~/.netrc`` file
-          doesn't exist. (`#3267 <https://github.com/aio-libs/aiohttp/pull/3267>`_)
-        - Add default logging handler to web.run_app
-        
-          If the `Application.debug` flag is set and the default logger `aiohttp.access` is used, access logs will now be output using a `stderr` `StreamHandler` if no handlers are attached. Furthermore, if the default logger has no log level set, the log level will be set to `DEBUG`. (`#3324 <https://github.com/aio-libs/aiohttp/pull/3324>`_)
-        - Add method argument to ``session.ws_connect()``.
-        
-          Sometimes server API requires a different HTTP method for WebSocket connection establishment.
-        
-          For example, ``Docker exec`` needs POST. (`#3378 <https://github.com/aio-libs/aiohttp/pull/3378>`_)
-        - Create a task per request handling. (`#3406 <https://github.com/aio-libs/aiohttp/pull/3406>`_)
-        
-        
-        Bugfixes
-        --------
-        
-        - Enable passing `access_log_class` via `handler_args` (`#3158 <https://github.com/aio-libs/aiohttp/pull/3158>`_)
-        - Return empty bytes with end-of-chunk marker in empty stream reader. (`#3186 <https://github.com/aio-libs/aiohttp/pull/3186>`_)
-        - Accept ``CIMultiDictProxy`` instances for ``headers`` argument in ``web.Response``
-          constructor. (`#3207 <https://github.com/aio-libs/aiohttp/pull/3207>`_)
-        - Don't uppercase HTTP method in parser (`#3233 <https://github.com/aio-libs/aiohttp/pull/3233>`_)
-        - Make method match regexp RFC-7230 compliant (`#3235 <https://github.com/aio-libs/aiohttp/pull/3235>`_)
-        - Add ``app.pre_frozen`` state to properly handle startup signals in sub-applications. (`#3237 <https://github.com/aio-libs/aiohttp/pull/3237>`_)
-        - Enhanced parsing and validation of helpers.BasicAuth.decode. (`#3239 <https://github.com/aio-libs/aiohttp/pull/3239>`_)
-        - Change imports from collections module in preparation for 3.8. (`#3258 <https://github.com/aio-libs/aiohttp/pull/3258>`_)
-        - Ensure Host header is added first to ClientRequest to better replicate browser (`#3265 <https://github.com/aio-libs/aiohttp/pull/3265>`_)
-        - Fix forward compatibility with Python 3.8: importing ABCs directly from the collections module will not be supported anymore. (`#3273 <https://github.com/aio-libs/aiohttp/pull/3273>`_)
-        - Keep the query string by `normalize_path_middleware`. (`#3278 <https://github.com/aio-libs/aiohttp/pull/3278>`_)
-        - Fix missing parameter ``raise_for_status`` for aiohttp.request() (`#3290 <https://github.com/aio-libs/aiohttp/pull/3290>`_)
-        - Bracket IPv6 addresses in the HOST header (`#3304 <https://github.com/aio-libs/aiohttp/pull/3304>`_)
-        - Fix default message for server ping and pong frames. (`#3308 <https://github.com/aio-libs/aiohttp/pull/3308>`_)
-        - Fix tests/test_connector.py typo and tests/autobahn/server.py duplicate loop def. (`#3337 <https://github.com/aio-libs/aiohttp/pull/3337>`_)
-        - Fix false-negative indicator end_of_HTTP_chunk in StreamReader.readchunk function (`#3361 <https://github.com/aio-libs/aiohttp/pull/3361>`_)
-        - Release HTTP response before raising status exception (`#3364 <https://github.com/aio-libs/aiohttp/pull/3364>`_)
-        - Fix task cancellation when ``sendfile()`` syscall is used by static file handling. (`#3383 <https://github.com/aio-libs/aiohttp/pull/3383>`_)
-        - Fix stack trace for ``asyncio.TimeoutError`` which was not logged, when it is caught
-          in the handler. (`#3414 <https://github.com/aio-libs/aiohttp/pull/3414>`_)
-        
-        
-        Improved Documentation
-        ----------------------
-        
-        - Improve documentation of ``Application.make_handler`` parameters. (`#3152 <https://github.com/aio-libs/aiohttp/pull/3152>`_)
-        - Fix BaseRequest.raw_headers doc. (`#3215 <https://github.com/aio-libs/aiohttp/pull/3215>`_)
-        - Fix typo in TypeError exception reason in ``web.Application._handle`` (`#3229 <https://github.com/aio-libs/aiohttp/pull/3229>`_)
-        - Make server access log format placeholder %b documentation reflect
-          behavior and docstring. (`#3307 <https://github.com/aio-libs/aiohttp/pull/3307>`_)
-        
-        
-        Deprecations and Removals
-        -------------------------
-        
-        - Deprecate modification of ``session.requote_redirect_url`` (`#2278 <https://github.com/aio-libs/aiohttp/pull/2278>`_)
-        - Deprecate ``stream.unread_data()`` (`#3260 <https://github.com/aio-libs/aiohttp/pull/3260>`_)
-        - Deprecated use of boolean in ``resp.enable_compression()`` (`#3318 <https://github.com/aio-libs/aiohttp/pull/3318>`_)
-        - Encourage creation of aiohttp public objects inside a coroutine (`#3331 <https://github.com/aio-libs/aiohttp/pull/3331>`_)
-        - Drop dead ``Connection.detach()`` and ``Connection.writer``. Both methods were broken
-          for more than 2 years. (`#3358 <https://github.com/aio-libs/aiohttp/pull/3358>`_)
-        - Deprecate ``app.loop``, ``request.loop``, ``client.loop`` and ``connector.loop`` properties. (`#3374 <https://github.com/aio-libs/aiohttp/pull/3374>`_)
-        - Deprecate explicit debug argument. Use asyncio debug mode instead. (`#3381 <https://github.com/aio-libs/aiohttp/pull/3381>`_)
-        - Deprecate body parameter in HTTPException (and derived classes) constructor. (`#3385 <https://github.com/aio-libs/aiohttp/pull/3385>`_)
-        - Deprecate bare connector close, use ``async with connector:`` and ``await connector.close()`` instead. (`#3417 <https://github.com/aio-libs/aiohttp/pull/3417>`_)
-        - Deprecate obsolete ``read_timeout`` and ``conn_timeout`` in ``ClientSession`` constructor. (`#3438 <https://github.com/aio-libs/aiohttp/pull/3438>`_)
-        
-        
-        Misc
-        ----
-        
-        - #3341, #3351
-Platform: UNKNOWN
-Classifier: License :: OSI Approved :: Apache Software License
-Classifier: Intended Audience :: Developers
-Classifier: Programming Language :: Python
-Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.5
-Classifier: Programming Language :: Python :: 3.6
-Classifier: Programming Language :: Python :: 3.7
-Classifier: Development Status :: 5 - Production/Stable
-Classifier: Operating System :: POSIX
-Classifier: Operating System :: MacOS :: MacOS X
-Classifier: Operating System :: Microsoft :: Windows
-Classifier: Topic :: Internet :: WWW/HTTP
-Classifier: Framework :: AsyncIO
-Requires-Python: >=3.5.3
-Provides-Extra: speedups
+Metadata-Version: 2.1
+Name: aiohttp
+Version: 4.0.0a1
+Summary: Async http client/server framework (asyncio)
+Home-page: https://github.com/aio-libs/aiohttp
+Author: Nikolay Kim
+Author-email: fafhrd91@gmail.com
+Maintainer: Nikolay Kim <fafhrd91@gmail.com>, Andrew Svetlov <andrew.svetlov@gmail.com>
+Maintainer-email: aio-libs@googlegroups.com
+License: Apache 2
+Project-URL: Chat: Gitter, https://gitter.im/aio-libs/Lobby
+Project-URL: CI: AppVeyor, https://ci.appveyor.com/project/aio-libs/aiohttp
+Project-URL: CI: Circle, https://circleci.com/gh/aio-libs/aiohttp
+Project-URL: CI: Shippable, https://app.shippable.com/github/aio-libs/aiohttp
+Project-URL: CI: Travis, https://travis-ci.com/aio-libs/aiohttp
+Project-URL: Coverage: codecov, https://codecov.io/github/aio-libs/aiohttp
+Project-URL: Docs: RTD, https://docs.aiohttp.org
+Project-URL: GitHub: issues, https://github.com/aio-libs/aiohttp/issues
+Project-URL: GitHub: repo, https://github.com/aio-libs/aiohttp
+Description: ==================================
+        Async http client/server framework
+        ==================================
+        
+        .. image:: https://raw.githubusercontent.com/aio-libs/aiohttp/master/docs/_static/aiohttp-icon-128x128.png
+           :height: 64px
+           :width: 64px
+           :alt: aiohttp logo
+        
+        |
+        
+        .. image:: https://travis-ci.com/aio-libs/aiohttp.svg?branch=master
+           :target: https://travis-ci.com/aio-libs/aiohttp
+           :align: right
+           :alt: Travis status for master branch
+        
+        .. image:: https://ci.appveyor.com/api/projects/status/tnddy9k6pphl8w7k/branch/master?svg=true
+           :target: https://ci.appveyor.com/project/aio-libs/aiohttp
+           :align: right
+           :alt: AppVeyor status for master branch
+        
+        .. image:: https://codecov.io/gh/aio-libs/aiohttp/branch/master/graph/badge.svg
+           :target: https://codecov.io/gh/aio-libs/aiohttp
+           :alt: codecov.io status for master branch
+        
+        .. image:: https://badge.fury.io/py/aiohttp.svg
+           :target: https://pypi.org/project/aiohttp
+           :alt: Latest PyPI package version
+        
+        .. image:: https://readthedocs.org/projects/aiohttp/badge/?version=latest
+           :target: https://docs.aiohttp.org/
+           :alt: Latest Read The Docs
+        
+        .. image:: https://badges.gitter.im/Join%20Chat.svg
+            :target: https://gitter.im/aio-libs/Lobby
+            :alt: Chat on Gitter
+        
+        Key Features
+        ============
+        
+        - Supports both client and server side of HTTP protocol.
+        - Supports both client and server Web-Sockets out-of-the-box and avoids
+          Callback Hell.
+        - Provides Web-server with middlewares and pluggable routing.
+        
+        
+        Getting started
+        ===============
+        
+        Client
+        ------
+        
+        To get something from the web:
+        
+        .. code-block:: python
+        
+          import aiohttp
+          import asyncio
+        
+          async def fetch(session, url):
+              async with session.get(url) as response:
+                  return await response.text()
+        
+          async def main():
+              async with aiohttp.ClientSession() as session:
+                  html = await fetch(session, 'http://python.org')
+                  print(html)
+        
+          if __name__ == '__main__':
+              loop = asyncio.get_event_loop()
+              loop.run_until_complete(main())
+        
+        
+        Server
+        ------
+        
+        An example using a simple server:
+        
+        .. code-block:: python
+        
+            # examples/server_simple.py
+            from aiohttp import web
+        
+            async def handle(request):
+                name = request.match_info.get('name', "Anonymous")
+                text = "Hello, " + name
+                return web.Response(text=text)
+        
+            async def wshandle(request):
+                ws = web.WebSocketResponse()
+                await ws.prepare(request)
+        
+                async for msg in ws:
+                    if msg.type == web.WSMsgType.text:
+                        await ws.send_str("Hello, {}".format(msg.data))
+                    elif msg.type == web.WSMsgType.binary:
+                        await ws.send_bytes(msg.data)
+                    elif msg.type == web.WSMsgType.close:
+                        break
+        
+                return ws
+        
+        
+            app = web.Application()
+            app.add_routes([web.get('/', handle),
+                            web.get('/echo', wshandle),
+                            web.get('/{name}', handle)])
+        
+            if __name__ == '__main__':
+                web.run_app(app)
+        
+        
+        Documentation
+        =============
+        
+        https://aiohttp.readthedocs.io/
+        
+        
+        Demos
+        =====
+        
+        https://github.com/aio-libs/aiohttp-demos
+        
+        
+        External links
+        ==============
+        
+        * `Third party libraries
+          <http://aiohttp.readthedocs.io/en/latest/third_party.html>`_
+        * `Built with aiohttp
+          <http://aiohttp.readthedocs.io/en/latest/built_with.html>`_
+        * `Powered by aiohttp
+          <http://aiohttp.readthedocs.io/en/latest/powered_by.html>`_
+        
+        Feel free to make a Pull Request for adding your link to these pages!
+        
+        
+        Communication channels
+        ======================
+        
+        *aio-libs* google group: https://groups.google.com/forum/#!forum/aio-libs
+        
+        Feel free to post your questions and ideas here.
+        
+        *gitter chat* https://gitter.im/aio-libs/Lobby
+        
+        We support `Stack Overflow
+        <https://stackoverflow.com/questions/tagged/aiohttp>`_.
+        Please add *aiohttp* tag to your question there.
+        
+        Requirements
+        ============
+        
+        - Python >= 3.5.3
+        - async-timeout_
+        - attrs_
+        - chardet_
+        - multidict_
+        - yarl_
+        
+        Optionally you may install the cChardet_ and aiodns_ libraries (highly
+        recommended for sake of speed).
+        
+        .. _chardet: https://pypi.python.org/pypi/chardet
+        .. _aiodns: https://pypi.python.org/pypi/aiodns
+        .. _attrs: https://github.com/python-attrs/attrs
+        .. _multidict: https://pypi.python.org/pypi/multidict
+        .. _yarl: https://pypi.python.org/pypi/yarl
+        .. _async-timeout: https://pypi.python.org/pypi/async_timeout
+        .. _cChardet: https://pypi.python.org/pypi/cchardet
+        
+        License
+        =======
+        
+        ``aiohttp`` is offered under the Apache 2 license.
+        
+        
+        Keepsafe
+        ========
+        
+        The aiohttp community would like to thank Keepsafe
+        (https://www.getkeepsafe.com) for its support in the early days of
+        the project.
+        
+        
+        Source code
+        ===========
+        
+        The latest developer version is available in a GitHub repository:
+        https://github.com/aio-libs/aiohttp
+        
+        Benchmarks
+        ==========
+        
+        If you are interested in efficiency, the AsyncIO community maintains a
+        list of benchmarks on the official wiki:
+        https://github.com/python/asyncio/wiki/Benchmarks
+        
+        =========
+        Changelog
+        =========
+        
+        ..
+            You should *NOT* be adding new change log entries to this file, this
+            file is managed by towncrier. You *may* edit previous change logs to
+            fix problems like typo corrections or such.
+            To add a new change log entry, please see
+            https://pip.pypa.io/en/latest/development/#adding-a-news-entry
+            we named the news folder "changes".
+        
+            WARNING: Don't drop the next directive!
+        
+        .. towncrier release notes start
+        
+        3.6.1 (2019-09-19)
+        ==================
+        
+        Features
+        --------
+        
+        - Compatibility with Python 3.8.
+          `#4056 <https://github.com/aio-libs/aiohttp/issues/4056>`_
+        
+        
+        Bugfixes
+        --------
+        
+        - correct some exception string format
+          `#4068 <https://github.com/aio-libs/aiohttp/issues/4068>`_
+        - Emit a warning when ``ssl.OP_NO_COMPRESSION`` is
+          unavailable because the runtime is built against
+          an outdated OpenSSL.
+          `#4052 <https://github.com/aio-libs/aiohttp/issues/4052>`_
+        - Update multidict requirement to >= 4.5
+          `#4057 <https://github.com/aio-libs/aiohttp/issues/4057>`_
+        
+        
+        Improved Documentation
+        ----------------------
+        
+        - Provide pytest-aiohttp namespace for pytest fixtures in docs.
+          `#3723 <https://github.com/aio-libs/aiohttp/issues/3723>`_
+        
+        
+        ----
+        
+        
+        3.6.0 (2019-09-06)
+        ==================
+        
+        Features
+        --------
+        
+        - Add support for Named Pipes (Site and Connector) under Windows. This feature requires Proactor event loop to work.
+          `#3629 <https://github.com/aio-libs/aiohttp/issues/3629>`_
+        - Removed `Transfer-Encoding: chunked` header from websocket responses to be compatible with more http proxy servers.
+          `#3798 <https://github.com/aio-libs/aiohttp/issues/3798>`_
+        - Accept non-GET request for starting websocket handshake on server side.
+          `#3980 <https://github.com/aio-libs/aiohttp/issues/3980>`_
+        
+        
+        Bugfixes
+        --------
+        
+        - Raise a ClientResponseError instead of an AssertionError for a blank
+          HTTP Reason Phrase.
+          `#3532 <https://github.com/aio-libs/aiohttp/issues/3532>`_
+        - Fix an issue where cookies would sometimes not be set during a redirect.
+          `#3576 <https://github.com/aio-libs/aiohttp/issues/3576>`_
+        - Change normalize_path_middleware to use 308 redirect instead of 301.
+        
+          This behavior should prevent clients from being unable to use PUT/POST
+          methods on endpoints that are redirected because of a trailing slash.
+          `#3579 <https://github.com/aio-libs/aiohttp/issues/3579>`_
+        - Drop the processed task from ``all_tasks()`` list early. It prevents logging about a task with unhandled exception when the server is used in conjunction with ``asyncio.run()``.
+          `#3587 <https://github.com/aio-libs/aiohttp/issues/3587>`_
+        - ``Signal`` type annotation changed from `Signal[Callable[['TraceConfig'], Awaitable[None]]]` to `Signal[Callable[ClientSession, SimpleNamespace, ...]`.
+          `#3595 <https://github.com/aio-libs/aiohttp/issues/3595>`_
+        - Use sanitized URL as Location header in redirects
+          `#3614 <https://github.com/aio-libs/aiohttp/issues/3614>`_
+        - Improve typing annotations for multipart.py along with changes required
+          by mypy in files that references multipart.py.
+          `#3621 <https://github.com/aio-libs/aiohttp/issues/3621>`_
+        - Close session created inside ``aiohttp.request`` when unhandled exception occurs
+          `#3628 <https://github.com/aio-libs/aiohttp/issues/3628>`_
+        - Cleanup per-chunk data in generic data read. Memory leak fixed.
+          `#3631 <https://github.com/aio-libs/aiohttp/issues/3631>`_
+        - Use correct type for add_view and family
+          `#3633 <https://github.com/aio-libs/aiohttp/issues/3633>`_
+        - Fix _keepalive field in __slots__ of ``RequestHandler``.
+          `#3644 <https://github.com/aio-libs/aiohttp/issues/3644>`_
+        - Properly handle ConnectionResetError, to silence the "Cannot write to closing
+          transport" exception when clients disconnect uncleanly.
+          `#3648 <https://github.com/aio-libs/aiohttp/issues/3648>`_
+        - Suppress pytest warnings due to ``test_utils`` classes
+          `#3660 <https://github.com/aio-libs/aiohttp/issues/3660>`_
+        - Fix overshadowing of overlapped sub-application prefixes.
+          `#3701 <https://github.com/aio-libs/aiohttp/issues/3701>`_
+        - Fixed return type annotation for WSMessage.json()
+          `#3720 <https://github.com/aio-libs/aiohttp/issues/3720>`_
+        - Properly expose TooManyRedirects publicly as documented.
+          `#3818 <https://github.com/aio-libs/aiohttp/issues/3818>`_
+        - Fix missing brackets for IPv6 in proxy CONNECT request
+          `#3841 <https://github.com/aio-libs/aiohttp/issues/3841>`_
+        - Make the signature of `aiohttp.test_utils.TestClient.request` match `asyncio.ClientSession.request` according to the docs
+          `#3852 <https://github.com/aio-libs/aiohttp/issues/3852>`_
+        - Use correct style for re-exported imports, makes mypy ``--strict`` mode happy.
+          `#3868 <https://github.com/aio-libs/aiohttp/issues/3868>`_
+        - Fixed type annotation for add_view method of UrlDispatcher to accept any subclass of View
+          `#3880 <https://github.com/aio-libs/aiohttp/issues/3880>`_
+        - Made cython HTTP parser set Reason-Phrase of the response to an empty string if it is missing.
+          `#3906 <https://github.com/aio-libs/aiohttp/issues/3906>`_
+        - Add URL to the string representation of ClientResponseError.
+          `#3959 <https://github.com/aio-libs/aiohttp/issues/3959>`_
+        - Accept ``istr`` keys in ``LooseHeaders`` type hints.
+          `#3976 <https://github.com/aio-libs/aiohttp/issues/3976>`_
+        - Fixed race conditions in _resolve_host caching and throttling when tracing is enabled.
+          `#4013 <https://github.com/aio-libs/aiohttp/issues/4013>`_
+        - For URLs like "unix://localhost/..." set Host HTTP header to "localhost" instead of "localhost:None".
+          `#4039 <https://github.com/aio-libs/aiohttp/issues/4039>`_
+        
+        
+        Improved Documentation
+        ----------------------
+        
+        - Modify documentation for Background Tasks to remove deprecated usage of event loop.
+          `#3526 <https://github.com/aio-libs/aiohttp/issues/3526>`_
+        - use ``if __name__ == '__main__':`` in server examples.
+          `#3775 <https://github.com/aio-libs/aiohttp/issues/3775>`_
+        - Update documentation reference to the default access logger.
+          `#3783 <https://github.com/aio-libs/aiohttp/issues/3783>`_
+        - Improve documentation for ``web.BaseRequest.path`` and ``web.BaseRequest.raw_path``.
+          `#3791 <https://github.com/aio-libs/aiohttp/issues/3791>`_
+        - Removed deprecation warning in tracing example docs
+          `#3964 <https://github.com/aio-libs/aiohttp/issues/3964>`_
+        
+        
+        ----
+        
+        
+        3.5.4 (2019-01-12)
+        ==================
+        
+        Bugfixes
+        --------
+        
+        - Fix stream ``.read()`` / ``.readany()`` / ``.iter_any()`` which used to return a
+          partial content only in case of compressed content
+          `#3525 <https://github.com/aio-libs/aiohttp/issues/3525>`_
+        
+        
+        3.5.3 (2019-01-10)
+        ==================
+        
+        Bugfixes
+        --------
+        
+        - Fix type stubs for ``aiohttp.web.run_app(access_log=True)`` and fix edge case of ``access_log=True`` and the event loop being in debug mode.
+          `#3504 <https://github.com/aio-libs/aiohttp/issues/3504>`_
+        - Fix ``aiohttp.ClientTimeout`` type annotations to accept ``None`` for fields
+          `#3511 <https://github.com/aio-libs/aiohttp/issues/3511>`_
+        - Send custom per-request cookies even if session jar is empty
+          `#3515 <https://github.com/aio-libs/aiohttp/issues/3515>`_
+        - Restore Linux binary wheels publishing on PyPI
+        
+        ----
+        
+        
+        3.5.2 (2019-01-08)
+        ==================
+        
+        Features
+        --------
+        
+        - ``FileResponse`` from ``web_fileresponse.py`` uses a ``ThreadPoolExecutor`` to work with files asynchronously.
+          I/O based payloads from ``payload.py`` uses a ``ThreadPoolExecutor`` to work with I/O objects asynchronously.
+          `#3313 <https://github.com/aio-libs/aiohttp/issues/3313>`_
+        - Internal Server Errors in plain text if the browser does not support HTML.
+          `#3483 <https://github.com/aio-libs/aiohttp/issues/3483>`_
+        
+        
+        Bugfixes
+        --------
+        
+        - Preserve MultipartWriter parts headers on write.
+        
+          Refactor the way how ``Payload.headers`` are handled. Payload instances now always
+          have headers and Content-Type defined.
+        
+          Fix Payload Content-Disposition header reset after initial creation.
+          `#3035 <https://github.com/aio-libs/aiohttp/issues/3035>`_
+        - Log suppressed exceptions in ``GunicornWebWorker``.
+          `#3464 <https://github.com/aio-libs/aiohttp/issues/3464>`_
+        - Remove wildcard imports.
+          `#3468 <https://github.com/aio-libs/aiohttp/issues/3468>`_
+        - Use the same task for app initialization and web server handling in gunicorn workers.
+          It allows to use Python3.7 context vars smoothly.
+          `#3471 <https://github.com/aio-libs/aiohttp/issues/3471>`_
+        - Fix handling of chunked+gzipped response when first chunk does not give uncompressed data
+          `#3477 <https://github.com/aio-libs/aiohttp/issues/3477>`_
+        - Replace ``collections.MutableMapping`` with ``collections.abc.MutableMapping`` to avoid a deprecation warning.
+          `#3480 <https://github.com/aio-libs/aiohttp/issues/3480>`_
+        - ``Payload.size`` type annotation changed from `Optional[float]` to `Optional[int]`.
+          `#3484 <https://github.com/aio-libs/aiohttp/issues/3484>`_
+        - Ignore done tasks when cancels pending activities on ``web.run_app`` finalization.
+          `#3497 <https://github.com/aio-libs/aiohttp/issues/3497>`_
+        
+        
+        Improved Documentation
+        ----------------------
+        
+        - Add documentation for ``aiohttp.web.HTTPException``.
+          `#3490 <https://github.com/aio-libs/aiohttp/issues/3490>`_
+        
+        
+        Misc
+        ----
+        
+        - `#3487 <https://github.com/aio-libs/aiohttp/issues/3487>`_
+        
+        
+        ----
+        
+        
+        3.5.1 (2018-12-24)
+        ====================
+        
+        - Fix a regression about ``ClientSession._requote_redirect_url`` modification in debug
+          mode.
+        
+        3.5.0 (2018-12-22)
+        ====================
+        
+        Features
+        --------
+        
+        - The library type annotations are checked in strict mode now.
+        - Add support for setting cookies for individual request (`#2387 <https://github.com/aio-libs/aiohttp/pull/2387>`_)
+        - Application.add_domain implementation (`#2809 <https://github.com/aio-libs/aiohttp/pull/2809>`_)
+        - The default ``app`` in the request returned by ``test_utils.make_mocked_request``
+          can now have objects assigned to it and retrieved using the ``[]`` operator. (`#3174 <https://github.com/aio-libs/aiohttp/pull/3174>`_)
+        - Make ``request.url`` accessible when transport is closed. (`#3177 <https://github.com/aio-libs/aiohttp/pull/3177>`_)
+        - Add ``zlib_executor_size`` argument to ``Response`` constructor to allow compression to run in a background executor to avoid blocking the main thread and potentially triggering health check failures. (`#3205 <https://github.com/aio-libs/aiohttp/pull/3205>`_)
+        - Enable users to set `ClientTimeout` in `aiohttp.request` (`#3213 <https://github.com/aio-libs/aiohttp/pull/3213>`_)
+        - Don't raise a warning if ``NETRC`` environment variable is not set and ``~/.netrc`` file
+          doesn't exist. (`#3267 <https://github.com/aio-libs/aiohttp/pull/3267>`_)
+        - Add default logging handler to web.run_app
+        
+          If the `Application.debug` flag is set and the default logger `aiohttp.access` is used, access logs will now be output using a `stderr` `StreamHandler` if no handlers are attached. Furthermore, if the default logger has no log level set, the log level will be set to `DEBUG`. (`#3324 <https://github.com/aio-libs/aiohttp/pull/3324>`_)
+        - Add method argument to ``session.ws_connect()``.
+        
+          Sometimes server API requires a different HTTP method for WebSocket connection establishment.
+        
+          For example, ``Docker exec`` needs POST. (`#3378 <https://github.com/aio-libs/aiohttp/pull/3378>`_)
+        - Create a task per request handling. (`#3406 <https://github.com/aio-libs/aiohttp/pull/3406>`_)
+        
+        
+        Bugfixes
+        --------
+        
+        - Enable passing `access_log_class` via `handler_args` (`#3158 <https://github.com/aio-libs/aiohttp/pull/3158>`_)
+        - Return empty bytes with end-of-chunk marker in empty stream reader. (`#3186 <https://github.com/aio-libs/aiohttp/pull/3186>`_)
+        - Accept ``CIMultiDictProxy`` instances for ``headers`` argument in ``web.Response``
+          constructor. (`#3207 <https://github.com/aio-libs/aiohttp/pull/3207>`_)
+        - Don't uppercase HTTP method in parser (`#3233 <https://github.com/aio-libs/aiohttp/pull/3233>`_)
+        - Make method match regexp RFC-7230 compliant (`#3235 <https://github.com/aio-libs/aiohttp/pull/3235>`_)
+        - Add ``app.pre_frozen`` state to properly handle startup signals in sub-applications. (`#3237 <https://github.com/aio-libs/aiohttp/pull/3237>`_)
+        - Enhanced parsing and validation of helpers.BasicAuth.decode. (`#3239 <https://github.com/aio-libs/aiohttp/pull/3239>`_)
+        - Change imports from collections module in preparation for 3.8. (`#3258 <https://github.com/aio-libs/aiohttp/pull/3258>`_)
+        - Ensure Host header is added first to ClientRequest to better replicate browser (`#3265 <https://github.com/aio-libs/aiohttp/pull/3265>`_)
+        - Fix forward compatibility with Python 3.8: importing ABCs directly from the collections module will not be supported anymore. (`#3273 <https://github.com/aio-libs/aiohttp/pull/3273>`_)
+        - Keep the query string by `normalize_path_middleware`. (`#3278 <https://github.com/aio-libs/aiohttp/pull/3278>`_)
+        - Fix missing parameter ``raise_for_status`` for aiohttp.request() (`#3290 <https://github.com/aio-libs/aiohttp/pull/3290>`_)
+        - Bracket IPv6 addresses in the HOST header (`#3304 <https://github.com/aio-libs/aiohttp/pull/3304>`_)
+        - Fix default message for server ping and pong frames. (`#3308 <https://github.com/aio-libs/aiohttp/pull/3308>`_)
+        - Fix tests/test_connector.py typo and tests/autobahn/server.py duplicate loop def. (`#3337 <https://github.com/aio-libs/aiohttp/pull/3337>`_)
+        - Fix false-negative indicator end_of_HTTP_chunk in StreamReader.readchunk function (`#3361 <https://github.com/aio-libs/aiohttp/pull/3361>`_)
+        - Release HTTP response before raising status exception (`#3364 <https://github.com/aio-libs/aiohttp/pull/3364>`_)
+        - Fix task cancellation when ``sendfile()`` syscall is used by static file handling. (`#3383 <https://github.com/aio-libs/aiohttp/pull/3383>`_)
+        - Fix stack trace for ``asyncio.TimeoutError`` which was not logged, when it is caught
+          in the handler. (`#3414 <https://github.com/aio-libs/aiohttp/pull/3414>`_)
+        
+        
+        Improved Documentation
+        ----------------------
+        
+        - Improve documentation of ``Application.make_handler`` parameters. (`#3152 <https://github.com/aio-libs/aiohttp/pull/3152>`_)
+        - Fix BaseRequest.raw_headers doc. (`#3215 <https://github.com/aio-libs/aiohttp/pull/3215>`_)
+        - Fix typo in TypeError exception reason in ``web.Application._handle`` (`#3229 <https://github.com/aio-libs/aiohttp/pull/3229>`_)
+        - Make server access log format placeholder %b documentation reflect
+          behavior and docstring. (`#3307 <https://github.com/aio-libs/aiohttp/pull/3307>`_)
+        
+        
+        Deprecations and Removals
+        -------------------------
+        
+        - Deprecate modification of ``session.requote_redirect_url`` (`#2278 <https://github.com/aio-libs/aiohttp/pull/2278>`_)
+        - Deprecate ``stream.unread_data()`` (`#3260 <https://github.com/aio-libs/aiohttp/pull/3260>`_)
+        - Deprecated use of boolean in ``resp.enable_compression()`` (`#3318 <https://github.com/aio-libs/aiohttp/pull/3318>`_)
+        - Encourage creation of aiohttp public objects inside a coroutine (`#3331 <https://github.com/aio-libs/aiohttp/pull/3331>`_)
+        - Drop dead ``Connection.detach()`` and ``Connection.writer``. Both methods were broken
+          for more than 2 years. (`#3358 <https://github.com/aio-libs/aiohttp/pull/3358>`_)
+        - Deprecate ``app.loop``, ``request.loop``, ``client.loop`` and ``connector.loop`` properties. (`#3374 <https://github.com/aio-libs/aiohttp/pull/3374>`_)
+        - Deprecate explicit debug argument. Use asyncio debug mode instead. (`#3381 <https://github.com/aio-libs/aiohttp/pull/3381>`_)
+        - Deprecate body parameter in HTTPException (and derived classes) constructor. (`#3385 <https://github.com/aio-libs/aiohttp/pull/3385>`_)
+        - Deprecate bare connector close, use ``async with connector:`` and ``await connector.close()`` instead. (`#3417 <https://github.com/aio-libs/aiohttp/pull/3417>`_)
+        - Deprecate obsolete ``read_timeout`` and ``conn_timeout`` in ``ClientSession`` constructor. (`#3438 <https://github.com/aio-libs/aiohttp/pull/3438>`_)
+        
+        
+        Misc
+        ----
+        
+        - #3341, #3351
+Platform: UNKNOWN
+Classifier: License :: OSI Approved :: Apache Software License
+Classifier: Intended Audience :: Developers
+Classifier: Programming Language :: Python
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.6
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Operating System :: POSIX
+Classifier: Operating System :: MacOS :: MacOS X
+Classifier: Operating System :: Microsoft :: Windows
+Classifier: Topic :: Internet :: WWW/HTTP
+Classifier: Framework :: AsyncIO
+Requires-Python: >=3.6
+Description-Content-Type: text/x-rst
+Provides-Extra: speedups
```

### Comparing `aiohttp-4.0.0a0/README.rst` & `aiohttp-4.0.0a1/README.rst`

 * *Files 1% similar despite different names*

```diff
@@ -102,15 +102,16 @@
 
 
     app = web.Application()
     app.add_routes([web.get('/', handle),
                     web.get('/echo', wshandle),
                     web.get('/{name}', handle)])
 
-    web.run_app(app)
+    if __name__ == '__main__':
+        web.run_app(app)
 
 
 Documentation
 =============
 
 https://aiohttp.readthedocs.io/
```

### Comparing `aiohttp-4.0.0a0/setup.cfg` & `aiohttp-4.0.0a1/setup.cfg`

 * *Files 19% similar despite different names*

```diff
@@ -1,85 +1,81 @@
-00000000: 5b61 6c69 6173 6573 5d0d 0a74 6573 7420  [aliases]..test 
-00000010: 3d20 7079 7465 7374 0d0a 0d0a 5b6d 6574  = pytest....[met
-00000020: 6164 6174 615d 0d0a 6c69 6365 6e73 655f  adata]..license_
-00000030: 6669 6c65 203d 204c 4943 454e 5345 2e74  file = LICENSE.t
-00000040: 7874 0d0a 0d0a 5b70 6570 385d 0d0a 6d61  xt....[pep8]..ma
-00000050: 782d 6c69 6e65 2d6c 656e 6774 6820 3d20  x-line-length = 
-00000060: 3739 0d0a 0d0a 5b65 6173 795f 696e 7374  79....[easy_inst
-00000070: 616c 6c5d 0d0a 7a69 705f 6f6b 203d 2066  all]..zip_ok = f
-00000080: 616c 7365 0d0a 0d0a 5b66 6c61 6b65 385d  alse....[flake8]
-00000090: 0d0a 6967 6e6f 7265 203d 204e 3830 312c  ..ignore = N801,
-000000a0: 4e38 3032 2c4e 3830 332c 4532 3236 2c57  N802,N803,E226,W
-000000b0: 3530 342c 4532 3532 0d0a 6d61 782d 6c69  504,E252..max-li
-000000c0: 6e65 2d6c 656e 6774 6820 3d20 3739 0d0a  ne-length = 79..
-000000d0: 0d0a 5b69 736f 7274 5d0d 0a6d 756c 7469  ..[isort]..multi
-000000e0: 5f6c 696e 655f 6f75 7470 7574 203d 2033  _line_output = 3
-000000f0: 0d0a 696e 636c 7564 655f 7472 6169 6c69  ..include_traili
-00000100: 6e67 5f63 6f6d 6d61 203d 2054 7275 650d  ng_comma = True.
-00000110: 0a66 6f72 6365 5f67 7269 645f 7772 6170  .force_grid_wrap
-00000120: 203d 2030 0d0a 7573 655f 7061 7265 6e74   = 0..use_parent
-00000130: 6865 7365 7320 3d20 5472 7565 0d0a 6b6e  heses = True..kn
-00000140: 6f77 6e5f 7468 6972 645f 7061 7274 7920  own_third_party 
-00000150: 3d20 6a69 6e6a 6132 0d0a 6b6e 6f77 6e5f  = jinja2..known_
-00000160: 6669 7273 745f 7061 7274 7920 3d20 6169  first_party = ai
-00000170: 6f68 7474 702c 6169 6f68 7474 705f 6a69  ohttp,aiohttp_ji
-00000180: 6e6a 6132 2c61 696f 7067 0d0a 0d0a 5b72  nja2,aiopg....[r
-00000190: 6570 6f72 745d 0d0a 6578 636c 7564 655f  eport]..exclude_
-000001a0: 6c69 6e65 7320 3d20 0d0a 0940 6162 632e  lines = ...@abc.
-000001b0: 6162 7374 7261 6374 6d65 7468 6f64 0d0a  abstractmethod..
-000001c0: 0940 6162 7374 7261 6374 6d65 7468 6f64  .@abstractmethod
-000001d0: 0d0a 0d0a 5b63 6f76 6572 6167 653a 7275  ....[coverage:ru
-000001e0: 6e5d 0d0a 6272 616e 6368 203d 2054 7275  n]..branch = Tru
-000001f0: 650d 0a73 6f75 7263 6520 3d20 6169 6f68  e..source = aioh
-00000200: 7474 702c 2074 6573 7473 0d0a 6f6d 6974  ttp, tests..omit
-00000210: 203d 2073 6974 652d 7061 636b 6167 6573   = site-packages
-00000220: 0d0a 0d0a 5b6d 7970 795d 0d0a 666f 6c6c  ....[mypy]..foll
-00000230: 6f77 5f69 6d70 6f72 7473 203d 2073 696c  ow_imports = sil
-00000240: 656e 740d 0a73 7472 6963 745f 6f70 7469  ent..strict_opti
-00000250: 6f6e 616c 203d 2054 7275 650d 0a77 6172  onal = True..war
-00000260: 6e5f 7265 6475 6e64 616e 745f 6361 7374  n_redundant_cast
-00000270: 7320 3d20 5472 7565 0d0a 6368 6563 6b5f  s = True..check_
-00000280: 756e 7479 7065 645f 6465 6673 203d 2054  untyped_defs = T
-00000290: 7275 650d 0a64 6973 616c 6c6f 775f 616e  rue..disallow_an
-000002a0: 795f 6765 6e65 7269 6373 203d 2054 7275  y_generics = Tru
-000002b0: 650d 0a64 6973 616c 6c6f 775f 756e 7479  e..disallow_unty
-000002c0: 7065 645f 6465 6673 203d 2054 7275 650d  ped_defs = True.
-000002d0: 0a77 6172 6e5f 756e 7573 6564 5f69 676e  .warn_unused_ign
-000002e0: 6f72 6573 203d 2054 7275 650d 0a0d 0a5b  ores = True....[
-000002f0: 6d79 7079 2d70 7974 6573 745d 0d0a 6967  mypy-pytest]..ig
-00000300: 6e6f 7265 5f6d 6973 7369 6e67 5f69 6d70  nore_missing_imp
-00000310: 6f72 7473 203d 2074 7275 650d 0a0d 0a5b  orts = true....[
-00000320: 6d79 7079 2d75 766c 6f6f 705d 0d0a 6967  mypy-uvloop]..ig
-00000330: 6e6f 7265 5f6d 6973 7369 6e67 5f69 6d70  nore_missing_imp
-00000340: 6f72 7473 203d 2074 7275 650d 0a0d 0a5b  orts = true....[
-00000350: 6d79 7079 2d74 6f6b 696f 5d0d 0a69 676e  mypy-tokio]..ign
-00000360: 6f72 655f 6d69 7373 696e 675f 696d 706f  ore_missing_impo
-00000370: 7274 7320 3d20 7472 7565 0d0a 0d0a 5b6d  rts = true....[m
-00000380: 7970 792d 6173 796e 635f 6765 6e65 7261  ypy-async_genera
-00000390: 746f 725d 0d0a 6967 6e6f 7265 5f6d 6973  tor]..ignore_mis
-000003a0: 7369 6e67 5f69 6d70 6f72 7473 203d 2074  sing_imports = t
-000003b0: 7275 650d 0a0d 0a5b 6d79 7079 2d61 696f  rue....[mypy-aio
-000003c0: 646e 735d 0d0a 6967 6e6f 7265 5f6d 6973  dns]..ignore_mis
-000003d0: 7369 6e67 5f69 6d70 6f72 7473 203d 2074  sing_imports = t
-000003e0: 7275 650d 0a0d 0a5b 6d79 7079 2d67 756e  rue....[mypy-gun
-000003f0: 6963 6f72 6e2e 636f 6e66 6967 5d0d 0a69  icorn.config]..i
-00000400: 676e 6f72 655f 6d69 7373 696e 675f 696d  gnore_missing_im
-00000410: 706f 7274 7320 3d20 7472 7565 0d0a 0d0a  ports = true....
-00000420: 5b6d 7970 792d 6775 6e69 636f 726e 2e77  [mypy-gunicorn.w
-00000430: 6f72 6b65 7273 5d0d 0a69 676e 6f72 655f  orkers]..ignore_
+00000000: 5b61 6c69 6173 6573 5d0a 7465 7374 203d  [aliases].test =
+00000010: 2070 7974 6573 740a 0a5b 6d65 7461 6461   pytest..[metada
+00000020: 7461 5d0a 6c69 6365 6e73 655f 6669 6c65  ta].license_file
+00000030: 203d 204c 4943 454e 5345 2e74 7874 0a0a   = LICENSE.txt..
+00000040: 5b70 6570 385d 0a6d 6178 2d6c 696e 652d  [pep8].max-line-
+00000050: 6c65 6e67 7468 203d 2037 390a 0a5b 6561  length = 79..[ea
+00000060: 7379 5f69 6e73 7461 6c6c 5d0a 7a69 705f  sy_install].zip_
+00000070: 6f6b 203d 2066 616c 7365 0a0a 5b66 6c61  ok = false..[fla
+00000080: 6b65 385d 0a69 676e 6f72 6520 3d20 4e38  ke8].ignore = N8
+00000090: 3031 2c4e 3830 322c 4e38 3033 2c45 3232  01,N802,N803,E22
+000000a0: 362c 5735 3034 2c45 3235 322c 4533 3031  6,W504,E252,E301
+000000b0: 2c45 3330 322c 4537 3034 2c57 3530 332c  ,E302,E704,W503,
+000000c0: 5735 3034 2c46 3831 310a 6d61 782d 6c69  W504,F811.max-li
+000000d0: 6e65 2d6c 656e 6774 6820 3d20 3739 0a0a  ne-length = 79..
+000000e0: 5b69 736f 7274 5d0a 6d75 6c74 695f 6c69  [isort].multi_li
+000000f0: 6e65 5f6f 7574 7075 7420 3d20 330a 696e  ne_output = 3.in
+00000100: 636c 7564 655f 7472 6169 6c69 6e67 5f63  clude_trailing_c
+00000110: 6f6d 6d61 203d 2054 7275 650a 666f 7263  omma = True.forc
+00000120: 655f 6772 6964 5f77 7261 7020 3d20 300a  e_grid_wrap = 0.
+00000130: 7573 655f 7061 7265 6e74 6865 7365 7320  use_parentheses 
+00000140: 3d20 5472 7565 0a6b 6e6f 776e 5f74 6869  = True.known_thi
+00000150: 7264 5f70 6172 7479 203d 206a 696e 6a61  rd_party = jinja
+00000160: 322c 7079 7465 7374 2c6d 756c 7469 6469  2,pytest,multidi
+00000170: 6374 2c79 6172 6c2c 6775 6e69 636f 726e  ct,yarl,gunicorn
+00000180: 2c66 7265 657a 6567 756e 0a6b 6e6f 776e  ,freezegun.known
+00000190: 5f66 6972 7374 5f70 6172 7479 203d 2061  _first_party = a
+000001a0: 696f 6874 7470 2c61 696f 6874 7470 5f6a  iohttp,aiohttp_j
+000001b0: 696e 6a61 322c 6169 6f70 670a 0a5b 7265  inja2,aiopg..[re
+000001c0: 706f 7274 5d0a 6578 636c 7564 655f 6c69  port].exclude_li
+000001d0: 6e65 7320 3d20 0a09 4061 6263 2e61 6273  nes = ..@abc.abs
+000001e0: 7472 6163 746d 6574 686f 640a 0940 6162  tractmethod..@ab
+000001f0: 7374 7261 6374 6d65 7468 6f64 0a0a 5b63  stractmethod..[c
+00000200: 6f76 6572 6167 653a 7275 6e5d 0a62 7261  overage:run].bra
+00000210: 6e63 6820 3d20 5472 7565 0a73 6f75 7263  nch = True.sourc
+00000220: 6520 3d20 6169 6f68 7474 702c 2074 6573  e = aiohttp, tes
+00000230: 7473 0a6f 6d69 7420 3d20 7369 7465 2d70  ts.omit = site-p
+00000240: 6163 6b61 6765 730a 0a5b 6d79 7079 5d0a  ackages..[mypy].
+00000250: 666f 6c6c 6f77 5f69 6d70 6f72 7473 203d  follow_imports =
+00000260: 2073 696c 656e 740a 7374 7269 6374 5f6f   silent.strict_o
+00000270: 7074 696f 6e61 6c20 3d20 5472 7565 0a77  ptional = True.w
+00000280: 6172 6e5f 7265 6475 6e64 616e 745f 6361  arn_redundant_ca
+00000290: 7374 7320 3d20 5472 7565 0a63 6865 636b  sts = True.check
+000002a0: 5f75 6e74 7970 6564 5f64 6566 7320 3d20  _untyped_defs = 
+000002b0: 5472 7565 0a64 6973 616c 6c6f 775f 616e  True.disallow_an
+000002c0: 795f 6765 6e65 7269 6373 203d 2054 7275  y_generics = Tru
+000002d0: 650a 6469 7361 6c6c 6f77 5f75 6e74 7970  e.disallow_untyp
+000002e0: 6564 5f64 6566 7320 3d20 5472 7565 0a77  ed_defs = True.w
+000002f0: 6172 6e5f 756e 7573 6564 5f69 676e 6f72  arn_unused_ignor
+00000300: 6573 203d 2054 7275 650a 0a5b 6d79 7079  es = True..[mypy
+00000310: 2d70 7974 6573 745d 0a69 676e 6f72 655f  -pytest].ignore_
+00000320: 6d69 7373 696e 675f 696d 706f 7274 7320  missing_imports 
+00000330: 3d20 7472 7565 0a0a 5b6d 7970 792d 7576  = true..[mypy-uv
+00000340: 6c6f 6f70 5d0a 6967 6e6f 7265 5f6d 6973  loop].ignore_mis
+00000350: 7369 6e67 5f69 6d70 6f72 7473 203d 2074  sing_imports = t
+00000360: 7275 650a 0a5b 6d79 7079 2d74 6f6b 696f  rue..[mypy-tokio
+00000370: 5d0a 6967 6e6f 7265 5f6d 6973 7369 6e67  ].ignore_missing
+00000380: 5f69 6d70 6f72 7473 203d 2074 7275 650a  _imports = true.
+00000390: 0a5b 6d79 7079 2d61 696f 646e 735d 0a69  .[mypy-aiodns].i
+000003a0: 676e 6f72 655f 6d69 7373 696e 675f 696d  gnore_missing_im
+000003b0: 706f 7274 7320 3d20 7472 7565 0a0a 5b6d  ports = true..[m
+000003c0: 7970 792d 6775 6e69 636f 726e 2e63 6f6e  ypy-gunicorn.con
+000003d0: 6669 675d 0a69 676e 6f72 655f 6d69 7373  fig].ignore_miss
+000003e0: 696e 675f 696d 706f 7274 7320 3d20 7472  ing_imports = tr
+000003f0: 7565 0a0a 5b6d 7970 792d 6775 6e69 636f  ue..[mypy-gunico
+00000400: 726e 2e77 6f72 6b65 7273 5d0a 6967 6e6f  rn.workers].igno
+00000410: 7265 5f6d 6973 7369 6e67 5f69 6d70 6f72  re_missing_impor
+00000420: 7473 203d 2074 7275 650a 0a5b 6d79 7079  ts = true..[mypy
+00000430: 2d62 726f 746c 695d 0a69 676e 6f72 655f  -brotli].ignore_
 00000440: 6d69 7373 696e 675f 696d 706f 7274 7320  missing_imports 
-00000450: 3d20 7472 7565 0d0a 0d0a 5b6d 7970 792d  = true....[mypy-
-00000460: 6272 6f74 6c69 5d0d 0a69 676e 6f72 655f  brotli]..ignore_
-00000470: 6d69 7373 696e 675f 696d 706f 7274 7320  missing_imports 
-00000480: 3d20 7472 7565 0d0a 0d0a 5b6d 7970 792d  = true....[mypy-
-00000490: 6368 6172 6465 745d 0d0a 6967 6e6f 7265  chardet]..ignore
-000004a0: 5f6d 6973 7369 6e67 5f69 6d70 6f72 7473  _missing_imports
-000004b0: 203d 2074 7275 650d 0a0d 0a5b 6d79 7079   = true....[mypy
-000004c0: 2d63 6368 6172 6465 745d 0d0a 6967 6e6f  -cchardet]..igno
-000004d0: 7265 5f6d 6973 7369 6e67 5f69 6d70 6f72  re_missing_impor
-000004e0: 7473 203d 2074 7275 650d 0a0d 0a5b 6d79  ts = true....[my
-000004f0: 7079 2d69 646e 615f 7373 6c5d 0d0a 6967  py-idna_ssl]..ig
-00000500: 6e6f 7265 5f6d 6973 7369 6e67 5f69 6d70  nore_missing_imp
-00000510: 6f72 7473 203d 2074 7275 650d 0a0d 0a5b  orts = true....[
-00000520: 6567 675f 696e 666f 5d0d 0a74 6167 5f62  egg_info]..tag_b
-00000530: 7569 6c64 203d 200d 0a74 6167 5f64 6174  uild = ..tag_dat
-00000540: 6520 3d20 300d 0a0d 0a                   e = 0....
+00000450: 3d20 7472 7565 0a0a 5b6d 7970 792d 6368  = true..[mypy-ch
+00000460: 6172 6465 745d 0a69 676e 6f72 655f 6d69  ardet].ignore_mi
+00000470: 7373 696e 675f 696d 706f 7274 7320 3d20  ssing_imports = 
+00000480: 7472 7565 0a0a 5b6d 7970 792d 6363 6861  true..[mypy-ccha
+00000490: 7264 6574 5d0a 6967 6e6f 7265 5f6d 6973  rdet].ignore_mis
+000004a0: 7369 6e67 5f69 6d70 6f72 7473 203d 2074  sing_imports = t
+000004b0: 7275 650a 0a5b 6d79 7079 2d69 646e 615f  rue..[mypy-idna_
+000004c0: 7373 6c5d 0a69 676e 6f72 655f 6d69 7373  ssl].ignore_miss
+000004d0: 696e 675f 696d 706f 7274 7320 3d20 7472  ing_imports = tr
+000004e0: 7565 0a0a 5b65 6767 5f69 6e66 6f5d 0a74  ue..[egg_info].t
+000004f0: 6167 5f62 7569 6c64 203d 200a 7461 675f  ag_build = .tag_
+00000500: 6461 7465 203d 2030 0a0a                 date = 0..
```

### Comparing `aiohttp-4.0.0a0/tests/aiohttp.jpg` & `aiohttp-4.0.0a1/tests/aiohttp.jpg`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/tests/aiohttp.png` & `aiohttp-4.0.0a1/tests/aiohttp.png`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/tests/autobahn/client.py` & `aiohttp-4.0.0a1/tests/autobahn/client.py`

 * *Files 3% similar despite different names*

```diff
@@ -14,19 +14,19 @@
     for i in range(1, num_tests + 1):
         print('running test case:', i)
         text_url = url + '/runCase?case=%d&agent=%s' % (i, name)
         ws = await aiohttp.ws_connect(text_url)
         while True:
             msg = await ws.receive()
 
-            if msg.type == aiohttp.WSMsgType.text:
+            if msg.type == aiohttp.WSMsgType.TEXT:
                 await ws.send_str(msg.data)
-            elif msg.type == aiohttp.WSMsgType.binary:
+            elif msg.type == aiohttp.WSMsgType.BINARY:
                 await ws.send_bytes(msg.data)
-            elif msg.type == aiohttp.WSMsgType.close:
+            elif msg.type == aiohttp.WSMsgType.CLOSE:
                 await ws.close()
                 break
             else:
                 break
 
     url = url + '/updateReports?agent=%s' % name
     ws = await aiohttp.ws_connect(url)
```

### Comparing `aiohttp-4.0.0a0/tests/autobahn/server.py` & `aiohttp-4.0.0a1/tests/autobahn/server.py`

 * *Files 3% similar despite different names*

```diff
@@ -13,19 +13,19 @@
         return web.HTTPBadRequest()
 
     await ws.prepare(request)
 
     while True:
         msg = await ws.receive()
 
-        if msg.type == web.WSMsgType.text:
+        if msg.type == web.WSMsgType.TEXT:
             await ws.send_str(msg.data)
-        elif msg.type == web.WSMsgType.binary:
+        elif msg.type == web.WSMsgType.BINARY:
             await ws.send_bytes(msg.data)
-        elif msg.type == web.WSMsgType.close:
+        elif msg.type == web.WSMsgType.CLOSE:
             await ws.close()
             break
         else:
             break
 
     return ws
```

### Comparing `aiohttp-4.0.0a0/tests/test_base_protocol.py` & `aiohttp-4.0.0a1/tests/test_base_protocol.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/tests/test_classbasedview.py` & `aiohttp-4.0.0a1/tests/test_classbasedview.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/tests/test_client_connection.py` & `aiohttp-4.0.0a1/tests/test_client_connection.py`

 * *Files 4% similar despite different names*

```diff
@@ -24,16 +24,14 @@
 @pytest.fixture
 def protocol():
     return mock.Mock(should_close=False)
 
 
 def test_ctor(connector, key, protocol, loop) -> None:
     conn = Connection(connector, key, protocol, loop)
-    with pytest.warns(DeprecationWarning):
-        assert conn.loop is loop
     assert conn.protocol is protocol
     conn.close()
 
 
 def test_callbacks_on_close(connector, key, protocol, loop) -> None:
     conn = Connection(connector, key, protocol, loop)
     notified = False
```

### Comparing `aiohttp-4.0.0a0/tests/test_client_functional.py` & `aiohttp-4.0.0a1/tests/test_client_functional.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 """HTTP client functional tests against aiohttp.web server"""
 
 import asyncio
+import datetime
 import http.cookies
 import io
 import json
 import pathlib
 import socket
 from unittest import mock
 
 import pytest
-from async_generator import async_generator, yield_
 from multidict import MultiDict
 
 import aiohttp
-from aiohttp import Fingerprint, ServerFingerprintMismatch, hdrs, web
+from aiohttp import Fingerprint, ServerFingerprintMismatch, hdrs, helpers, web
 from aiohttp.abc import AbstractResolver
 from aiohttp.client_exceptions import TooManyRedirects
 from aiohttp.test_utils import unused_port
 
 
 @pytest.fixture
 def here():
@@ -324,24 +324,22 @@
         await client.get('/')
     exc = cm.value
     assert exc.expected == bad_fingerprint
     assert exc.got == tls_certificate_fingerprint_sha256
 
 
 async def test_format_task_get(aiohttp_server) -> None:
-    loop = asyncio.get_event_loop()
-
     async def handler(request):
         return web.Response(body=b'OK')
 
     app = web.Application()
     app.router.add_route('GET', '/', handler)
     server = await aiohttp_server(app)
     client = aiohttp.ClientSession()
-    task = loop.create_task(client.get(server.make_url('/')))
+    task = helpers.create_task(client.get(server.make_url('/')))
     assert "{}".format(task).startswith("<Task pending")
     resp = await task
     resp.close()
     await client.close()
 
 
 async def test_str_params(aiohttp_client) -> None:
@@ -593,14 +591,64 @@
         connector=conn,
         timeout=aiohttp.ClientTimeout(sock_read=0.01))
 
     with pytest.raises(asyncio.TimeoutError):
         await client.get('/')
 
 
+async def test_read_timeout_between_chunks(aiohttp_client, mocker) -> None:
+    mocker.patch('aiohttp.helpers.ceil').side_effect = ceil
+
+    async def handler(request):
+        resp = aiohttp.web.StreamResponse()
+        await resp.prepare(request)
+        # write data 4 times, with pauses. Total time 0.4 seconds.
+        for _ in range(4):
+            await asyncio.sleep(0.1)
+            await resp.write(b'data\n')
+        return resp
+
+    app = web.Application()
+    app.add_routes([web.get('/', handler)])
+
+    # A timeout of 0.2 seconds should apply per read.
+    timeout = aiohttp.ClientTimeout(sock_read=0.2)
+    client = await aiohttp_client(app, timeout=timeout)
+
+    res = b''
+    async with await client.get('/') as resp:
+        res += await resp.read()
+
+    assert res == b'data\n' * 4
+
+
+async def test_read_timeout_on_reading_chunks(aiohttp_client, mocker) -> None:
+    mocker.patch('aiohttp.helpers.ceil').side_effect = ceil
+
+    async def handler(request):
+        resp = aiohttp.web.StreamResponse()
+        await resp.prepare(request)
+        await resp.write(b'data\n')
+        await asyncio.sleep(1)
+        await resp.write(b'data\n')
+        return resp
+
+    app = web.Application()
+    app.add_routes([web.get('/', handler)])
+
+    # A timeout of 0.2 seconds should apply per read.
+    timeout = aiohttp.ClientTimeout(sock_read=0.2)
+    client = await aiohttp_client(app, timeout=timeout)
+
+    async with await client.get('/') as resp:
+        assert (await resp.content.read(5)) == b'data\n'
+        with pytest.raises(asyncio.TimeoutError):
+            await resp.content.read()
+
+
 async def test_timeout_on_reading_data(aiohttp_client, mocker) -> None:
     loop = asyncio.get_event_loop()
 
     mocker.patch('aiohttp.helpers.ceil').side_effect = ceil
     fut = loop.create_future()
 
     async def handler(request):
@@ -1515,59 +1563,23 @@
     app = web.Application()
     app.router.add_post('/', handler)
     client = await aiohttp_client(app)
 
     with fname.open('rb') as f:
         data_size = len(f.read())
 
-    with pytest.warns(DeprecationWarning):
-        @aiohttp.streamer
-        async def stream(writer, fname):
-            with fname.open('rb') as f:
-                data = f.read(100)
-                while data:
-                    await writer.write(data)
-                    data = f.read(100)
-
-    resp = await client.post(
-        '/', data=stream(fname), headers={'Content-Length': str(data_size)})
-    assert 200 == resp.status
-    resp.close()
-
-
-async def test_POST_STREAM_DATA_no_params(aiohttp_client, fname) -> None:
-
-    async def handler(request):
-        assert request.content_type == 'application/octet-stream'
-        content = await request.read()
+    async def gen(fname):
         with fname.open('rb') as f:
-            expected = f.read()
-            assert request.content_length == len(expected)
-            assert content == expected
-
-        return web.Response()
-
-    app = web.Application()
-    app.router.add_post('/', handler)
-    client = await aiohttp_client(app)
-
-    with fname.open('rb') as f:
-        data_size = len(f.read())
-
-    with pytest.warns(DeprecationWarning):
-        @aiohttp.streamer
-        async def stream(writer):
-            with fname.open('rb') as f:
+            data = f.read(100)
+            while data:
+                yield data
                 data = f.read(100)
-                while data:
-                    await writer.write(data)
-                    data = f.read(100)
 
     resp = await client.post(
-        '/', data=stream, headers={'Content-Length': str(data_size)})
+        '/', data=gen(fname), headers={'Content-Length': str(data_size)})
     assert 200 == resp.status
     resp.close()
 
 
 async def test_json(aiohttp_client) -> None:
 
     async def handler(request):
@@ -1915,14 +1927,58 @@
 
     resp = await client.get(
         '/', cookies={'test4': '789', 'test5': rc})
     assert 200 == resp.status
     resp.close()
 
 
+async def test_cookies_redirect(aiohttp_client) -> None:
+
+    async def redirect1(request):
+        ret = web.Response(status=301, headers={'Location': '/redirect2'})
+        ret.set_cookie('c', '1')
+        return ret
+
+    async def redirect2(request):
+        ret = web.Response(status=301, headers={'Location': '/'})
+        ret.set_cookie('c', '2')
+        return ret
+
+    async def handler(request):
+        assert request.cookies.keys() == {'c'}
+        assert request.cookies['c'] == '2'
+        return web.Response()
+
+    app = web.Application()
+    app.router.add_get('/redirect1', redirect1)
+    app.router.add_get('/redirect2', redirect2)
+    app.router.add_get('/', handler)
+
+    client = await aiohttp_client(app)
+    resp = await client.get('/redirect1')
+    assert 200 == resp.status
+    resp.close()
+
+
+async def test_cookies_on_empty_session_jar(aiohttp_client) -> None:
+    async def handler(request):
+        assert 'custom-cookie' in request.cookies
+        assert request.cookies['custom-cookie'] == 'abc'
+        return web.Response()
+
+    app = web.Application()
+    app.router.add_get('/', handler)
+    client = await aiohttp_client(
+        app, cookies=None)
+
+    resp = await client.get('/', cookies={'custom-cookie': 'abc'})
+    assert 200 == resp.status
+    resp.close()
+
+
 async def test_morsel_with_attributes(aiohttp_client) -> None:
     # A comment from original test:
     #
     # No cookie attribute should pass here
     # they are only used as filters
     # whether to send particular cookie or not.
     # E.g. if cookie expires it just becomes thrown away.
@@ -1972,14 +2028,94 @@
         assert cookie_names == {'c1', 'c2'}
         resp.close()
 
         m_log.warning.assert_called_with('Can not load response cookies: %s',
                                          mock.ANY)
 
 
+async def test_set_cookies_expired(aiohttp_client) -> None:
+
+    async def handler(request):
+        ret = web.Response()
+        ret.set_cookie('c1', 'cookie1')
+        ret.set_cookie('c2', 'cookie2')
+        ret.headers.add('Set-Cookie',
+                        'c3=cookie3; '
+                        'HttpOnly; Path=/'
+                        " Expires=Tue, 1 Jan 1980 12:00:00 GMT; ")
+        return ret
+
+    app = web.Application()
+    app.router.add_get('/', handler)
+    client = await aiohttp_client(app)
+
+    resp = await client.get('/')
+    assert 200 == resp.status
+    cookie_names = {c.key for c in client.session.cookie_jar}
+    assert cookie_names == {'c1', 'c2'}
+    resp.close()
+
+
+async def test_set_cookies_max_age(aiohttp_client) -> None:
+
+    async def handler(request):
+        ret = web.Response()
+        ret.set_cookie('c1', 'cookie1')
+        ret.set_cookie('c2', 'cookie2')
+        ret.headers.add('Set-Cookie',
+                        'c3=cookie3; '
+                        'HttpOnly; Path=/'
+                        " Max-Age=1; ")
+        return ret
+
+    app = web.Application()
+    app.router.add_get('/', handler)
+    client = await aiohttp_client(app)
+
+    resp = await client.get('/')
+    assert 200 == resp.status
+    cookie_names = {c.key for c in client.session.cookie_jar}
+    assert cookie_names == {'c1', 'c2', 'c3'}
+    await asyncio.sleep(2)
+    cookie_names = {c.key for c in client.session.cookie_jar}
+    assert cookie_names == {'c1', 'c2'}
+    resp.close()
+
+
+async def test_set_cookies_max_age_overflow(aiohttp_client) -> None:
+
+    async def handler(request):
+        ret = web.Response()
+        ret.headers.add('Set-Cookie',
+                        'overflow=overflow; '
+                        'HttpOnly; Path=/'
+                        " Max-Age=" + str(overflow) + "; ")
+        return ret
+
+    overflow = int(datetime.datetime.max.replace(
+        tzinfo=datetime.timezone.utc).timestamp())
+    empty = None
+    try:
+        empty = (datetime.datetime.now(datetime.timezone.utc) +
+                 datetime.timedelta(seconds=overflow))
+    except OverflowError as ex:
+        assert isinstance(ex, OverflowError)
+    assert not isinstance(empty, datetime.datetime)
+    app = web.Application()
+    app.router.add_get('/', handler)
+    client = await aiohttp_client(app)
+
+    resp = await client.get('/')
+    assert 200 == resp.status
+    for cookie in client.session.cookie_jar:
+        if cookie.key == 'overflow':
+            assert int(cookie['max-age']) == int(overflow)
+    resp.close()
+
+
 async def test_request_conn_error() -> None:
     client = aiohttp.ClientSession()
     with pytest.raises(aiohttp.ClientConnectionError):
         await client.get('http://0.0.0.0:1')
     await client.close()
 
 
@@ -2062,60 +2198,47 @@
     client = await aiohttp_client(app)
 
     resp = await client.get('/redirect')
     data = await resp.read()
     assert data == body
 
 
-async def test_chunked_deprecated(aiohttp_client) -> None:
-
-    async def handler_redirect(request):
-        return web.Response(status=301)
-
-    app = web.Application()
-    app.router.add_route('GET', '/redirect', handler_redirect)
-    client = await aiohttp_client(app)
-
-    with pytest.warns(DeprecationWarning):
-        await client.post('/', chunked=1024)
-
-
 async def test_raise_for_status(aiohttp_client) -> None:
 
-    async def handler_redirect(request):
+    async def handler(request):
         raise web.HTTPBadRequest()
 
     app = web.Application()
-    app.router.add_route('GET', '/', handler_redirect)
+    app.router.add_route('GET', '/', handler)
     client = await aiohttp_client(app, raise_for_status=True)
 
     with pytest.raises(aiohttp.ClientResponseError):
         await client.get('/')
 
 
 async def test_raise_for_status_per_request(aiohttp_client) -> None:
 
-    async def handler_redirect(request):
+    async def handler(request):
         raise web.HTTPBadRequest()
 
     app = web.Application()
-    app.router.add_route('GET', '/', handler_redirect)
+    app.router.add_route('GET', '/', handler)
     client = await aiohttp_client(app)
 
     with pytest.raises(aiohttp.ClientResponseError):
         await client.get('/', raise_for_status=True)
 
 
 async def test_raise_for_status_disable_per_request(aiohttp_client) -> None:
 
-    async def handler_redirect(request):
+    async def handler(request):
         raise web.HTTPBadRequest()
 
     app = web.Application()
-    app.router.add_route('GET', '/', handler_redirect)
+    app.router.add_route('GET', '/', handler)
     client = await aiohttp_client(app, raise_for_status=True)
 
     resp = await client.get('/', raise_for_status=False)
     assert 400 == resp.status
     resp.close()
 
 
@@ -2154,14 +2277,64 @@
     url = server.make_url('/')
 
     with pytest.raises(aiohttp.ClientResponseError):
         async with aiohttp.request('GET', url, raise_for_status=True):
             assert False, "never executed"  # pragma: no cover
 
 
+async def test_session_raise_for_status_coro(aiohttp_client) -> None:
+
+    async def handle(request):
+        return web.Response(text='ok')
+
+    app = web.Application()
+    app.router.add_route('GET', '/', handle)
+
+    raise_for_status_called = 0
+
+    async def custom_r4s(response):
+        nonlocal raise_for_status_called
+        raise_for_status_called += 1
+        assert response.status == 200
+        assert response.request_info.method == 'GET'
+
+    client = await aiohttp_client(app, raise_for_status=custom_r4s)
+    await client.get('/')
+    assert raise_for_status_called == 1
+    await client.get('/', raise_for_status=True)
+    assert raise_for_status_called == 1  # custom_r4s not called again
+    await client.get('/', raise_for_status=False)
+    assert raise_for_status_called == 1  # custom_r4s not called again
+
+
+async def test_request_raise_for_status_coro(aiohttp_client) -> None:
+
+    async def handle(request):
+        return web.Response(text='ok')
+
+    app = web.Application()
+    app.router.add_route('GET', '/', handle)
+
+    raise_for_status_called = 0
+
+    async def custom_r4s(response):
+        nonlocal raise_for_status_called
+        raise_for_status_called += 1
+        assert response.status == 200
+        assert response.request_info.method == 'GET'
+
+    client = await aiohttp_client(app)
+    await client.get('/', raise_for_status=custom_r4s)
+    assert raise_for_status_called == 1
+    await client.get('/', raise_for_status=True)
+    assert raise_for_status_called == 1  # custom_r4s not called again
+    await client.get('/', raise_for_status=False)
+    assert raise_for_status_called == 1  # custom_r4s not called again
+
+
 async def test_invalid_idna() -> None:
     session = aiohttp.ClientSession()
     try:
         with pytest.raises(aiohttp.InvalidURL):
             await session.get('http://\u2061owhefopw.com')
     finally:
         await session.close()
@@ -2335,14 +2508,32 @@
     server = await aiohttp_server(app)
 
     async with aiohttp.request('GET', server.make_url('/')) as resp:
         await resp.read()
         assert resp.status == 200
 
 
+async def test_aiohttp_request_ctx_manager_close_sess_on_error(
+        ssl_ctx, aiohttp_server) -> None:
+    async def handler(request):
+        return web.Response()
+
+    app = web.Application()
+    app.router.add_get('/', handler)
+    server = await aiohttp_server(app, ssl=ssl_ctx)
+
+    cm = aiohttp.request('GET', server.make_url('/'))
+
+    with pytest.raises(aiohttp.ClientConnectionError):
+        async with cm:
+            pass
+
+    assert cm._session.closed
+
+
 async def test_aiohttp_request_ctx_manager_not_found() -> None:
 
     with pytest.raises(aiohttp.ClientConnectionError):
         async with aiohttp.request('GET', 'http://wrong-dns-name.com'):
             assert False, "never executed"  # pragma: no cover
 
 
@@ -2354,38 +2545,36 @@
     app.router.add_get('/', handler)
     server = await aiohttp_server(app)
 
     with pytest.raises(TypeError):
         await aiohttp.request('GET', server.make_url('/'))
 
 
-@asyncio.coroutine
-def test_yield_from_in_session_request(aiohttp_client) -> None:
+async def test_yield_from_in_session_request(aiohttp_client) -> None:
     # a test for backward compatibility with yield from syntax
     async def handler(request):
         return web.Response()
 
     app = web.Application()
     app.router.add_get('/', handler)
 
-    client = yield from aiohttp_client(app)
-    resp = yield from client.get('/')
+    client = await aiohttp_client(app)
+    resp = await client.get('/')
     assert resp.status == 200
 
 
-@asyncio.coroutine
-def test_close_context_manager(aiohttp_client) -> None:
+async def test_close_context_manager(aiohttp_client) -> None:
     # a test for backward compatibility with yield from syntax
     async def handler(request):
         return web.Response()
 
     app = web.Application()
     app.router.add_get('/', handler)
 
-    client = yield from aiohttp_client(app)
+    client = await aiohttp_client(app)
     ctx = client.get('/')
     ctx.close()
     assert not ctx._coro.cr_running
 
 
 async def test_session_auth(aiohttp_client) -> None:
     async def handler(request):
@@ -2668,18 +2857,17 @@
         return web.Response()
 
     app = web.Application()
     app.add_routes([web.post('/', handler)])
 
     client = await aiohttp_client(app)
 
-    @async_generator
     async def gen():
         for i in range(100):
-            await yield_(b'1234567890')
+            yield b'1234567890'
 
     resp = await client.post('/', data=gen())
     assert resp.status == 200
 
 
 async def test_read_from_closed_response(aiohttp_client) -> None:
     async def handler(request):
```

### Comparing `aiohttp-4.0.0a0/tests/test_client_proto.py` & `aiohttp-4.0.0a1/tests/test_client_proto.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/tests/test_client_request.py` & `aiohttp-4.0.0a1/tests/test_client_request.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,31 +1,24 @@
 # coding: utf-8
 
 import asyncio
 import hashlib
 import io
-import os.path
-import urllib.parse
+import pathlib
 import zlib
 from http.cookies import SimpleCookie
 from unittest import mock
 
 import pytest
-from async_generator import async_generator, yield_
 from multidict import CIMultiDict, CIMultiDictProxy, istr
 from yarl import URL
 
 import aiohttp
 from aiohttp import BaseConnector, hdrs, payload
-from aiohttp.client_reqrep import (
-    ClientRequest,
-    ClientResponse,
-    Fingerprint,
-    _merge_ssl_params,
-)
+from aiohttp.client_reqrep import ClientRequest, ClientResponse, Fingerprint
 from aiohttp.test_utils import make_mocked_coro
 
 
 @pytest.fixture
 def make_request(loop):
     request = None
 
@@ -200,14 +193,19 @@
 def test_host_port_nondefault_wss(make_request) -> None:
     req = make_request('get', 'wss://python.org:960/')
     assert req.host == 'python.org'
     assert req.port == 960
     assert req.is_ssl()
 
 
+def test_host_port_none_port(make_request) -> None:
+    req = make_request('get', 'unix://localhost/path')
+    assert req.headers['Host'] == 'localhost'
+
+
 def test_host_port_err(make_request) -> None:
     with pytest.raises(ValueError):
         make_request('get', 'http://python.org:123e/')
 
 
 def test_hostname_err(make_request) -> None:
     with pytest.raises(ValueError):
@@ -272,20 +270,14 @@
 
 
 def test_host_header_ipv6_with_port(make_request) -> None:
     req = make_request('get', 'http://[::2]:99')
     assert req.headers['HOST'] == '[::2]:99'
 
 
-def test_default_loop(loop) -> None:
-    asyncio.set_event_loop(loop)
-    req = ClientRequest('get', URL('http://python.org/'))
-    assert req.loop is loop
-
-
 def test_default_headers_useragent(make_request) -> None:
     req = make_request('get', 'http://python.org/')
 
     assert 'SERVER' not in req.headers
     assert 'USER-AGENT' in req.headers
 
 
@@ -453,40 +445,14 @@
     req = make_request('get', 'http://test.com/path',
                        headers={'cookie': 'cookie1=val1'},
                        cookies={'cookie2': 'val2'})
 
     assert 'cookie1=val1; cookie2=val2' == req.headers['COOKIE']
 
 
-def test_unicode_get1(make_request) -> None:
-    req = make_request('get', 'http://python.org',
-                       params={'foo': 'f\xf8\xf8'})
-    assert 'http://python.org/?foo=f%C3%B8%C3%B8' == str(req.url)
-
-
-def test_unicode_get2(make_request) -> None:
-    req = make_request('', 'http://python.org',
-                       params={'f\xf8\xf8': 'f\xf8\xf8'})
-
-    assert 'http://python.org/?f%C3%B8%C3%B8=f%C3%B8%C3%B8' == str(req.url)
-
-
-def test_unicode_get3(make_request) -> None:
-    req = make_request('', 'http://python.org', params={'foo': 'foo'})
-    assert 'http://python.org/?foo=foo' == str(req.url)
-
-
-def test_unicode_get4(make_request) -> None:
-    def join(*suffix):
-        return urllib.parse.urljoin('http://python.org/', '/'.join(suffix))
-
-    req = make_request('', join('\xf8'), params={'foo': 'foo'})
-    assert 'http://python.org/%C3%B8?foo=foo' == str(req.url)
-
-
 def test_query_multivalued_param(make_request) -> None:
     for meth in ClientRequest.ALL_METHODS:
         req = make_request(
             meth, 'http://python.org',
             params=(('test', 'foo'), ('test', 'baz')))
 
         assert str(req.url) == 'http://python.org/?test=foo&test=baz'
@@ -662,16 +628,16 @@
         req = ClientRequest(
             'post', URL('http://python.org/'),
             data={}, loop=loop)
         req.update_body_from_data.assert_called_once_with({})
     await req.close()
 
 
-async def test_pass_falsy_data_file(loop, tmpdir) -> None:
-    testfile = tmpdir.join('tmpfile').open('w+b')
+async def test_pass_falsy_data_file(loop, tmp_path) -> None:
+    testfile = (tmp_path / 'tmpfile').open('w+b')
     testfile.write(b'data')
     testfile.seek(0)
     skip = frozenset([hdrs.CONTENT_TYPE])
     req = ClientRequest(
         'post', URL('http://python.org/'),
         data=testfile,
         skip_auto_headers=skip,
@@ -796,23 +762,22 @@
     with pytest.raises(ValueError):
         ClientRequest(
             'post', URL('http://python.org/'),
             headers={'TRANSFER-ENCODING': 'chunked'}, chunked=True, loop=loop)
 
 
 async def test_file_upload_not_chunked(loop) -> None:
-    here = os.path.dirname(__file__)
-    fname = os.path.join(here, 'aiohttp.png')
-    with open(fname, 'rb') as f:
+    file_path = pathlib.Path(__file__).parent / 'aiohttp.png'
+    with file_path.open('rb') as f:
         req = ClientRequest(
             'post', URL('http://python.org/'),
             data=f,
             loop=loop)
         assert not req.chunked
-        assert req.headers['CONTENT-LENGTH'] == str(os.path.getsize(fname))
+        assert req.headers['CONTENT-LENGTH'] == str(file_path.stat().st_size)
         await req.close()
 
 
 async def test_precompressed_data_stays_intact(loop) -> None:
     data = zlib.compress(b'foobar')
     req = ClientRequest(
         'post', URL('http://python.org/'),
@@ -823,31 +788,29 @@
     assert not req.compress
     assert not req.chunked
     assert req.headers['CONTENT-ENCODING'] == 'deflate'
     await req.close()
 
 
 async def test_file_upload_not_chunked_seek(loop) -> None:
-    here = os.path.dirname(__file__)
-    fname = os.path.join(here, 'aiohttp.png')
-    with open(fname, 'rb') as f:
+    file_path = pathlib.Path(__file__).parent / 'aiohttp.png'
+    with file_path.open('rb') as f:
         f.seek(100)
         req = ClientRequest(
             'post', URL('http://python.org/'),
             data=f,
             loop=loop)
         assert req.headers['CONTENT-LENGTH'] == \
-            str(os.path.getsize(fname) - 100)
+            str(file_path.stat().st_size - 100)
         await req.close()
 
 
 async def test_file_upload_force_chunked(loop) -> None:
-    here = os.path.dirname(__file__)
-    fname = os.path.join(here, 'aiohttp.png')
-    with open(fname, 'rb') as f:
+    file_path = pathlib.Path(__file__).parent / 'aiohttp.png'
+    with file_path.open('rb') as f:
         req = ClientRequest(
             'post', URL('http://python.org/'),
             data=f,
             chunked=True,
             loop=loop)
         assert req.chunked
         assert 'CONTENT-LENGTH' not in req.headers
@@ -871,39 +834,17 @@
     assert '100-continue' == req.headers['EXPECT']
     assert req._continue is not None
     req.terminate()
     resp.close()
 
 
 async def test_data_stream(loop, buf, conn) -> None:
-    @async_generator
     async def gen():
-        await yield_(b'binary data')
-        await yield_(b' result')
-
-    req = ClientRequest(
-        'POST', URL('http://python.org/'), data=gen(), loop=loop)
-    assert req.chunked
-    assert req.headers['TRANSFER-ENCODING'] == 'chunked'
-
-    resp = await req.send(conn)
-    assert asyncio.isfuture(req._writer)
-    await resp.wait_for_close()
-    assert req._writer is None
-    assert buf.split(b'\r\n\r\n', 1)[1] == \
-        b'b\r\nbinary data\r\n7\r\n result\r\n0\r\n\r\n'
-    await req.close()
-
-
-async def test_data_stream_deprecated(loop, buf, conn) -> None:
-    with pytest.warns(DeprecationWarning):
-        @aiohttp.streamer
-        async def gen(writer):
-            await writer.write(b'binary data')
-            await writer.write(b' result')
+        yield b'binary data'
+        yield b' result'
 
     req = ClientRequest(
         'POST', URL('http://python.org/'), data=gen(), loop=loop)
     assert req.chunked
     assert req.headers['TRANSFER-ENCODING'] == 'chunked'
 
     resp = await req.send(conn)
@@ -932,108 +873,51 @@
         b'2\r\n' + b'*' * 2 + b'\r\n0\r\n\r\n'
     await req.close()
 
 
 async def test_data_stream_exc(loop, conn) -> None:
     fut = loop.create_future()
 
-    @async_generator
     async def gen():
-        await yield_(b'binary data')
+        yield b'binary data'
         await fut
 
     req = ClientRequest(
         'POST', URL('http://python.org/'), data=gen(), loop=loop)
     assert req.chunked
     assert req.headers['TRANSFER-ENCODING'] == 'chunked'
 
     async def throw_exc():
-        await asyncio.sleep(0.01, loop=loop)
-        fut.set_exception(ValueError)
-
-    loop.create_task(throw_exc())
-
-    await req.send(conn)
-    await req._writer
-    # assert conn.close.called
-    assert conn.protocol.set_exception.called
-    await req.close()
-
-
-async def test_data_stream_exc_deprecated(loop, conn) -> None:
-    fut = loop.create_future()
-
-    with pytest.warns(DeprecationWarning):
-        @aiohttp.streamer
-        async def gen(writer):
-            await writer.write(b'binary data')
-            await fut
-
-    req = ClientRequest(
-        'POST', URL('http://python.org/'), data=gen(), loop=loop)
-    assert req.chunked
-    assert req.headers['TRANSFER-ENCODING'] == 'chunked'
-
-    async def throw_exc():
-        await asyncio.sleep(0.01, loop=loop)
+        await asyncio.sleep(0.01)
         fut.set_exception(ValueError)
 
     loop.create_task(throw_exc())
 
     await req.send(conn)
     await req._writer
     # assert conn.close.called
     assert conn.protocol.set_exception.called
     await req.close()
 
 
 async def test_data_stream_exc_chain(loop, conn) -> None:
     fut = loop.create_future()
 
-    @async_generator
     async def gen():
         await fut
+        return
+        yield
 
     req = ClientRequest('POST', URL('http://python.org/'),
                         data=gen(), loop=loop)
 
     inner_exc = ValueError()
 
     async def throw_exc():
-        await asyncio.sleep(0.01, loop=loop)
-        fut.set_exception(inner_exc)
-
-    loop.create_task(throw_exc())
-
-    await req.send(conn)
-    await req._writer
-    # assert connection.close.called
-    assert conn.protocol.set_exception.called
-    outer_exc = conn.protocol.set_exception.call_args[0][0]
-    assert isinstance(outer_exc, ValueError)
-    assert inner_exc is outer_exc
-    assert inner_exc is outer_exc
-    await req.close()
-
-
-async def test_data_stream_exc_chain_deprecated(loop, conn) -> None:
-    fut = loop.create_future()
-
-    with pytest.warns(DeprecationWarning):
-        @aiohttp.streamer
-        async def gen(writer):
-            await fut
-
-    req = ClientRequest('POST', URL('http://python.org/'),
-                        data=gen(), loop=loop)
-
-    inner_exc = ValueError()
-
-    async def throw_exc():
-        await asyncio.sleep(0.01, loop=loop)
+        await asyncio.sleep(0.01)
         fut.set_exception(inner_exc)
 
     loop.create_task(throw_exc())
 
     await req.send(conn)
     await req._writer
     # assert connection.close.called
@@ -1042,53 +926,25 @@
     assert isinstance(outer_exc, ValueError)
     assert inner_exc is outer_exc
     assert inner_exc is outer_exc
     await req.close()
 
 
 async def test_data_stream_continue(loop, buf, conn) -> None:
-    @async_generator
     async def gen():
-        await yield_(b'binary data')
-        await yield_(b' result')
+        yield b'binary data'
+        yield b' result'
 
     req = ClientRequest(
         'POST', URL('http://python.org/'), data=gen(),
         expect100=True, loop=loop)
     assert req.chunked
 
     async def coro():
-        await asyncio.sleep(0.0001, loop=loop)
-        req._continue.set_result(1)
-
-    loop.create_task(coro())
-
-    resp = await req.send(conn)
-    await req._writer
-    assert buf.split(b'\r\n\r\n', 1)[1] == \
-        b'b\r\nbinary data\r\n7\r\n result\r\n0\r\n\r\n'
-    await req.close()
-    resp.close()
-
-
-async def test_data_stream_continue_deprecated(loop, buf, conn) -> None:
-    with pytest.warns(DeprecationWarning):
-        @aiohttp.streamer
-        async def gen(writer):
-            await writer.write(b'binary data')
-            await writer.write(b' result')
-            await writer.write_eof()
-
-    req = ClientRequest(
-        'POST', URL('http://python.org/'), data=gen(),
-        expect100=True, loop=loop)
-    assert req.chunked
-
-    async def coro():
-        await asyncio.sleep(0.0001, loop=loop)
+        await asyncio.sleep(0.0001)
         req._continue.set_result(1)
 
     loop.create_task(coro())
 
     resp = await req.send(conn)
     await req._writer
     assert buf.split(b'\r\n\r\n', 1)[1] == \
@@ -1099,48 +955,31 @@
 
 async def test_data_continue(loop, buf, conn) -> None:
     req = ClientRequest(
         'POST', URL('http://python.org/'), data=b'data',
         expect100=True, loop=loop)
 
     async def coro():
-        await asyncio.sleep(0.0001, loop=loop)
+        await asyncio.sleep(0.0001)
         req._continue.set_result(1)
 
     loop.create_task(coro())
 
     resp = await req.send(conn)
 
     await req._writer
     assert buf.split(b'\r\n\r\n', 1)[1] == b'data'
     await req.close()
     resp.close()
 
 
 async def test_close(loop, buf, conn) -> None:
-    @async_generator
     async def gen():
         await asyncio.sleep(0.00001)
-        await yield_(b'result')
-
-    req = ClientRequest(
-        'POST', URL('http://python.org/'), data=gen(), loop=loop)
-    resp = await req.send(conn)
-    await req.close()
-    assert buf.split(b'\r\n\r\n', 1)[1] == b'6\r\nresult\r\n0\r\n\r\n'
-    await req.close()
-    resp.close()
-
-
-async def test_close_deprecated(loop, buf, conn) -> None:
-    with pytest.warns(DeprecationWarning):
-        @aiohttp.streamer
-        async def gen(writer):
-            await asyncio.sleep(0.00001, loop=loop)
-            await writer.write(b'result')
+        yield b'result'
 
     req = ClientRequest(
         'POST', URL('http://python.org/'), data=gen(), loop=loop)
     resp = await req.send(conn)
     await req.close()
     assert buf.split(b'\r\n\r\n', 1)[1] == b'6\r\nresult\r\n0\r\n\r\n'
     await req.close()
@@ -1188,15 +1027,15 @@
 
 
 def test_terminate_with_closed_loop(loop, conn) -> None:
     req = resp = writer = None
 
     async def go():
         nonlocal req, resp, writer
-        req = ClientRequest('get', URL('http://python.org'))
+        req = ClientRequest('get', URL('http://python.org'), loop=loop)
         resp = await req.send(conn)
         assert req._writer is not None
         writer = req._writer = mock.Mock()
 
         await asyncio.sleep(0.05)
 
     loop.run_until_complete(go())
@@ -1212,15 +1051,15 @@
     req = ClientRequest('get', URL('http://python.org'), loop=loop)
     assert req._writer is None
 
     req.terminate()
     assert req._writer is None
 
 
-async def test_custom_req_rep(loop) -> None:
+async def test_custom_req_rep(loop, create_mocked_conn) -> None:
     conn = None
 
     class CustomResponse(ClientResponse):
 
         async def start(self, connection, read_until_eof=False):
             nonlocal conn
             conn = connection
@@ -1247,40 +1086,32 @@
             self.response = resp
             nonlocal called
             called = True
             return resp
 
     async def create_connection(req, traces, timeout):
         assert isinstance(req, CustomRequest)
-        return mock.Mock()
-    connector = BaseConnector(loop=loop)
+        return create_mocked_conn()
+    connector = BaseConnector()
     connector._create_connection = create_connection
 
     session = aiohttp.ClientSession(
         request_class=CustomRequest,
         response_class=CustomResponse,
-        connector=connector,
-        loop=loop)
+        connector=connector)
 
     resp = await session.request(
         'get', URL('http://example.com/path/to'))
     assert isinstance(resp, CustomResponse)
     assert called
     resp.close()
     await session.close()
     conn.close()
 
 
-def test_verify_ssl_false_with_ssl_context(loop, ssl_ctx) -> None:
-    with pytest.warns(DeprecationWarning):
-        with pytest.raises(ValueError):
-            _merge_ssl_params(None, verify_ssl=False,
-                              ssl_context=ssl_ctx, fingerprint=None)
-
-
 def test_bad_fingerprint(loop) -> None:
     with pytest.raises(ValueError):
         Fingerprint(b'invalid')
 
 
 def test_insecure_fingerprint_md5(loop) -> None:
     with pytest.raises(ValueError):
```

### Comparing `aiohttp-4.0.0a0/tests/test_client_response.py` & `aiohttp-4.0.0a1/tests/test_client_response.py`

 * *Files 0% similar despite different names*

```diff
@@ -154,27 +154,14 @@
                               loop=mock.Mock(),
                               session=mock.Mock())
     response.reason = '\u03bb'
     assert "<ClientResponse(http://fake-host.org/path) [None \\u03bb]>"\
         in repr(response)
 
 
-def test_url_obj_deprecated() -> None:
-    response = ClientResponse('get', URL('http://fake-host.org/'),
-                              request_info=mock.Mock(),
-                              writer=mock.Mock(),
-                              continue100=None,
-                              timer=TimerNoop(),
-                              traces=[],
-                              loop=mock.Mock(),
-                              session=mock.Mock())
-    with pytest.warns(DeprecationWarning):
-        response.url_obj
-
-
 async def test_read_and_release_connection(loop, session) -> None:
     response = ClientResponse('get', URL('http://def-cl-resp.org'),
                               request_info=mock.Mock(),
                               writer=mock.Mock(),
                               continue100=None,
                               timer=TimerNoop(),
                               traces=[],
@@ -665,14 +652,32 @@
     with pytest.raises(aiohttp.ClientResponseError) as cm:
         response.raise_for_status()
     assert str(cm.value.status) == '409'
     assert str(cm.value.message) == "CONFLICT"
     assert response.closed
 
 
+def test_raise_for_status_4xx_without_reason() -> None:
+    response = ClientResponse('get', URL('http://def-cl-resp.org'),
+                              request_info=mock.Mock(),
+                              writer=mock.Mock(),
+                              continue100=None,
+                              timer=TimerNoop(),
+                              traces=[],
+                              loop=mock.Mock(),
+                              session=mock.Mock())
+    response.status = 404
+    response.reason = ''
+    with pytest.raises(aiohttp.ClientResponseError) as cm:
+        response.raise_for_status()
+    assert str(cm.value.status) == '404'
+    assert str(cm.value.message) == ''
+    assert response.closed
+
+
 def test_resp_host() -> None:
     response = ClientResponse('get', URL('http://del-cl-resp.org'),
                               request_info=mock.Mock(),
                               writer=mock.Mock(),
                               continue100=None,
                               timer=TimerNoop(),
                               traces=[],
```

### Comparing `aiohttp-4.0.0a0/tests/test_client_session.py` & `aiohttp-4.0.0a1/tests/test_client_session.py`

 * *Files 4% similar despite different names*

```diff
@@ -12,35 +12,36 @@
 from yarl import URL
 
 import aiohttp
 from aiohttp import client, hdrs, web
 from aiohttp.client import ClientSession
 from aiohttp.client_reqrep import ClientRequest
 from aiohttp.connector import BaseConnector, TCPConnector
-from aiohttp.helpers import DEBUG, PY_36
+from aiohttp.helpers import PY_36
+from aiohttp.test_utils import make_mocked_coro
 
 
 @pytest.fixture
-def connector(loop):
+def connector(loop, create_mocked_conn):
     async def make_conn():
-        return BaseConnector(loop=loop)
+        return BaseConnector()
     conn = loop.run_until_complete(make_conn())
-    proto = mock.Mock()
+    proto = create_mocked_conn()
     conn._conns['a'] = [(proto, 123)]
     yield conn
     conn.close()
 
 
 @pytest.fixture
 def create_session(loop):
     session = None
 
     async def maker(*args, **kwargs):
         nonlocal session
-        session = ClientSession(*args, loop=loop, **kwargs)
+        session = ClientSession(*args, **kwargs)
         return session
     yield maker
     if session is not None:
         loop.run_until_complete(session.close())
 
 
 @pytest.fixture
@@ -120,15 +121,15 @@
     cookies = session.cookie_jar.filter_cookies()
     assert set(cookies) == {'c1', 'c2'}
     assert cookies['c1'].value == 'cookie1'
     assert cookies['c2'].value == 'cookie2'
 
 
 async def test_merge_headers(create_session) -> None:
-        # Check incoming simple dict
+    # Check incoming simple dict
     session = await create_session(headers={"h1": "header1",
                                             "h2": "header2"})
     headers = session._prepare_headers({"h1": "h1"})
 
     assert isinstance(headers, CIMultiDict)
     assert headers == {"h1": "h1", "h2": "header2"}
 
@@ -160,96 +161,118 @@
     assert isinstance(headers, CIMultiDict)
     assert list(sorted(headers.items())) == [("h1", "v1"),
                                              ("h1", "v2"),
                                              ("h2", "header2")]
 
 
 def test_http_GET(session, params) -> None:
-    with mock.patch("aiohttp.client.ClientSession._request") as patched:
+    # Python 3.8 will auto use mock.AsyncMock, it has different behavior
+    with mock.patch(
+        "aiohttp.client.ClientSession._request",
+        new_callable=mock.MagicMock
+    ) as patched:
         session.get("http://test.example.com",
                     params={"x": 1},
                     **params)
     assert patched.called, "`ClientSession._request` not called"
     assert list(patched.call_args) == [("GET", "http://test.example.com",),
                                        dict(
                                            params={"x": 1},
                                            allow_redirects=True,
                                            **params)]
 
 
 def test_http_OPTIONS(session, params) -> None:
-    with mock.patch("aiohttp.client.ClientSession._request") as patched:
+    with mock.patch(
+        "aiohttp.client.ClientSession._request",
+        new_callable=mock.MagicMock
+    ) as patched:
         session.options("http://opt.example.com",
                         params={"x": 2},
                         **params)
     assert patched.called, "`ClientSession._request` not called"
     assert list(patched.call_args) == [("OPTIONS", "http://opt.example.com",),
                                        dict(
                                            params={"x": 2},
                                            allow_redirects=True,
                                            **params)]
 
 
 def test_http_HEAD(session, params) -> None:
-    with mock.patch("aiohttp.client.ClientSession._request") as patched:
+    with mock.patch(
+        "aiohttp.client.ClientSession._request",
+        new_callable=mock.MagicMock
+    ) as patched:
         session.head("http://head.example.com",
                      params={"x": 2},
                      **params)
     assert patched.called, "`ClientSession._request` not called"
     assert list(patched.call_args) == [("HEAD", "http://head.example.com",),
                                        dict(
                                            params={"x": 2},
                                            allow_redirects=False,
                                            **params)]
 
 
 def test_http_POST(session, params) -> None:
-    with mock.patch("aiohttp.client.ClientSession._request") as patched:
+    with mock.patch(
+        "aiohttp.client.ClientSession._request",
+        new_callable=mock.MagicMock
+    ) as patched:
         session.post("http://post.example.com",
                      params={"x": 2},
                      data="Some_data",
                      **params)
     assert patched.called, "`ClientSession._request` not called"
     assert list(patched.call_args) == [("POST", "http://post.example.com",),
                                        dict(
                                            params={"x": 2},
                                            data="Some_data",
                                            **params)]
 
 
 def test_http_PUT(session, params) -> None:
-    with mock.patch("aiohttp.client.ClientSession._request") as patched:
+    with mock.patch(
+        "aiohttp.client.ClientSession._request",
+        new_callable=mock.MagicMock
+    ) as patched:
         session.put("http://put.example.com",
                     params={"x": 2},
                     data="Some_data",
                     **params)
     assert patched.called, "`ClientSession._request` not called"
     assert list(patched.call_args) == [("PUT", "http://put.example.com",),
                                        dict(
                                            params={"x": 2},
                                            data="Some_data",
                                            **params)]
 
 
 def test_http_PATCH(session, params) -> None:
-    with mock.patch("aiohttp.client.ClientSession._request") as patched:
+    with mock.patch(
+        "aiohttp.client.ClientSession._request",
+        new_callable=mock.MagicMock
+    ) as patched:
         session.patch("http://patch.example.com",
                       params={"x": 2},
                       data="Some_data",
                       **params)
     assert patched.called, "`ClientSession._request` not called"
     assert list(patched.call_args) == [("PATCH", "http://patch.example.com",),
                                        dict(
                                            params={"x": 2},
                                            data="Some_data",
                                            **params)]
 
 
 def test_http_DELETE(session, params) -> None:
-    with mock.patch("aiohttp.client.ClientSession._request") as patched:
+    with mock.patch(
+        "aiohttp.client.ClientSession._request",
+        new_callable=mock.MagicMock
+    ) as patched:
         session.delete("http://delete.example.com",
                        params={"x": 2},
                        **params)
     assert patched.called, "`ClientSession._request` not called"
     assert list(patched.call_args) == [("DELETE",
                                         "http://delete.example.com",),
                                        dict(
@@ -268,15 +291,15 @@
 async def test_closed(session) -> None:
     assert not session.closed
     await session.close()
     assert session.closed
 
 
 async def test_connector(create_session, loop, mocker) -> None:
-    connector = TCPConnector(loop=loop)
+    connector = TCPConnector()
     mocker.spy(connector, 'close')
     session = await create_session(connector=connector)
     assert session.connector is connector
 
     await session.close()
     assert connector.close.called
     connector.close()
@@ -299,15 +322,15 @@
         async def make_connector():
             return TCPConnector()
         connector = another_loop.run_until_complete(make_connector())
 
         stack.enter_context(contextlib.closing(connector))
         with pytest.raises(RuntimeError) as ctx:
             async def make_sess():
-                return ClientSession(connector=connector, loop=loop)
+                return ClientSession(connector=connector)
             loop.run_until_complete(make_sess())
         assert re.match("Session and connector have to use same event loop",
                         str(ctx.value))
 
 
 def test_detach(session) -> None:
     conn = session.connector
@@ -323,18 +346,18 @@
 
 async def test_request_closed_session(session) -> None:
     await session.close()
     with pytest.raises(RuntimeError):
         await session.request('get', '/')
 
 
-def test_close_flag_for_closed_connector(session) -> None:
+async def test_close_flag_for_closed_connector(session) -> None:
     conn = session.connector
     assert not session.closed
-    conn.close()
+    await conn.close()
     assert session.closed
 
 
 async def test_double_close(connector, create_session) -> None:
     session = await create_session(connector=connector)
 
     await session.close()
@@ -343,15 +366,15 @@
     assert session.closed
     assert connector.closed
 
 
 async def test_del(connector, loop) -> None:
     loop.set_debug(False)
     # N.B. don't use session fixture, it stores extra reference internally
-    session = ClientSession(connector=connector, loop=loop)
+    session = ClientSession(connector=connector)
     logs = []
     loop.set_exception_handler(lambda loop, ctx: logs.append(ctx))
 
     with pytest.warns(ResourceWarning):
         del session
         gc.collect()
 
@@ -360,66 +383,58 @@
                 'message': 'Unclosed client session'}
     assert logs[0] == expected
 
 
 async def test_del_debug(connector, loop) -> None:
     loop.set_debug(True)
     # N.B. don't use session fixture, it stores extra reference internally
-    session = ClientSession(connector=connector, loop=loop)
+    session = ClientSession(connector=connector)
     logs = []
     loop.set_exception_handler(lambda loop, ctx: logs.append(ctx))
 
     with pytest.warns(ResourceWarning):
         del session
         gc.collect()
 
     assert len(logs) == 1
     expected = {'client_session': mock.ANY,
                 'message': 'Unclosed client session',
                 'source_traceback': mock.ANY}
     assert logs[0] == expected
 
 
-async def test_context_manager(connector, loop) -> None:
-    with pytest.raises(TypeError):
-        with ClientSession(loop=loop, connector=connector) as session:
-            pass
-
-        assert session.closed
-
-
 async def test_borrow_connector_loop(connector, create_session, loop) -> None:
-    session = ClientSession(connector=connector, loop=None)
+    session = ClientSession(connector=connector)
     try:
         assert session._loop, loop
     finally:
         await session.close()
 
 
-async def test_reraise_os_error(create_session) -> None:
+async def test_reraise_os_error(create_session, create_mocked_conn) -> None:
     err = OSError(1, "permission error")
     req = mock.Mock()
     req_factory = mock.Mock(return_value=req)
     req.send = mock.Mock(side_effect=err)
     session = await create_session(request_class=req_factory)
 
     async def create_connection(req, traces, timeout):
         # return self.transport, self.protocol
-        return mock.Mock()
+        return create_mocked_conn()
     session._connector._create_connection = create_connection
     session._connector._release = mock.Mock()
 
     with pytest.raises(aiohttp.ClientOSError) as ctx:
         await session.request('get', 'http://example.com')
     e = ctx.value
     assert e.errno == err.errno
     assert e.strerror == err.strerror
 
 
-async def test_close_conn_on_error(create_session) -> None:
+async def test_close_conn_on_error(create_session, create_mocked_conn) -> None:
     class UnexpectedException(BaseException):
         pass
 
     err = UnexpectedException("permission error")
     req = mock.Mock()
     req_factory = mock.Mock(return_value=req)
     req.send = mock.Mock(side_effect=err)
@@ -431,15 +446,15 @@
     async def connect(req, traces, timeout):
         conn = await original_connect(req, traces, timeout)
         connections.append(conn)
         return conn
 
     async def create_connection(req, traces, timeout):
         # return self.transport, self.protocol
-        conn = mock.Mock()
+        conn = create_mocked_conn()
         return conn
 
     session._connector.connect = connect
     session._connector._create_connection = create_connection
     session._connector._release = mock.Mock()
 
     with pytest.raises(UnexpectedException):
@@ -490,27 +505,23 @@
     resp_cookies = jar.update_cookies.call_args[0][0]
     assert isinstance(resp_cookies, SimpleCookie)
     assert "response" in resp_cookies
     assert resp_cookies["response"].value == "resp_value"
 
 
 async def test_session_default_version(loop) -> None:
-    session = aiohttp.ClientSession(loop=loop)
+    session = aiohttp.ClientSession()
     assert session.version == aiohttp.HttpVersion11
 
 
-async def test_session_loop(loop) -> None:
-    session = aiohttp.ClientSession(loop=loop)
-    with pytest.warns(DeprecationWarning):
-        assert session.loop is loop
-    await session.close()
-
-
 def test_proxy_str(session, params) -> None:
-    with mock.patch("aiohttp.client.ClientSession._request") as patched:
+    with mock.patch(
+        "aiohttp.client.ClientSession._request",
+        new_callable=mock.MagicMock
+    ) as patched:
         session.get("http://test.example.com",
                     proxy='http://proxy.com',
                     **params)
     assert patched.called, "`ClientSession._request` not called"
     assert list(patched.call_args) == [("GET", "http://test.example.com",),
                                        dict(
                                            allow_redirects=True,
@@ -526,17 +537,17 @@
     app.router.add_post('/', handler)
 
     trace_config_ctx = mock.Mock()
     trace_request_ctx = {}
     body = 'This is request body'
     gathered_req_body = BytesIO()
     gathered_res_body = BytesIO()
-    on_request_start = mock.Mock(side_effect=asyncio.coroutine(mock.Mock()))
-    on_request_redirect = mock.Mock(side_effect=asyncio.coroutine(mock.Mock()))
-    on_request_end = mock.Mock(side_effect=asyncio.coroutine(mock.Mock()))
+    on_request_start = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))
+    on_request_redirect = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))
+    on_request_end = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))
 
     async def on_request_chunk_sent(session, context, params):
         gathered_req_body.write(params.chunk)
 
     async def on_response_chunk_received(session, context, params):
         gathered_res_body.write(params.chunk)
 
@@ -579,31 +590,30 @@
         assert not on_request_redirect.called
         assert gathered_req_body.getvalue() == body.encode('utf8')
         assert gathered_res_body.getvalue() == json.dumps(
             {'ok': True}).encode('utf8')
 
 
 async def test_request_tracing_exception(loop) -> None:
-    on_request_end = mock.Mock(side_effect=asyncio.coroutine(mock.Mock()))
+    on_request_end = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))
     on_request_exception = mock.Mock(
-        side_effect=asyncio.coroutine(mock.Mock())
+        side_effect=make_mocked_coro(mock.Mock())
     )
 
     trace_config = aiohttp.TraceConfig()
     trace_config.on_request_end.append(on_request_end)
     trace_config.on_request_exception.append(on_request_exception)
 
     with mock.patch("aiohttp.client.TCPConnector.connect") as connect_patched:
         error = Exception()
         f = loop.create_future()
         f.set_exception(error)
         connect_patched.return_value = f
 
         session = aiohttp.ClientSession(
-            loop=loop,
             trace_configs=[trace_config]
         )
 
         try:
             await session.get('http://example.com')
         except Exception:
             pass
@@ -654,58 +664,31 @@
     await session.get('/')
     assert MyClientRequest.headers['foo'] == 'bar'
 
 
 @pytest.mark.skipif(not PY_36,
                     reason="Python 3.6+ required")
 def test_client_session_inheritance() -> None:
-    with pytest.warns(DeprecationWarning):
+    with pytest.raises(TypeError):
         class A(ClientSession):
             pass
 
 
-@pytest.mark.skipif(not DEBUG,
-                    reason="The check is applied in DEBUG mode only")
-async def test_client_session_custom_attr(loop) -> None:
-    session = ClientSession(loop=loop)
-    with pytest.warns(DeprecationWarning):
+async def test_client_session_custom_attr() -> None:
+    session = ClientSession()
+    with pytest.raises(AttributeError):
         session.custom = None
 
 
 async def test_client_session_timeout_args(loop) -> None:
-    session1 = ClientSession(loop=loop)
+    session1 = ClientSession()
     assert session1._timeout == client.DEFAULT_TIMEOUT
 
-    with pytest.warns(DeprecationWarning):
-        session2 = ClientSession(loop=loop,
-                                 read_timeout=20*60,
-                                 conn_timeout=30*60)
-    assert session2._timeout == client.ClientTimeout(total=20*60,
-                                                     connect=30*60)
-
-    with pytest.raises(ValueError):
-        ClientSession(loop=loop,
-                      timeout=client.ClientTimeout(total=10*60),
-                      read_timeout=20*60)
-
-    with pytest.raises(ValueError):
-        ClientSession(loop=loop,
-                      timeout=client.ClientTimeout(total=10 * 60),
-                      conn_timeout=30 * 60)
-
 
 async def test_requote_redirect_url_default() -> None:
     session = ClientSession()
     assert session.requote_redirect_url
 
 
 async def test_requote_redirect_url_default_disable() -> None:
     session = ClientSession(requote_redirect_url=False)
     assert not session.requote_redirect_url
-
-
-async def test_requote_redirect_setter() -> None:
-    session = ClientSession()
-    assert session.requote_redirect_url
-    with pytest.warns(DeprecationWarning):
-        session.requote_redirect_url = False
-    assert not session.requote_redirect_url
```

### Comparing `aiohttp-4.0.0a0/tests/test_client_ws.py` & `aiohttp-4.0.0a1/tests/test_client_ws.py`

 * *Files 4% similar despite different names*

```diff
@@ -5,15 +5,14 @@
 from unittest import mock
 
 import pytest
 
 import aiohttp
 from aiohttp import client, hdrs
 from aiohttp.http import WS_KEY
-from aiohttp.log import ws_logger
 from aiohttp.streams import EofStream
 from aiohttp.test_utils import make_mocked_coro
 
 
 @pytest.fixture
 def key_data():
     return os.urandom(16)
@@ -40,15 +39,15 @@
     }
     with mock.patch('aiohttp.client.os') as m_os:
         with mock.patch('aiohttp.client.ClientSession.request') as m_req:
             m_os.urandom.return_value = key_data
             m_req.return_value = loop.create_future()
             m_req.return_value.set_result(resp)
 
-            res = await aiohttp.ClientSession(loop=loop).ws_connect(
+            res = await aiohttp.ClientSession().ws_connect(
                 'http://test.org',
                 protocols=('t1', 't2', 'chat'))
 
     assert isinstance(res, client.ClientWebSocketResponse)
     assert res.protocol == 'chat'
     assert hdrs.ORIGIN not in m_req.call_args[1]["headers"]
 
@@ -60,15 +59,15 @@
         with mock.patch('aiohttp.client.ClientSession.request') as m_req:
             m_os.urandom.return_value = key_data
             m_req.return_value = loop.create_future()
             m_req.return_value.set_result(resp)
 
             origin = 'https://example.org/page.html'
             with pytest.raises(client.WSServerHandshakeError):
-                await aiohttp.ClientSession(loop=loop).ws_connect(
+                await aiohttp.ClientSession().ws_connect(
                     'http://test.org', origin=origin)
 
     assert hdrs.ORIGIN in m_req.call_args[1]["headers"]
     assert m_req.call_args[1]["headers"][hdrs.ORIGIN] == origin
 
 
 async def test_ws_connect_custom_response(loop, ws_key, key_data) -> None:
@@ -87,15 +86,15 @@
     with mock.patch('aiohttp.client.os') as m_os:
         with mock.patch('aiohttp.client.ClientSession.request') as m_req:
             m_os.urandom.return_value = key_data
             m_req.return_value = loop.create_future()
             m_req.return_value.set_result(resp)
 
             res = await aiohttp.ClientSession(
-                ws_response_class=CustomResponse, loop=loop).ws_connect(
+                ws_response_class=CustomResponse).ws_connect(
                     'http://test.org')
 
     assert res.read() == 'customized!'
 
 
 async def test_ws_connect_err_status(loop, ws_key, key_data) -> None:
     resp = mock.Mock()
@@ -108,15 +107,15 @@
     with mock.patch('aiohttp.client.os') as m_os:
         with mock.patch('aiohttp.client.ClientSession.request') as m_req:
             m_os.urandom.return_value = key_data
             m_req.return_value = loop.create_future()
             m_req.return_value.set_result(resp)
 
             with pytest.raises(client.WSServerHandshakeError) as ctx:
-                await aiohttp.ClientSession(loop=loop).ws_connect(
+                await aiohttp.ClientSession().ws_connect(
                     'http://test.org',
                     protocols=('t1', 't2', 'chat'))
 
     assert ctx.value.message == 'Invalid response status'
 
 
 async def test_ws_connect_err_upgrade(loop, ws_key, key_data) -> None:
@@ -130,15 +129,15 @@
     with mock.patch('aiohttp.client.os') as m_os:
         with mock.patch('aiohttp.client.ClientSession.request') as m_req:
             m_os.urandom.return_value = key_data
             m_req.return_value = loop.create_future()
             m_req.return_value.set_result(resp)
 
             with pytest.raises(client.WSServerHandshakeError) as ctx:
-                await aiohttp.ClientSession(loop=loop).ws_connect(
+                await aiohttp.ClientSession().ws_connect(
                     'http://test.org',
                     protocols=('t1', 't2', 'chat'))
 
     assert ctx.value.message == 'Invalid upgrade header'
 
 
 async def test_ws_connect_err_conn(loop, ws_key, key_data) -> None:
@@ -152,15 +151,15 @@
     with mock.patch('aiohttp.client.os') as m_os:
         with mock.patch('aiohttp.client.ClientSession.request') as m_req:
             m_os.urandom.return_value = key_data
             m_req.return_value = loop.create_future()
             m_req.return_value.set_result(resp)
 
             with pytest.raises(client.WSServerHandshakeError) as ctx:
-                await aiohttp.ClientSession(loop=loop).ws_connect(
+                await aiohttp.ClientSession().ws_connect(
                     'http://test.org',
                     protocols=('t1', 't2', 'chat'))
 
     assert ctx.value.message == 'Invalid connection header'
 
 
 async def test_ws_connect_err_challenge(loop, ws_key, key_data) -> None:
@@ -174,15 +173,15 @@
     with mock.patch('aiohttp.client.os') as m_os:
         with mock.patch('aiohttp.client.ClientSession.request') as m_req:
             m_os.urandom.return_value = key_data
             m_req.return_value = loop.create_future()
             m_req.return_value.set_result(resp)
 
             with pytest.raises(client.WSServerHandshakeError) as ctx:
-                await aiohttp.ClientSession(loop=loop).ws_connect(
+                await aiohttp.ClientSession().ws_connect(
                     'http://test.org',
                     protocols=('t1', 't2', 'chat'))
 
     assert ctx.value.message == 'Invalid challenge response'
 
 
 async def test_ws_connect_common_headers(ws_key, loop, key_data) -> None:
@@ -210,15 +209,15 @@
             }
             return resp
         with mock.patch('aiohttp.client.os') as m_os:
             with mock.patch('aiohttp.client.ClientSession.request',
                             side_effect=mock_get) as m_req:
                 m_os.urandom.return_value = key_data
 
-                res = await aiohttp.ClientSession(loop=loop).ws_connect(
+                res = await aiohttp.ClientSession().ws_connect(
                     'http://test.org',
                     protocols=('t1', 't2', 'chat'),
                     headers=headers)
 
         assert isinstance(res, client.ClientWebSocketResponse)
         assert res.protocol == 'chat'
         assert hdrs.ORIGIN not in m_req.call_args[1]["headers"]
@@ -243,15 +242,15 @@
                 m_os.urandom.return_value = key_data
                 m_req.return_value = loop.create_future()
                 m_req.return_value.set_result(resp)
                 writer = mock.Mock()
                 WebSocketWriter.return_value = writer
                 writer.close = make_mocked_coro()
 
-                session = aiohttp.ClientSession(loop=loop)
+                session = aiohttp.ClientSession()
                 resp = await session.ws_connect(
                     'http://test.org')
                 assert not resp.closed
 
                 resp._reader.feed_data(
                     aiohttp.WSMessage(aiohttp.WSMsgType.CLOSE, b'', b''), 0)
 
@@ -281,15 +280,15 @@
         with mock.patch('aiohttp.client.os') as m_os:
             with mock.patch('aiohttp.client.ClientSession.request') as m_req:
                 m_os.urandom.return_value = key_data
                 m_req.return_value = loop.create_future()
                 m_req.return_value.set_result(resp)
                 writer = WebSocketWriter.return_value = mock.Mock()
 
-                session = aiohttp.ClientSession(loop=loop)
+                session = aiohttp.ClientSession()
                 resp = await session.ws_connect('http://test.org')
                 assert not resp.closed
 
                 exc = EofStream()
                 resp._reader.set_exception(exc)
 
                 await resp.receive()
@@ -313,15 +312,15 @@
                 m_os.urandom.return_value = key_data
                 m_req.return_value = loop.create_future()
                 m_req.return_value.set_result(resp)
                 writer = mock.Mock()
                 WebSocketWriter.return_value = writer
                 writer.close = make_mocked_coro()
 
-                session = aiohttp.ClientSession(loop=loop)
+                session = aiohttp.ClientSession()
                 resp = await session.ws_connect('http://test.org')
                 assert not resp.closed
 
                 exc = ValueError()
                 resp._reader.set_exception(exc)
 
                 await resp.close()
@@ -343,15 +342,15 @@
         with mock.patch('aiohttp.client.os') as m_os:
             with mock.patch('aiohttp.client.ClientSession.request') as m_req:
                 m_os.urandom.return_value = key_data
                 m_req.return_value = loop.create_future()
                 m_req.return_value.set_result(resp)
                 writer = WebSocketWriter.return_value = mock.Mock()
 
-                resp = await aiohttp.ClientSession(loop=loop).ws_connect(
+                resp = await aiohttp.ClientSession().ws_connect(
                     'http://test.org')
                 assert not resp.closed
 
                 exc = ValueError()
                 writer.close.side_effect = exc
 
                 await resp.close()
@@ -360,42 +359,39 @@
 
                 resp._closed = False
                 writer.close.side_effect = asyncio.CancelledError()
                 with pytest.raises(asyncio.CancelledError):
                     await resp.close()
 
 
-async def test_send_data_after_close(ws_key, key_data, loop, mocker) -> None:
+async def test_send_data_after_close(ws_key, key_data, loop) -> None:
     resp = mock.Mock()
     resp.status = 101
     resp.headers = {
         hdrs.UPGRADE: hdrs.WEBSOCKET,
         hdrs.CONNECTION: hdrs.UPGRADE,
         hdrs.SEC_WEBSOCKET_ACCEPT: ws_key,
     }
     with mock.patch('aiohttp.client.os') as m_os:
         with mock.patch('aiohttp.client.ClientSession.request') as m_req:
             m_os.urandom.return_value = key_data
             m_req.return_value = loop.create_future()
             m_req.return_value.set_result(resp)
 
-            resp = await aiohttp.ClientSession(loop=loop).ws_connect(
+            resp = await aiohttp.ClientSession().ws_connect(
                 'http://test.org')
             resp._writer._closing = True
 
-            mocker.spy(ws_logger, 'warning')
-
             for meth, args in ((resp.ping, ()),
                                (resp.pong, ()),
                                (resp.send_str, ('s',)),
                                (resp.send_bytes, (b'b',)),
                                (resp.send_json, ({},))):
-                await meth(*args)
-                assert ws_logger.warning.called
-                ws_logger.warning.reset_mock()
+                with pytest.raises(ConnectionResetError):
+                    await meth(*args)
 
 
 async def test_send_data_type_errors(ws_key, key_data, loop) -> None:
     resp = mock.Mock()
     resp.status = 101
     resp.headers = {
         hdrs.UPGRADE: hdrs.WEBSOCKET,
@@ -406,15 +402,15 @@
         with mock.patch('aiohttp.client.os') as m_os:
             with mock.patch('aiohttp.client.ClientSession.request') as m_req:
                 m_os.urandom.return_value = key_data
                 m_req.return_value = loop.create_future()
                 m_req.return_value.set_result(resp)
                 WebSocketWriter.return_value = mock.Mock()
 
-                resp = await aiohttp.ClientSession(loop=loop).ws_connect(
+                resp = await aiohttp.ClientSession().ws_connect(
                     'http://test.org')
 
                 with pytest.raises(TypeError):
                     await resp.send_str(b's')
                 with pytest.raises(TypeError):
                     await resp.send_bytes('b')
                 with pytest.raises(TypeError):
@@ -436,15 +432,15 @@
                 m_req.return_value = loop.create_future()
                 m_req.return_value.set_result(hresp)
 
                 writer = mock.Mock()
                 WebSocketWriter.return_value = writer
                 writer.close = make_mocked_coro()
 
-                session = aiohttp.ClientSession(loop=loop)
+                session = aiohttp.ClientSession()
                 resp = await session.ws_connect('http://test.org')
 
                 exc = ValueError()
                 resp._reader.set_exception(exc)
 
                 msg = await resp.receive()
                 assert msg.type == aiohttp.WSMsgType.ERROR
@@ -474,15 +470,15 @@
     with mock.patch('aiohttp.client.os') as m_os:
         with mock.patch('aiohttp.client.ClientSession.request') as m_req:
             m_os.urandom.return_value = key_data
             m_req.return_value = loop.create_future()
             m_req.return_value.set_result(resp)
 
             with pytest.raises(client.WSServerHandshakeError):
-                await aiohttp.ClientSession(loop=loop).ws_connect(
+                await aiohttp.ClientSession().ws_connect(
                     'http://test.org',
                     protocols=('t1', 't2', 'chat'))
             resp.close.assert_called_with()
 
 
 async def test_ws_connect_non_overlapped_protocols(ws_key,
                                                    loop, key_data) -> None:
@@ -496,15 +492,15 @@
     }
     with mock.patch('aiohttp.client.os') as m_os:
         with mock.patch('aiohttp.client.ClientSession.request') as m_req:
             m_os.urandom.return_value = key_data
             m_req.return_value = loop.create_future()
             m_req.return_value.set_result(resp)
 
-            res = await aiohttp.ClientSession(loop=loop).ws_connect(
+            res = await aiohttp.ClientSession().ws_connect(
                 'http://test.org',
                 protocols=('t1', 't2', 'chat'))
 
     assert res.protocol is None
 
 
 async def test_ws_connect_non_overlapped_protocols_2(ws_key,
@@ -519,17 +515,17 @@
     }
     with mock.patch('aiohttp.client.os') as m_os:
         with mock.patch('aiohttp.client.ClientSession.request') as m_req:
             m_os.urandom.return_value = key_data
             m_req.return_value = loop.create_future()
             m_req.return_value.set_result(resp)
 
-            connector = aiohttp.TCPConnector(loop=loop, force_close=True)
+            connector = aiohttp.TCPConnector(force_close=True)
             res = await aiohttp.ClientSession(
-                connector=connector, loop=loop).ws_connect(
+                connector=connector).ws_connect(
                 'http://test.org',
                 protocols=('t1', 't2', 'chat'))
 
     assert res.protocol is None
     del res
 
 
@@ -544,15 +540,15 @@
     }
     with mock.patch('aiohttp.client.os') as m_os:
         with mock.patch('aiohttp.client.ClientSession.request') as m_req:
             m_os.urandom.return_value = key_data
             m_req.return_value = loop.create_future()
             m_req.return_value.set_result(resp)
 
-            res = await aiohttp.ClientSession(loop=loop).ws_connect(
+            res = await aiohttp.ClientSession().ws_connect(
                 'http://test.org', compress=15)
 
     assert res.compress == 15
     assert res.client_notakeover is False
 
 
 async def test_ws_connect_deflate_per_message(loop, ws_key, key_data) -> None:
@@ -569,15 +565,15 @@
             with mock.patch('aiohttp.client.ClientSession.request') as m_req:
                 m_os.urandom.return_value = key_data
                 m_req.return_value = loop.create_future()
                 m_req.return_value.set_result(resp)
                 writer = WebSocketWriter.return_value = mock.Mock()
                 send = writer.send = make_mocked_coro()
 
-                session = aiohttp.ClientSession(loop=loop)
+                session = aiohttp.ClientSession()
                 resp = await session.ws_connect('http://test.org')
 
                 await resp.send_str('string', compress=-1)
                 send.assert_called_with('string', binary=False, compress=-1)
 
                 await resp.send_bytes(b'bytes', compress=15)
                 send.assert_called_with(b'bytes', binary=True, compress=15)
@@ -599,15 +595,15 @@
     }
     with mock.patch('aiohttp.client.os') as m_os:
         with mock.patch('aiohttp.client.ClientSession.request') as m_req:
             m_os.urandom.return_value = key_data
             m_req.return_value = loop.create_future()
             m_req.return_value.set_result(resp)
 
-            res = await aiohttp.ClientSession(loop=loop).ws_connect(
+            res = await aiohttp.ClientSession().ws_connect(
                 'http://test.org', compress=15)
 
     assert res.compress == 0
     assert res.client_notakeover is False
 
 
 async def test_ws_connect_deflate_notakeover(loop, ws_key, key_data) -> None:
@@ -622,15 +618,15 @@
     }
     with mock.patch('aiohttp.client.os') as m_os:
         with mock.patch('aiohttp.client.ClientSession.request') as m_req:
             m_os.urandom.return_value = key_data
             m_req.return_value = loop.create_future()
             m_req.return_value.set_result(resp)
 
-            res = await aiohttp.ClientSession(loop=loop).ws_connect(
+            res = await aiohttp.ClientSession().ws_connect(
                 'http://test.org', compress=15)
 
     assert res.compress == 15
     assert res.client_notakeover is True
 
 
 async def test_ws_connect_deflate_client_wbits(loop, ws_key, key_data) -> None:
@@ -645,15 +641,15 @@
     }
     with mock.patch('aiohttp.client.os') as m_os:
         with mock.patch('aiohttp.client.ClientSession.request') as m_req:
             m_os.urandom.return_value = key_data
             m_req.return_value = loop.create_future()
             m_req.return_value.set_result(resp)
 
-            res = await aiohttp.ClientSession(loop=loop).ws_connect(
+            res = await aiohttp.ClientSession().ws_connect(
                 'http://test.org', compress=15)
 
     assert res.compress == 10
     assert res.client_notakeover is False
 
 
 async def test_ws_connect_deflate_client_wbits_bad(loop,
@@ -670,15 +666,15 @@
     with mock.patch('aiohttp.client.os') as m_os:
         with mock.patch('aiohttp.client.ClientSession.request') as m_req:
             m_os.urandom.return_value = key_data
             m_req.return_value = loop.create_future()
             m_req.return_value.set_result(resp)
 
             with pytest.raises(client.WSServerHandshakeError):
-                await aiohttp.ClientSession(loop=loop).ws_connect(
+                await aiohttp.ClientSession().ws_connect(
                     'http://test.org', compress=15)
 
 
 async def test_ws_connect_deflate_server_ext_bad(loop,
                                                  ws_key, key_data) -> None:
     resp = mock.Mock()
     resp.status = 101
@@ -691,9 +687,9 @@
     with mock.patch('aiohttp.client.os') as m_os:
         with mock.patch('aiohttp.client.ClientSession.request') as m_req:
             m_os.urandom.return_value = key_data
             m_req.return_value = loop.create_future()
             m_req.return_value.set_result(resp)
 
             with pytest.raises(client.WSServerHandshakeError):
-                await aiohttp.ClientSession(loop=loop).ws_connect(
+                await aiohttp.ClientSession().ws_connect(
                     'http://test.org', compress=15)
```

### Comparing `aiohttp-4.0.0a0/tests/test_client_ws_functional.py` & `aiohttp-4.0.0a1/tests/test_client_ws_functional.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 import asyncio
 
 import async_timeout
 import pytest
 
 import aiohttp
 from aiohttp import hdrs, web
+from aiohttp.client_ws import ClientWSTimeout
 
 
 @pytest.fixture
 def ceil(mocker):
     def ceil(val):
         return val
 
@@ -336,28 +337,60 @@
     assert not resp.closed
 
     await resp.close()
     await closed
     assert resp.closed
 
 
-async def test_close_timeout(aiohttp_client) -> None:
+async def test_close_timeout_sock_close_read(aiohttp_client) -> None:
 
     async def handler(request):
         ws = web.WebSocketResponse()
         await ws.prepare(request)
         await ws.receive_bytes()
         await ws.send_str('test')
         await asyncio.sleep(1)
         return ws
 
     app = web.Application()
     app.router.add_route('GET', '/', handler)
     client = await aiohttp_client(app)
-    resp = await client.ws_connect('/', timeout=0.2, autoclose=False)
+    timeout = ClientWSTimeout(ws_close=0.2)
+    resp = await client.ws_connect('/', timeout=timeout, autoclose=False)
+
+    await resp.send_bytes(b'ask')
+
+    msg = await resp.receive()
+    assert msg.data == 'test'
+    assert msg.type == aiohttp.WSMsgType.TEXT
+
+    msg = await resp.close()
+    assert resp.closed
+    assert isinstance(resp.exception(), asyncio.TimeoutError)
+
+
+async def test_close_timeout_deprecated(aiohttp_client) -> None:
+
+    async def handler(request):
+        ws = web.WebSocketResponse()
+        await ws.prepare(request)
+        await ws.receive_bytes()
+        await ws.send_str('test')
+        await asyncio.sleep(1)
+        return ws
+
+    app = web.Application()
+    app.router.add_route('GET', '/', handler)
+    client = await aiohttp_client(app)
+    with pytest.warns(DeprecationWarning,
+                      match="parameter 'timeout' of type 'float' "
+                            "is deprecated, please use "
+                            r"'timeout=ClientWSTimeout\(ws_close=...\)'"
+                      ):
+        resp = await client.ws_connect('/', timeout=0.2, autoclose=False)
 
     await resp.send_bytes(b'ask')
 
     msg = await resp.receive()
     assert msg.data == 'test'
     assert msg.type == aiohttp.WSMsgType.TEXT
 
@@ -450,15 +483,16 @@
     client = await aiohttp_client(app)
     resp = await client.ws_connect('/')
     await resp.send_str('ask')
 
     msg = await resp.receive()
     assert msg.type == aiohttp.WSMsgType.ERROR
     assert type(msg.data) is aiohttp.WebSocketError
-    assert msg.data.args[0] == 'Received frame with non-zero reserved bits'
+    assert msg.data.code == aiohttp.WSCloseCode.PROTOCOL_ERROR
+    assert str(msg.data) == 'Received frame with non-zero reserved bits'
     assert msg.extra is None
     await resp.close()
 
 
 async def test_recv_timeout(aiohttp_client) -> None:
 
     async def handler(request):
@@ -481,31 +515,59 @@
     with pytest.raises(asyncio.TimeoutError):
         with async_timeout.timeout(0.01):
             await resp.receive()
 
     await resp.close()
 
 
-async def test_receive_timeout(aiohttp_client) -> None:
+async def test_receive_timeout_sock_read(aiohttp_client) -> None:
 
     async def handler(request):
         ws = web.WebSocketResponse()
         await ws.prepare(request)
         await ws.receive()
         await ws.close()
         return ws
 
     app = web.Application()
     app.router.add_route('GET', '/', handler)
 
     client = await aiohttp_client(app)
-    resp = await client.ws_connect('/', receive_timeout=0.1)
+    receive_timeout = ClientWSTimeout(ws_receive=0.1)
+    resp = await client.ws_connect('/', timeout=receive_timeout)
 
     with pytest.raises(asyncio.TimeoutError):
-        await resp.receive(0.05)
+        await resp.receive(timeout=0.05)
+
+    await resp.close()
+
+
+async def test_receive_timeout_deprecation(aiohttp_client) -> None:
+
+    async def handler(request):
+        ws = web.WebSocketResponse()
+        await ws.prepare(request)
+        await ws.receive()
+        await ws.close()
+        return ws
+
+    app = web.Application()
+    app.router.add_route('GET', '/', handler)
+
+    client = await aiohttp_client(app)
+    with pytest.warns(
+        DeprecationWarning,
+        match="float parameter 'receive_timeout' "
+              "is deprecated, please use parameter "
+              r"'timeout=ClientWSTimeout\(ws_receive=...\)'"
+    ):
+        resp = await client.ws_connect('/', receive_timeout=0.1)
+
+    with pytest.raises(asyncio.TimeoutError):
+        await resp.receive(timeout=0.05)
 
     await resp.close()
 
 
 async def test_custom_receive_timeout(aiohttp_client) -> None:
 
     async def handler(request):
@@ -531,15 +593,15 @@
     ping_received = False
 
     async def handler(request):
         nonlocal ping_received
         ws = web.WebSocketResponse(autoping=False)
         await ws.prepare(request)
         msg = await ws.receive()
-        if msg.type == aiohttp.WSMsgType.ping:
+        if msg.type == aiohttp.WSMsgType.PING:
             ping_received = True
         await ws.close()
         return ws
 
     app = web.Application()
     app.router.add_route('GET', '/', handler)
 
@@ -556,15 +618,15 @@
     ping_received = False
 
     async def handler(request):
         nonlocal ping_received
         ws = web.WebSocketResponse(autoping=False)
         await ws.prepare(request)
         msg = await ws.receive()
-        if msg.type == aiohttp.WSMsgType.ping:
+        if msg.type == aiohttp.WSMsgType.PING:
             ping_received = True
         await ws.receive()
         return ws
 
     app = web.Application()
     app.router.add_route('GET', '/', handler)
```

### Comparing `aiohttp-4.0.0a0/tests/test_connector.py` & `aiohttp-4.0.0a1/tests/test_connector.py`

 * *Files 7% similar despite different names*

```diff
@@ -14,18 +14,20 @@
 import pytest
 from yarl import URL
 
 import aiohttp
 from aiohttp import client, web
 from aiohttp.client import ClientRequest, ClientTimeout
 from aiohttp.client_reqrep import ConnectionKey
-from aiohttp.connector import Connection, _DNSCacheTable
+from aiohttp.connector import Connection, TCPConnector, _DNSCacheTable
 from aiohttp.helpers import PY_37
+from aiohttp.locks import EventResultOrError
 from aiohttp.test_utils import make_mocked_coro, unused_port
 from aiohttp.tracing import Trace
+from conftest import needs_unix
 
 
 @pytest.fixture()
 def key():
     """Connection key"""
     return ConnectionKey('localhost', 80, False, None, None, None, None)
 
@@ -39,20 +41,14 @@
 @pytest.fixture
 def ssl_key():
     """Connection key"""
     return ConnectionKey('localhost', 80, True, None, None, None, None)
 
 
 @pytest.fixture
-def unix_sockname(shorttmpdir):
-    sock_path = shorttmpdir / 'socket.sock'
-    return str(sock_path)
-
-
-@pytest.fixture
 def unix_server(loop, unix_sockname):
     runners = []
 
     async def go(app):
         runner = web.AppRunner(app)
         runners.append(runner)
         await runner.setup()
@@ -61,14 +57,40 @@
 
     yield go
 
     for runner in runners:
         loop.run_until_complete(runner.cleanup())
 
 
+@pytest.fixture
+def named_pipe_server(proactor_loop, pipe_name):
+    runners = []
+
+    async def go(app):
+        runner = web.AppRunner(app)
+        runners.append(runner)
+        await runner.setup()
+        site = web.NamedPipeSite(runner, pipe_name)
+        await site.start()
+
+    yield go
+
+    for runner in runners:
+        proactor_loop.run_until_complete(runner.cleanup())
+
+
+def create_mocked_conn(conn_closing_result=None, **kwargs):
+    assert 'loop' not in kwargs
+    loop = asyncio.get_event_loop()
+    proto = mock.Mock(**kwargs)
+    proto.closed = loop.create_future()
+    proto.closed.set_result(conn_closing_result)
+    return proto
+
+
 def test_connection_del(loop) -> None:
     connector = mock.Mock()
     key = mock.Mock()
     protocol = mock.Mock()
     loop.set_debug(0)
     conn = Connection(connector, key, protocol, loop=loop)
     exc_handler = mock.Mock()
@@ -127,15 +149,15 @@
 
     assert not connector._release.called
     assert not exc_handler.called
 
 
 async def test_del(loop) -> None:
     conn = aiohttp.BaseConnector()
-    proto = mock.Mock(should_close=False)
+    proto = create_mocked_conn(loop, should_close=False)
     conn._release('a', proto)
     conns_impl = conn._conns
 
     exc_handler = mock.Mock()
     loop.set_exception_handler(exc_handler)
 
     with pytest.warns(ResourceWarning):
@@ -151,16 +173,16 @@
         msg['source_traceback'] = mock.ANY
     exc_handler.assert_called_with(loop, msg)
 
 
 @pytest.mark.xfail
 async def test_del_with_scheduled_cleanup(loop) -> None:
     loop.set_debug(True)
-    conn = aiohttp.BaseConnector(loop=loop, keepalive_timeout=0.01)
-    transp = mock.Mock()
+    conn = aiohttp.BaseConnector(keepalive_timeout=0.01)
+    transp = create_mocked_conn(loop)
     conn._conns['a'] = [(transp, 123)]
 
     conns_impl = conn._conns
     exc_handler = mock.Mock()
     loop.set_exception_handler(exc_handler)
 
     with pytest.warns(ResourceWarning):
@@ -181,15 +203,15 @@
 
 @pytest.mark.skipif(sys.implementation.name != 'cpython',
                     reason="CPython GC is required for the test")
 def test_del_with_closed_loop(loop) -> None:
     async def make_conn():
         return aiohttp.BaseConnector()
     conn = loop.run_until_complete(make_conn())
-    transp = mock.Mock()
+    transp = create_mocked_conn(loop)
     conn._conns['a'] = [(transp, 123)]
 
     conns_impl = conn._conns
     exc_handler = mock.Mock()
     loop.set_exception_handler(exc_handler)
     loop.close()
 
@@ -199,306 +221,296 @@
 
     assert not conns_impl
     assert not transp.close.called
     assert exc_handler.called
 
 
 async def test_del_empty_connector(loop) -> None:
-    conn = aiohttp.BaseConnector(loop=loop)
+    conn = aiohttp.BaseConnector()
 
     exc_handler = mock.Mock()
     loop.set_exception_handler(exc_handler)
 
     del conn
 
     assert not exc_handler.called
 
 
-async def test_create_conn(loop) -> None:
-    conn = aiohttp.BaseConnector(loop=loop)
+async def test_create_conn() -> None:
+    conn = aiohttp.BaseConnector()
     with pytest.raises(NotImplementedError):
         await conn._create_connection(object(), [], object())
 
 
-async def test_context_manager(loop) -> None:
-    conn = aiohttp.BaseConnector(loop=loop)
-
-    with pytest.warns(DeprecationWarning):
-        with conn as c:
-            assert conn is c
-
-    assert conn.closed
-
-
 async def test_async_context_manager(loop) -> None:
-    conn = aiohttp.BaseConnector(loop=loop)
+    conn = aiohttp.BaseConnector()
 
     async with conn as c:
         assert conn is c
 
     assert conn.closed
 
 
-async def test_close(loop) -> None:
-    proto = mock.Mock()
+async def test_close() -> None:
+    proto = create_mocked_conn()
 
-    conn = aiohttp.BaseConnector(loop=loop)
+    conn = aiohttp.BaseConnector()
     assert not conn.closed
     conn._conns[('host', 8080, False)] = [(proto, object())]
-    conn.close()
+    await conn.close()
 
     assert not conn._conns
     assert proto.close.called
     assert conn.closed
 
 
 async def test_get(loop) -> None:
-    conn = aiohttp.BaseConnector(loop=loop)
+    conn = aiohttp.BaseConnector()
     assert conn._get(1) is None
 
-    proto = mock.Mock()
+    proto = create_mocked_conn(loop)
     conn._conns[1] = [(proto, loop.time())]
     assert conn._get(1) == proto
-    conn.close()
+    await conn.close()
 
 
 async def test_get_expired(loop) -> None:
-    conn = aiohttp.BaseConnector(loop=loop)
+    conn = aiohttp.BaseConnector()
     key = ConnectionKey('localhost', 80, False, None, None, None, None)
     assert conn._get(key) is None
 
-    proto = mock.Mock()
+    proto = create_mocked_conn(loop)
     conn._conns[key] = [(proto, loop.time() - 1000)]
     assert conn._get(key) is None
     assert not conn._conns
-    conn.close()
+    await conn.close()
 
 
 async def test_get_expired_ssl(loop) -> None:
-    conn = aiohttp.BaseConnector(loop=loop, enable_cleanup_closed=True)
+    conn = aiohttp.BaseConnector(enable_cleanup_closed=True)
     key = ConnectionKey('localhost', 80, True, None, None, None, None)
     assert conn._get(key) is None
 
-    proto = mock.Mock()
+    proto = create_mocked_conn(loop)
     transport = proto.transport
     conn._conns[key] = [(proto, loop.time() - 1000)]
     assert conn._get(key) is None
     assert not conn._conns
     assert conn._cleanup_closed_transports == [transport]
-    conn.close()
+    await conn.close()
 
 
-async def test_release_acquired(loop, key) -> None:
-    proto = mock.Mock()
-    conn = aiohttp.BaseConnector(loop=loop, limit=5)
+async def test_release_acquired(key) -> None:
+    proto = create_mocked_conn()
+    conn = aiohttp.BaseConnector(limit=5)
     conn._release_waiter = mock.Mock()
 
     conn._acquired.add(proto)
     conn._acquired_per_host[key].add(proto)
     conn._release_acquired(key, proto)
     assert 0 == len(conn._acquired)
     assert 0 == len(conn._acquired_per_host)
     assert conn._release_waiter.called
 
     conn._release_acquired(key, proto)
     assert 0 == len(conn._acquired)
     assert 0 == len(conn._acquired_per_host)
 
-    conn.close()
+    await conn.close()
 
 
-async def test_release_acquired_closed(loop, key) -> None:
-    proto = mock.Mock()
-    conn = aiohttp.BaseConnector(loop=loop, limit=5)
+async def test_release_acquired_closed(key) -> None:
+    proto = create_mocked_conn()
+    conn = aiohttp.BaseConnector(limit=5)
     conn._release_waiter = mock.Mock()
 
     conn._acquired.add(proto)
     conn._acquired_per_host[key].add(proto)
     conn._closed = True
     conn._release_acquired(key, proto)
     assert 1 == len(conn._acquired)
     assert 1 == len(conn._acquired_per_host[key])
     assert not conn._release_waiter.called
-    conn.close()
+    await conn.close()
 
 
 async def test_release(loop, key) -> None:
-    conn = aiohttp.BaseConnector(loop=loop)
+    conn = aiohttp.BaseConnector()
     conn._release_waiter = mock.Mock()
 
-    proto = mock.Mock(should_close=False)
+    proto = create_mocked_conn(loop, should_close=False)
 
     conn._acquired.add(proto)
     conn._acquired_per_host[key].add(proto)
 
     conn._release(key, proto)
     assert conn._release_waiter.called
     assert conn._conns[key][0][0] == proto
     assert conn._conns[key][0][1] == pytest.approx(loop.time(), abs=0.1)
     assert not conn._cleanup_closed_transports
-    conn.close()
+    await conn.close()
 
 
 async def test_release_ssl_transport(loop, ssl_key) -> None:
-    conn = aiohttp.BaseConnector(loop=loop, enable_cleanup_closed=True)
+    conn = aiohttp.BaseConnector(enable_cleanup_closed=True)
     conn._release_waiter = mock.Mock()
 
-    proto = mock.Mock()
+    proto = create_mocked_conn(loop)
     transport = proto.transport
     conn._acquired.add(proto)
     conn._acquired_per_host[ssl_key].add(proto)
 
     conn._release(ssl_key, proto, should_close=True)
     assert conn._cleanup_closed_transports == [transport]
-    conn.close()
+    await conn.close()
 
 
-async def test_release_already_closed(loop) -> None:
-    conn = aiohttp.BaseConnector(loop=loop)
+async def test_release_already_closed() -> None:
+    conn = aiohttp.BaseConnector()
 
-    proto = mock.Mock()
+    proto = create_mocked_conn()
     key = 1
     conn._acquired.add(proto)
-    conn.close()
+    await conn.close()
 
     conn._release_waiters = mock.Mock()
     conn._release_acquired = mock.Mock()
 
     conn._release(key, proto)
     assert not conn._release_waiters.called
     assert not conn._release_acquired.called
 
 
 async def test_release_waiter_no_limit(loop, key, key2) -> None:
     # limit is 0
-    conn = aiohttp.BaseConnector(limit=0, loop=loop)
+    conn = aiohttp.BaseConnector(limit=0)
     w = mock.Mock()
     w.done.return_value = False
     conn._waiters[key].append(w)
     conn._release_waiter()
     assert len(conn._waiters[key]) == 0
     assert w.done.called
-    conn.close()
+    await conn.close()
 
 
 async def test_release_waiter_first_available(loop, key, key2) -> None:
-    conn = aiohttp.BaseConnector(loop=loop)
+    conn = aiohttp.BaseConnector()
     w1, w2 = mock.Mock(), mock.Mock()
     w1.done.return_value = False
     w2.done.return_value = False
     conn._waiters[key].append(w2)
     conn._waiters[key2].append(w1)
     conn._release_waiter()
     assert (w1.set_result.called and not w2.set_result.called or
             not w1.set_result.called and w2.set_result.called)
-    conn.close()
+    await conn.close()
 
 
 async def test_release_waiter_release_first(loop, key, key2) -> None:
-    conn = aiohttp.BaseConnector(loop=loop, limit=1)
+    conn = aiohttp.BaseConnector(limit=1)
     w1, w2 = mock.Mock(), mock.Mock()
     w1.done.return_value = False
     w2.done.return_value = False
     conn._waiters[key] = deque([w1, w2])
     conn._release_waiter()
     assert w1.set_result.called
     assert not w2.set_result.called
-    conn.close()
+    await conn.close()
 
 
 async def test_release_waiter_skip_done_waiter(loop, key, key2) -> None:
-    conn = aiohttp.BaseConnector(loop=loop, limit=1)
+    conn = aiohttp.BaseConnector(limit=1)
     w1, w2 = mock.Mock(), mock.Mock()
     w1.done.return_value = True
     w2.done.return_value = False
     conn._waiters[key] = deque([w1, w2])
     conn._release_waiter()
     assert not w1.set_result.called
     assert w2.set_result.called
-    conn.close()
+    await conn.close()
 
 
 async def test_release_waiter_per_host(loop, key, key2) -> None:
     # no limit
-    conn = aiohttp.BaseConnector(loop=loop, limit=0, limit_per_host=2)
+    conn = aiohttp.BaseConnector(limit=0, limit_per_host=2)
     w1, w2 = mock.Mock(), mock.Mock()
     w1.done.return_value = False
     w2.done.return_value = False
     conn._waiters[key] = deque([w1])
     conn._waiters[key2] = deque([w2])
     conn._release_waiter()
     assert ((w1.set_result.called and not w2.set_result.called) or
             (not w1.set_result.called and w2.set_result.called))
-    conn.close()
+    await conn.close()
 
 
 async def test_release_waiter_no_available(loop, key, key2) -> None:
     # limit is 0
-    conn = aiohttp.BaseConnector(limit=0, loop=loop)
+    conn = aiohttp.BaseConnector(limit=0)
     w = mock.Mock()
     w.done.return_value = False
     conn._waiters[key].append(w)
     conn._available_connections = mock.Mock(return_value=0)
     conn._release_waiter()
     assert len(conn._waiters) == 1
     assert not w.done.called
-    conn.close()
+    await conn.close()
 
 
-async def test_release_close(loop, key) -> None:
-    conn = aiohttp.BaseConnector(loop=loop)
-    proto = mock.Mock(should_close=True)
+async def test_release_close(key) -> None:
+    conn = aiohttp.BaseConnector()
+    proto = create_mocked_conn(should_close=True)
 
     conn._acquired.add(proto)
     conn._release(key, proto)
     assert not conn._conns
     assert proto.close.called
 
 
 async def test__drop_acquire_per_host1(loop) -> None:
-    conn = aiohttp.BaseConnector(loop=loop)
+    conn = aiohttp.BaseConnector()
     conn._drop_acquired_per_host(123, 456)
     assert len(conn._acquired_per_host) == 0
 
 
 async def test__drop_acquire_per_host2(loop) -> None:
-    conn = aiohttp.BaseConnector(loop=loop)
+    conn = aiohttp.BaseConnector()
     conn._acquired_per_host[123].add(456)
     conn._drop_acquired_per_host(123, 456)
     assert len(conn._acquired_per_host) == 0
 
 
 async def test__drop_acquire_per_host3(loop) -> None:
-    conn = aiohttp.BaseConnector(loop=loop)
+    conn = aiohttp.BaseConnector()
     conn._acquired_per_host[123].add(456)
     conn._acquired_per_host[123].add(789)
     conn._drop_acquired_per_host(123, 456)
     assert len(conn._acquired_per_host) == 1
     assert conn._acquired_per_host[123] == {789}
 
 
 async def test_tcp_connector_certificate_error(loop) -> None:
     req = ClientRequest('GET', URL('https://127.0.0.1:443'), loop=loop)
 
     async def certificate_error(*args, **kwargs):
         raise ssl.CertificateError
 
-    conn = aiohttp.TCPConnector(loop=loop)
+    conn = aiohttp.TCPConnector()
     conn._loop.create_connection = certificate_error
 
     with pytest.raises(aiohttp.ClientConnectorCertificateError) as ctx:
         await conn.connect(req, [], ClientTimeout())
 
     assert isinstance(ctx.value, ssl.CertificateError)
     assert isinstance(ctx.value.certificate_error, ssl.CertificateError)
     assert isinstance(ctx.value, aiohttp.ClientSSLError)
 
 
 async def test_tcp_connector_multiple_hosts_errors(loop) -> None:
-    conn = aiohttp.TCPConnector(loop=loop)
+    conn = aiohttp.TCPConnector()
 
     ip1 = '192.168.1.1'
     ip2 = '192.168.1.2'
     ip3 = '192.168.1.3'
     ip4 = '192.168.1.4'
     ip5 = '192.168.1.5'
     ips = [ip1, ip2, ip3, ip4, ip5]
@@ -543,43 +555,45 @@
 
         if ip == ip3:
             ssl_error = True
             raise ssl.SSLError
 
         if ip == ip4:
             fingerprint_error = True
-            tr, pr = mock.Mock(), mock.Mock()
+            tr = create_mocked_conn(loop)
+            pr = create_mocked_conn(loop)
 
             def get_extra_info(param):
                 if param == 'sslcontext':
                     return True
 
                 if param == 'ssl_object':
-                    s = mock.Mock()
+                    s = create_mocked_conn(loop)
                     s.getpeercert.return_value = b'not foo'
                     return s
 
                 if param == 'peername':
                     return ('192.168.1.5', 12345)
 
                 assert False, param
 
             tr.get_extra_info = get_extra_info
             return tr, pr
 
         if ip == ip5:
             connected = True
-            tr, pr = mock.Mock(), mock.Mock()
+            tr = create_mocked_conn(loop)
+            pr = create_mocked_conn(loop)
 
             def get_extra_info(param):
                 if param == 'sslcontext':
                     return True
 
                 if param == 'ssl_object':
-                    s = mock.Mock()
+                    s = create_mocked_conn(loop)
                     s.getpeercert.return_value = b'foo'
                     return s
 
                 assert False
 
             tr.get_extra_info = get_extra_info
             return tr, pr
@@ -595,15 +609,15 @@
     assert certificate_error
     assert ssl_error
     assert fingerprint_error
     assert connected
 
 
 async def test_tcp_connector_resolve_host(loop) -> None:
-    conn = aiohttp.TCPConnector(loop=loop, use_dns_cache=True)
+    conn = aiohttp.TCPConnector(use_dns_cache=True)
 
     res = await conn._resolve_host('localhost', 8080)
     assert res
     for rec in res:
         if rec['family'] == socket.AF_INET:
             assert rec['host'] == '127.0.0.1'
             assert rec['hostname'] == 'localhost'
@@ -617,23 +631,22 @@
                 assert rec['host'] == '::1'
 
 
 @pytest.fixture
 def dns_response(loop):
     async def coro():
         # simulates a network operation
-        await asyncio.sleep(0, loop=loop)
+        await asyncio.sleep(0)
         return ["127.0.0.1"]
     return coro
 
 
 async def test_tcp_connector_dns_cache_not_expired(loop, dns_response) -> None:
     with mock.patch('aiohttp.connector.DefaultResolver') as m_resolver:
         conn = aiohttp.TCPConnector(
-            loop=loop,
             use_dns_cache=True,
             ttl_dns_cache=10
         )
         m_resolver().resolve.return_value = dns_response()
         await conn._resolve_host('localhost', 8080)
         await conn._resolve_host('localhost', 8080)
         m_resolver().resolve.assert_called_once_with(
@@ -642,15 +655,14 @@
             family=0
         )
 
 
 async def test_tcp_connector_dns_cache_forever(loop, dns_response) -> None:
     with mock.patch('aiohttp.connector.DefaultResolver') as m_resolver:
         conn = aiohttp.TCPConnector(
-            loop=loop,
             use_dns_cache=True,
             ttl_dns_cache=10
         )
         m_resolver().resolve.return_value = dns_response()
         await conn._resolve_host('localhost', 8080)
         await conn._resolve_host('localhost', 8080)
         m_resolver().resolve.assert_called_once_with(
@@ -659,94 +671,91 @@
             family=0
         )
 
 
 async def test_tcp_connector_use_dns_cache_disabled(loop,
                                                     dns_response) -> None:
     with mock.patch('aiohttp.connector.DefaultResolver') as m_resolver:
-        conn = aiohttp.TCPConnector(loop=loop, use_dns_cache=False)
+        conn = aiohttp.TCPConnector(use_dns_cache=False)
         m_resolver().resolve.side_effect = [dns_response(), dns_response()]
         await conn._resolve_host('localhost', 8080)
         await conn._resolve_host('localhost', 8080)
         m_resolver().resolve.assert_has_calls([
             mock.call('localhost', 8080, family=0),
             mock.call('localhost', 8080, family=0)
         ])
 
 
 async def test_tcp_connector_dns_throttle_requests(loop, dns_response) -> None:
     with mock.patch('aiohttp.connector.DefaultResolver') as m_resolver:
         conn = aiohttp.TCPConnector(
-            loop=loop,
             use_dns_cache=True,
             ttl_dns_cache=10
         )
         m_resolver().resolve.return_value = dns_response()
         loop.create_task(conn._resolve_host('localhost', 8080))
         loop.create_task(conn._resolve_host('localhost', 8080))
-        await asyncio.sleep(0, loop=loop)
+        await asyncio.sleep(0)
         m_resolver().resolve.assert_called_once_with(
             'localhost',
             8080,
             family=0
         )
 
 
 async def test_tcp_connector_dns_throttle_requests_exception_spread(
         loop) -> None:
     with mock.patch('aiohttp.connector.DefaultResolver') as m_resolver:
         conn = aiohttp.TCPConnector(
-            loop=loop,
             use_dns_cache=True,
             ttl_dns_cache=10
         )
         e = Exception()
         m_resolver().resolve.side_effect = e
         r1 = loop.create_task(conn._resolve_host('localhost', 8080))
         r2 = loop.create_task(conn._resolve_host('localhost', 8080))
-        await asyncio.sleep(0, loop=loop)
+        await asyncio.sleep(0)
         assert r1.exception() == e
         assert r2.exception() == e
 
 
 async def test_tcp_connector_dns_throttle_requests_cancelled_when_close(
         loop,
         dns_response):
 
     with mock.patch('aiohttp.connector.DefaultResolver') as m_resolver:
         conn = aiohttp.TCPConnector(
-            loop=loop,
             use_dns_cache=True,
             ttl_dns_cache=10
         )
         m_resolver().resolve.return_value = dns_response()
         loop.create_task(conn._resolve_host('localhost', 8080))
         f = loop.create_task(conn._resolve_host('localhost', 8080))
 
-        await asyncio.sleep(0, loop=loop)
-        conn.close()
+        await asyncio.sleep(0)
+        await conn.close()
 
-        with pytest.raises(asyncio.futures.CancelledError):
+        with pytest.raises(asyncio.CancelledError):
             await f
 
 
 async def test_tcp_connector_dns_tracing(loop, dns_response) -> None:
     session = mock.Mock()
     trace_config_ctx = mock.Mock()
     on_dns_resolvehost_start = mock.Mock(
-        side_effect=asyncio.coroutine(mock.Mock())
+        side_effect=make_mocked_coro(mock.Mock())
     )
     on_dns_resolvehost_end = mock.Mock(
-        side_effect=asyncio.coroutine(mock.Mock())
+        side_effect=make_mocked_coro(mock.Mock())
     )
     on_dns_cache_hit = mock.Mock(
-        side_effect=asyncio.coroutine(mock.Mock())
+        side_effect=make_mocked_coro(mock.Mock())
     )
     on_dns_cache_miss = mock.Mock(
-        side_effect=asyncio.coroutine(mock.Mock())
+        side_effect=make_mocked_coro(mock.Mock())
     )
 
     trace_config = aiohttp.TraceConfig(
         trace_config_ctx_factory=mock.Mock(return_value=trace_config_ctx)
     )
     trace_config.on_dns_resolvehost_start.append(on_dns_resolvehost_start)
     trace_config.on_dns_resolvehost_end.append(on_dns_resolvehost_end)
@@ -759,15 +768,14 @@
             trace_config,
             trace_config.trace_config_ctx()
         )
     ]
 
     with mock.patch('aiohttp.connector.DefaultResolver') as m_resolver:
         conn = aiohttp.TCPConnector(
-            loop=loop,
             use_dns_cache=True,
             ttl_dns_cache=10
         )
 
         m_resolver().resolve.return_value = dns_response()
 
         await conn._resolve_host(
@@ -805,18 +813,18 @@
 
 
 async def test_tcp_connector_dns_tracing_cache_disabled(loop,
                                                         dns_response) -> None:
     session = mock.Mock()
     trace_config_ctx = mock.Mock()
     on_dns_resolvehost_start = mock.Mock(
-        side_effect=asyncio.coroutine(mock.Mock())
+        side_effect=make_mocked_coro(mock.Mock())
     )
     on_dns_resolvehost_end = mock.Mock(
-        side_effect=asyncio.coroutine(mock.Mock())
+        side_effect=make_mocked_coro(mock.Mock())
     )
 
     trace_config = aiohttp.TraceConfig(
         trace_config_ctx_factory=mock.Mock(return_value=trace_config_ctx)
     )
     trace_config.on_dns_resolvehost_start.append(on_dns_resolvehost_start)
     trace_config.on_dns_resolvehost_end.append(on_dns_resolvehost_end)
@@ -827,15 +835,14 @@
             trace_config,
             trace_config.trace_config_ctx()
         )
     ]
 
     with mock.patch('aiohttp.connector.DefaultResolver') as m_resolver:
         conn = aiohttp.TCPConnector(
-            loop=loop,
             use_dns_cache=False
         )
 
         m_resolver().resolve.side_effect = [
             dns_response(),
             dns_response()
         ]
@@ -876,21 +883,22 @@
                 aiohttp.TraceDnsResolveHostEndParams('localhost')
             )
         ])
 
 
 async def test_tcp_connector_dns_tracing_throttle_requests(
         loop, dns_response) -> None:
+
     session = mock.Mock()
     trace_config_ctx = mock.Mock()
     on_dns_cache_hit = mock.Mock(
-        side_effect=asyncio.coroutine(mock.Mock())
+        side_effect=make_mocked_coro(mock.Mock())
     )
     on_dns_cache_miss = mock.Mock(
-        side_effect=asyncio.coroutine(mock.Mock())
+        side_effect=make_mocked_coro(mock.Mock())
     )
 
     trace_config = aiohttp.TraceConfig(
         trace_config_ctx_factory=mock.Mock(return_value=trace_config_ctx)
     )
     trace_config.on_dns_cache_hit.append(on_dns_cache_hit)
     trace_config.on_dns_cache_miss.append(on_dns_cache_miss)
@@ -901,114 +909,115 @@
             trace_config,
             trace_config.trace_config_ctx()
         )
     ]
 
     with mock.patch('aiohttp.connector.DefaultResolver') as m_resolver:
         conn = aiohttp.TCPConnector(
-            loop=loop,
             use_dns_cache=True,
             ttl_dns_cache=10
         )
         m_resolver().resolve.return_value = dns_response()
         loop.create_task(conn._resolve_host('localhost', 8080, traces=traces))
         loop.create_task(conn._resolve_host('localhost', 8080, traces=traces))
-        await asyncio.sleep(0, loop=loop)
+        await asyncio.sleep(0)
         on_dns_cache_hit.assert_called_once_with(
             session,
             trace_config_ctx,
             aiohttp.TraceDnsCacheHitParams('localhost')
         )
         on_dns_cache_miss.assert_called_once_with(
             session,
             trace_config_ctx,
             aiohttp.TraceDnsCacheMissParams('localhost')
         )
 
 
 async def test_dns_error(loop) -> None:
-    connector = aiohttp.TCPConnector(loop=loop)
+    connector = aiohttp.TCPConnector()
     connector._resolve_host = make_mocked_coro(
         raise_exception=OSError('dont take it serious'))
 
     req = ClientRequest(
         'GET', URL('http://www.python.org'),
         loop=loop)
 
     with pytest.raises(aiohttp.ClientConnectorError):
         await connector.connect(req, [], ClientTimeout())
 
 
 async def test_get_pop_empty_conns(loop) -> None:
     # see issue #473
-    conn = aiohttp.BaseConnector(loop=loop)
+    conn = aiohttp.BaseConnector()
     key = ('127.0.0.1', 80, False)
     conn._conns[key] = []
     proto = conn._get(key)
     assert proto is None
     assert not conn._conns
 
 
 async def test_release_close_do_not_add_to_pool(loop, key) -> None:
     # see issue #473
-    conn = aiohttp.BaseConnector(loop=loop)
+    conn = aiohttp.BaseConnector()
 
-    proto = mock.Mock(should_close=True)
+    proto = create_mocked_conn(loop, should_close=True)
 
     conn._acquired.add(proto)
     conn._release(key, proto)
     assert not conn._conns
 
 
-async def test_release_close_do_not_delete_existing_connections(key) -> None:
-    proto1 = mock.Mock()
+async def test_release_close_do_not_delete_existing_connections(loop,
+                                                                key) -> None:
+
+    proto1 = create_mocked_conn(loop)
 
     conn = aiohttp.BaseConnector()
     conn._conns[key] = [(proto1, 1)]
 
-    proto = mock.Mock(should_close=True)
+    proto = create_mocked_conn(loop, should_close=True)
     conn._acquired.add(proto)
     conn._release(key, proto)
     assert conn._conns[key] == [(proto1, 1)]
     assert proto.close.called
-    conn.close()
+    await conn.close()
 
 
 async def test_release_not_started(loop) -> None:
-    conn = aiohttp.BaseConnector(loop=loop)
-    proto = mock.Mock(should_close=False)
+    conn = aiohttp.BaseConnector()
+    proto = create_mocked_conn(should_close=False)
     key = 1
     conn._acquired.add(proto)
     conn._release(key, proto)
     # assert conn._conns == {1: [(proto, 10)]}
     rec = conn._conns[1]
     assert rec[0][0] == proto
     assert rec[0][1] == pytest.approx(loop.time(), abs=0.05)
     assert not proto.close.called
-    conn.close()
+    await conn.close()
 
 
 async def test_release_not_opened(loop, key) -> None:
-    conn = aiohttp.BaseConnector(loop=loop)
+    conn = aiohttp.BaseConnector()
 
-    proto = mock.Mock()
+    proto = create_mocked_conn(loop)
     conn._acquired.add(proto)
     conn._release(key, proto)
     assert proto.close.called
 
 
 async def test_connect(loop, key) -> None:
-    proto = mock.Mock()
+    proto = create_mocked_conn(loop)
     proto.is_connected.return_value = True
 
     req = ClientRequest('GET', URL('http://localhost:80'), loop=loop)
 
-    conn = aiohttp.BaseConnector(loop=loop)
+    conn = aiohttp.BaseConnector()
     conn._conns[key] = [(proto, loop.time())]
-    conn._create_connection = mock.Mock()
+    conn._create_connection = create_mocked_conn(loop)
     conn._create_connection.return_value = loop.create_future()
     conn._create_connection.return_value.set_result(proto)
 
     connection = await conn.connect(req, [], ClientTimeout())
     assert not conn._create_connection.called
     assert connection._protocol is proto
     assert connection.transport is proto.transport
@@ -1016,18 +1025,18 @@
     connection.close()
 
 
 async def test_connect_tracing(loop) -> None:
     session = mock.Mock()
     trace_config_ctx = mock.Mock()
     on_connection_create_start = mock.Mock(
-        side_effect=asyncio.coroutine(mock.Mock())
+        side_effect=make_mocked_coro(mock.Mock())
     )
     on_connection_create_end = mock.Mock(
-        side_effect=asyncio.coroutine(mock.Mock())
+        side_effect=make_mocked_coro(mock.Mock())
     )
 
     trace_config = aiohttp.TraceConfig(
         trace_config_ctx_factory=mock.Mock(return_value=trace_config_ctx)
     )
     trace_config.on_connection_create_start.append(on_connection_create_start)
     trace_config.on_connection_create_end.append(on_connection_create_end)
@@ -1036,20 +1045,20 @@
         Trace(
             session,
             trace_config,
             trace_config.trace_config_ctx()
         )
     ]
 
-    proto = mock.Mock()
+    proto = create_mocked_conn(loop)
     proto.is_connected.return_value = True
 
     req = ClientRequest('GET', URL('http://host:80'), loop=loop)
 
-    conn = aiohttp.BaseConnector(loop=loop)
+    conn = aiohttp.BaseConnector()
     conn._create_connection = mock.Mock()
     conn._create_connection.return_value = loop.create_future()
     conn._create_connection.return_value.set_result(proto)
 
     conn2 = await conn.connect(req, traces, ClientTimeout())
     conn2.release()
 
@@ -1062,175 +1071,177 @@
         session,
         trace_config_ctx,
         aiohttp.TraceConnectionCreateEndParams()
     )
 
 
 async def test_close_during_connect(loop) -> None:
-    proto = mock.Mock()
+    proto = create_mocked_conn(loop)
     proto.is_connected.return_value = True
 
     fut = loop.create_future()
     req = ClientRequest('GET', URL('http://host:80'), loop=loop)
 
-    conn = aiohttp.BaseConnector(loop=loop)
+    conn = aiohttp.BaseConnector()
     conn._create_connection = mock.Mock()
     conn._create_connection.return_value = fut
 
     task = loop.create_task(conn.connect(req, None, ClientTimeout()))
-    await asyncio.sleep(0, loop=loop)
-    conn.close()
+    await asyncio.sleep(0)
+    await conn.close()
 
     fut.set_result(proto)
     with pytest.raises(aiohttp.ClientConnectionError):
         await task
 
     assert proto.close.called
 
 
 async def test_ctor_cleanup() -> None:
     loop = mock.Mock()
     loop.time.return_value = 1.5
     conn = aiohttp.BaseConnector(
-        loop=loop, keepalive_timeout=10, enable_cleanup_closed=True)
+        keepalive_timeout=10, enable_cleanup_closed=True)
     assert conn._cleanup_handle is None
     assert conn._cleanup_closed_handle is not None
 
 
 async def test_cleanup(key) -> None:
     testset = {
         key: [(mock.Mock(), 10),
               (mock.Mock(), 300)],
     }
     testset[key][0][0].is_connected.return_value = True
     testset[key][1][0].is_connected.return_value = False
 
     loop = mock.Mock()
     loop.time.return_value = 300
-    conn = aiohttp.BaseConnector(loop=loop)
+    conn = aiohttp.BaseConnector()
     conn._conns = testset
     existing_handle = conn._cleanup_handle = mock.Mock()
 
     conn._cleanup()
     assert existing_handle.cancel.called
     assert conn._conns == {}
     assert conn._cleanup_handle is not None
 
 
-async def test_cleanup_close_ssl_transport(ssl_key) -> None:
-    proto = mock.Mock()
+async def test_cleanup_close_ssl_transport(loop, ssl_key) -> None:
+    proto = create_mocked_conn(loop)
     transport = proto.transport
     testset = {ssl_key: [(proto, 10)]}
 
     loop = mock.Mock()
-    loop.time.return_value = 300
-    conn = aiohttp.BaseConnector(loop=loop, enable_cleanup_closed=True)
+    loop.time.return_value = asyncio.get_event_loop().time() + 300
+    conn = aiohttp.BaseConnector(enable_cleanup_closed=True)
+    conn._loop = loop
     conn._conns = testset
     existing_handle = conn._cleanup_handle = mock.Mock()
 
     conn._cleanup()
     assert existing_handle.cancel.called
     assert conn._conns == {}
     assert conn._cleanup_closed_transports == [transport]
 
 
-async def test_cleanup2() -> None:
-    testset = {1: [(mock.Mock(), 300)]}
+async def test_cleanup2(loop) -> None:
+    testset = {1: [(create_mocked_conn(), 300)]}
     testset[1][0][0].is_connected.return_value = True
 
-    loop = mock.Mock()
-    loop.time.return_value = 300
-
-    conn = aiohttp.BaseConnector(loop=loop, keepalive_timeout=10)
+    conn = aiohttp.BaseConnector(keepalive_timeout=10)
+    conn._loop = mock.Mock()
+    conn._loop.time.return_value = 300
     conn._conns = testset
     conn._cleanup()
     assert conn._conns == testset
 
     assert conn._cleanup_handle is not None
-    loop.call_at.assert_called_with(310, mock.ANY, mock.ANY)
-    conn.close()
+    conn._loop.call_at.assert_called_with(310, mock.ANY, mock.ANY)
+    await conn.close()
 
 
-async def test_cleanup3(key) -> None:
-    testset = {key: [(mock.Mock(), 290.1),
-                     (mock.Mock(), 305.1)]}
+async def test_cleanup3(loop, key) -> None:
+    testset = {key: [(create_mocked_conn(loop), 290.1),
+                     (create_mocked_conn(loop), 305.1)]}
     testset[key][0][0].is_connected.return_value = True
 
-    loop = mock.Mock()
-    loop.time.return_value = 308.5
-
-    conn = aiohttp.BaseConnector(loop=loop, keepalive_timeout=10)
+    conn = aiohttp.BaseConnector(keepalive_timeout=10)
+    conn._loop = mock.Mock()
+    conn._loop.time.return_value = 308.5
     conn._conns = testset
 
     conn._cleanup()
     assert conn._conns == {key: [testset[key][1]]}
 
     assert conn._cleanup_handle is not None
-    loop.call_at.assert_called_with(319, mock.ANY, mock.ANY)
-    conn.close()
+    conn._loop.call_at.assert_called_with(319, mock.ANY, mock.ANY)
+    await conn.close()
 
 
 async def test_cleanup_closed(loop, mocker) -> None:
     if not hasattr(loop, '__dict__'):
         pytest.skip("can not override loop attributes")
 
     mocker.spy(loop, 'call_at')
-    conn = aiohttp.BaseConnector(loop=loop, enable_cleanup_closed=True)
+    conn = aiohttp.BaseConnector(enable_cleanup_closed=True)
 
     tr = mock.Mock()
     conn._cleanup_closed_handle = cleanup_closed_handle = mock.Mock()
     conn._cleanup_closed_transports = [tr]
     conn._cleanup_closed()
     assert tr.abort.called
     assert not conn._cleanup_closed_transports
     assert loop.call_at.called
     assert cleanup_closed_handle.cancel.called
 
 
 async def test_cleanup_closed_disabled(loop, mocker) -> None:
     conn = aiohttp.BaseConnector(
-        loop=loop, enable_cleanup_closed=False)
+        enable_cleanup_closed=False)
 
     tr = mock.Mock()
     conn._cleanup_closed_transports = [tr]
     conn._cleanup_closed()
     assert tr.abort.called
     assert not conn._cleanup_closed_transports
 
 
 async def test_tcp_connector_ctor(loop) -> None:
-    conn = aiohttp.TCPConnector(loop=loop)
+    conn = aiohttp.TCPConnector()
     assert conn._ssl is None
 
     assert conn.use_dns_cache
     assert conn.family == 0
 
 
+async def test_invalid_ssl_param() -> None:
+    with pytest.raises(TypeError):
+        aiohttp.TCPConnector(ssl=object())
+
+
 async def test_tcp_connector_ctor_fingerprint_valid(loop) -> None:
     valid = aiohttp.Fingerprint(hashlib.sha256(b"foo").digest())
-    conn = aiohttp.TCPConnector(ssl=valid, loop=loop)
+    conn = aiohttp.TCPConnector(ssl=valid)
     assert conn._ssl is valid
 
 
 async def test_insecure_fingerprint_md5(loop) -> None:
     with pytest.raises(ValueError):
         aiohttp.TCPConnector(
-            ssl=aiohttp.Fingerprint(hashlib.md5(b"foo").digest()),
-            loop=loop)
+            ssl=aiohttp.Fingerprint(hashlib.md5(b"foo").digest()))
 
 
 async def test_insecure_fingerprint_sha1(loop) -> None:
     with pytest.raises(ValueError):
         aiohttp.TCPConnector(
-            ssl=aiohttp.Fingerprint(hashlib.sha1(b"foo").digest()),
-            loop=loop)
+            ssl=aiohttp.Fingerprint(hashlib.sha1(b"foo").digest()))
 
 
 async def test_tcp_connector_clear_dns_cache(loop) -> None:
-    conn = aiohttp.TCPConnector(loop=loop)
+    conn = aiohttp.TCPConnector()
     hosts = ['a', 'b']
     conn._cached_hosts.add(('localhost', 123), hosts)
     conn._cached_hosts.add(('localhost', 124), hosts)
     conn.clear_dns_cache('localhost', 123)
     with pytest.raises(KeyError):
         conn._cached_hosts.next_addrs(('localhost', 123))
 
@@ -1243,139 +1254,139 @@
 
     conn.clear_dns_cache()
     with pytest.raises(KeyError):
         conn._cached_hosts.next_addrs(('localhost', 124))
 
 
 async def test_tcp_connector_clear_dns_cache_bad_args(loop) -> None:
-    conn = aiohttp.TCPConnector(loop=loop)
+    conn = aiohttp.TCPConnector()
     with pytest.raises(ValueError):
         conn.clear_dns_cache('localhost')
 
 
 async def test_dont_recreate_ssl_context(loop) -> None:
-    conn = aiohttp.TCPConnector(loop=loop)
+    conn = aiohttp.TCPConnector()
     ctx = conn._make_ssl_context(True)
     assert ctx is conn._make_ssl_context(True)
 
 
 async def test_dont_recreate_ssl_context2(loop) -> None:
-    conn = aiohttp.TCPConnector(loop=loop)
+    conn = aiohttp.TCPConnector()
     ctx = conn._make_ssl_context(False)
     assert ctx is conn._make_ssl_context(False)
 
 
 async def test___get_ssl_context1(loop) -> None:
-    conn = aiohttp.TCPConnector(loop=loop)
+    conn = aiohttp.TCPConnector()
     req = mock.Mock()
     req.is_ssl.return_value = False
     assert conn._get_ssl_context(req) is None
 
 
 async def test___get_ssl_context2(loop) -> None:
     ctx = ssl.SSLContext()
-    conn = aiohttp.TCPConnector(loop=loop)
+    conn = aiohttp.TCPConnector()
     req = mock.Mock()
     req.is_ssl.return_value = True
     req.ssl = ctx
     assert conn._get_ssl_context(req) is ctx
 
 
 async def test___get_ssl_context3(loop) -> None:
     ctx = ssl.SSLContext()
-    conn = aiohttp.TCPConnector(loop=loop, ssl=ctx)
+    conn = aiohttp.TCPConnector(ssl=ctx)
     req = mock.Mock()
     req.is_ssl.return_value = True
     req.ssl = None
     assert conn._get_ssl_context(req) is ctx
 
 
 async def test___get_ssl_context4(loop) -> None:
     ctx = ssl.SSLContext()
-    conn = aiohttp.TCPConnector(loop=loop, ssl=ctx)
+    conn = aiohttp.TCPConnector(ssl=ctx)
     req = mock.Mock()
     req.is_ssl.return_value = True
     req.ssl = False
     assert conn._get_ssl_context(req) is conn._make_ssl_context(False)
 
 
 async def test___get_ssl_context5(loop) -> None:
     ctx = ssl.SSLContext()
-    conn = aiohttp.TCPConnector(loop=loop, ssl=ctx)
+    conn = aiohttp.TCPConnector(ssl=ctx)
     req = mock.Mock()
     req.is_ssl.return_value = True
     req.ssl = aiohttp.Fingerprint(hashlib.sha256(b'1').digest())
     assert conn._get_ssl_context(req) is conn._make_ssl_context(False)
 
 
 async def test___get_ssl_context6(loop) -> None:
-    conn = aiohttp.TCPConnector(loop=loop)
+    conn = aiohttp.TCPConnector()
     req = mock.Mock()
     req.is_ssl.return_value = True
     req.ssl = None
     assert conn._get_ssl_context(req) is conn._make_ssl_context(True)
 
 
 async def test_close_twice(loop) -> None:
-    proto = mock.Mock()
+    proto = create_mocked_conn(loop)
 
-    conn = aiohttp.BaseConnector(loop=loop)
+    conn = aiohttp.BaseConnector()
     conn._conns[1] = [(proto, object())]
-    conn.close()
+    await conn.close()
 
     assert not conn._conns
     assert proto.close.called
     assert conn.closed
 
     conn._conns = 'Invalid'  # fill with garbage
-    conn.close()
+    await conn.close()
     assert conn.closed
 
 
 async def test_close_cancels_cleanup_handle(loop) -> None:
-    conn = aiohttp.BaseConnector(loop=loop)
-    conn._release(1, mock.Mock(should_close=False))
+    conn = aiohttp.BaseConnector()
+    conn._release(1, create_mocked_conn(should_close=False))
     assert conn._cleanup_handle is not None
-    conn.close()
+    await conn.close()
     assert conn._cleanup_handle is None
 
 
 async def test_close_abort_closed_transports(loop) -> None:
     tr = mock.Mock()
 
-    conn = aiohttp.BaseConnector(loop=loop)
+    conn = aiohttp.BaseConnector()
     conn._cleanup_closed_transports.append(tr)
-    conn.close()
+    await conn.close()
 
     assert not conn._cleanup_closed_transports
     assert tr.abort.called
     assert conn.closed
 
 
 async def test_close_cancels_cleanup_closed_handle(loop) -> None:
-    conn = aiohttp.BaseConnector(loop=loop, enable_cleanup_closed=True)
+    conn = aiohttp.BaseConnector(enable_cleanup_closed=True)
     assert conn._cleanup_closed_handle is not None
-    conn.close()
+    await conn.close()
     assert conn._cleanup_closed_handle is None
 
 
 async def test_ctor_with_default_loop(loop) -> None:
     conn = aiohttp.BaseConnector()
     assert loop is conn._loop
 
 
 async def test_connect_with_limit(loop, key) -> None:
-    proto = mock.Mock()
+    proto = create_mocked_conn(loop)
     proto.is_connected.return_value = True
 
     req = ClientRequest('GET', URL('http://localhost:80'),
                         loop=loop,
                         response_class=mock.Mock())
 
-    conn = aiohttp.BaseConnector(loop=loop, limit=1)
+    conn = aiohttp.BaseConnector(limit=1)
     conn._conns[key] = [(proto, loop.time())]
     conn._create_connection = mock.Mock()
     conn._create_connection.return_value = loop.create_future()
     conn._create_connection.return_value.set_result(proto)
 
     connection1 = await conn.connect(req, None, ClientTimeout())
     assert connection1._protocol == proto
@@ -1393,31 +1404,31 @@
         acquired = True
         assert 1 == len(conn._acquired)
         assert 1 == len(conn._acquired_per_host[key])
         connection2.release()
 
     task = loop.create_task(f())
 
-    await asyncio.sleep(0.01, loop=loop)
+    await asyncio.sleep(0.01)
     assert not acquired
     connection1.release()
-    await asyncio.sleep(0, loop=loop)
+    await asyncio.sleep(0)
     assert acquired
     await task
-    conn.close()
+    await conn.close()
 
 
 async def test_connect_queued_operation_tracing(loop, key) -> None:
     session = mock.Mock()
     trace_config_ctx = mock.Mock()
     on_connection_queued_start = mock.Mock(
-        side_effect=asyncio.coroutine(mock.Mock())
+        side_effect=make_mocked_coro(mock.Mock())
     )
     on_connection_queued_end = mock.Mock(
-        side_effect=asyncio.coroutine(mock.Mock())
+        side_effect=make_mocked_coro(mock.Mock())
     )
 
     trace_config = aiohttp.TraceConfig(
         trace_config_ctx_factory=mock.Mock(return_value=trace_config_ctx)
     )
     trace_config.on_connection_queued_start.append(on_connection_queued_start)
     trace_config.on_connection_queued_end.append(on_connection_queued_end)
@@ -1426,22 +1437,22 @@
         Trace(
             session,
             trace_config,
             trace_config.trace_config_ctx()
         )
     ]
 
-    proto = mock.Mock()
+    proto = create_mocked_conn(loop)
     proto.is_connected.return_value = True
 
     req = ClientRequest('GET', URL('http://localhost1:80'),
                         loop=loop,
                         response_class=mock.Mock())
 
-    conn = aiohttp.BaseConnector(loop=loop, limit=1)
+    conn = aiohttp.BaseConnector(limit=1)
     conn._conns[key] = [(proto, loop.time())]
     conn._create_connection = mock.Mock()
     conn._create_connection.return_value = loop.create_future()
     conn._create_connection.return_value.set_result(proto)
 
     connection1 = await conn.connect(req, traces, ClientTimeout())
 
@@ -1455,26 +1466,26 @@
         on_connection_queued_end.assert_called_with(
             session,
             trace_config_ctx,
             aiohttp.TraceConnectionQueuedEndParams()
         )
         connection2.release()
 
-    task = asyncio.ensure_future(f(), loop=loop)
-    await asyncio.sleep(0.01, loop=loop)
+    task = asyncio.ensure_future(f())
+    await asyncio.sleep(0.01)
     connection1.release()
     await task
-    conn.close()
+    await conn.close()
 
 
 async def test_connect_reuseconn_tracing(loop, key) -> None:
     session = mock.Mock()
     trace_config_ctx = mock.Mock()
     on_connection_reuseconn = mock.Mock(
-        side_effect=asyncio.coroutine(mock.Mock())
+        side_effect=make_mocked_coro(mock.Mock())
     )
 
     trace_config = aiohttp.TraceConfig(
         trace_config_ctx_factory=mock.Mock(return_value=trace_config_ctx)
     )
     trace_config.on_connection_reuseconn.append(on_connection_reuseconn)
     trace_config.freeze()
@@ -1482,41 +1493,42 @@
         Trace(
             session,
             trace_config,
             trace_config.trace_config_ctx()
         )
     ]
 
-    proto = mock.Mock()
+    proto = create_mocked_conn(loop)
     proto.is_connected.return_value = True
 
     req = ClientRequest('GET', URL('http://localhost:80'),
                         loop=loop,
                         response_class=mock.Mock())
 
-    conn = aiohttp.BaseConnector(loop=loop, limit=1)
+    conn = aiohttp.BaseConnector(limit=1)
     conn._conns[key] = [(proto, loop.time())]
     conn2 = await conn.connect(req, traces, ClientTimeout())
     conn2.release()
 
     on_connection_reuseconn.assert_called_with(
         session,
         trace_config_ctx,
         aiohttp.TraceConnectionReuseconnParams()
     )
-    conn.close()
+    await conn.close()
 
 
 async def test_connect_with_limit_and_limit_per_host(loop, key) -> None:
-    proto = mock.Mock()
+
+    proto = create_mocked_conn(loop)
     proto.is_connected.return_value = True
 
     req = ClientRequest('GET', URL('http://localhost:80'), loop=loop)
 
-    conn = aiohttp.BaseConnector(loop=loop, limit=1000, limit_per_host=1)
+    conn = aiohttp.BaseConnector(limit=1000, limit_per_host=1)
     conn._conns[key] = [(proto, loop.time())]
     conn._create_connection = mock.Mock()
     conn._create_connection.return_value = loop.create_future()
     conn._create_connection.return_value.set_result(proto)
 
     acquired = False
     connection1 = await conn.connect(req, None, ClientTimeout())
@@ -1527,30 +1539,30 @@
         acquired = True
         assert 1 == len(conn._acquired)
         assert 1 == len(conn._acquired_per_host[key])
         connection2.release()
 
     task = loop.create_task(f())
 
-    await asyncio.sleep(0.01, loop=loop)
+    await asyncio.sleep(0.01)
     assert not acquired
     connection1.release()
-    await asyncio.sleep(0, loop=loop)
+    await asyncio.sleep(0)
     assert acquired
     await task
-    conn.close()
+    await conn.close()
 
 
 async def test_connect_with_no_limit_and_limit_per_host(loop, key) -> None:
-    proto = mock.Mock()
+    proto = create_mocked_conn(loop)
     proto.is_connected.return_value = True
 
     req = ClientRequest('GET', URL('http://localhost1:80'), loop=loop)
 
-    conn = aiohttp.BaseConnector(loop=loop, limit=0, limit_per_host=1)
+    conn = aiohttp.BaseConnector(limit=0, limit_per_host=1)
     conn._conns[key] = [(proto, loop.time())]
     conn._create_connection = mock.Mock()
     conn._create_connection.return_value = loop.create_future()
     conn._create_connection.return_value.set_result(proto)
 
     acquired = False
     connection1 = await conn.connect(req, None, ClientTimeout())
@@ -1559,30 +1571,30 @@
         nonlocal acquired
         connection2 = await conn.connect(req, None, ClientTimeout())
         acquired = True
         connection2.release()
 
     task = loop.create_task(f())
 
-    await asyncio.sleep(0.01, loop=loop)
+    await asyncio.sleep(0.01)
     assert not acquired
     connection1.release()
-    await asyncio.sleep(0, loop=loop)
+    await asyncio.sleep(0)
     assert acquired
     await task
-    conn.close()
+    await conn.close()
 
 
 async def test_connect_with_no_limits(loop, key) -> None:
-    proto = mock.Mock()
+    proto = create_mocked_conn(loop)
     proto.is_connected.return_value = True
 
     req = ClientRequest('GET', URL('http://localhost:80'), loop=loop)
 
-    conn = aiohttp.BaseConnector(loop=loop, limit=0, limit_per_host=0)
+    conn = aiohttp.BaseConnector(limit=0, limit_per_host=0)
     conn._conns[key] = [(proto, loop.time())]
     conn._create_connection = mock.Mock()
     conn._create_connection.return_value = loop.create_future()
     conn._create_connection.return_value.set_result(proto)
 
     acquired = False
     connection1 = await conn.connect(req, None, ClientTimeout())
@@ -1593,29 +1605,29 @@
         acquired = True
         assert 1 == len(conn._acquired)
         assert 1 == len(conn._acquired_per_host[key])
         connection2.release()
 
     task = loop.create_task(f())
 
-    await asyncio.sleep(0.01, loop=loop)
+    await asyncio.sleep(0.01)
     assert acquired
     connection1.release()
     await task
-    conn.close()
+    await conn.close()
 
 
 async def test_connect_with_limit_cancelled(loop) -> None:
 
-    proto = mock.Mock()
+    proto = create_mocked_conn(loop)
     proto.is_connected.return_value = True
 
     req = ClientRequest('GET', URL('http://host:80'), loop=loop)
 
-    conn = aiohttp.BaseConnector(loop=loop, limit=1)
+    conn = aiohttp.BaseConnector(limit=1)
     key = ('host', 80, False)
     conn._conns[key] = [(proto, loop.time())]
     conn._create_connection = mock.Mock()
     conn._create_connection.return_value = loop.create_future()
     conn._create_connection.return_value.set_result(proto)
 
     connection = await conn.connect(req, None, ClientTimeout())
@@ -1623,22 +1635,22 @@
     assert connection.transport == proto.transport
 
     assert 1 == len(conn._acquired)
 
     with pytest.raises(asyncio.TimeoutError):
         # limit exhausted
         await asyncio.wait_for(conn.connect(req, None, ClientTimeout()),
-                               0.01, loop=loop)
+                               0.01)
     connection.close()
 
 
 async def test_connect_with_capacity_release_waiters(loop) -> None:
 
     def check_with_exc(err):
-        conn = aiohttp.BaseConnector(limit=1, loop=loop)
+        conn = aiohttp.BaseConnector(limit=1)
         conn._create_connection = mock.Mock()
         conn._create_connection.return_value = \
             loop.create_future()
         conn._create_connection.return_value.set_exception(err)
 
         with pytest.raises(Exception):
             req = mock.Mock()
@@ -1648,37 +1660,37 @@
 
     check_with_exc(OSError(1, 'permission error'))
     check_with_exc(RuntimeError())
     check_with_exc(asyncio.TimeoutError())
 
 
 async def test_connect_with_limit_concurrent(loop) -> None:
-    proto = mock.Mock()
+    proto = create_mocked_conn(loop)
     proto.should_close = False
     proto.is_connected.return_value = True
 
     req = ClientRequest('GET', URL('http://host:80'), loop=loop)
 
     max_connections = 2
     num_connections = 0
 
-    conn = aiohttp.BaseConnector(limit=max_connections, loop=loop)
+    conn = aiohttp.BaseConnector(limit=max_connections)
 
     # Use a real coroutine for _create_connection; a mock would mask
     # problems that only happen when the method yields.
 
     async def create_connection(req, traces, timeout):
         nonlocal num_connections
         num_connections += 1
-        await asyncio.sleep(0, loop=loop)
+        await asyncio.sleep(0)
 
         # Make a new transport mock each time because acquired
         # transports are stored in a set. Reusing the same object
         # messes with the count.
-        proto = mock.Mock(should_close=False)
+        proto = create_mocked_conn(loop, should_close=False)
         proto.is_connected.return_value = True
 
         return proto
 
     conn._create_connection = create_connection
 
     # Simulate something like a crawler. It opens a connection, does
@@ -1694,147 +1706,147 @@
     async def f(start=True):
         nonlocal num_requests
         if num_requests == max_requests:
             return
         num_requests += 1
         if not start:
             connection = await conn.connect(req, None, ClientTimeout())
-            await asyncio.sleep(0, loop=loop)
+            await asyncio.sleep(0)
             connection.release()
         tasks = [
             loop.create_task(f(start=False))
             for i in range(start_requests)
         ]
-        await asyncio.wait(tasks, loop=loop)
+        await asyncio.wait(tasks)
 
     await f()
-    conn.close()
+    await conn.close()
 
     assert max_connections == num_connections
 
 
 async def test_connect_waiters_cleanup(loop) -> None:
-    proto = mock.Mock()
+    proto = create_mocked_conn(loop)
     proto.is_connected.return_value = True
 
     req = ClientRequest('GET', URL('http://host:80'), loop=loop)
 
-    conn = aiohttp.BaseConnector(loop=loop, limit=1)
+    conn = aiohttp.BaseConnector(limit=1)
     conn._available_connections = mock.Mock(return_value=0)
 
     t = loop.create_task(conn.connect(req, None, ClientTimeout()))
 
-    await asyncio.sleep(0, loop=loop)
+    await asyncio.sleep(0)
     assert conn._waiters.keys()
 
     t.cancel()
-    await asyncio.sleep(0, loop=loop)
+    await asyncio.sleep(0)
     assert not conn._waiters.keys()
 
 
 async def test_connect_waiters_cleanup_key_error(loop) -> None:
-    proto = mock.Mock()
+    proto = create_mocked_conn(loop)
     proto.is_connected.return_value = True
 
     req = ClientRequest('GET', URL('http://host:80'), loop=loop)
 
-    conn = aiohttp.BaseConnector(loop=loop, limit=1)
+    conn = aiohttp.BaseConnector(limit=1)
     conn._available_connections = mock.Mock(return_value=0)
 
     t = loop.create_task(conn.connect(req, None, ClientTimeout()))
 
-    await asyncio.sleep(0, loop=loop)
+    await asyncio.sleep(0)
     assert conn._waiters.keys()
 
     # we delete the entry explicitly before the
     # canceled connection grabs the loop again, we
     # must expect a none failure termination
     conn._waiters.clear()
     t.cancel()
-    await asyncio.sleep(0, loop=loop)
+    await asyncio.sleep(0)
     assert not conn._waiters.keys() == []
 
 
 async def test_close_with_acquired_connection(loop) -> None:
-    proto = mock.Mock()
+    proto = create_mocked_conn(loop)
     proto.is_connected.return_value = True
 
     req = ClientRequest('GET', URL('http://host:80'), loop=loop)
 
-    conn = aiohttp.BaseConnector(loop=loop, limit=1)
+    conn = aiohttp.BaseConnector(limit=1)
     key = ('host', 80, False)
     conn._conns[key] = [(proto, loop.time())]
     conn._create_connection = mock.Mock()
     conn._create_connection.return_value = loop.create_future()
     conn._create_connection.return_value.set_result(proto)
 
     connection = await conn.connect(req, None, ClientTimeout())
 
     assert 1 == len(conn._acquired)
-    conn.close()
+    await conn.close()
     assert 0 == len(conn._acquired)
     assert conn.closed
     proto.close.assert_called_with()
 
     assert not connection.closed
     connection.close()
     assert connection.closed
 
 
 async def test_default_force_close(loop) -> None:
-    connector = aiohttp.BaseConnector(loop=loop)
+    connector = aiohttp.BaseConnector()
     assert not connector.force_close
 
 
 async def test_limit_property(loop) -> None:
-    conn = aiohttp.BaseConnector(loop=loop, limit=15)
+    conn = aiohttp.BaseConnector(limit=15)
     assert 15 == conn.limit
 
-    conn.close()
+    await conn.close()
 
 
 async def test_limit_per_host_property(loop) -> None:
-    conn = aiohttp.BaseConnector(loop=loop, limit_per_host=15)
+    conn = aiohttp.BaseConnector(limit_per_host=15)
     assert 15 == conn.limit_per_host
 
-    conn.close()
+    await conn.close()
 
 
 async def test_limit_property_default(loop) -> None:
-    conn = aiohttp.BaseConnector(loop=loop)
+    conn = aiohttp.BaseConnector()
     assert conn.limit == 100
-    conn.close()
+    await conn.close()
 
 
 async def test_limit_per_host_property_default(loop) -> None:
-    conn = aiohttp.BaseConnector(loop=loop)
+    conn = aiohttp.BaseConnector()
     assert conn.limit_per_host == 0
-    conn.close()
+    await conn.close()
 
 
 async def test_force_close_and_explicit_keep_alive(loop) -> None:
     with pytest.raises(ValueError):
-        aiohttp.BaseConnector(loop=loop, keepalive_timeout=30,
+        aiohttp.BaseConnector(keepalive_timeout=30,
                               force_close=True)
 
-    conn = aiohttp.BaseConnector(loop=loop, force_close=True,
+    conn = aiohttp.BaseConnector(force_close=True,
                                  keepalive_timeout=None)
     assert conn
 
-    conn = aiohttp.BaseConnector(loop=loop, force_close=True)
+    conn = aiohttp.BaseConnector(force_close=True)
 
     assert conn
 
 
 async def test_error_on_connection(loop, key) -> None:
-    conn = aiohttp.BaseConnector(limit=1, loop=loop)
+    conn = aiohttp.BaseConnector(limit=1)
 
     req = mock.Mock()
     req.connection_key = key
-    proto = mock.Mock()
+    proto = create_mocked_conn(loop)
     i = 0
 
     fut = loop.create_future()
     exc = OSError()
 
     async def create_connection(req, traces, timeout):
         nonlocal i
@@ -1845,15 +1857,15 @@
         elif i == 2:
             return proto
 
     conn._create_connection = create_connection
 
     t1 = loop.create_task(conn.connect(req, None, ClientTimeout()))
     t2 = loop.create_task(conn.connect(req, None, ClientTimeout()))
-    await asyncio.sleep(0, loop=loop)
+    await asyncio.sleep(0)
     assert not t1.done()
     assert not t2.done()
     assert len(conn._acquired_per_host[key]) == 1
 
     fut.set_result(None)
     with pytest.raises(OSError):
         await t1
@@ -1864,41 +1876,43 @@
     assert ret._key == key
     assert ret.protocol == proto
     assert proto in conn._acquired
     ret.release()
 
 
 async def test_cancelled_waiter(loop) -> None:
-    conn = aiohttp.BaseConnector(limit=1, loop=loop)
+    conn = aiohttp.BaseConnector(limit=1)
     req = mock.Mock()
     req.connection_key = 'key'
-    proto = mock.Mock()
+    proto = create_mocked_conn(loop)
 
     async def create_connection(req, traces=None):
         await asyncio.sleep(1)
         return proto
 
     conn._create_connection = create_connection
 
     conn._acquired.add(proto)
 
     conn2 = loop.create_task(conn.connect(req, None, ClientTimeout()))
-    await asyncio.sleep(0, loop=loop)
+    await asyncio.sleep(0)
     conn2.cancel()
 
     with pytest.raises(asyncio.CancelledError):
         await conn2
 
 
-async def test_error_on_connection_with_cancelled_waiter(loop, key) -> None:
-    conn = aiohttp.BaseConnector(limit=1, loop=loop)
+async def test_error_on_connection_with_cancelled_waiter(
+        loop, key) -> None:
+
+    conn = aiohttp.BaseConnector(limit=1)
 
     req = mock.Mock()
     req.connection_key = key
-    proto = mock.Mock()
+    proto = create_mocked_conn()
     i = 0
 
     fut1 = loop.create_future()
     fut2 = loop.create_future()
     exc = OSError()
 
     async def create_connection(req, traces, timeout):
@@ -1913,15 +1927,15 @@
             return proto
 
     conn._create_connection = create_connection
 
     t1 = loop.create_task(conn.connect(req, None, ClientTimeout()))
     t2 = loop.create_task(conn.connect(req, None, ClientTimeout()))
     t3 = loop.create_task(conn.connect(req, None, ClientTimeout()))
-    await asyncio.sleep(0, loop=loop)
+    await asyncio.sleep(0)
     assert not t1.done()
     assert not t2.done()
     assert len(conn._acquired_per_host[key]) == 1
 
     fut1.set_result(None)
     fut2.cancel()
     with pytest.raises(OSError):
@@ -1948,40 +1962,79 @@
     app.router.add_get('/', handler)
     client = await aiohttp_client(app)
 
     r = await client.get('/')
     assert r.status == 200
 
 
-@pytest.mark.skipif(not hasattr(socket, 'AF_UNIX'),
-                    reason="requires unix socket")
+@needs_unix
 async def test_unix_connector_not_found(loop) -> None:
-    connector = aiohttp.UnixConnector('/' + uuid.uuid4().hex, loop=loop)
+    connector = aiohttp.UnixConnector('/' + uuid.uuid4().hex)
 
     req = ClientRequest(
         'GET', URL('http://www.python.org'),
         loop=loop)
     with pytest.raises(aiohttp.ClientConnectorError):
         await connector.connect(req, None, ClientTimeout())
 
 
-@pytest.mark.skipif(not hasattr(socket, 'AF_UNIX'),
-                    reason="requires unix socket")
+@needs_unix
 async def test_unix_connector_permission(loop) -> None:
     loop.create_unix_connection = make_mocked_coro(
         raise_exception=PermissionError())
-    connector = aiohttp.UnixConnector('/' + uuid.uuid4().hex, loop=loop)
+    connector = aiohttp.UnixConnector('/' + uuid.uuid4().hex)
 
     req = ClientRequest(
         'GET', URL('http://www.python.org'),
         loop=loop)
     with pytest.raises(aiohttp.ClientConnectorError):
         await connector.connect(req, None, ClientTimeout())
 
 
+@pytest.mark.skipif(platform.system() != "Windows",
+                    reason="Proactor Event loop present only in Windows")
+async def test_named_pipe_connector_wrong_loop(pipe_name) -> None:
+    with pytest.raises(RuntimeError):
+        aiohttp.NamedPipeConnector(pipe_name)
+
+
+@pytest.mark.skipif(platform.system() != "Windows",
+                    reason="Proactor Event loop present only in Windows")
+async def test_named_pipe_connector_not_found(
+    proactor_loop,
+    pipe_name
+) -> None:
+    asyncio.set_event_loop(proactor_loop)
+    connector = aiohttp.NamedPipeConnector(pipe_name)
+
+    req = ClientRequest(
+        'GET', URL('http://www.python.org'),
+        loop=proactor_loop)
+    with pytest.raises(aiohttp.ClientConnectorError):
+        await connector.connect(req, None, ClientTimeout())
+
+
+@pytest.mark.skipif(platform.system() != "Windows",
+                    reason="Proactor Event loop present only in Windows")
+async def test_named_pipe_connector_permission(
+    proactor_loop,
+    pipe_name
+) -> None:
+    proactor_loop.create_pipe_connection = make_mocked_coro(
+        raise_exception=PermissionError()
+    )
+    asyncio.set_event_loop(proactor_loop)
+    connector = aiohttp.NamedPipeConnector(pipe_name)
+
+    req = ClientRequest('GET', URL('http://www.python.org'),
+                        loop=proactor_loop)
+    with pytest.raises(aiohttp.ClientConnectorError):
+        await connector.connect(req, None, ClientTimeout())
+
+
 async def test_default_use_dns_cache() -> None:
     conn = aiohttp.TCPConnector()
     assert conn.use_dns_cache
 
 
 async def test_resolver_not_called_with_address_is_ip(loop) -> None:
     resolver = mock.MagicMock()
@@ -2058,15 +2111,15 @@
     except AttributeError:
         _sslcontext = first_conn.transport._sslcontext
 
     assert _sslcontext is client_ssl_ctx
     r.close()
 
     await session.close()
-    conn.close()
+    await conn.close()
 
 
 async def test_tcp_connector_uses_provided_local_addr(aiohttp_server) -> None:
     async def handler(request):
         return web.Response()
 
     app = web.Application()
@@ -2083,19 +2136,17 @@
     r.release()
 
     first_conn = next(iter(conn._conns.values()))[0][0]
     assert first_conn.transport.get_extra_info(
         'sockname') == ('127.0.0.1', port)
     r.close()
     await session.close()
-    conn.close()
+    await conn.close()
 
 
-@pytest.mark.skipif(not hasattr(socket, 'AF_UNIX'),
-                    reason='requires UNIX sockets')
 async def test_unix_connector(unix_server, unix_sockname) -> None:
     async def handler(request):
         return web.Response()
 
     app = web.Application()
     app.router.add_get('/', handler)
     await unix_server(app)
@@ -2108,14 +2159,40 @@
     session = client.ClientSession(connector=connector)
     r = await session.get(url)
     assert r.status == 200
     r.close()
     await session.close()
 
 
+@pytest.mark.skipif(platform.system() != "Windows",
+                    reason="Proactor Event loop present only in Windows")
+async def test_named_pipe_connector(
+    proactor_loop,
+    named_pipe_server,
+    pipe_name
+) -> None:
+    async def handler(request):
+        return web.Response()
+
+    app = web.Application()
+    app.router.add_get('/', handler)
+    await named_pipe_server(app)
+
+    url = "http://this-does-not-matter.com"
+
+    connector = aiohttp.NamedPipeConnector(pipe_name)
+    assert pipe_name == connector.path
+
+    session = client.ClientSession(connector=connector)
+    r = await session.get(url)
+    assert r.status == 200
+    r.close()
+    await session.close()
+
+
 class TestDNSCacheTable:
 
     @pytest.fixture
     def dns_cache_table(self):
         return _DNSCacheTable()
 
     def test_next_addrs_basic(self, dns_cache_table) -> None:
@@ -2149,15 +2226,15 @@
         dns_cache_table = _DNSCacheTable(ttl=0.1)
         dns_cache_table.add('localhost', ['127.0.0.1'])
         assert not dns_cache_table.expired('localhost')
 
     async def test_expired_ttl(self, loop) -> None:
         dns_cache_table = _DNSCacheTable(ttl=0.01)
         dns_cache_table.add('localhost', ['127.0.0.1'])
-        await asyncio.sleep(0.02, loop=loop)
+        await asyncio.sleep(0.02)
         assert dns_cache_table.expired('localhost')
 
     def test_next_addrs(self, dns_cache_table) -> None:
         dns_cache_table.add('foo', ['127.0.0.1', '127.0.0.2', '127.0.0.3'])
 
         # Each calls to next_addrs return the hosts using
         # a round robin strategy.
@@ -2177,7 +2254,36 @@
         dns_cache_table.add('foo', ['127.0.0.1'])
 
         addrs = dns_cache_table.next_addrs('foo')
         assert addrs == ['127.0.0.1']
 
         addrs = dns_cache_table.next_addrs('foo')
         assert addrs == ['127.0.0.1']
+
+
+async def test_connector_cache_trace_race():
+    class DummyTracer:
+        async def send_dns_cache_hit(self, *args, **kwargs):
+            connector._cached_hosts.remove(("", 0))
+
+    token = object()
+    connector = TCPConnector()
+    connector._cached_hosts.add(("", 0), [token])
+
+    traces = [DummyTracer()]
+    assert await connector._resolve_host("", 0, traces) == [token]
+
+
+async def test_connector_throttle_trace_race(loop):
+    key = ("", 0)
+    token = object()
+
+    class DummyTracer:
+        async def send_dns_cache_hit(self, *args, **kwargs):
+            event = connector._throttle_dns_events.pop(key)
+            event.set()
+            connector._cached_hosts.add(key, [token])
+
+    connector = TCPConnector()
+    connector._throttle_dns_events[key] = EventResultOrError(loop)
+    traces = [DummyTracer()]
+    assert await connector._resolve_host("", 0, traces) == [token]
```

### Comparing `aiohttp-4.0.0a0/tests/test_cookiejar.py` & `aiohttp-4.0.0a1/tests/test_cookiejar.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 import asyncio
 import datetime
 import itertools
-import os
-import tempfile
+import pathlib
 import unittest
 from http.cookies import SimpleCookie
 from unittest import mock
 
 import pytest
+from freezegun import freeze_time
 from yarl import URL
 
 from aiohttp import CookieJar, DummyCookieJar
 
 
 @pytest.fixture
 def cookies_to_send():
@@ -25,14 +25,40 @@
         "secure-cookie=seventh; Domain=secure.com; Secure; "
         "no-path-cookie=eighth; Domain=pathtest.com; "
         "path1-cookie=nineth; Domain=pathtest.com; Path=/; "
         "path2-cookie=tenth; Domain=pathtest.com; Path=/one; "
         "path3-cookie=eleventh; Domain=pathtest.com; Path=/one/two; "
         "path4-cookie=twelfth; Domain=pathtest.com; Path=/one/two/; "
         "expires-cookie=thirteenth; Domain=expirestest.com; Path=/;"
+        " Expires=Tue, 1 Jan 2039 12:00:00 GMT; "
+        "max-age-cookie=fourteenth; Domain=maxagetest.com; Path=/;"
+        " Max-Age=60; "
+        "invalid-max-age-cookie=fifteenth; Domain=invalid-values.com; "
+        " Max-Age=string; "
+        "invalid-expires-cookie=sixteenth; Domain=invalid-values.com; "
+        " Expires=string;"
+    )
+
+
+@pytest.fixture
+def cookies_to_send_with_expired():
+    return SimpleCookie(
+        "shared-cookie=first; "
+        "domain-cookie=second; Domain=example.com; "
+        "subdomain1-cookie=third; Domain=test1.example.com; "
+        "subdomain2-cookie=fourth; Domain=test2.example.com; "
+        "dotted-domain-cookie=fifth; Domain=.example.com; "
+        "different-domain-cookie=sixth; Domain=different.org; "
+        "secure-cookie=seventh; Domain=secure.com; Secure; "
+        "no-path-cookie=eighth; Domain=pathtest.com; "
+        "path1-cookie=nineth; Domain=pathtest.com; Path=/; "
+        "path2-cookie=tenth; Domain=pathtest.com; Path=/one; "
+        "path3-cookie=eleventh; Domain=pathtest.com; Path=/one/two; "
+        "path4-cookie=twelfth; Domain=pathtest.com; Path=/one/two/; "
+        "expires-cookie=thirteenth; Domain=expirestest.com; Path=/;"
         " Expires=Tue, 1 Jan 1980 12:00:00 GMT; "
         "max-age-cookie=fourteenth; Domain=maxagetest.com; Path=/;"
         " Max-Age=60; "
         "invalid-max-age-cookie=fifteenth; Domain=invalid-values.com; "
         " Max-Age=string; "
         "invalid-expires-cookie=sixteenth; Domain=invalid-values.com; "
         " Expires=string;"
@@ -130,50 +156,63 @@
     assert not test_func("/file", "/folder/file")
     assert not test_func("/folder/", "/folder/file")
     assert not test_func("/different-file", "/file")
     assert not test_func("/different-folder/", "/folder/")
 
 
 async def test_constructor(loop, cookies_to_send, cookies_to_receive) -> None:
-    jar = CookieJar(loop=loop)
+    jar = CookieJar()
     jar.update_cookies(cookies_to_send)
     jar_cookies = SimpleCookie()
     for cookie in jar:
         dict.__setitem__(jar_cookies, cookie.key, cookie)
     expected_cookies = cookies_to_send
     assert jar_cookies == expected_cookies
     assert jar._loop is loop
 
 
-async def test_save_load(loop, cookies_to_send, cookies_to_receive) -> None:
-    file_path = tempfile.mkdtemp() + '/aiohttp.test.cookie'
+async def test_constructor_with_expired(loop, cookies_to_send_with_expired,
+                                        cookies_to_receive) -> None:
+    jar = CookieJar()
+    jar.update_cookies(cookies_to_send_with_expired)
+    jar_cookies = SimpleCookie()
+    for cookie in jar:
+        dict.__setitem__(jar_cookies, cookie.key, cookie)
+    expected_cookies = cookies_to_send_with_expired
+    assert jar_cookies != expected_cookies
+    assert jar._loop is loop
+
+
+async def test_save_load(
+    tmp_path, loop, cookies_to_send, cookies_to_receive
+) -> None:
+    file_path = pathlib.Path(str(tmp_path)) / 'aiohttp.test.cookie'
 
     # export cookie jar
-    jar_save = CookieJar(loop=loop)
+    jar_save = CookieJar()
     jar_save.update_cookies(cookies_to_receive)
     jar_save.save(file_path=file_path)
 
-    jar_load = CookieJar(loop=loop)
+    jar_load = CookieJar()
     jar_load.load(file_path=file_path)
 
     jar_test = SimpleCookie()
     for cookie in jar_load:
         jar_test[cookie.key] = cookie
 
-    os.unlink(file_path)
     assert jar_test == cookies_to_receive
 
 
 async def test_update_cookie_with_unicode_domain(loop) -> None:
     cookies = (
         "idna-domain-first=first; Domain=xn--9caa.com; Path=/;",
         "idna-domain-second=second; Domain=xn--9caa.com; Path=/;",
     )
 
-    jar = CookieJar(loop=loop)
+    jar = CookieJar()
     jar.update_cookies(SimpleCookie(cookies[0]), URL("http://.com/"))
     jar.update_cookies(SimpleCookie(cookies[1]), URL("http://xn--9caa.com/"))
 
     jar_test = SimpleCookie()
     for cookie in jar:
         jar_test[cookie.key] = cookie
 
@@ -185,16 +224,22 @@
     jar.update_cookies(SimpleCookie(
         "idna-domain-first=first; Domain=xn--9caa.com; Path=/; "
     ))
     assert len(jar.filter_cookies(URL("http://.com"))) == 1
     assert len(jar.filter_cookies(URL("http://xn--9caa.com"))) == 1
 
 
+async def test_filter_cookies_str_deprecated(loop) -> None:
+    jar = CookieJar()
+    with pytest.warns(DeprecationWarning):
+        jar.filter_cookies("http://.com")
+
+
 async def test_domain_filter_ip_cookie_send(loop) -> None:
-    jar = CookieJar(loop=loop)
+    jar = CookieJar()
     cookies = SimpleCookie(
         "shared-cookie=first; "
         "domain-cookie=second; Domain=example.com; "
         "subdomain1-cookie=third; Domain=test1.example.com; "
         "subdomain2-cookie=fourth; Domain=test2.example.com; "
         "dotted-domain-cookie=fifth; Domain=.example.com; "
         "different-domain-cookie=sixth; Domain=different.org; "
@@ -224,37 +269,37 @@
     jar = CookieJar()
 
     jar.update_cookies(cookies_to_receive, URL("http://1.2.3.4/"))
     assert len(jar) == 0
 
 
 async def test_preserving_ip_domain_cookies(loop) -> None:
-    jar = CookieJar(loop=loop, unsafe=True)
+    jar = CookieJar(unsafe=True)
     jar.update_cookies(SimpleCookie(
         "shared-cookie=first; "
         "ip-cookie=second; Domain=127.0.0.1;"
     ))
     cookies_sent = jar.filter_cookies(URL("http://127.0.0.1/")).output(
         header='Cookie:')
     assert cookies_sent == ('Cookie: ip-cookie=second\r\n'
                             'Cookie: shared-cookie=first')
 
 
 async def test_preserving_quoted_cookies(loop) -> None:
-    jar = CookieJar(loop=loop, unsafe=True)
+    jar = CookieJar(unsafe=True)
     jar.update_cookies(SimpleCookie(
         "ip-cookie=\"second\"; Domain=127.0.0.1;"
     ))
     cookies_sent = jar.filter_cookies(URL("http://127.0.0.1/")).output(
         header='Cookie:')
     assert cookies_sent == 'Cookie: ip-cookie=\"second\"'
 
 
 async def test_ignore_domain_ending_with_dot(loop) -> None:
-    jar = CookieJar(loop=loop, unsafe=True)
+    jar = CookieJar(unsafe=True)
     jar.update_cookies(SimpleCookie("cookie=val; Domain=example.com.;"),
                        URL("http://www.example.com"))
     cookies_sent = jar.filter_cookies(URL("http://www.example.com/"))
     assert cookies_sent.output(header='Cookie:') == "Cookie: cookie=val"
     cookies_sent = jar.filter_cookies(URL("http://example.com/"))
     assert cookies_sent.output(header='Cookie:') == ""
 
@@ -330,18 +375,27 @@
         )
 
         async def make_jar():
             return CookieJar()
         self.jar = self.loop.run_until_complete(make_jar())
 
     def timed_request(self, url, update_time, send_time):
-        with mock.patch.object(self.loop, 'time', return_value=update_time):
+        if isinstance(update_time, int):
+            update_time = datetime.timedelta(seconds=update_time)
+        elif isinstance(update_time, float):
+            update_time = datetime.datetime.fromtimestamp(update_time)
+        if isinstance(send_time, int):
+            send_time = datetime.timedelta(seconds=send_time)
+        elif isinstance(send_time, float):
+            send_time = datetime.datetime.fromtimestamp(send_time)
+
+        with freeze_time(update_time):
             self.jar.update_cookies(self.cookies_to_send)
 
-        with mock.patch.object(self.loop, 'time', return_value=send_time):
+        with freeze_time(send_time):
             cookies_sent = self.jar.filter_cookies(URL(url))
 
         self.jar.clear()
 
         return cookies_sent
 
     def test_domain_filter_same_host(self) -> None:
```

### Comparing `aiohttp-4.0.0a0/tests/test_flowcontrol_streams.py` & `aiohttp-4.0.0a1/tests/test_flowcontrol_streams.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/tests/test_formdata.py` & `aiohttp-4.0.0a1/tests/test_formdata.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/tests/test_frozenlist.py` & `aiohttp-4.0.0a1/tests/test_frozenlist.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/tests/test_helpers.py` & `aiohttp-4.0.0a1/tests/test_helpers.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 import asyncio
 import base64
 import gc
 import os
 import platform
-import tempfile
 from unittest import mock
 
 import pytest
 from multidict import MultiDict
 from yarl import URL
 
 from aiohttp import helpers
+from aiohttp.helpers import is_expected_content_type
 
 IS_PYPY = platform.python_implementation() == 'PyPy'
 
 
 # ------------------- parse_mimetype ----------------------------------
 
 @pytest.mark.parametrize('mimetype, expected', [
@@ -41,19 +41,29 @@
 
     assert isinstance(result, helpers.MimeType)
     assert result == expected
 
 
 # ------------------- guess_filename ----------------------------------
 
-def test_guess_filename_with_tempfile() -> None:
-    with tempfile.TemporaryFile() as fp:
+def test_guess_filename_with_file_object(tmp_path) -> None:
+    file_path = tmp_path / 'test_guess_filename'
+    with file_path.open('w+b') as fp:
         assert (helpers.guess_filename(fp, 'no-throw') is not None)
 
 
+def test_guess_filename_with_path(tmp_path) -> None:
+    file_path = tmp_path / 'test_guess_filename'
+    assert (helpers.guess_filename(file_path, 'no-throw') is not None)
+
+
+def test_guess_filename_with_default() -> None:
+    assert (helpers.guess_filename(None, 'no-throw') == 'no-throw')
+
+
 # ------------------- BasicAuth -----------------------------------
 
 def test_basic_auth1() -> None:
     # missing password here
     with pytest.raises(ValueError):
         helpers.BasicAuth(None)
 
@@ -330,24 +340,24 @@
 
 # -------------------------------- CeilTimeout --------------------------
 
 
 async def test_weakref_handle(loop) -> None:
     cb = mock.Mock()
     helpers.weakref_handle(cb, 'test', 0.01, loop, False)
-    await asyncio.sleep(0.1, loop=loop)
+    await asyncio.sleep(0.1)
     assert cb.test.called
 
 
 async def test_weakref_handle_weak(loop) -> None:
     cb = mock.Mock()
     helpers.weakref_handle(cb, 'test', 0.01, loop, False)
     del cb
     gc.collect()
-    await asyncio.sleep(0.1, loop=loop)
+    await asyncio.sleep(0.1)
 
 
 def test_ceil_call_later() -> None:
     cb = mock.Mock()
     loop = mock.Mock()
     loop.time.return_value = 10.1
     helpers.call_later(cb, 10.1, loop)
@@ -443,15 +453,17 @@
     assert proxy_auth.password == 'pass'
     assert proxy_auth.encoding == 'latin1'
 
 # ------------ get_running_loop ---------------------------------
 
 
 def test_get_running_loop_not_running(loop) -> None:
-    with pytest.warns(DeprecationWarning):
+    with pytest.raises(
+            RuntimeError,
+            match="The object should be created from async function"):
         helpers.get_running_loop()
 
 
 async def test_get_running_loop_ok(loop) -> None:
     assert helpers.get_running_loop() is loop
 
 
@@ -557,7 +569,35 @@
 
     def test_repr(self) -> None:
         d1 = {'a': 2, 'b': 3}
         d2 = {'a': 1}
         cp = helpers.ChainMapProxy([d1, d2])
         expected = "ChainMapProxy({!r}, {!r})".format(d1, d2)
         assert expected == repr(cp)
+
+
+def test_is_expected_content_type_json_match_exact():
+    expected_ct = 'application/json'
+    response_ct = 'application/json'
+    assert is_expected_content_type(response_content_type=response_ct,
+                                    expected_content_type=expected_ct)
+
+
+def test_is_expected_content_type_json_match_partially():
+    expected_ct = 'application/json'
+    response_ct = 'application/alto-costmap+json'  # mime-type from rfc7285
+    assert is_expected_content_type(response_content_type=response_ct,
+                                    expected_content_type=expected_ct)
+
+
+def test_is_expected_content_type_non_json_match_exact():
+    expected_ct = 'text/javascript'
+    response_ct = 'text/javascript'
+    assert is_expected_content_type(response_content_type=response_ct,
+                                    expected_content_type=expected_ct)
+
+
+def test_is_expected_content_type_non_json_not_match():
+    expected_ct = 'application/json'
+    response_ct = 'text/plain'
+    assert not is_expected_content_type(response_content_type=response_ct,
+                                        expected_content_type=expected_ct)
```

### Comparing `aiohttp-4.0.0a0/tests/test_http_parser.py` & `aiohttp-4.0.0a1/tests/test_http_parser.py`

 * *Files 0% similar despite different names*

```diff
@@ -622,15 +622,15 @@
 
 
 def test_http_response_parser_no_reason(response) -> None:
     msg = response.feed_data(b'HTTP/1.1 200\r\n\r\n')[0][0][0]
 
     assert msg.version == (1, 1)
     assert msg.code == 200
-    assert not msg.reason
+    assert msg.reason == ''
 
 
 def test_http_response_parser_bad(response) -> None:
     with pytest.raises(http_exceptions.BadHttpMessage):
         response.feed_data(b'HTT/1\r\n\r\n')
```

### Comparing `aiohttp-4.0.0a0/tests/test_http_writer.py` & `aiohttp-4.0.0a1/tests/test_http_writer.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/tests/test_locks.py` & `aiohttp-4.0.0a1/tests/test_locks.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/tests/test_loop.py` & `aiohttp-4.0.0a1/tests/test_loop.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/tests/test_multipart.py` & `aiohttp-4.0.0a1/tests/test_multipart.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 import asyncio
 import io
 import json
+import pathlib
 import zlib
 from unittest import mock
 
 import pytest
 
 import aiohttp
 from aiohttp import payload
@@ -19,14 +20,19 @@
 from aiohttp.streams import DEFAULT_LIMIT as stream_reader_default_limit
 from aiohttp.streams import StreamReader
 from aiohttp.test_utils import make_mocked_coro
 
 BOUNDARY = b'--:'
 
 
+def pytest_generate_tests(metafunc):  # pragma: no cover
+    if "newline" in metafunc.fixturenames:
+        metafunc.parametrize("newline", [b'\r\n', b'\n'], ids=str)
+
+
 @pytest.fixture
 def buf():
     return bytearray()
 
 
 @pytest.fixture
 def stream(buf):
@@ -114,627 +120,830 @@
         await wrapper.next()
         assert wrapper.stream.next.called
         assert wrapper.resp.release.called
 
 
 class TestPartReader:
 
-    async def test_next(self) -> None:
+    async def test_next(self, newline) -> None:
+        data = b'Hello, world!%s--:' % newline
         obj = aiohttp.BodyPartReader(
-            BOUNDARY, {}, Stream(b'Hello, world!\r\n--:'))
+            BOUNDARY, {}, Stream(data), _newline=newline
+        )
         result = await obj.next()
         assert b'Hello, world!' == result
         assert obj.at_eof()
 
-    async def test_next_next(self) -> None:
+    async def test_next_next(self, newline) -> None:
+        data = b'Hello, world!%s--:' % newline
         obj = aiohttp.BodyPartReader(
-            BOUNDARY, {}, Stream(b'Hello, world!\r\n--:'))
+            BOUNDARY, {}, Stream(data), _newline=newline
+        )
         result = await obj.next()
         assert b'Hello, world!' == result
         assert obj.at_eof()
         result = await obj.next()
         assert result is None
 
-    async def test_read(self) -> None:
+    async def test_read(self, newline) -> None:
+        data = b'Hello, world!%s--:' % newline
         obj = aiohttp.BodyPartReader(
-            BOUNDARY, {}, Stream(b'Hello, world!\r\n--:'))
+            BOUNDARY, {}, Stream(data), _newline=newline
+        )
         result = await obj.read()
         assert b'Hello, world!' == result
         assert obj.at_eof()
 
     async def test_read_chunk_at_eof(self) -> None:
-        obj = aiohttp.BodyPartReader(
-            BOUNDARY, {}, Stream(b'--:'))
+        obj = aiohttp.BodyPartReader(BOUNDARY, {}, Stream(b'--:'))
         obj._at_eof = True
         result = await obj.read_chunk()
         assert b'' == result
 
-    async def test_read_chunk_without_content_length(self) -> None:
+    async def test_read_chunk_without_content_length(self, newline) -> None:
+        data = b'Hello, world!%s--:' % newline
         obj = aiohttp.BodyPartReader(
-            BOUNDARY, {}, Stream(b'Hello, world!\r\n--:'))
+            BOUNDARY, {}, Stream(data), _newline=newline
+        )
         c1 = await obj.read_chunk(8)
         c2 = await obj.read_chunk(8)
         c3 = await obj.read_chunk(8)
         assert c1 + c2 == b'Hello, world!'
         assert c3 == b''
 
-    async def test_read_incomplete_chunk(self) -> None:
+    async def test_read_incomplete_chunk(self, newline) -> None:
         loop = asyncio.get_event_loop()
         stream = Stream(b'')
 
         def prepare(data):
             f = loop.create_future()
             f.set_result(data)
             return f
 
         with mock.patch.object(stream, 'read', side_effect=[
             prepare(b'Hello, '),
             prepare(b'World'),
-            prepare(b'!\r\n--:'),
+            prepare(b'!%s--:' % newline),
             prepare(b'')
         ]):
             obj = aiohttp.BodyPartReader(
-                BOUNDARY, {}, stream)
+                BOUNDARY, {}, stream, _newline=newline
+            )
             c1 = await obj.read_chunk(8)
             assert c1 == b'Hello, '
             c2 = await obj.read_chunk(8)
             assert c2 == b'World'
             c3 = await obj.read_chunk(8)
             assert c3 == b'!'
 
-    async def test_read_all_at_once(self) -> None:
-        stream = Stream(b'Hello, World!\r\n--:--\r\n')
-        obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)
+    async def test_read_all_at_once(self, newline) -> None:
+        data = b'Hello, World!%s--:--%s' % (newline, newline)
+        obj = aiohttp.BodyPartReader(
+            BOUNDARY, {}, Stream(data), _newline=newline
+        )
         result = await obj.read_chunk()
         assert b'Hello, World!' == result
         result = await obj.read_chunk()
         assert b'' == result
         assert obj.at_eof()
 
-    async def test_read_incomplete_body_chunked(self) -> None:
-        stream = Stream(b'Hello, World!\r\n-')
-        obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)
+    async def test_read_incomplete_body_chunked(self, newline) -> None:
+        data = b'Hello, World!%s--' % newline
+        obj = aiohttp.BodyPartReader(
+            BOUNDARY, {}, Stream(data), _newline=newline
+        )
         result = b''
         with pytest.raises(AssertionError):
             for _ in range(4):
                 result += await obj.read_chunk(7)
-        assert b'Hello, World!\r\n-' == result
+        assert data == result
 
-    async def test_read_boundary_with_incomplete_chunk(self) -> None:
+    async def test_read_boundary_with_incomplete_chunk(self, newline) -> None:
         loop = asyncio.get_event_loop()
         stream = Stream(b'')
 
         def prepare(data):
             f = loop.create_future()
             f.set_result(data)
             return f
 
         with mock.patch.object(stream, 'read', side_effect=[
             prepare(b'Hello, World'),
-            prepare(b'!\r\n'),
+            prepare(b'!%s' % newline),
             prepare(b'--:'),
             prepare(b'')
         ]):
             obj = aiohttp.BodyPartReader(
-                BOUNDARY, {}, stream)
+                BOUNDARY, {}, stream, _newline=newline
+            )
             c1 = await obj.read_chunk(12)
             assert c1 == b'Hello, World'
             c2 = await obj.read_chunk(8)
             assert c2 == b'!'
             c3 = await obj.read_chunk(8)
             assert c3 == b''
 
-    async def test_multi_read_chunk(self) -> None:
-        stream = Stream(b'Hello,\r\n--:\r\n\r\nworld!\r\n--:--')
-        obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream)
+    async def test_multi_read_chunk(self, newline) -> None:
+        data = b'Hello,%s--:%s%sworld!%s--:--' % ((newline,) * 4)
+        obj = aiohttp.BodyPartReader(
+            BOUNDARY, {}, Stream(data), _newline=newline
+        )
         result = await obj.read_chunk(8)
         assert b'Hello,' == result
         result = await obj.read_chunk(8)
         assert b'' == result
         assert obj.at_eof()
 
-    async def test_read_chunk_properly_counts_read_bytes(self) -> None:
+    async def test_read_chunk_properly_counts_read_bytes(
+        self, newline
+    ) -> None:
         expected = b'.' * 10
+        tail = b'%s--:--' % newline
         size = len(expected)
         obj = aiohttp.BodyPartReader(
             BOUNDARY, {'CONTENT-LENGTH': size},
-            StreamWithShortenRead(expected + b'\r\n--:--'))
+            StreamWithShortenRead(expected + tail),
+            _newline=newline,
+        )
         result = bytearray()
         while True:
             chunk = await obj.read_chunk()
             if not chunk:
                 break
             result.extend(chunk)
         assert size == len(result)
         assert b'.' * size == result
         assert obj.at_eof()
 
-    async def test_read_does_not_read_boundary(self) -> None:
-        stream = Stream(b'Hello, world!\r\n--:')
-        obj = aiohttp.BodyPartReader(
-            BOUNDARY, {}, stream)
+    async def test_read_does_not_read_boundary(self, newline) -> None:
+        data = b'Hello, world!%s--:' % newline
+        stream = Stream(data)
+        obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream, _newline=newline)
         result = await obj.read()
         assert b'Hello, world!' == result
         assert b'--:' == (await stream.read())
 
-    async def test_multiread(self) -> None:
+    async def test_multiread(self, newline) -> None:
+        data = b'Hello,%s--:%s%sworld!%s--:--' % ((newline,) * 4)
         obj = aiohttp.BodyPartReader(
-            BOUNDARY, {}, Stream(b'Hello,\r\n--:\r\n\r\nworld!\r\n--:--'))
+            BOUNDARY, {}, Stream(data), _newline=newline
+        )
         result = await obj.read()
         assert b'Hello,' == result
         result = await obj.read()
         assert b'' == result
         assert obj.at_eof()
 
-    async def test_read_multiline(self) -> None:
+    async def test_read_multiline(self, newline) -> None:
+        data = b'Hello\n,\r\nworld!%s--:--' % newline
         obj = aiohttp.BodyPartReader(
-            BOUNDARY, {}, Stream(b'Hello\n,\r\nworld!\r\n--:--'))
+            BOUNDARY, {}, Stream(data), _newline=newline
+        )
         result = await obj.read()
         assert b'Hello\n,\r\nworld!' == result
         result = await obj.read()
         assert b'' == result
         assert obj.at_eof()
 
-    async def test_read_respects_content_length(self) -> None:
+    async def test_read_respects_content_length(self, newline) -> None:
+        data = b'.' * 100500
+        tail = b'%s--:--' % newline
         obj = aiohttp.BodyPartReader(
-            BOUNDARY, {'CONTENT-LENGTH': 100500},
-            Stream(b'.' * 100500 + b'\r\n--:--'))
+            BOUNDARY,
+            {'CONTENT-LENGTH': 100500},
+            Stream(data + tail),
+            _newline=newline,
+        )
         result = await obj.read()
-        assert b'.' * 100500 == result
+        assert data == result
         assert obj.at_eof()
 
-    async def test_read_with_content_encoding_gzip(self) -> None:
+    async def test_read_with_content_encoding_gzip(self, newline) -> None:
         obj = aiohttp.BodyPartReader(
             BOUNDARY, {CONTENT_ENCODING: 'gzip'},
             Stream(b'\x1f\x8b\x08\x00\x00\x00\x00\x00\x00\x03\x0b\xc9\xccMU'
                    b'(\xc9W\x08J\xcdI\xacP\x04\x00$\xfb\x9eV\x0e\x00\x00\x00'
-                   b'\r\n--:--'))
+                   b'%s--:--' % newline),
+            _newline=newline,
+        )
         result = await obj.read(decode=True)
         assert b'Time to Relax!' == result
 
-    async def test_read_with_content_encoding_deflate(self) -> None:
+    async def test_read_with_content_encoding_deflate(self, newline) -> None:
+        data = b'\x0b\xc9\xccMU(\xc9W\x08J\xcdI\xacP\x04\x00'
+        tail = b'%s--:--' % newline
         obj = aiohttp.BodyPartReader(
             BOUNDARY, {CONTENT_ENCODING: 'deflate'},
-            Stream(b'\x0b\xc9\xccMU(\xc9W\x08J\xcdI\xacP\x04\x00\r\n--:--'))
+            Stream(data + tail),
+            _newline=newline,
+        )
         result = await obj.read(decode=True)
         assert b'Time to Relax!' == result
 
-    async def test_read_with_content_encoding_identity(self) -> None:
+    async def test_read_with_content_encoding_identity(self, newline) -> None:
         thing = (b'\x1f\x8b\x08\x00\x00\x00\x00\x00\x00\x03\x0b\xc9\xccMU'
-                 b'(\xc9W\x08J\xcdI\xacP\x04\x00$\xfb\x9eV\x0e\x00\x00\x00'
-                 b'\r\n')
+                 b'(\xc9W\x08J\xcdI\xacP\x04\x00$\xfb\x9eV\x0e\x00\x00\x00')
         obj = aiohttp.BodyPartReader(
             BOUNDARY, {CONTENT_ENCODING: 'identity'},
-            Stream(thing + b'--:--'))
+            Stream(thing + b'%s--:--' % newline),
+            _newline=newline,
+        )
         result = await obj.read(decode=True)
-        assert thing[:-2] == result
+        assert thing == result
 
-    async def test_read_with_content_encoding_unknown(self) -> None:
+    async def test_read_with_content_encoding_unknown(self, newline) -> None:
         obj = aiohttp.BodyPartReader(
             BOUNDARY, {CONTENT_ENCODING: 'snappy'},
-            Stream(b'\x0e4Time to Relax!\r\n--:--'))
+            Stream(b'\x0e4Time to Relax!%s--:--' % newline),
+            _newline=newline,
+        )
         with pytest.raises(RuntimeError):
             await obj.read(decode=True)
 
-    async def test_read_with_content_transfer_encoding_base64(self) -> None:
+    async def test_read_with_content_transfer_encoding_base64(
+        self, newline
+    ) -> None:
         obj = aiohttp.BodyPartReader(
             BOUNDARY, {CONTENT_TRANSFER_ENCODING: 'base64'},
-            Stream(b'VGltZSB0byBSZWxheCE=\r\n--:--'))
+            Stream(b'VGltZSB0byBSZWxheCE=%s--:--' % newline),
+            _newline=newline,
+        )
         result = await obj.read(decode=True)
         assert b'Time to Relax!' == result
 
+    async def test_decode_with_content_transfer_encoding_base64(
+        self, newline
+    ) -> None:
+
+        obj = aiohttp.BodyPartReader(
+            BOUNDARY, {CONTENT_TRANSFER_ENCODING: 'base64'},
+            Stream(b'VG\r\r\nltZSB0byBSZ\r\nWxheCE=%s--:--' % newline),
+            _newline=newline,
+        )
+        result = b''
+        while not obj.at_eof():
+            chunk = await obj.read_chunk(size=6)
+            result += obj.decode(chunk)
+        assert b'Time to Relax!' == result
+
     async def test_read_with_content_transfer_encoding_quoted_printable(
-            self) -> None:
+        self, newline
+    ) -> None:
         obj = aiohttp.BodyPartReader(
             BOUNDARY, {CONTENT_TRANSFER_ENCODING: 'quoted-printable'},
             Stream(b'=D0=9F=D1=80=D0=B8=D0=B2=D0=B5=D1=82,'
-                   b' =D0=BC=D0=B8=D1=80!\r\n--:--'))
+                   b' =D0=BC=D0=B8=D1=80!%s--:--' % newline),
+            _newline=newline,
+        )
         result = await obj.read(decode=True)
         expected = (b'\xd0\x9f\xd1\x80\xd0\xb8\xd0\xb2\xd0\xb5\xd1\x82,'
                     b' \xd0\xbc\xd0\xb8\xd1\x80!')
         assert result == expected
 
     @pytest.mark.parametrize('encoding', ('binary', '8bit', '7bit'))
     async def test_read_with_content_transfer_encoding_binary(
-            self, encoding) -> None:
+        self, encoding, newline
+    ) -> None:
         data = b'\xd0\x9f\xd1\x80\xd0\xb8\xd0\xb2\xd0\xb5\xd1\x82,' \
                b' \xd0\xbc\xd0\xb8\xd1\x80!'
         obj = aiohttp.BodyPartReader(
             BOUNDARY, {CONTENT_TRANSFER_ENCODING: encoding},
-            Stream(data + b'\r\n--:--'))
+            Stream(data + b'%s--:--' % newline),
+            _newline=newline,
+        )
         result = await obj.read(decode=True)
         assert data == result
 
-    async def test_read_with_content_transfer_encoding_unknown(self) -> None:
+    async def test_read_with_content_transfer_encoding_unknown(
+        self, newline
+    ) -> None:
         obj = aiohttp.BodyPartReader(
             BOUNDARY, {CONTENT_TRANSFER_ENCODING: 'unknown'},
-            Stream(b'\x0e4Time to Relax!\r\n--:--'))
+            Stream(b'\x0e4Time to Relax!%s--:--' % newline),
+            _newline=newline,
+        )
         with pytest.raises(RuntimeError):
             await obj.read(decode=True)
 
-    async def test_read_text(self) -> None:
+    async def test_read_text(self, newline) -> None:
         obj = aiohttp.BodyPartReader(
-            BOUNDARY, {}, Stream(b'Hello, world!\r\n--:--'))
+            BOUNDARY,
+            {},
+            Stream(b'Hello, world!%s--:--' % newline),
+            _newline=newline,
+        )
         result = await obj.text()
         assert 'Hello, world!' == result
 
-    async def test_read_text_default_encoding(self) -> None:
+    async def test_read_text_default_encoding(self, newline) -> None:
+        data = ', !'
+        tail = b'%s--:--' % newline
         obj = aiohttp.BodyPartReader(
-            BOUNDARY, {},
-            Stream(', !\r\n--:--'.encode('utf-8')))
+            BOUNDARY,
+            {},
+            Stream(data.encode('utf-8') + tail),
+            _newline=newline,
+        )
         result = await obj.text()
-        assert ', !' == result
+        assert data == result
 
-    async def test_read_text_encoding(self) -> None:
+    async def test_read_text_encoding(self, newline) -> None:
+        data = ', !'
+        tail = b'%s--:--' % newline
         obj = aiohttp.BodyPartReader(
-            BOUNDARY, {},
-            Stream(', !\r\n--:--'.encode('cp1251')))
+            BOUNDARY,
+            {},
+            Stream(data.encode('cp1251') + tail),
+            _newline=newline,
+        )
         result = await obj.text(encoding='cp1251')
-        assert ', !' == result
+        assert data == result
 
-    async def test_read_text_guess_encoding(self) -> None:
+    async def test_read_text_guess_encoding(self, newline) -> None:
+        data = ', !'
+        tail = b'%s--:--' % newline
         obj = aiohttp.BodyPartReader(
-            BOUNDARY, {CONTENT_TYPE: 'text/plain;charset=cp1251'},
-            Stream(', !\r\n--:--'.encode('cp1251')))
+            BOUNDARY,
+            {CONTENT_TYPE: 'text/plain;charset=cp1251'},
+            Stream(data.encode('cp1251') + tail),
+            _newline=newline,
+        )
         result = await obj.text()
-        assert ', !' == result
+        assert data == result
 
-    async def test_read_text_compressed(self) -> None:
+    async def test_read_text_compressed(self, newline) -> None:
+        data = (
+            b'\x0b\xc9\xccMU(\xc9W\x08J\xcdI\xacP\x04\x00'
+            b'%s--:--' % newline
+        )
         obj = aiohttp.BodyPartReader(
-            BOUNDARY, {CONTENT_ENCODING: 'deflate',
-                       CONTENT_TYPE: 'text/plain'},
-            Stream(b'\x0b\xc9\xccMU(\xc9W\x08J\xcdI\xacP\x04\x00\r\n--:--'))
+            BOUNDARY,
+            {CONTENT_ENCODING: 'deflate', CONTENT_TYPE: 'text/plain'},
+            Stream(data),
+            _newline=newline,
+        )
         result = await obj.text()
         assert 'Time to Relax!' == result
 
     async def test_read_text_while_closed(self) -> None:
         obj = aiohttp.BodyPartReader(
             BOUNDARY, {CONTENT_TYPE: 'text/plain'}, Stream(b''))
         obj._at_eof = True
         result = await obj.text()
         assert '' == result
 
-    async def test_read_json(self) -> None:
+    async def test_read_json(self, newline) -> None:
         obj = aiohttp.BodyPartReader(
             BOUNDARY, {CONTENT_TYPE: 'application/json'},
-            Stream(b'{"test": "passed"}\r\n--:--'))
+            Stream(b'{"test": "passed"}%s--:--' % newline),
+            _newline=newline,
+        )
         result = await obj.json()
         assert {'test': 'passed'} == result
 
-    async def test_read_json_encoding(self) -> None:
+    async def test_read_json_encoding(self, newline) -> None:
+        data = '{"": ""}'.encode('cp1251')
+        tail = b'%s--:--' % newline
         obj = aiohttp.BodyPartReader(
             BOUNDARY, {CONTENT_TYPE: 'application/json'},
-            Stream('{"": ""}\r\n--:--'.encode('cp1251')))
+            Stream(data + tail),
+            _newline=newline,
+        )
         result = await obj.json(encoding='cp1251')
         assert {'': ''} == result
 
-    async def test_read_json_guess_encoding(self) -> None:
+    async def test_read_json_guess_encoding(self, newline) -> None:
+        data = '{"": ""}'.encode('cp1251')
+        tail = b'%s--:--' % newline
         obj = aiohttp.BodyPartReader(
             BOUNDARY, {CONTENT_TYPE: 'application/json; charset=cp1251'},
-            Stream('{"": ""}\r\n--:--'.encode('cp1251')))
+            Stream(data + tail),
+            _newline=newline,
+        )
         result = await obj.json()
         assert {'': ''} == result
 
-    async def test_read_json_compressed(self) -> None:
+    async def test_read_json_compressed(self, newline) -> None:
         obj = aiohttp.BodyPartReader(
             BOUNDARY, {CONTENT_ENCODING: 'deflate',
                        CONTENT_TYPE: 'application/json'},
-            Stream(b'\xabV*I-.Q\xb2RP*H,.NMQ\xaa\x05\x00\r\n--:--'))
+            Stream(b'\xabV*I-.Q\xb2RP*H,.NMQ\xaa\x05\x00'
+                   b'%s--:--' % newline),
+            _newline=newline,
+        )
         result = await obj.json()
         assert {'test': 'passed'} == result
 
     async def test_read_json_while_closed(self) -> None:
         stream = Stream(b'')
         obj = aiohttp.BodyPartReader(
             BOUNDARY, {CONTENT_TYPE: 'application/json'}, stream)
         obj._at_eof = True
         result = await obj.json()
         assert result is None
 
-    async def test_read_form(self) -> None:
+    async def test_read_form(self, newline) -> None:
+        data = b'foo=bar&foo=baz&boo=%s--:--' % newline
         obj = aiohttp.BodyPartReader(
             BOUNDARY, {CONTENT_TYPE: 'application/x-www-form-urlencoded'},
-            Stream(b'foo=bar&foo=baz&boo=\r\n--:--'))
+            Stream(data),
+            _newline=newline,
+        )
         result = await obj.form()
         assert [('foo', 'bar'), ('foo', 'baz'), ('boo', '')] == result
 
-    async def test_read_form_encoding(self) -> None:
+    async def test_read_form_encoding(self, newline) -> None:
+        data = b'foo=bar&foo=baz&boo=%s--:--' % newline
         obj = aiohttp.BodyPartReader(
             BOUNDARY, {CONTENT_TYPE: 'application/x-www-form-urlencoded'},
-            Stream('foo=bar&foo=baz&boo=\r\n--:--'.encode('cp1251')))
+            Stream(data),
+            _newline=newline,
+        )
         result = await obj.form(encoding='cp1251')
         assert [('foo', 'bar'), ('foo', 'baz'), ('boo', '')] == result
 
-    async def test_read_form_guess_encoding(self) -> None:
+    async def test_read_form_guess_encoding(self, newline) -> None:
+        data = b'foo=bar&foo=baz&boo=%s--:--' % newline
         obj = aiohttp.BodyPartReader(
             BOUNDARY,
             {CONTENT_TYPE: 'application/x-www-form-urlencoded; charset=utf-8'},
-            Stream('foo=bar&foo=baz&boo=\r\n--:--'.encode('utf-8')))
+            Stream(data),
+            _newline=newline,
+        )
         result = await obj.form()
         assert [('foo', 'bar'), ('foo', 'baz'), ('boo', '')] == result
 
     async def test_read_form_while_closed(self) -> None:
         stream = Stream(b'')
         obj = aiohttp.BodyPartReader(
             BOUNDARY,
-            {CONTENT_TYPE: 'application/x-www-form-urlencoded'}, stream)
+            {CONTENT_TYPE: 'application/x-www-form-urlencoded'},
+            stream,
+        )
         obj._at_eof = True
         result = await obj.form()
         assert not result
 
-    async def test_readline(self) -> None:
+    async def test_readline(self, newline) -> None:
+        data = b'Hello\n,\r\nworld!%s--:--' % newline
         obj = aiohttp.BodyPartReader(
-            BOUNDARY, {}, Stream(b'Hello\n,\r\nworld!\r\n--:--'))
+            BOUNDARY,
+            {},
+            Stream(data),
+            _newline=newline,
+        )
         result = await obj.readline()
         assert b'Hello\n' == result
         result = await obj.readline()
         assert b',\r\n' == result
         result = await obj.readline()
         assert b'world!' == result
         result = await obj.readline()
         assert b'' == result
         assert obj.at_eof()
 
-    async def test_release(self) -> None:
-        stream = Stream(b'Hello,\r\n--:\r\n\r\nworld!\r\n--:--')
+    async def test_release(self, newline) -> None:
+        data = b'Hello,%s--:\r\n\r\nworld!%s--:--' % (newline, newline)
+        stream = Stream(data)
         obj = aiohttp.BodyPartReader(
-            BOUNDARY, {}, stream)
+            BOUNDARY,
+            {},
+            stream,
+            _newline=newline,
+        )
+        remained = b'--:\r\n\r\nworld!%s--:--' % newline
         await obj.release()
         assert obj.at_eof()
-        assert b'--:\r\n\r\nworld!\r\n--:--' == stream.content.read()
+        assert remained == stream.content.read()
 
-    async def test_release_respects_content_length(self) -> None:
+    async def test_release_respects_content_length(self, newline) -> None:
         obj = aiohttp.BodyPartReader(
             BOUNDARY, {'CONTENT-LENGTH': 100500},
-            Stream(b'.' * 100500 + b'\r\n--:--'))
+            Stream(b'.' * 100500 + b'%s--:--' % newline),
+            _newline=newline,
+        )
         result = await obj.release()
         assert result is None
         assert obj.at_eof()
 
-    async def test_release_release(self) -> None:
-        stream = Stream(b'Hello,\r\n--:\r\n\r\nworld!\r\n--:--')
+    async def test_release_release(self, newline) -> None:
+        data = b'Hello,%s--:\r\n\r\nworld!%s--:--' % (newline, newline)
+        remained = b'--:\r\n\r\nworld!%s--:--' % newline
+        stream = Stream(data)
         obj = aiohttp.BodyPartReader(
-            BOUNDARY, {}, stream)
+            BOUNDARY,
+            {},
+            stream,
+            _newline=newline,
+        )
         await obj.release()
         await obj.release()
-        assert b'--:\r\n\r\nworld!\r\n--:--' == stream.content.read()
+        assert remained == stream.content.read()
 
     async def test_filename(self) -> None:
         part = aiohttp.BodyPartReader(
             BOUNDARY,
             {CONTENT_DISPOSITION: 'attachment; filename=foo.html'},
             None)
         assert 'foo.html' == part.filename
 
-    async def test_reading_long_part(self) -> None:
+    async def test_reading_long_part(self, newline) -> None:
         size = 2 * stream_reader_default_limit
         protocol = mock.Mock(_reading_paused=False)
-        stream = StreamReader(protocol)
-        stream.feed_data(b'0' * size + b'\r\n--:--')
+        stream = StreamReader(protocol, loop=asyncio.get_event_loop())
+        stream.feed_data(b'0' * size + b'%s--:--' % newline)
         stream.feed_eof()
-        obj = aiohttp.BodyPartReader(
-            BOUNDARY, {}, stream)
+        obj = aiohttp.BodyPartReader(BOUNDARY, {}, stream, _newline=newline)
         data = await obj.read()
         assert len(data) == size
 
 
 class TestMultipartReader:
 
-    def test_from_response(self) -> None:
+    def test_from_response(self, newline) -> None:
         resp = Response({CONTENT_TYPE: 'multipart/related;boundary=":"'},
-                        Stream(b'--:\r\n\r\nhello\r\n--:--'))
+                        Stream(b'--:%s\r\nhello%s--:--' % (newline, newline)))
         res = aiohttp.MultipartReader.from_response(resp)
         assert isinstance(res,
                           MultipartResponseWrapper)
         assert isinstance(res.stream,
                           aiohttp.MultipartReader)
 
     def test_bad_boundary(self) -> None:
         resp = Response(
             {CONTENT_TYPE: 'multipart/related;boundary=' + 'a' * 80},
             Stream(b''))
         with pytest.raises(ValueError):
             aiohttp.MultipartReader.from_response(resp)
 
-    def test_dispatch(self) -> None:
+    def test_dispatch(self, newline) -> None:
         reader = aiohttp.MultipartReader(
             {CONTENT_TYPE: 'multipart/related;boundary=":"'},
-            Stream(b'--:\r\n\r\necho\r\n--:--'))
+            Stream(b'--:%s\r\necho%s--:--' % (newline, newline)))
         res = reader._get_part_reader({CONTENT_TYPE: 'text/plain'})
         assert isinstance(res, reader.part_reader_cls)
 
-    def test_dispatch_bodypart(self) -> None:
+    def test_dispatch_bodypart(self, newline) -> None:
         reader = aiohttp.MultipartReader(
             {CONTENT_TYPE: 'multipart/related;boundary=":"'},
-            Stream(b'--:\r\n\r\necho\r\n--:--'))
+            Stream(b'--:%s\r\necho%s--:--' % (newline, newline)))
         res = reader._get_part_reader({CONTENT_TYPE: 'text/plain'})
         assert isinstance(res, reader.part_reader_cls)
 
-    def test_dispatch_multipart(self) -> None:
+    def test_dispatch_multipart(self, newline) -> None:
         reader = aiohttp.MultipartReader(
             {CONTENT_TYPE: 'multipart/related;boundary=":"'},
-            Stream(b'----:--\r\n'
-                   b'\r\n'
-                   b'test\r\n'
-                   b'----:--\r\n'
-                   b'\r\n'
-                   b'passed\r\n'
-                   b'----:----\r\n'
-                   b'--:--'))
+            Stream(
+                newline.join([
+                    b'----:--',
+                    b'',
+                    b'test',
+                    b'----:--',
+                    b'',
+                    b'passed',
+                    b'----:----'
+                    b'--:--',
+                ])
+            )
+        )
         res = reader._get_part_reader(
             {CONTENT_TYPE: 'multipart/related;boundary=--:--'})
         assert isinstance(res, reader.__class__)
 
-    def test_dispatch_custom_multipart_reader(self) -> None:
+    def test_dispatch_custom_multipart_reader(self, newline) -> None:
         class CustomReader(aiohttp.MultipartReader):
             pass
         reader = aiohttp.MultipartReader(
             {CONTENT_TYPE: 'multipart/related;boundary=":"'},
-            Stream(b'----:--\r\n'
-                   b'\r\n'
-                   b'test\r\n'
-                   b'----:--\r\n'
-                   b'\r\n'
-                   b'passed\r\n'
-                   b'----:----\r\n'
-                   b'--:--'))
+            Stream(
+                newline.join([
+                    b'----:--',
+                    b'',
+                    b'test',
+                    b'----:--',
+                    b'',
+                    b'passed',
+                    b'----:----',
+                    b'--:--',
+                ])
+            )
+        )
         reader.multipart_reader_cls = CustomReader
         res = reader._get_part_reader(
             {CONTENT_TYPE: 'multipart/related;boundary=--:--'})
         assert isinstance(res, CustomReader)
 
-    async def test_emit_next(self) -> None:
+    async def test_emit_next(self, newline) -> None:
         reader = aiohttp.MultipartReader(
             {CONTENT_TYPE: 'multipart/related;boundary=":"'},
-            Stream(b'--:\r\n\r\necho\r\n--:--'))
+            Stream(b'--:%s\r\necho%s--:--' % (newline, newline)))
         res = await reader.next()
         assert isinstance(res, reader.part_reader_cls)
 
-    async def test_invalid_boundary(self) -> None:
+    async def test_invalid_boundary(self, newline) -> None:
         reader = aiohttp.MultipartReader(
             {CONTENT_TYPE: 'multipart/related;boundary=":"'},
-            Stream(b'---:\r\n\r\necho\r\n---:--'))
+            Stream(b'---:%s\r\necho%s---:--' % (newline, newline)))
         with pytest.raises(ValueError):
             await reader.next()
 
-    async def test_release(self) -> None:
+    async def test_release(self, newline) -> None:
         reader = aiohttp.MultipartReader(
             {CONTENT_TYPE: 'multipart/mixed;boundary=":"'},
-            Stream(b'--:\r\n'
-                   b'Content-Type: multipart/related;boundary=--:--\r\n'
-                   b'\r\n'
-                   b'----:--\r\n'
-                   b'\r\n'
-                   b'test\r\n'
-                   b'----:--\r\n'
-                   b'\r\n'
-                   b'passed\r\n'
-                   b'----:----\r\n'
-                   b'\r\n'
-                   b'--:--'))
+            Stream(
+                newline.join([
+                    b'--:',
+                    b'Content-Type: multipart/related;boundary=--:--',
+                    b'',
+                    b'----:--',
+                    b'',
+                    b'test',
+                    b'----:--',
+                    b'',
+                    b'passed',
+                    b'----:----',
+                    b'',
+                    b'--:--',
+                ])
+            )
+        )
         await reader.release()
         assert reader.at_eof()
 
-    async def test_release_release(self) -> None:
+    async def test_release_release(self, newline) -> None:
         reader = aiohttp.MultipartReader(
             {CONTENT_TYPE: 'multipart/related;boundary=":"'},
-            Stream(b'--:\r\n\r\necho\r\n--:--'))
+            Stream(b'--:%s\r\necho%s--:--' % (newline, newline)))
         await reader.release()
         assert reader.at_eof()
         await reader.release()
         assert reader.at_eof()
 
-    async def test_release_next(self) -> None:
+    async def test_release_next(self, newline) -> None:
         reader = aiohttp.MultipartReader(
             {CONTENT_TYPE: 'multipart/related;boundary=":"'},
-            Stream(b'--:\r\n\r\necho\r\n--:--'))
+            Stream(b'--:%s\r\necho%s--:--' % (newline, newline)))
         await reader.release()
         assert reader.at_eof()
         res = await reader.next()
         assert res is None
 
-    async def test_second_next_releases_previous_object(self) -> None:
+    async def test_second_next_releases_previous_object(self, newline) -> None:
         reader = aiohttp.MultipartReader(
             {CONTENT_TYPE: 'multipart/related;boundary=":"'},
-            Stream(b'--:\r\n'
-                   b'\r\n'
-                   b'test\r\n'
-                   b'--:\r\n'
-                   b'\r\n'
-                   b'passed\r\n'
-                   b'--:--'))
+            Stream(
+                newline.join([
+                    b'--:',
+                    b'',
+                    b'test',
+                    b'--:',
+                    b'',
+                    b'passed',
+                    b'--:--',
+                ])
+            )
+        )
         first = await reader.next()
         assert isinstance(first, aiohttp.BodyPartReader)
         second = await reader.next()
         assert first.at_eof()
         assert not second.at_eof()
 
-    async def test_release_without_read_the_last_object(self) -> None:
+    async def test_release_without_read_the_last_object(self, newline) -> None:
         reader = aiohttp.MultipartReader(
             {CONTENT_TYPE: 'multipart/related;boundary=":"'},
-            Stream(b'--:\r\n'
-                   b'\r\n'
-                   b'test\r\n'
-                   b'--:\r\n'
-                   b'\r\n'
-                   b'passed\r\n'
-                   b'--:--'))
+            Stream(
+                newline.join([
+                    b'--:',
+                    b'',
+                    b'test',
+                    b'--:',
+                    b'',
+                    b'passed',
+                    b'--:--',
+                ])
+            )
+        )
         first = await reader.next()
         second = await reader.next()
         third = await reader.next()
         assert first.at_eof()
         assert second.at_eof()
         assert second.at_eof()
         assert third is None
 
-    async def test_read_chunk_by_length_doesnt_breaks_reader(self) -> None:
+    async def test_read_chunk_by_length_doesnt_breaks_reader(
+        self, newline
+    ) -> None:
         reader = aiohttp.MultipartReader(
             {CONTENT_TYPE: 'multipart/related;boundary=":"'},
-            Stream(b'--:\r\n'
-                   b'Content-Length: 4\r\n\r\n'
-                   b'test'
-                   b'\r\n--:\r\n'
-                   b'Content-Length: 6\r\n\r\n'
-                   b'passed'
-                   b'\r\n--:--'))
+            Stream(newline.join([
+                b'--:',
+                b'Content-Length: 4',
+                b'',
+                b'test',
+                b'--:',
+                b'Content-Length: 6',
+                b'',
+                b'passed',
+                b'--:--',
+            ]))
+        )
         body_parts = []
         while True:
             read_part = b''
             part = await reader.next()
             if part is None:
                 break
             while not part.at_eof():
                 read_part += await part.read_chunk(3)
             body_parts.append(read_part)
         assert body_parts == [b'test', b'passed']
 
-    async def test_read_chunk_from_stream_doesnt_breaks_reader(self) -> None:
+    async def test_read_chunk_from_stream_doesnt_breaks_reader(
+        self, newline
+    ) -> None:
         reader = aiohttp.MultipartReader(
             {CONTENT_TYPE: 'multipart/related;boundary=":"'},
-            Stream(b'--:\r\n'
-                   b'\r\n'
-                   b'chunk'
-                   b'\r\n--:\r\n'
-                   b'\r\n'
-                   b'two_chunks'
-                   b'\r\n--:--'))
+            Stream(newline.join([
+                b'--:',
+                b'',
+                b'chunk',
+                b'--:',
+                b'',
+                b'two_chunks',
+                b'--:--',
+            ]))
+        )
         body_parts = []
         while True:
             read_part = b''
             part = await reader.next()
             if part is None:
                 break
             while not part.at_eof():
                 chunk = await part.read_chunk(5)
                 assert chunk
                 read_part += chunk
             body_parts.append(read_part)
         assert body_parts == [b'chunk', b'two_chunks']
 
-    async def test_reading_skips_prelude(self) -> None:
+    async def test_reading_skips_prelude(self, newline) -> None:
         reader = aiohttp.MultipartReader(
             {CONTENT_TYPE: 'multipart/related;boundary=":"'},
-            Stream(b'Multi-part data is not supported.\r\n'
-                   b'\r\n'
-                   b'--:\r\n'
-                   b'\r\n'
-                   b'test\r\n'
-                   b'--:\r\n'
-                   b'\r\n'
-                   b'passed\r\n'
-                   b'--:--'))
+            Stream(newline.join([
+                b'Multi-part data is not supported.',
+                b'',
+                b'--:',
+                b'',
+                b'test',
+                b'--:',
+                b'',
+                b'passed',
+                b'--:--'
+            ]))
+        )
         first = await reader.next()
         assert isinstance(first, aiohttp.BodyPartReader)
         second = await reader.next()
         assert first.at_eof()
         assert not second.at_eof()
 
+    async def test_read_mixed_newlines(self) -> None:
+        reader = aiohttp.MultipartReader(
+            {CONTENT_TYPE: 'multipart/mixed;boundary=":"'},
+            Stream(
+                b''.join([
+                    b'--:\n',
+                    b'Content-Type: multipart/related;boundary=--:--\n',
+                    b'\n',
+                    b'----:--\r\n',
+                    b'\r\n',
+                    b'test\r\n',
+                    b'----:--\r\n',
+                    b'\r\n',
+                    b'passed\r\n',
+                    b'----:----\r\n',
+                    b'\n',
+                    b'--:--',
+                ])
+            )
+        )
+        while True:
+            part = await reader.next()
+            if part is None:
+                break
+            while True:
+                subpart = await part.next()
+                if subpart is None:
+                    break
+
 
 async def test_writer(writer) -> None:
-    assert writer.size == 0
+    assert writer.size == 7
     assert writer.boundary == ':'
 
 
 async def test_writer_serialize_io_chunk(buf, stream, writer) -> None:
     flo = io.BytesIO(b'foobarbaz')
     writer.append(flo)
     await writer.write(stream)
@@ -844,14 +1053,19 @@
          b'--:\r\n'
          b'Content-Type: application/x-www-form-urlencoded\r\n'
          b'Content-Length: 11\r\n\r\n'
          b'one=1&two=2'
          b'\r\n') == bytes(buf))
 
 
+async def test_writer_write_no_parts(buf, stream, writer) -> None:
+    await writer.write(stream)
+    assert b'--:--\r\n' == bytes(buf)
+
+
 async def test_writer_serialize_with_content_encoding_gzip(buf, stream,
                                                            writer):
     writer.append('Time to Relax!', {CONTENT_ENCODING: 'gzip'})
     await writer.write(stream)
     headers, message = bytes(buf).split(b'\r\n\r\n', 1)
 
     assert (b'--:\r\nContent-Type: text/plain; charset=utf-8\r\n'
@@ -1049,15 +1263,15 @@
         )
         assert message == b'foo\r\n--:--\r\n'
 
     async def test_preserve_content_disposition_header(self, buf, stream):
         """
         https://github.com/aio-libs/aiohttp/pull/3475#issuecomment-451072381
         """
-        with open(__file__, 'rb') as fobj:
+        with pathlib.Path(__file__).open('rb') as fobj:
             with aiohttp.MultipartWriter('form-data', boundary=':') as writer:
                 part = writer.append(
                     fobj,
                     headers={
                         CONTENT_DISPOSITION: 'attachments; filename="bug.py"',
                         CONTENT_TYPE: 'text/python',
                     }
@@ -1080,15 +1294,15 @@
             b'' % (str(content_length).encode(),)
         )
 
     async def test_set_content_disposition_override(self, buf, stream):
         """
         https://github.com/aio-libs/aiohttp/pull/3475#issuecomment-451072381
         """
-        with open(__file__, 'rb') as fobj:
+        with pathlib.Path(__file__).open('rb') as fobj:
             with aiohttp.MultipartWriter('form-data', boundary=':') as writer:
                 part = writer.append(
                     fobj,
                     headers={
                         CONTENT_DISPOSITION: 'attachments; filename="bug.py"',
                         CONTENT_TYPE: 'text/python',
                     }
@@ -1111,15 +1325,15 @@
             b'' % (str(content_length).encode(),)
         )
 
     async def test_reset_content_disposition_header(self, buf, stream):
         """
         https://github.com/aio-libs/aiohttp/pull/3475#issuecomment-451072381
         """
-        with open(__file__, 'rb') as fobj:
+        with pathlib.Path(__file__).open('rb') as fobj:
             with aiohttp.MultipartWriter('form-data', boundary=':') as writer:
                 part = writer.append(
                     fobj,
                     headers={CONTENT_TYPE: 'text/plain'},
                 )
 
             content_length = part.size
```

### Comparing `aiohttp-4.0.0a0/tests/test_multipart_helpers.py` & `aiohttp-4.0.0a1/tests/test_multipart_helpers.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/tests/test_payload.py` & `aiohttp-4.0.0a1/tests/test_payload.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,15 +1,12 @@
-import asyncio
 from io import StringIO
-from unittest import mock
 
 import pytest
-from async_generator import async_generator
 
-from aiohttp import payload, streams
+from aiohttp import payload
 
 
 @pytest.fixture
 def registry():
     old = payload.PAYLOAD_REGISTRY
     reg = payload.PAYLOAD_REGISTRY = payload.PayloadRegistry()
     yield reg
@@ -88,46 +85,28 @@
     p = payload.StringIOPayload(s)
     assert p.encoding == 'utf-8'
     assert p.content_type == 'text/plain; charset=utf-8'
     assert p.size == 10000
 
 
 def test_async_iterable_payload_default_content_type() -> None:
-    @async_generator
     async def gen():
-        pass
+        return
+        yield
 
     p = payload.AsyncIterablePayload(gen())
     assert p.content_type == 'application/octet-stream'
 
 
 def test_async_iterable_payload_explicit_content_type() -> None:
-    @async_generator
     async def gen():
-        pass
+        return
+        yield
 
     p = payload.AsyncIterablePayload(gen(), content_type='application/custom')
     assert p.content_type == 'application/custom'
 
 
 def test_async_iterable_payload_not_async_iterable() -> None:
 
     with pytest.raises(TypeError):
         payload.AsyncIterablePayload(object())
-
-
-async def test_stream_reader_long_lines() -> None:
-    loop = asyncio.get_event_loop()
-    DATA = b'0' * 1024 ** 3
-
-    stream = streams.StreamReader(mock.Mock(), loop=loop)
-    stream.feed_data(DATA)
-    stream.feed_eof()
-    body = payload.get_payload(stream)
-
-    writer = mock.Mock()
-    writer.write.return_value = loop.create_future()
-    writer.write.return_value.set_result(None)
-    await body.write(writer)
-    writer.write.assert_called_once_with(mock.ANY)
-    (chunk,), _ = writer.write.call_args
-    assert len(chunk) == len(DATA)
```

### Comparing `aiohttp-4.0.0a0/tests/test_proxy.py` & `aiohttp-4.0.0a1/tests/test_proxy.py`

 * *Files 0% similar despite different names*

```diff
@@ -220,16 +220,15 @@
         connector = self.loop.run_until_complete(make_conn())
         connector._resolve_host = make_mocked_coro(
             [{'hostname': 'hostname', 'host': '127.0.0.1', 'port': 80,
               'family': socket.AF_INET, 'proto': 0, 'flags': 0}])
 
         seq = 0
 
-        @asyncio.coroutine
-        def create_connection(*args, **kwargs):
+        async def create_connection(*args, **kwargs):
             nonlocal seq
             seq += 1
 
             # connection to http://proxy.example.com
             if seq == 1:
                 return mock.Mock(), mock.Mock()
             # connection to https://www.python.org
@@ -271,16 +270,15 @@
         connector = self.loop.run_until_complete(make_conn())
         connector._resolve_host = make_mocked_coro(
             [{'hostname': 'hostname', 'host': '127.0.0.1', 'port': 80,
               'family': socket.AF_INET, 'proto': 0, 'flags': 0}])
 
         seq = 0
 
-        @asyncio.coroutine
-        def create_connection(*args, **kwargs):
+        async def create_connection(*args, **kwargs):
             nonlocal seq
             seq += 1
 
             # connection to http://proxy.example.com
             if seq == 1:
                 return mock.Mock(), mock.Mock()
             # connection to https://www.python.org
```

### Comparing `aiohttp-4.0.0a0/tests/test_proxy_functional.py` & `aiohttp-4.0.0a1/tests/test_proxy_functional.py`

 * *Files 3% similar despite different names*

```diff
@@ -59,15 +59,15 @@
 
     return proxy_server
 
 
 @pytest.fixture()
 def get_request(loop):
     async def _request(method='GET', *, url, trust_env=False, **kwargs):
-        connector = aiohttp.TCPConnector(ssl=False, loop=loop)
+        connector = aiohttp.TCPConnector(ssl=False)
         client = aiohttp.ClientSession(connector=connector,
                                        trust_env=trust_env)
         try:
             resp = await client.request(method, url, **kwargs)
             await resp.release()
             return resp
         finally:
@@ -186,16 +186,16 @@
     assert 'Authorization' not in proxy.request.headers
     assert 'Proxy-Authorization' in proxy.request.headers
 
 
 async def test_proxy_http_acquired_cleanup(proxy_test_server, loop) -> None:
     url = 'http://aiohttp.io/path'
 
-    conn = aiohttp.TCPConnector(loop=loop)
-    sess = aiohttp.ClientSession(connector=conn, loop=loop)
+    conn = aiohttp.TCPConnector()
+    sess = aiohttp.ClientSession(connector=conn)
     proxy = await proxy_test_server()
 
     assert 0 == len(conn._acquired)
 
     resp = await sess.get(url, proxy=proxy.url)
     assert resp.closed
 
@@ -205,16 +205,16 @@
 
 
 @pytest.mark.skip('we need to reconsider how we test this')
 async def test_proxy_http_acquired_cleanup_force(proxy_test_server,
                                                  loop) -> None:
     url = 'http://aiohttp.io/path'
 
-    conn = aiohttp.TCPConnector(force_close=True, loop=loop)
-    sess = aiohttp.ClientSession(connector=conn, loop=loop)
+    conn = aiohttp.TCPConnector(force_close=True)
+    sess = aiohttp.ClientSession(connector=conn)
     proxy = await proxy_test_server()
 
     assert 0 == len(conn._acquired)
 
     async def request():
         resp = await sess.get(url, proxy=proxy.url)
 
@@ -230,35 +230,35 @@
 
 
 @pytest.mark.skip('we need to reconsider how we test this')
 async def test_proxy_http_multi_conn_limit(proxy_test_server, loop) -> None:
     url = 'http://aiohttp.io/path'
     limit, multi_conn_num = 1, 5
 
-    conn = aiohttp.TCPConnector(limit=limit, loop=loop)
-    sess = aiohttp.ClientSession(connector=conn, loop=loop)
+    conn = aiohttp.TCPConnector(limit=limit)
+    sess = aiohttp.ClientSession(connector=conn)
     proxy = await proxy_test_server()
 
     current_pid = None
 
     async def request(pid):
         # process requests only one by one
         nonlocal current_pid
 
         resp = await sess.get(url, proxy=proxy.url)
 
         current_pid = pid
-        await asyncio.sleep(0.2, loop=loop)
+        await asyncio.sleep(0.2)
         assert current_pid == pid
 
         await resp.release()
         return resp
 
     requests = [request(pid) for pid in range(multi_conn_num)]
-    responses = await asyncio.gather(*requests, loop=loop)
+    responses = await asyncio.gather(*requests)
 
     assert len(responses) == multi_conn_num
     assert set(resp.status for resp in responses) == {200}
 
     await sess.close()
 
 
@@ -292,15 +292,15 @@
 
     assert proxy.request.host == 'secure.aiohttp.io:2242'
     assert proxy.request.path_qs == '/path'
 
 
 @pytest.mark.xfail
 async def xtest_proxy_https_send_body(proxy_test_server, loop):
-    sess = aiohttp.ClientSession(loop=loop)
+    sess = aiohttp.ClientSession()
     proxy = await proxy_test_server()
     proxy.return_value = {'status': 200, 'body': b'1'*(2**20)}
     url = 'https://www.google.com.ua/search?q=aiohttp proxy'
 
     resp = await sess.get(url, proxy=proxy.url)
     body = await resp.read()
     await resp.release()
@@ -389,16 +389,16 @@
     assert 'Proxy-Authorization' not in proxy.request.headers
 
 
 @pytest.mark.xfail
 async def xtest_proxy_https_acquired_cleanup(proxy_test_server, loop):
     url = 'https://secure.aiohttp.io/path'
 
-    conn = aiohttp.TCPConnector(loop=loop)
-    sess = aiohttp.ClientSession(connector=conn, loop=loop)
+    conn = aiohttp.TCPConnector()
+    sess = aiohttp.ClientSession(connector=conn)
     proxy = await proxy_test_server()
 
     assert 0 == len(conn._acquired)
 
     async def request():
         resp = await sess.get(url, proxy=proxy.url)
 
@@ -413,16 +413,16 @@
     await sess.close()
 
 
 @pytest.mark.xfail
 async def xtest_proxy_https_acquired_cleanup_force(proxy_test_server, loop):
     url = 'https://secure.aiohttp.io/path'
 
-    conn = aiohttp.TCPConnector(force_close=True, loop=loop)
-    sess = aiohttp.ClientSession(connector=conn, loop=loop)
+    conn = aiohttp.TCPConnector(force_close=True)
+    sess = aiohttp.ClientSession(connector=conn)
     proxy = await proxy_test_server()
 
     assert 0 == len(conn._acquired)
 
     async def request():
         resp = await sess.get(url, proxy=proxy.url)
 
@@ -438,35 +438,35 @@
 
 
 @pytest.mark.xfail
 async def xtest_proxy_https_multi_conn_limit(proxy_test_server, loop):
     url = 'https://secure.aiohttp.io/path'
     limit, multi_conn_num = 1, 5
 
-    conn = aiohttp.TCPConnector(limit=limit, loop=loop)
-    sess = aiohttp.ClientSession(connector=conn, loop=loop)
+    conn = aiohttp.TCPConnector(limit=limit)
+    sess = aiohttp.ClientSession(connector=conn)
     proxy = await proxy_test_server()
 
     current_pid = None
 
     async def request(pid):
         # process requests only one by one
         nonlocal current_pid
 
         resp = await sess.get(url, proxy=proxy.url)
 
         current_pid = pid
-        await asyncio.sleep(0.2, loop=loop)
+        await asyncio.sleep(0.2)
         assert current_pid == pid
 
         await resp.release()
         return resp
 
     requests = [request(pid) for pid in range(multi_conn_num)]
-    responses = await asyncio.gather(*requests, loop=loop)
+    responses = await asyncio.gather(*requests)
 
     assert len(responses) == multi_conn_num
     assert set(resp.status for resp in responses) == {200}
 
     await sess.close()
 
 
@@ -526,66 +526,66 @@
     assert proxy.request.method == 'GET'
     assert proxy.request.host == 'aiohttp.io'
     assert proxy.request.path_qs == 'http://aiohttp.io/path'
     assert proxy.request.headers['Proxy-Authorization'] == auth.encode()
 
 
 async def test_proxy_from_env_http_with_auth_from_netrc(
-        proxy_test_server, get_request, tmpdir, mocker):
+        proxy_test_server, get_request, tmp_path, mocker):
     url = 'http://aiohttp.io/path'
     proxy = await proxy_test_server()
     auth = aiohttp.BasicAuth('user', 'pass')
-    netrc_file = tmpdir.join('test_netrc')
+    netrc_file = tmp_path / 'test_netrc'
     netrc_file_data = 'machine 127.0.0.1 login %s password %s' % (
         auth.login, auth.password)
-    with open(str(netrc_file), 'w') as f:
+    with netrc_file.open('w') as f:
         f.write(netrc_file_data)
     mocker.patch.dict(os.environ, {'http_proxy': str(proxy.url),
                                    'NETRC': str(netrc_file)})
 
     await get_request(url=url, trust_env=True)
 
     assert len(proxy.requests_list) == 1
     assert proxy.request.method == 'GET'
     assert proxy.request.host == 'aiohttp.io'
     assert proxy.request.path_qs == 'http://aiohttp.io/path'
     assert proxy.request.headers['Proxy-Authorization'] == auth.encode()
 
 
 async def test_proxy_from_env_http_without_auth_from_netrc(
-        proxy_test_server, get_request, tmpdir, mocker):
+        proxy_test_server, get_request, tmp_path, mocker):
     url = 'http://aiohttp.io/path'
     proxy = await proxy_test_server()
     auth = aiohttp.BasicAuth('user', 'pass')
-    netrc_file = tmpdir.join('test_netrc')
+    netrc_file = tmp_path / 'test_netrc'
     netrc_file_data = 'machine 127.0.0.2 login %s password %s' % (
         auth.login, auth.password)
-    with open(str(netrc_file), 'w') as f:
+    with netrc_file.open('w') as f:
         f.write(netrc_file_data)
     mocker.patch.dict(os.environ, {'http_proxy': str(proxy.url),
                                    'NETRC': str(netrc_file)})
 
     await get_request(url=url, trust_env=True)
 
     assert len(proxy.requests_list) == 1
     assert proxy.request.method == 'GET'
     assert proxy.request.host == 'aiohttp.io'
     assert proxy.request.path_qs == 'http://aiohttp.io/path'
     assert 'Proxy-Authorization' not in proxy.request.headers
 
 
 async def test_proxy_from_env_http_without_auth_from_wrong_netrc(
-        proxy_test_server, get_request, tmpdir, mocker):
+        proxy_test_server, get_request, tmp_path, mocker):
     url = 'http://aiohttp.io/path'
     proxy = await proxy_test_server()
     auth = aiohttp.BasicAuth('user', 'pass')
-    netrc_file = tmpdir.join('test_netrc')
+    netrc_file = tmp_path / 'test_netrc'
     invalid_data = 'machine 127.0.0.1 %s pass %s' % (
         auth.login, auth.password)
-    with open(str(netrc_file), 'w') as f:
+    with netrc_file.open('w') as f:
         f.write(invalid_data)
 
     mocker.patch.dict(os.environ, {'http_proxy': str(proxy.url),
                                    'NETRC': str(netrc_file)})
 
     await get_request(url=url, trust_env=True)
```

### Comparing `aiohttp-4.0.0a0/tests/test_pytest_plugin.py` & `aiohttp-4.0.0a1/tests/test_pytest_plugin.py`

 * *Files 10% similar despite different names*

```diff
@@ -22,137 +22,105 @@
 from aiohttp import web
 
 
 async def hello(request):
     return web.Response(body=b'Hello, world')
 
 
-def create_app(loop=None):
+async def create_app():
     app = web.Application()
     app.router.add_route('GET', '/', hello)
     return app
 
 
 async def test_hello(aiohttp_client) -> None:
-    client = await aiohttp_client(create_app)
+    client = await aiohttp_client(await create_app())
     resp = await client.get('/')
     assert resp.status == 200
     text = await resp.text()
     assert 'Hello, world' in text
 
 
-async def test_hello_from_app(aiohttp_client, loop) -> None:
+async def test_hello_from_app(aiohttp_client) -> None:
     app = web.Application()
     app.router.add_get('/', hello)
     client = await aiohttp_client(app)
     resp = await client.get('/')
     assert resp.status == 200
     text = await resp.text()
     assert 'Hello, world' in text
 
 
-async def test_hello_with_loop(aiohttp_client, loop) -> None:
-    client = await aiohttp_client(create_app)
+async def test_hello_with_loop(aiohttp_client) -> None:
+    client = await aiohttp_client(await create_app())
     resp = await client.get('/')
     assert resp.status == 200
     text = await resp.text()
     assert 'Hello, world' in text
 
 
-async def test_set_args(aiohttp_client, loop) -> None:
-    with pytest.raises(AssertionError):
-        app = web.Application()
-        await aiohttp_client(app, 1, 2, 3)
-
-
-async def test_set_keyword_args(aiohttp_client, loop) -> None:
-    app = web.Application()
-    with pytest.raises(TypeError):
-        await aiohttp_client(app, param=1)
-
-
 async def test_noop() -> None:
     pass
 
 
 async def previous(request):
     if request.method == 'POST':
         with pytest.warns(DeprecationWarning):
             request.app['value'] = (await request.post())['value']
         return web.Response(body=b'thanks for the data')
     else:
         v = request.app.get('value', 'unknown')
         return web.Response(body='value: {}'.format(v).encode())
 
 
-def create_stateful_app(loop):
+def create_stateful_app():
     app = web.Application()
     app.router.add_route('*', '/', previous)
     return app
 
 
 @pytest.fixture
 def cli(loop, aiohttp_client):
-    return loop.run_until_complete(aiohttp_client(create_stateful_app))
-
-
-async def test_set_value(cli) -> None:
-    resp = await cli.post('/', data={'value': 'foo'})
-    assert resp.status == 200
-    text = await resp.text()
-    assert text == 'thanks for the data'
-    assert cli.server.app['value'] == 'foo'
-
-
-async def test_get_value(cli) -> None:
-    resp = await cli.get('/')
-    assert resp.status == 200
-    text = await resp.text()
-    assert text == 'value: unknown'
-    with pytest.warns(DeprecationWarning):
-        cli.server.app['value'] = 'bar'
-    resp = await cli.get('/')
-    assert resp.status == 200
-    text = await resp.text()
-    assert text == 'value: bar'
+    return loop.run_until_complete(aiohttp_client(create_stateful_app()))
 
 
 def test_noncoro() -> None:
     assert True
 
 
 async def test_failed_to_create_client(aiohttp_client) -> None:
 
-    def make_app(loop):
+    def make_app():
         raise RuntimeError()
 
     with pytest.raises(RuntimeError):
-        await aiohttp_client(make_app)
+        await aiohttp_client(make_app())
 
 
 async def test_custom_port_aiohttp_client(aiohttp_client, aiohttp_unused_port):
     port = aiohttp_unused_port()
-    client = await aiohttp_client(create_app, server_kwargs={'port': port})
+    client = await aiohttp_client(await create_app(),
+                                  server_kwargs={'port': port})
     assert client.port == port
     resp = await client.get('/')
     assert resp.status == 200
     text = await resp.text()
     assert 'Hello, world' in text
 
 
 async def test_custom_port_test_server(aiohttp_server, aiohttp_unused_port):
-    app = create_app()
+    app = await create_app()
     port = aiohttp_unused_port()
     server = await aiohttp_server(app, port=port)
     assert server.port == port
 
 """)
     testdir.makeconftest(CONFTEST)
     result = testdir.runpytest('-p', 'no:sugar', '--aiohttp-loop=pyloop')
-    result.assert_outcomes(passed=12)
+    result.assert_outcomes(passed=8)
 
 
 def test_warning_checks(testdir) -> None:
     testdir.makepyfile("""\
 
 async def foobar():
     return 123
@@ -183,23 +151,23 @@
 from aiohttp import web
 
 
 async def hello(request):
     return web.Response(body=b'Hello, world')
 
 
-def create_app(loop):
+def create_app():
     app = web.Application()
     app.router.add_route('GET', '/', hello)
     return app
 
 
 @pytest.fixture
 async def cli(aiohttp_client):
-    client = await aiohttp_client(create_app)
+    client = await aiohttp_client(create_app())
     return client
 
 
 @pytest.fixture
 async def foo():
     return 42
 
@@ -248,23 +216,23 @@
 canary = mock.Mock()
 
 
 async def hello(request):
     return web.Response(body=b'Hello, world')
 
 
-def create_app(loop):
+def create_app():
     app = web.Application()
     app.router.add_route('GET', '/', hello)
     return app
 
 
 @pytest.fixture
-async def cli(aiohttp_client):
-    yield await aiohttp_client(create_app)
+async def cli(aiohttp_client, loop):
+    yield await aiohttp_client(create_app())
     canary()
 
 
 async def test_hello(cli) -> None:
     resp = await cli.get('/')
     assert resp.status == 200
```

### Comparing `aiohttp-4.0.0a0/tests/test_resolver.py` & `aiohttp-4.0.0a1/tests/test_resolver.py`

 * *Files 22% similar despite different names*

```diff
@@ -45,127 +45,88 @@
     return fake
 
 
 @pytest.mark.skipif(not gethostbyname, reason="aiodns 1.1 required")
 async def test_async_resolver_positive_lookup(loop) -> None:
     with patch('aiodns.DNSResolver') as mock:
         mock().gethostbyname.return_value = fake_result(['127.0.0.1'])
-        resolver = AsyncResolver(loop=loop)
+        resolver = AsyncResolver()
         real = await resolver.resolve('www.python.org')
         ipaddress.ip_address(real[0]['host'])
         mock().gethostbyname.assert_called_with('www.python.org',
                                                 socket.AF_INET)
 
 
-@pytest.mark.skipif(aiodns is None, reason="aiodns required")
-async def test_async_resolver_query_positive_lookup(loop) -> None:
-    with patch('aiodns.DNSResolver') as mock:
-        del mock().gethostbyname
-        mock().query.return_value = fake_query_result(['127.0.0.1'])
-        resolver = AsyncResolver(loop=loop)
-        real = await resolver.resolve('www.python.org')
-        ipaddress.ip_address(real[0]['host'])
-        mock().query.assert_called_with('www.python.org', 'A')
-
-
 @pytest.mark.skipif(not gethostbyname, reason="aiodns 1.1 required")
 async def test_async_resolver_multiple_replies(loop) -> None:
     with patch('aiodns.DNSResolver') as mock:
         ips = ['127.0.0.1', '127.0.0.2', '127.0.0.3', '127.0.0.4']
         mock().gethostbyname.return_value = fake_result(ips)
-        resolver = AsyncResolver(loop=loop)
+        resolver = AsyncResolver()
         real = await resolver.resolve('www.google.com')
         ips = [ipaddress.ip_address(x['host']) for x in real]
         assert len(ips) > 3, "Expecting multiple addresses"
 
 
-@pytest.mark.skipif(aiodns is None, reason="aiodns required")
-async def test_async_resolver_query_multiple_replies(loop) -> None:
-    with patch('aiodns.DNSResolver') as mock:
-        del mock().gethostbyname
-        ips = ['127.0.0.1', '127.0.0.2', '127.0.0.3', '127.0.0.4']
-        mock().query.return_value = fake_query_result(ips)
-        resolver = AsyncResolver(loop=loop)
-        real = await resolver.resolve('www.google.com')
-        ips = [ipaddress.ip_address(x['host']) for x in real]
-
-
 @pytest.mark.skipif(not gethostbyname, reason="aiodns 1.1 required")
 async def test_async_resolver_negative_lookup(loop) -> None:
     with patch('aiodns.DNSResolver') as mock:
         mock().gethostbyname.side_effect = aiodns.error.DNSError()
-        resolver = AsyncResolver(loop=loop)
-        with pytest.raises(OSError):
-            await resolver.resolve('doesnotexist.bla')
-
-
-@pytest.mark.skipif(aiodns is None, reason="aiodns required")
-async def test_async_resolver_query_negative_lookup(loop) -> None:
-    with patch('aiodns.DNSResolver') as mock:
-        del mock().gethostbyname
-        mock().query.side_effect = aiodns.error.DNSError()
-        resolver = AsyncResolver(loop=loop)
-        with pytest.raises(OSError):
-            await resolver.resolve('doesnotexist.bla')
-
-
-@pytest.mark.skipif(aiodns is None, reason="aiodns required")
-async def test_async_resolver_no_hosts_in_query(loop) -> None:
-    with patch('aiodns.DNSResolver') as mock:
-        del mock().gethostbyname
-        mock().query.return_value = fake_query_result([])
-        resolver = AsyncResolver(loop=loop)
+        resolver = AsyncResolver()
         with pytest.raises(OSError):
             await resolver.resolve('doesnotexist.bla')
 
 
 @pytest.mark.skipif(not gethostbyname, reason="aiodns 1.1 required")
 async def test_async_resolver_no_hosts_in_gethostbyname(loop) -> None:
     with patch('aiodns.DNSResolver') as mock:
         mock().gethostbyname.return_value = fake_result([])
-        resolver = AsyncResolver(loop=loop)
+        resolver = AsyncResolver()
         with pytest.raises(OSError):
             await resolver.resolve('doesnotexist.bla')
 
 
 async def test_threaded_resolver_positive_lookup() -> None:
     loop = Mock()
     loop.getaddrinfo = fake_addrinfo(["127.0.0.1"])
-    resolver = ThreadedResolver(loop=loop)
+    resolver = ThreadedResolver()
+    resolver._loop = loop
     real = await resolver.resolve('www.python.org')
     ipaddress.ip_address(real[0]['host'])
 
 
 async def test_threaded_resolver_multiple_replies() -> None:
     loop = Mock()
     ips = ['127.0.0.1', '127.0.0.2', '127.0.0.3', '127.0.0.4']
     loop.getaddrinfo = fake_addrinfo(ips)
-    resolver = ThreadedResolver(loop=loop)
+    resolver = ThreadedResolver()
+    resolver._loop = loop
     real = await resolver.resolve('www.google.com')
     ips = [ipaddress.ip_address(x['host']) for x in real]
     assert len(ips) > 3, "Expecting multiple addresses"
 
 
 async def test_threaded_negative_lookup() -> None:
     loop = Mock()
     ips = []
     loop.getaddrinfo = fake_addrinfo(ips)
-    resolver = ThreadedResolver(loop=loop)
+    resolver = ThreadedResolver()
+    resolver._loop = loop
     with pytest.raises(socket.gaierror):
         await resolver.resolve('doesnotexist.bla')
 
 
 async def test_close_for_threaded_resolver(loop) -> None:
-    resolver = ThreadedResolver(loop=loop)
+    resolver = ThreadedResolver()
     await resolver.close()
 
 
 @pytest.mark.skipif(aiodns is None, reason="aiodns required")
 async def test_close_for_async_resolver(loop) -> None:
-    resolver = AsyncResolver(loop=loop)
+    resolver = AsyncResolver()
     await resolver.close()
 
 
 async def test_default_loop_for_threaded_resolver(loop) -> None:
     asyncio.set_event_loop(loop)
     resolver = ThreadedResolver()
     assert resolver._loop is loop
@@ -178,38 +139,26 @@
     assert resolver._loop is loop
 
 
 @pytest.mark.skipif(not gethostbyname, reason="aiodns 1.1 required")
 async def test_async_resolver_ipv6_positive_lookup(loop) -> None:
     with patch('aiodns.DNSResolver') as mock:
         mock().gethostbyname.return_value = fake_result(['::1'])
-        resolver = AsyncResolver(loop=loop)
+        resolver = AsyncResolver()
         real = await resolver.resolve('www.python.org',
                                       family=socket.AF_INET6)
         ipaddress.ip_address(real[0]['host'])
         mock().gethostbyname.assert_called_with('www.python.org',
                                                 socket.AF_INET6)
 
 
-@pytest.mark.skipif(aiodns is None, reason="aiodns required")
-async def test_async_resolver_query_ipv6_positive_lookup(loop) -> None:
-    with patch('aiodns.DNSResolver') as mock:
-        del mock().gethostbyname
-        mock().query.return_value = fake_query_result(['::1'])
-        resolver = AsyncResolver(loop=loop)
-        real = await resolver.resolve('www.python.org',
-                                      family=socket.AF_INET6)
-        ipaddress.ip_address(real[0]['host'])
-        mock().query.assert_called_with('www.python.org', 'AAAA')
-
-
 async def test_async_resolver_aiodns_not_present(loop, monkeypatch) -> None:
     monkeypatch.setattr("aiohttp.resolver.aiodns", None)
     with pytest.raises(RuntimeError):
-        AsyncResolver(loop=loop)
+        AsyncResolver()
 
 
 def test_default_resolver() -> None:
     # if gethostbyname:
     #     assert DefaultResolver is AsyncResolver
     # else:
     #     assert DefaultResolver is ThreadedResolver
```

### Comparing `aiohttp-4.0.0a0/tests/test_route_def.py` & `aiohttp-4.0.0a1/tests/test_route_def.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/tests/test_run_app.py` & `aiohttp-4.0.0a1/tests/test_run_app.py`

 * *Files 2% similar despite different names*

```diff
@@ -349,31 +349,31 @@
                 backlog=10, print=stopper(patched_loop))
 
     patched_loop.create_unix_server.assert_called_with(
         mock.ANY, '/tmp/tmpsock.sock', ssl=None, backlog=10)
 
 
 @skip_if_no_unix_socks
-def test_run_app_http_unix_socket(patched_loop, shorttmpdir) -> None:
+def test_run_app_http_unix_socket(patched_loop, tmp_path) -> None:
     app = web.Application()
 
-    sock_path = str(shorttmpdir / 'socket.sock')
+    sock_path = str(tmp_path / 'socket.sock')
     printer = mock.Mock(wraps=stopper(patched_loop))
     web.run_app(app, path=sock_path, print=printer)
 
     patched_loop.create_unix_server.assert_called_with(mock.ANY, sock_path,
                                                        ssl=None, backlog=128)
     assert "http://unix:{}:".format(sock_path) in printer.call_args[0][0]
 
 
 @skip_if_no_unix_socks
-def test_run_app_https_unix_socket(patched_loop, shorttmpdir) -> None:
+def test_run_app_https_unix_socket(patched_loop, tmp_path) -> None:
     app = web.Application()
 
-    sock_path = str(shorttmpdir / 'socket.sock')
+    sock_path = str(tmp_path / 'socket.sock')
     ssl_context = ssl.create_default_context()
     printer = mock.Mock(wraps=stopper(patched_loop))
     web.run_app(app, path=sock_path, ssl_context=ssl_context, print=printer)
 
     patched_loop.create_unix_server.assert_called_with(
         mock.ANY, sock_path, ssl=ssl_context, backlog=128)
     assert "https://unix:{}:".format(sock_path) in printer.call_args[0][0]
```

### Comparing `aiohttp-4.0.0a0/tests/test_signals.py` & `aiohttp-4.0.0a1/tests/test_signals.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/tests/test_streams.py` & `aiohttp-4.0.0a1/tests/test_streams.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,16 @@
 """Tests for streams.py"""
 
+import abc
 import asyncio
+import gc
 import re
+import types
+from collections import defaultdict
+from itertools import groupby
 from unittest import mock
 
 import pytest
 
 from aiohttp import streams
 
 DATA = b'line1\nline2\nline3\n'
@@ -26,36 +31,62 @@
 
 
 @pytest.fixture
 def protocol():
     return mock.Mock(_reading_paused=False)
 
 
+MEMLEAK_SKIP_TYPES = (
+    *(getattr(types, name) for name in types.__all__ if name.endswith('Type')),
+    mock.Mock,
+    abc.ABCMeta,
+)
+
+
+def get_memory_usage(obj):
+    objs = [obj]
+    # Memory leak may be caused by leaked links to same objects.
+    # Without link counting, [1,2,3] is indistiguishable from [1,2,3,3,3,3,3,3]
+    known = defaultdict(int)
+    known[id(obj)] += 1
+
+    while objs:
+        refs = gc.get_referents(*objs)
+        objs = []
+        for obj in refs:
+            if isinstance(obj, MEMLEAK_SKIP_TYPES):
+                continue
+            i = id(obj)
+            known[i] += 1
+            if known[i] == 1:
+                objs.append(obj)
+
+        # Make list of unhashable objects uniq
+        objs.sort(key=id)
+        objs = [next(g) for (i, g) in groupby(objs, id)]
+
+    return sum(known.values())
+
+
 class TestStreamReader:
 
     DATA = b'line1\nline2\nline3\n'
 
     def _make_one(self, *args, **kwargs):
+        loop = asyncio.get_event_loop()
         return streams.StreamReader(mock.Mock(_reading_paused=False),
-                                    *args, **kwargs)
+                                    *args, **kwargs, loop=loop)
 
     async def test_create_waiter(self) -> None:
         loop = asyncio.get_event_loop()
-        stream = self._make_one(loop=loop)
+        stream = self._make_one()
         stream._waiter = loop.create_future
         with pytest.raises(RuntimeError):
             await stream._wait('test')
 
-    def test_ctor_global_loop(self) -> None:
-        loop = asyncio.new_event_loop()
-        asyncio.set_event_loop(loop)
-        stream = streams.StreamReader(mock.Mock(_reading_paused=False))
-
-        assert stream._loop is loop
-
     async def test_at_eof(self) -> None:
         stream = self._make_one()
         assert not stream.at_eof()
 
         stream.feed_data(b'some data\n')
         assert not stream.at_eof()
 
@@ -181,28 +212,14 @@
 
         data = await read_task
         assert b'' == data
 
         data = await stream.read()
         assert data == b''
 
-    async def test_read_eof_infinite(self) -> None:
-        # Read bytes.
-        stream = self._make_one()
-        stream.feed_eof()
-
-        with mock.patch('aiohttp.streams.internal_logger') as internal_logger:
-            await stream.read()
-            await stream.read()
-            await stream.read()
-            await stream.read()
-            await stream.read()
-            await stream.read()
-        assert internal_logger.warning.called
-
     async def test_read_eof_unread_data_no_warning(self) -> None:
         # Read bytes.
         stream = self._make_one()
         stream.feed_eof()
 
         with mock.patch('aiohttp.streams.internal_logger') as internal_logger:
             await stream.read()
@@ -392,15 +409,15 @@
         stream.feed_eof()
         data = await stream.read()
         assert self.DATA == data
 
     async def test_readexactly_eof(self) -> None:
         loop = asyncio.get_event_loop()
         # Read exact number of bytes (eof).
-        stream = self._make_one(loop=loop)
+        stream = self._make_one()
         n = 2 * len(self.DATA)
         read_task = loop.create_task(stream.readexactly(n))
 
         def cb():
             stream.feed_data(self.DATA)
             stream.feed_eof()
         loop.call_soon(cb)
@@ -645,14 +662,47 @@
 
         stream.feed_eof()
 
         data, end_of_chunk = await stream.readchunk()
         assert b'' == data
         assert not end_of_chunk
 
+    async def test_readany_chunk_end_race(self) -> None:
+        stream = self._make_one()
+        stream.begin_http_chunk_receiving()
+        stream.feed_data(b'part1')
+
+        data = await stream.readany()
+        assert data == b'part1'
+
+        loop = asyncio.get_event_loop()
+        task = loop.create_task(stream.readany())
+
+        # Give a chance for task to create waiter and start waiting for it.
+        await asyncio.sleep(0.1)
+        assert stream._waiter is not None
+        assert not task.done()  # Just for sure.
+
+        # This will trigger waiter, but without feeding any data.
+        # The stream should re-create waiter again.
+        stream.end_http_chunk_receiving()
+
+        # Give a chance for task to resolve.
+        # If everything is OK, previous action SHOULD NOT resolve the task.
+        await asyncio.sleep(0.1)
+        assert not task.done()  # The actual test.
+
+        stream.begin_http_chunk_receiving()
+        # This SHOULD unblock the task actually.
+        stream.feed_data(b'part2')
+        stream.end_http_chunk_receiving()
+
+        data = await task
+        assert data == b'part2'
+
     async def test_end_chunk_receiving_without_begin(self) -> None:
         stream = self._make_one()
         with pytest.raises(RuntimeError):
             stream.end_http_chunk_receiving()
 
     async def test_readchunk_with_unread(self) -> None:
         """Test that stream.unread does not break controlled chunk receiving.
@@ -702,27 +752,63 @@
 
         stream.begin_http_chunk_receiving()
         stream.feed_data(b'part1')
         stream.end_http_chunk_receiving()
         stream.begin_http_chunk_receiving()
         stream.feed_data(b'part2')
         stream.end_http_chunk_receiving()
+        stream.begin_http_chunk_receiving()
+        stream.feed_data(b'part3')
+        stream.end_http_chunk_receiving()
 
         data = await stream.read(7)
         assert b'part1pa' == data
 
         data, end_of_chunk = await stream.readchunk()
         assert b'rt2' == data
         assert end_of_chunk
 
+        # Corner case between read/readchunk
+        data = await stream.read(5)
+        assert b'part3' == data
+
+        data, end_of_chunk = await stream.readchunk()
+        assert b'' == data
+        assert end_of_chunk
+
         stream.feed_eof()
+
         data, end_of_chunk = await stream.readchunk()
         assert b'' == data
         assert not end_of_chunk
 
+    async def test_chunksplits_memory_leak(self) -> None:
+        """ Test for memory leak on chunksplits """
+        stream = self._make_one()
+
+        N = 500
+
+        # Warm-up variables
+        stream.begin_http_chunk_receiving()
+        stream.feed_data(b'Y' * N)
+        stream.end_http_chunk_receiving()
+        await stream.read(N)
+
+        N = 300
+
+        before = get_memory_usage(stream)
+        for _ in range(N):
+            stream.begin_http_chunk_receiving()
+            stream.feed_data(b'X')
+            stream.end_http_chunk_receiving()
+        await stream.read(N)
+        after = get_memory_usage(stream)
+
+        assert abs(after - before) == 0
+
     async def test_read_empty_chunks(self) -> None:
         """Test that feeding empty chunks does not break stream"""
         stream = self._make_one()
 
         # Simulate empty first chunk. This is significant special case
         stream.begin_http_chunk_receiving()
         stream.end_http_chunk_receiving()
@@ -825,16 +911,15 @@
 
     async def test___repr__data(self) -> None:
         stream = self._make_one()
         stream.feed_data(b'data')
         assert "<StreamReader 4 bytes>" == repr(stream)
 
     async def test___repr__exception(self) -> None:
-        loop = asyncio.get_event_loop()
-        stream = self._make_one(loop=loop)
+        stream = self._make_one()
         exc = RuntimeError()
         stream.set_exception(exc)
         assert "<StreamReader e=RuntimeError()>" == repr(stream)
 
     async def test___repr__waiter(self) -> None:
         loop = asyncio.get_event_loop()
         stream = self._make_one()
```

### Comparing `aiohttp-4.0.0a0/tests/test_tcp_helpers.py` & `aiohttp-4.0.0a1/tests/test_tcp_helpers.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/tests/test_test_utils.py` & `aiohttp-4.0.0a1/tests/test_test_utils.py`

 * *Files 5% similar despite different names*

```diff
@@ -62,37 +62,23 @@
 def app():
     return _create_example_app()
 
 
 @pytest.fixture
 def test_client(loop, app) -> None:
     async def make_client():
-        return _TestClient(_TestServer(app, loop=loop), loop=loop)
+        return _TestClient(_TestServer(app))
 
     client = loop.run_until_complete(make_client())
 
     loop.run_until_complete(client.start_server())
     yield client
     loop.run_until_complete(client.close())
 
 
-def test_with_test_server_fails(loop) -> None:
-    app = _create_example_app()
-    with pytest.raises(TypeError):
-        with _TestServer(app, loop=loop):
-            pass
-
-
-async def test_with_client_fails(loop) -> None:
-    app = _create_example_app()
-    with pytest.raises(TypeError):
-        with _TestClient(_TestServer(app, loop=loop), loop=loop):
-            pass
-
-
 async def test_aiohttp_client_close_is_idempotent() -> None:
     """
     a test client, called multiple times, should
     not attempt to close the server again.
     """
     app = _create_example_app()
     client = _TestClient(_TestServer(app))
@@ -211,47 +197,49 @@
 
 def test_make_mocked_request_transport() -> None:
     transport = mock.Mock()
     req = make_mocked_request('GET', '/', transport=transport)
     assert req.transport is transport
 
 
-async def test_test_client_props(loop) -> None:
+async def test_test_client_props() -> None:
     app = _create_example_app()
-    client = _TestClient(_TestServer(app, host='127.0.0.1', loop=loop),
-                         loop=loop)
+    server = _TestServer(app, scheme='http', host='127.0.0.1')
+    client = _TestClient(server)
+    assert client.scheme == 'http'
     assert client.host == '127.0.0.1'
     assert client.port is None
     async with client:
         assert isinstance(client.port, int)
         assert client.server is not None
         assert client.app is not None
     assert client.port is None
 
 
-async def test_test_client_raw_server_props(loop) -> None:
+async def test_test_client_raw_server_props() -> None:
 
     async def hello(request):
         return web.Response(body=_hello_world_bytes)
 
-    client = _TestClient(_RawTestServer(hello, host='127.0.0.1', loop=loop),
-                         loop=loop)
+    server = _RawTestServer(hello, scheme='http', host='127.0.0.1')
+    client = _TestClient(server)
+    assert client.scheme == 'http'
     assert client.host == '127.0.0.1'
     assert client.port is None
     async with client:
         assert isinstance(client.port, int)
         assert client.server is not None
         assert client.app is None
     assert client.port is None
 
 
 async def test_test_server_context_manager(loop) -> None:
     app = _create_example_app()
-    async with _TestServer(app, loop=loop) as server:
-        client = aiohttp.ClientSession(loop=loop)
+    async with _TestServer(app) as server:
+        client = aiohttp.ClientSession()
         resp = await client.head(server.make_url('/'))
         assert resp.status == 200
         resp.close()
         await client.close()
 
 
 def test_client_unsupported_arg() -> None:
@@ -260,15 +248,15 @@
 
     assert str(e.value) == \
         "server must be TestServer instance, found type: <class 'str'>"
 
 
 async def test_server_make_url_yarl_compatibility(loop) -> None:
     app = _create_example_app()
-    async with _TestServer(app, loop=loop) as server:
+    async with _TestServer(app) as server:
         make_url = server.make_url
         assert make_url(URL('/foo')) == make_url('/foo')
         with pytest.raises(AssertionError):
             make_url('http://foo.com')
         with pytest.raises(AssertionError):
             make_url(URL('http://foo.com'))
 
@@ -284,35 +272,35 @@
                 pass
         """)
     result = testdir.runpytest()
     result.stdout.fnmatch_lines(["*RuntimeError*"])
 
 
 async def test_server_context_manager(app, loop) -> None:
-    async with _TestServer(app, loop=loop) as server:
-        async with aiohttp.ClientSession(loop=loop) as client:
+    async with _TestServer(app) as server:
+        async with aiohttp.ClientSession() as client:
             async with client.head(server.make_url('/')) as resp:
                 assert resp.status == 200
 
 
 @pytest.mark.parametrize("method", [
     "head", "get", "post", "options", "post", "put", "patch", "delete"
 ])
 async def test_client_context_manager_response(method, app, loop) -> None:
-    async with _TestClient(_TestServer(app), loop=loop) as client:
+    async with _TestClient(_TestServer(app)) as client:
         async with getattr(client, method)('/') as resp:
             assert resp.status == 200
             if method != 'head':
                 text = await resp.text()
                 assert "Hello, world" in text
 
 
 async def test_custom_port(loop, app, aiohttp_unused_port) -> None:
     port = aiohttp_unused_port()
-    client = _TestClient(_TestServer(app, loop=loop, port=port), loop=loop)
+    client = _TestClient(_TestServer(app, port=port))
     await client.start_server()
 
     assert client.server.port == port
 
     resp = await client.get('/')
     assert resp.status == 200
     text = await resp.text()
```

### Comparing `aiohttp-4.0.0a0/tests/test_tracing.py` & `aiohttp-4.0.0a1/tests/test_tracing.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-import asyncio
 from types import SimpleNamespace
 from unittest.mock import Mock
 
 import pytest
 
+from aiohttp.test_utils import make_mocked_coro
 from aiohttp.tracing import (
     Trace,
     TraceConfig,
     TraceConnectionCreateEndParams,
     TraceConnectionCreateStartParams,
     TraceConnectionQueuedEndParams,
     TraceConnectionQueuedStartParams,
@@ -141,15 +141,15 @@
             (Mock(),),
             TraceDnsCacheMissParams
         )
     ])
     async def test_send(self, signal, params, param_obj) -> None:
         session = Mock()
         trace_request_ctx = Mock()
-        callback = Mock(side_effect=asyncio.coroutine(Mock()))
+        callback = Mock(side_effect=make_mocked_coro(Mock()))
 
         trace_config = TraceConfig()
         getattr(trace_config, "on_%s" % signal).append(callback)
         trace_config.freeze()
         trace = Trace(
             session,
             trace_config,
```

### Comparing `aiohttp-4.0.0a0/tests/test_urldispatch.py` & `aiohttp-4.0.0a1/tests/test_urldispatch.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-import os
 import pathlib
 import re
 from collections.abc import Container, Iterable, Mapping, MutableMapping, Sized
 from urllib.parse import unquote
 
 import pytest
 from yarl import URL
@@ -47,36 +46,43 @@
 @pytest.fixture
 def fill_routes(router):
     def go():
         route1 = router.add_route('GET', '/plain', make_handler())
         route2 = router.add_route('GET', '/variable/{name}',
                                   make_handler())
         resource = router.add_static('/static',
-                                     os.path.dirname(aiohttp.__file__))
+                                     pathlib.Path(aiohttp.__file__).parent)
         return [route1, route2] + list(resource)
     return go
 
 
 def test_register_uncommon_http_methods(router) -> None:
     uncommon_http_methods = {
         'PROPFIND',
         'PROPPATCH',
         'COPY',
         'LOCK',
-        'UNLOCK'
+        'UNLOCK',
         'MOVE',
         'SUBSCRIBE',
         'UNSUBSCRIBE',
         'NOTIFY'
     }
 
     for method in uncommon_http_methods:
         router.add_route(method, '/handler/to/path', make_handler())
 
 
+async def test_add_sync_handler(router) -> None:
+    def handler(request):
+        pass
+    with pytest.raises(TypeError):
+        router.add_get('/handler/to/path', handler)
+
+
 async def test_add_route_root(router) -> None:
     handler = make_handler()
     router.add_route('GET', '/', handler)
     req = make_mocked_request('GET', '/')
     info = await router.resolve(req)
     assert info is not None
     assert 0 == len(info)
@@ -341,115 +347,116 @@
     url = route2.url_for(name='John')
     assert '/get/John' == str(url)
     assert route is route2
 
 
 def test_add_static(router) -> None:
     resource = router.add_static('/st',
-                                 os.path.dirname(aiohttp.__file__),
+                                 pathlib.Path(aiohttp.__file__).parent,
                                  name='static')
     assert router['static'] is resource
     url = resource.url_for(filename='/dir/a.txt')
     assert '/st/dir/a.txt' == str(url)
     assert len(resource) == 2
 
 
 def test_add_static_append_version(router) -> None:
     resource = router.add_static('/st',
-                                 os.path.dirname(__file__),
+                                 pathlib.Path(__file__).parent,
                                  name='static')
     url = resource.url_for(filename='/data.unknown_mime_type',
                            append_version=True)
     expect_url = '/st/data.unknown_mime_type?' \
                  'v=aUsn8CHEhhszc81d28QmlcBW0KQpfS2F4trgQKhOYd8%3D'
     assert expect_url == str(url)
 
 
 def test_add_static_append_version_set_from_constructor(router) -> None:
     resource = router.add_static('/st',
-                                 os.path.dirname(__file__),
+                                 pathlib.Path(__file__).parent,
                                  append_version=True,
                                  name='static')
     url = resource.url_for(filename='/data.unknown_mime_type')
     expect_url = '/st/data.unknown_mime_type?' \
                  'v=aUsn8CHEhhszc81d28QmlcBW0KQpfS2F4trgQKhOYd8%3D'
     assert expect_url == str(url)
 
 
 def test_add_static_append_version_override_constructor(router) -> None:
     resource = router.add_static('/st',
-                                 os.path.dirname(__file__),
+                                 pathlib.Path(__file__).parent,
                                  append_version=True,
                                  name='static')
     url = resource.url_for(filename='/data.unknown_mime_type',
                            append_version=False)
     expect_url = '/st/data.unknown_mime_type'
     assert expect_url == str(url)
 
 
 def test_add_static_append_version_filename_without_slash(router) -> None:
     resource = router.add_static('/st',
-                                 os.path.dirname(__file__),
+                                 pathlib.Path(__file__).parent,
                                  name='static')
     url = resource.url_for(filename='data.unknown_mime_type',
                            append_version=True)
     expect_url = '/st/data.unknown_mime_type?' \
                  'v=aUsn8CHEhhszc81d28QmlcBW0KQpfS2F4trgQKhOYd8%3D'
     assert expect_url == str(url)
 
 
 def test_add_static_append_version_non_exists_file(router) -> None:
     resource = router.add_static('/st',
-                                 os.path.dirname(__file__),
+                                 pathlib.Path(__file__).parent,
                                  name='static')
     url = resource.url_for(filename='/non_exists_file', append_version=True)
     assert '/st/non_exists_file' == str(url)
 
 
 def test_add_static_append_version_non_exists_file_without_slash(
         router) -> None:
     resource = router.add_static('/st',
-                                 os.path.dirname(__file__),
+                                 pathlib.Path(__file__).parent,
                                  name='static')
     url = resource.url_for(filename='non_exists_file', append_version=True)
     assert '/st/non_exists_file' == str(url)
 
 
-def test_add_static_append_version_follow_symlink(router, tmpdir) -> None:
+def test_add_static_append_version_follow_symlink(router, tmp_path) -> None:
     """
     Tests the access to a symlink, in static folder with apeend_version
     """
-    tmp_dir_path = str(tmpdir)
-    symlink_path = os.path.join(tmp_dir_path, 'append_version_symlink')
-    symlink_target_path = os.path.dirname(__file__)
-    os.symlink(symlink_target_path, symlink_path, True)
+    symlink_path = tmp_path / 'append_version_symlink'
+    symlink_target_path = pathlib.Path(__file__).parent
+    pathlib.Path(str(symlink_path)).symlink_to(str(symlink_target_path), True)
 
     # Register global static route:
-    resource = router.add_static('/st', tmp_dir_path, follow_symlinks=True,
+    resource = router.add_static('/st', str(tmp_path), follow_symlinks=True,
                                  append_version=True)
 
     url = resource.url_for(
         filename='/append_version_symlink/data.unknown_mime_type')
 
     expect_url = '/st/append_version_symlink/data.unknown_mime_type?' \
                  'v=aUsn8CHEhhszc81d28QmlcBW0KQpfS2F4trgQKhOYd8%3D'
     assert expect_url == str(url)
 
 
-def test_add_static_append_version_not_follow_symlink(router, tmpdir) -> None:
+def test_add_static_append_version_not_follow_symlink(router,
+                                                      tmp_path) -> None:
     """
     Tests the access to a symlink, in static folder with apeend_version
     """
-    tmp_dir_path = str(tmpdir)
-    symlink_path = os.path.join(tmp_dir_path, 'append_version_symlink')
-    symlink_target_path = os.path.dirname(__file__)
-    os.symlink(symlink_target_path, symlink_path, True)
+
+    symlink_path = tmp_path / 'append_version_symlink'
+    symlink_target_path = pathlib.Path(__file__).parent
+
+    pathlib.Path(str(symlink_path)).symlink_to(str(symlink_target_path), True)
 
     # Register global static route:
-    resource = router.add_static('/st', tmp_dir_path, follow_symlinks=False,
+    resource = router.add_static('/st', str(tmp_path), follow_symlinks=False,
                                  append_version=True)
 
     filename = '/append_version_symlink/data.unknown_mime_type'
     url = resource.url_for(filename=filename)
     assert '/st/append_version_symlink/data.unknown_mime_type' == str(url)
 
 
@@ -464,15 +471,15 @@
     handler = make_handler()
     router.add_route('GET', '/get/{name}', handler, name='name')
     route = router['name']
     assert route._match('/another/path') is None
 
 
 async def test_static_not_match(router) -> None:
-    router.add_static('/pre', os.path.dirname(aiohttp.__file__),
+    router.add_static('/pre', pathlib.Path(aiohttp.__file__).parent,
                       name='name')
     resource = router['name']
     ret = await resource.resolve(
         make_mocked_request('GET', '/another/path'))
     assert (None, set()) == ret
 
 
@@ -502,28 +509,28 @@
     router.add_route('GET', '/get1', handler, name='name1')
     router.add_route('GET', '/get2', handler, name='name2')
     assert 'name1' in router
     assert 'name3' not in router
 
 
 def test_static_repr(router) -> None:
-    router.add_static('/get', os.path.dirname(aiohttp.__file__),
+    router.add_static('/get', pathlib.Path(aiohttp.__file__).parent,
                       name='name')
     assert re.match(r"<StaticResource 'name' /get", repr(router['name']))
 
 
 def test_static_adds_slash(router) -> None:
     route = router.add_static('/prefix',
-                              os.path.dirname(aiohttp.__file__))
+                              pathlib.Path(aiohttp.__file__).parent)
     assert '/prefix' == route._prefix
 
 
 def test_static_remove_trailing_slash(router) -> None:
     route = router.add_static('/prefix/',
-                              os.path.dirname(aiohttp.__file__))
+                              pathlib.Path(aiohttp.__file__).parent)
     assert '/prefix' == route._prefix
 
 
 async def test_add_route_with_re(router) -> None:
     handler = make_handler()
     router.add_route('GET', r'/handler/{to:\d+}', handler)
 
@@ -786,15 +793,15 @@
 
 def test_named_resources(router) -> None:
     route1 = router.add_route('GET', '/plain', make_handler(),
                               name='route1')
     route2 = router.add_route('GET', '/variable/{name}',
                               make_handler(), name='route2')
     route3 = router.add_static('/static',
-                               os.path.dirname(aiohttp.__file__),
+                               pathlib.Path(aiohttp.__file__).parent,
                                name='route3')
     names = {route1.name, route2.name, route3.name}
 
     assert 3 == len(router.named_resources())
 
     for name in names:
         assert name in router.named_resources()
@@ -808,28 +815,18 @@
     resource = router.add_resource('/path')
     r1 = resource.add_route('GET', handler)
     r2 = resource.add_route('POST', handler)
     assert 2 == len(resource)
     assert [r1, r2] == list(resource)
 
 
-def test_deprecate_bare_generators(router) -> None:
-    resource = router.add_resource('/path')
-
-    def gen(request):
-        yield
-
-    with pytest.warns(DeprecationWarning):
-        resource.add_route('GET', gen)
-
-
 def test_view_route(router) -> None:
     resource = router.add_resource('/path')
 
-    route = resource.add_route('GET', View)
+    route = resource.add_route('*', View)
     assert View is route.handler
 
 
 def test_resource_route_match(router) -> None:
     async def handler(request):
         pass
     resource = router.add_resource('/path')
@@ -901,15 +898,15 @@
                               '(?P<a>[^{}/]+)' +
                               PATH_SEP +
                               '(?P<b>[^{}/]+)'),
         'formatter': '/{a}/{b}'}
 
 
 def test_static_resource_get_info(router) -> None:
-    directory = pathlib.Path(aiohttp.__file__).parent
+    directory = pathlib.Path(aiohttp.__file__).parent.resolve()
     resource = router.add_static('/st', directory)
     assert resource.get_info() == {'directory': directory,
                                    'prefix': '/st'}
 
 
 async def test_system_route_get_info(router) -> None:
     handler = make_handler()
@@ -944,39 +941,39 @@
     assert isinstance(router.resources(), Sized)
     assert isinstance(router.resources(), Iterable)
     assert isinstance(router.resources(), Container)
 
 
 def test_static_route_user_home(router) -> None:
     here = pathlib.Path(aiohttp.__file__).parent
-    home = pathlib.Path(os.path.expanduser('~'))
-    if not str(here).startswith(str(home)):  # pragma: no cover
+    try:
+        static_dir = pathlib.Path('~') / here.relative_to(pathlib.Path.home())
+    except ValueError:
         pytest.skip("aiohttp folder is not placed in user's HOME")
-    static_dir = '~/' + str(here.relative_to(home))
-    route = router.add_static('/st', static_dir)
+    route = router.add_static('/st', str(static_dir))
     assert here == route.get_info()['directory']
 
 
 def test_static_route_points_to_file(router) -> None:
     here = pathlib.Path(aiohttp.__file__).parent / '__init__.py'
     with pytest.raises(ValueError):
         router.add_static('/st', here)
 
 
 async def test_404_for_static_resource(router) -> None:
     resource = router.add_static('/st',
-                                 os.path.dirname(aiohttp.__file__))
+                                 pathlib.Path(aiohttp.__file__).parent)
     ret = await resource.resolve(
         make_mocked_request('GET', '/unknown/path'))
     assert (None, set()) == ret
 
 
 async def test_405_for_resource_adapter(router) -> None:
     resource = router.add_static('/st',
-                                 os.path.dirname(aiohttp.__file__))
+                                 pathlib.Path(aiohttp.__file__).parent)
     ret = await resource.resolve(
         make_mocked_request('POST', '/st/abc.py'))
     assert (None, {'HEAD', 'GET'}) == ret
 
 
 async def test_check_allowed_method_for_found_resource(router) -> None:
     handler = make_handler()
@@ -985,21 +982,21 @@
     ret = await resource.resolve(make_mocked_request('GET', '/'))
     assert ret[0] is not None
     assert {'GET'} == ret[1]
 
 
 def test_url_for_in_static_resource(router) -> None:
     resource = router.add_static('/static',
-                                 os.path.dirname(aiohttp.__file__))
+                                 pathlib.Path(aiohttp.__file__).parent)
     assert URL('/static/file.txt') == resource.url_for(filename='file.txt')
 
 
 def test_url_for_in_static_resource_pathlib(router) -> None:
     resource = router.add_static('/static',
-                                 os.path.dirname(aiohttp.__file__))
+                                 pathlib.Path(aiohttp.__file__).parent)
     assert URL('/static/file.txt') == resource.url_for(
         filename=pathlib.Path('file.txt'))
 
 
 def test_url_for_in_resource_route(router) -> None:
     route = router.add_route('GET', '/get/{name}', make_handler(),
                              name='name')
@@ -1161,15 +1158,15 @@
     subapp = web.Application()
     with pytest.raises(RuntimeError):
         app.add_subapp('/pre', subapp)
 
 
 def test_set_options_route(router) -> None:
     resource = router.add_static('/static',
-                                 os.path.dirname(aiohttp.__file__))
+                                 pathlib.Path(aiohttp.__file__).parent)
     options = None
     for route in resource:
         if route.method == 'OPTIONS':
             options = route
     assert options is None
     resource.set_options_route(make_handler())
     for route in resource:
@@ -1203,22 +1200,14 @@
     route = router.add_get('', handler)
     resource = route.resource
     assert resource.get_info() == {'path': ''}
     router.freeze()
     assert resource.get_info() == {'path': '/'}
 
 
-def test_deprecate_non_coroutine(router) -> None:
-    def handler(request):
-        pass
-
-    with pytest.warns(DeprecationWarning):
-        router.add_route('GET', '/handler', handler)
-
-
 def test_plain_resource_canonical() -> None:
     canonical = '/plain/path'
     res = PlainResource(path=canonical)
     assert res.canonical == canonical
 
 
 def test_dynamic_resource_canonical() -> None:
@@ -1231,18 +1220,62 @@
     for pattern, canonical in canonicals.items():
         res = DynamicResource(path=pattern)
         assert res.canonical == canonical
 
 
 def test_static_resource_canonical() -> None:
     prefix = '/prefix'
-    directory = str(os.path.dirname(aiohttp.__file__))
+    directory = str(pathlib.Path(aiohttp.__file__).parent)
     canonical = prefix
     res = StaticResource(prefix=prefix, directory=directory)
     assert res.canonical == canonical
 
 
 def test_prefixed_subapp_resource_canonical(app) -> None:
     canonical = '/prefix'
     subapp = web.Application()
     res = subapp.add_subapp(canonical, subapp)
     assert res.canonical == canonical
+
+
+async def test_prefixed_subapp_overlap(app) -> None:
+    """
+    Subapp should not overshadow other subapps with overlapping prefixes
+    """
+    subapp1 = web.Application()
+    handler1 = make_handler()
+    subapp1.router.add_get('/a', handler1)
+    app.add_subapp('/s', subapp1)
+
+    subapp2 = web.Application()
+    handler2 = make_handler()
+    subapp2.router.add_get('/b', handler2)
+    app.add_subapp('/ss', subapp2)
+
+    match_info = await app.router.resolve(make_mocked_request('GET', '/s/a'))
+    assert match_info.route.handler is handler1
+    match_info = await app.router.resolve(make_mocked_request('GET', '/ss/b'))
+    assert match_info.route.handler is handler2
+
+
+async def test_prefixed_subapp_empty_route(app) -> None:
+    subapp = web.Application()
+    handler = make_handler()
+    subapp.router.add_get('', handler)
+    app.add_subapp('/s', subapp)
+
+    match_info = await app.router.resolve(make_mocked_request('GET', '/s'))
+    assert match_info.route.handler is handler
+    match_info = await app.router.resolve(make_mocked_request('GET', '/s/'))
+    assert "<MatchInfoError 404: Not Found>" == repr(match_info)
+
+
+async def test_prefixed_subapp_root_route(app) -> None:
+    subapp = web.Application()
+    handler = make_handler()
+    subapp.router.add_get('/', handler)
+    app.add_subapp('/s', subapp)
+
+    match_info = await app.router.resolve(make_mocked_request('GET', '/s/'))
+    assert match_info.route.handler is handler
+    match_info = await app.router.resolve(make_mocked_request('GET', '/s'))
+    assert "<MatchInfoError 404: Not Found>" == repr(match_info)
```

### Comparing `aiohttp-4.0.0a0/tests/test_websocket_handshake.py` & `aiohttp-4.0.0a1/tests/test_websocket_handshake.py`

 * *Files 2% similar despite different names*

```diff
@@ -28,21 +28,14 @@
             params += '; client_no_context_takeover'
         if extension_text:
             params += '; ' + extension_text
         hdrs += [('Sec-Websocket-Extensions', params)]
     return hdrs, key
 
 
-async def test_not_get() -> None:
-    ws = web.WebSocketResponse()
-    req = make_mocked_request('POST', '/')
-    with pytest.raises(web.HTTPMethodNotAllowed):
-        await ws.prepare(req)
-
-
 async def test_no_upgrade() -> None:
     ws = web.WebSocketResponse()
     req = make_mocked_request('GET', '/')
     with pytest.raises(web.HTTPBadRequest):
         await ws.prepare(req)
 
 
@@ -257,7 +250,17 @@
 
     ws = web.WebSocketResponse()
     headers, _, compress, notakeover = ws._handshake(req)
 
     assert 'Sec-Websocket-Extensions' in headers
     assert headers['Sec-Websocket-Extensions'] == 'permessage-deflate'
     assert compress == 15
+
+
+def test_handshake_no_transfer_encoding() -> None:
+    hdrs, sec_key = gen_ws_headers()
+    req = make_mocked_request('GET', '/', headers=hdrs)
+
+    ws = web.WebSocketResponse()
+    headers, _, compress, notakeover = ws._handshake(req)
+
+    assert 'Transfer-Encoding' not in headers
```

### Comparing `aiohttp-4.0.0a0/tests/test_websocket_parser.py` & `aiohttp-4.0.0a1/tests/test_websocket_parser.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,7 +1,8 @@
+import pickle
 import random
 import struct
 import zlib
 from unittest import mock
 
 import pytest
 
@@ -408,24 +409,14 @@
 def test_websocket_mask_cython_empty() -> None:
     message = bytearray()
     http_websocket._websocket_mask_cython(
         websocket_mask_mask, message)
     assert message == bytearray()
 
 
-def test_msgtype_aliases() -> None:
-    assert aiohttp.WSMsgType.TEXT == aiohttp.WSMsgType.text
-    assert aiohttp.WSMsgType.BINARY == aiohttp.WSMsgType.binary
-    assert aiohttp.WSMsgType.PING == aiohttp.WSMsgType.ping
-    assert aiohttp.WSMsgType.PONG == aiohttp.WSMsgType.pong
-    assert aiohttp.WSMsgType.CLOSE == aiohttp.WSMsgType.close
-    assert aiohttp.WSMsgType.CLOSED == aiohttp.WSMsgType.closed
-    assert aiohttp.WSMsgType.ERROR == aiohttp.WSMsgType.error
-
-
 def test_parse_compress_frame_single(parser) -> None:
     parser.parse_frame(struct.pack('!BB', 0b11000001, 0b00000001))
     res = parser.parse_frame(b'1')
     fin, opcode, payload, compress = res[0]
 
     assert (1, 1, b'1', True) == (fin, opcode, payload, not not compress)
 
@@ -489,7 +480,24 @@
 
 def test_compressed_msg_too_large(out) -> None:
     parser = WebSocketReader(out, 256, compress=True)
     data = build_frame(b'aaa'*256, WSMsgType.TEXT, compress=True)
     with pytest.raises(WebSocketError) as ctx:
         parser._feed_data(data)
     assert ctx.value.code == WSCloseCode.MESSAGE_TOO_BIG
+
+
+class TestWebSocketError:
+    def test_ctor(self) -> None:
+        err = WebSocketError(WSCloseCode.PROTOCOL_ERROR, 'Something invalid')
+        assert err.code == WSCloseCode.PROTOCOL_ERROR
+        assert str(err) == 'Something invalid'
+
+    def test_pickle(self) -> None:
+        err = WebSocketError(WSCloseCode.PROTOCOL_ERROR, 'Something invalid')
+        err.foo = 'bar'
+        for proto in range(pickle.HIGHEST_PROTOCOL + 1):
+            pickled = pickle.dumps(err, proto)
+            err2 = pickle.loads(pickled)
+            assert err2.code == WSCloseCode.PROTOCOL_ERROR
+            assert str(err2) == 'Something invalid'
+            assert err2.foo == 'bar'
```

### Comparing `aiohttp-4.0.0a0/tests/test_websocket_writer.py` & `aiohttp-4.0.0a1/tests/test_websocket_writer.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,15 +12,17 @@
     ret = mock.Mock()
     ret._drain_helper = make_mocked_coro()
     return ret
 
 
 @pytest.fixture
 def transport():
-    return mock.Mock()
+    ret = mock.Mock()
+    ret.is_closing.return_value = False
+    return ret
 
 
 @pytest.fixture
 def writer(protocol, transport):
     return WebSocketWriter(protocol, transport, use_mask=False)
```

### Comparing `aiohttp-4.0.0a0/tests/test_web_app.py` & `aiohttp-4.0.0a1/tests/test_web_app.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,136 +1,27 @@
 import asyncio
 from unittest import mock
 
 import pytest
-from async_generator import async_generator, yield_
 
 from aiohttp import log, web
-from aiohttp.abc import AbstractAccessLogger, AbstractRouter
-from aiohttp.helpers import DEBUG, PY_36
+from aiohttp.helpers import PY_36
 from aiohttp.test_utils import make_mocked_coro
 
 
 async def test_app_ctor() -> None:
-    loop = asyncio.get_event_loop()
-    with pytest.warns(DeprecationWarning):
-        app = web.Application(loop=loop)
-    with pytest.warns(DeprecationWarning):
-        assert loop is app.loop
+    app = web.Application()
     assert app.logger is log.web_logger
 
 
 def test_app_call() -> None:
     app = web.Application()
     assert app is app()
 
 
-def test_app_default_loop() -> None:
-    app = web.Application()
-    with pytest.warns(DeprecationWarning):
-        assert app.loop is None
-
-
-async def test_set_loop() -> None:
-    loop = asyncio.get_event_loop()
-    app = web.Application()
-    app._set_loop(loop)
-    with pytest.warns(DeprecationWarning):
-        assert app.loop is loop
-
-
-def test_set_loop_default_loop() -> None:
-    loop = asyncio.new_event_loop()
-    asyncio.set_event_loop(loop)
-    app = web.Application()
-    app._set_loop(None)
-    with pytest.warns(DeprecationWarning):
-        assert app.loop is loop
-    asyncio.set_event_loop(None)
-
-
-def test_set_loop_with_different_loops() -> None:
-    loop = asyncio.new_event_loop()
-    app = web.Application()
-    app._set_loop(loop)
-    with pytest.warns(DeprecationWarning):
-        assert app.loop is loop
-
-    with pytest.raises(RuntimeError):
-        app._set_loop(loop=object())
-
-
-@pytest.mark.parametrize('debug', [True, False])
-async def test_app_make_handler_debug_exc(mocker, debug) -> None:
-    with pytest.warns(DeprecationWarning):
-        app = web.Application(debug=debug)
-    srv = mocker.patch('aiohttp.web_app.Server')
-
-    with pytest.warns(DeprecationWarning):
-        assert app.debug == debug
-
-    app._make_handler()
-    srv.assert_called_with(app._handle,
-                           request_factory=app._make_request,
-                           access_log_class=mock.ANY,
-                           loop=asyncio.get_event_loop(),
-                           debug=debug)
-
-
-async def test_app_make_handler_args(mocker) -> None:
-    app = web.Application(handler_args={'test': True})
-    srv = mocker.patch('aiohttp.web_app.Server')
-
-    app._make_handler()
-    srv.assert_called_with(app._handle,
-                           request_factory=app._make_request,
-                           access_log_class=mock.ANY,
-                           loop=asyncio.get_event_loop(),
-                           debug=mock.ANY, test=True)
-
-
-async def test_app_make_handler_access_log_class(mocker) -> None:
-    class Logger:
-        pass
-
-    app = web.Application()
-
-    with pytest.raises(TypeError):
-        app._make_handler(access_log_class=Logger)
-
-    class Logger(AbstractAccessLogger):
-
-        def log(self, request, response, time):
-            self.logger.info('msg')
-
-    srv = mocker.patch('aiohttp.web_app.Server')
-
-    app._make_handler(access_log_class=Logger)
-    srv.assert_called_with(app._handle,
-                           access_log_class=Logger,
-                           request_factory=app._make_request,
-                           loop=asyncio.get_event_loop(),
-                           debug=mock.ANY)
-
-    app = web.Application(handler_args={'access_log_class': Logger})
-    app._make_handler(access_log_class=Logger)
-    srv.assert_called_with(app._handle,
-                           access_log_class=Logger,
-                           request_factory=app._make_request,
-                           loop=asyncio.get_event_loop(),
-                           debug=mock.ANY)
-
-
-async def test_app_make_handler_raises_deprecation_warning() -> None:
-    app = web.Application()
-
-    with pytest.warns(DeprecationWarning):
-        app.make_handler()
-
-
 async def test_app_register_on_finish() -> None:
     app = web.Application()
     cb1 = make_mocked_coro(None)
     cb2 = make_mocked_coro(None)
     app.on_cleanup.append(cb1)
     app.on_cleanup.append(cb2)
     app.freeze()
@@ -150,21 +41,14 @@
     app.on_cleanup.append(cb)
     app.freeze()
     await app.cleanup()
     assert fut.done()
     assert 123 == fut.result()
 
 
-def test_non_default_router() -> None:
-    router = mock.Mock(spec=AbstractRouter)
-    with pytest.warns(DeprecationWarning):
-        app = web.Application(router=router)
-    assert router is app.router
-
-
 def test_logging() -> None:
     logger = mock.Mock()
     app = web.Application()
     app.logger = logger
     assert app.logger is logger
 
 
@@ -249,15 +133,14 @@
 
     root = web.Application()
     sub = web.Application()
     root.add_subapp('/sub', sub)
     root.freeze()
     assert root._run_middlewares is False
 
-    @web.middleware
     async def middleware(request, handler):
         return await handler(request)
 
     root = web.Application(middlewares=[middleware])
     sub = web.Application()
     root.add_subapp('/sub', sub)
     root.freeze()
@@ -278,36 +161,33 @@
     assert subapp.pre_frozen
     assert not subapp.frozen
 
 
 @pytest.mark.skipif(not PY_36,
                     reason="Python 3.6+ required")
 def test_app_inheritance() -> None:
-    with pytest.warns(DeprecationWarning):
+    with pytest.raises(TypeError):
         class A(web.Application):
             pass
 
 
-@pytest.mark.skipif(not DEBUG,
-                    reason="The check is applied in DEBUG mode only")
 def test_app_custom_attr() -> None:
     app = web.Application()
-    with pytest.warns(DeprecationWarning):
+    with pytest.raises(AttributeError):
         app.custom = None
 
 
 async def test_cleanup_ctx() -> None:
     app = web.Application()
     out = []
 
     def f(num):
-        @async_generator
         async def inner(app):
             out.append('pre_' + str(num))
-            await yield_(None)
+            yield None
             out.append('post_' + str(num))
         return inner
 
     app.cleanup_ctx.append(f(1))
     app.cleanup_ctx.append(f(2))
     app.freeze()
     await app.startup()
@@ -319,20 +199,19 @@
 async def test_cleanup_ctx_exception_on_startup() -> None:
     app = web.Application()
     out = []
 
     exc = Exception('fail')
 
     def f(num, fail=False):
-        @async_generator
         async def inner(app):
             out.append('pre_' + str(num))
             if fail:
                 raise exc
-            await yield_(None)
+            yield None
             out.append('post_' + str(num))
         return inner
 
     app.cleanup_ctx.append(f(1))
     app.cleanup_ctx.append(f(2, True))
     app.cleanup_ctx.append(f(3))
     app.freeze()
@@ -347,18 +226,17 @@
 async def test_cleanup_ctx_exception_on_cleanup() -> None:
     app = web.Application()
     out = []
 
     exc = Exception('fail')
 
     def f(num, fail=False):
-        @async_generator
         async def inner(app):
             out.append('pre_' + str(num))
-            await yield_(None)
+            yield None
             out.append('post_' + str(num))
             if fail:
                 raise exc
         return inner
 
     app.cleanup_ctx.append(f(1))
     app.cleanup_ctx.append(f(2, True))
@@ -373,18 +251,17 @@
 
 
 async def test_cleanup_ctx_exception_on_cleanup_multiple() -> None:
     app = web.Application()
     out = []
 
     def f(num, fail=False):
-        @async_generator
         async def inner(app):
             out.append('pre_' + str(num))
-            await yield_(None)
+            yield None
             out.append('post_' + str(num))
             if fail:
                 raise Exception('fail_' + str(num))
         return inner
 
     app.cleanup_ctx.append(f(1))
     app.cleanup_ctx.append(f(2, True))
@@ -402,20 +279,19 @@
 
 
 async def test_cleanup_ctx_multiple_yields() -> None:
     app = web.Application()
     out = []
 
     def f(num):
-        @async_generator
         async def inner(app):
             out.append('pre_' + str(num))
-            await yield_(None)
+            yield None
             out.append('post_' + str(num))
-            await yield_(None)
+            yield None
         return inner
 
     app.cleanup_ctx.append(f(1))
     app.freeze()
     await app.startup()
     assert out == ['pre_1']
     with pytest.raises(RuntimeError) as ctx:
@@ -492,20 +368,19 @@
         app['startup'] = True
 
     subapp.on_startup.append(on_startup)
 
     ctx_pre_called = False
     ctx_post_called = False
 
-    @async_generator
     async def cleanup_ctx(app):
         nonlocal ctx_pre_called, ctx_post_called
         ctx_pre_called = True
         app['cleanup'] = True
-        await yield_(None)
+        yield None
         ctx_post_called = True
 
     subapp.cleanup_ctx.append(cleanup_ctx)
 
     shutdown_called = False
 
     async def on_shutdown(app):
@@ -556,7 +431,27 @@
 
 
 def test_app_iter():
     app = web.Application()
     app['a'] = '1'
     app['b'] = '2'
     assert sorted(list(app)) == ['a', 'b']
+
+
+def test_app_forbid_nonslot_attr():
+    app = web.Application()
+    with pytest.raises(AttributeError):
+        app.unknow_attr
+    with pytest.raises(AttributeError):
+        app.unknow_attr = 1
+
+
+def test_forbid_changing_frozen_app() -> None:
+    app = web.Application()
+    app.freeze()
+    with pytest.raises(RuntimeError):
+        app['key'] = 'value'
+
+
+def test_app_boolean() -> None:
+    app = web.Application()
+    assert app
```

### Comparing `aiohttp-4.0.0a0/tests/test_web_cli.py` & `aiohttp-4.0.0a1/tests/test_web_cli.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/tests/test_web_functional.py` & `aiohttp-4.0.0a1/tests/test_web_functional.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,27 +3,27 @@
 import json
 import pathlib
 import socket
 import zlib
 from unittest import mock
 
 import pytest
-from async_generator import async_generator, yield_
 from multidict import CIMultiDictProxy, MultiDict
 from yarl import URL
 
 import aiohttp
 from aiohttp import (
     FormData,
     HttpVersion10,
     HttpVersion11,
     TraceConfig,
     multipart,
     web,
 )
+from aiohttp.test_utils import make_mocked_coro
 
 try:
     import ssl
 except ImportError:
     ssl = None  # type: ignore
 
 
@@ -230,15 +230,35 @@
         resp.body = b''
         return resp
 
     app = web.Application()
     app.router.add_post('/', handler)
     client = await aiohttp_client(app)
 
-    resp = await client.post('/', data=writer, headers=writer.headers)
+    resp = await client.post('/', data=writer)
+    assert 200 == resp.status
+    await resp.release()
+
+
+async def test_multipart_empty(aiohttp_client) -> None:
+    with multipart.MultipartWriter() as writer:
+        pass
+
+    async def handler(request):
+        reader = await request.multipart()
+        assert isinstance(reader, multipart.MultipartReader)
+        async for part in reader:
+            assert False, 'Unexpected part found in reader: {!r}'.format(part)
+        return web.Response()
+
+    app = web.Application()
+    app.router.add_post('/', handler)
+    client = await aiohttp_client(app)
+
+    resp = await client.post('/', data=writer)
     assert 200 == resp.status
     await resp.release()
 
 
 async def test_multipart_content_transfer_encoding(aiohttp_client) -> None:
     """For issue #1168"""
     with multipart.MultipartWriter() as writer:
@@ -260,15 +280,15 @@
         resp.body = b''
         return resp
 
     app = web.Application()
     app.router.add_post('/', handler)
     client = await aiohttp_client(app)
 
-    resp = await client.post('/', data=writer, headers=writer.headers)
+    resp = await client.post('/', data=writer)
     assert 200 == resp.status
     await resp.release()
 
 
 async def test_render_redirect(aiohttp_client) -> None:
 
     async def handler(request):
@@ -668,16 +688,14 @@
 
 
 async def test_empty_content_for_query_without_body(aiohttp_client) -> None:
 
     async def handler(request):
         assert not request.body_exists
         assert not request.can_read_body
-        with pytest.warns(DeprecationWarning):
-            assert not request.has_body
         return web.Response()
 
     app = web.Application()
     app.router.add_post('/', handler)
     client = await aiohttp_client(app)
 
     resp = await client.post('/')
@@ -685,16 +703,14 @@
 
 
 async def test_empty_content_for_query_with_body(aiohttp_client) -> None:
 
     async def handler(request):
         assert request.body_exists
         assert request.can_read_body
-        with pytest.warns(DeprecationWarning):
-            assert request.has_body
         body = await request.read()
         return web.Response(body=body)
 
     app = web.Application()
     app.router.add_post('/', handler)
     client = await aiohttp_client(app)
 
@@ -764,20 +780,19 @@
 async def test_response_with_async_gen(aiohttp_client, fname) -> None:
 
     with fname.open('rb') as f:
         data = f.read()
 
     data_size = len(data)
 
-    @async_generator
     async def stream(f_name):
         with f_name.open('rb') as f:
             data = f.read(100)
             while data:
-                await yield_(data)
+                yield data
                 data = f.read(100)
 
     async def handler(request):
         headers = {'Content-Length': str(data_size)}
         return web.Response(body=stream(fname), headers=headers)
 
     app = web.Application()
@@ -787,59 +802,27 @@
     resp = await client.get('/')
     assert 200 == resp.status
     resp_data = await resp.read()
     assert resp_data == data
     assert resp.headers.get('Content-Length') == str(len(resp_data))
 
 
-async def test_response_with_streamer(aiohttp_client, fname) -> None:
-
-    with fname.open('rb') as f:
-        data = f.read()
-
-    data_size = len(data)
-
-    with pytest.warns(DeprecationWarning):
-        @aiohttp.streamer
-        async def stream(writer, f_name):
-            with f_name.open('rb') as f:
-                data = f.read(100)
-                while data:
-                    await writer.write(data)
-                    data = f.read(100)
-
-    async def handler(request):
-        headers = {'Content-Length': str(data_size)}
-        return web.Response(body=stream(fname), headers=headers)
-
-    app = web.Application()
-    app.router.add_get('/', handler)
-    client = await aiohttp_client(app)
-
-    resp = await client.get('/')
-    assert 200 == resp.status
-    resp_data = await resp.read()
-    assert resp_data == data
-    assert resp.headers.get('Content-Length') == str(len(resp_data))
-
-
 async def test_response_with_async_gen_no_params(aiohttp_client,
                                                  fname) -> None:
 
     with fname.open('rb') as f:
         data = f.read()
 
     data_size = len(data)
 
-    @async_generator
     async def stream():
         with fname.open('rb') as f:
             data = f.read(100)
             while data:
-                await yield_(data)
+                yield data
                 data = f.read(100)
 
     async def handler(request):
         headers = {'Content-Length': str(data_size)}
         return web.Response(body=stream(), headers=headers)
 
     app = web.Application()
@@ -849,45 +832,14 @@
     resp = await client.get('/')
     assert 200 == resp.status
     resp_data = await resp.read()
     assert resp_data == data
     assert resp.headers.get('Content-Length') == str(len(resp_data))
 
 
-async def test_response_with_streamer_no_params(aiohttp_client, fname) -> None:
-
-    with fname.open('rb') as f:
-        data = f.read()
-
-    data_size = len(data)
-
-    with pytest.warns(DeprecationWarning):
-        @aiohttp.streamer
-        async def stream(writer):
-            with fname.open('rb') as f:
-                data = f.read(100)
-                while data:
-                    await writer.write(data)
-                    data = f.read(100)
-
-    async def handler(request):
-        headers = {'Content-Length': str(data_size)}
-        return web.Response(body=stream, headers=headers)
-
-    app = web.Application()
-    app.router.add_get('/', handler)
-    client = await aiohttp_client(app)
-
-    resp = await client.get('/')
-    assert 200 == resp.status
-    resp_data = await resp.read()
-    assert resp_data == data
-    assert resp.headers.get('Content-Length') == str(len(resp_data))
-
-
 async def test_response_with_file(aiohttp_client, fname) -> None:
 
     with fname.open('rb') as f:
         data = f.read()
 
     async def handler(request):
         return web.Response(body=fname.open('rb'))
@@ -1269,43 +1221,47 @@
     app.add_subapp('/path/', subapp)
 
     client = await aiohttp_client(app)
     resp = await client.get('/path/to')
     assert resp.status == 500
 
 
-async def test_subapp_middlewares(aiohttp_client) -> None:
+async def test_old_style_subapp_middlewares(aiohttp_client) -> None:
     order = []
 
     async def handler(request):
         return web.Response(text='OK')
 
-    async def middleware_factory(app, handler):
-
-        async def middleware(request):
-            order.append((1, app))
+    with pytest.warns(
+        DeprecationWarning, match='Middleware decorator is deprecated'
+    ):
+        @web.middleware
+        async def middleware(request, handler):
+            order.append((1, request.app['name']))
             resp = await handler(request)
             assert 200 == resp.status
-            order.append((2, app))
+            order.append((2, request.app['name']))
             return resp
-        return middleware
 
-    app = web.Application(middlewares=[middleware_factory])
-    subapp1 = web.Application(middlewares=[middleware_factory])
-    subapp2 = web.Application(middlewares=[middleware_factory])
+    app = web.Application(middlewares=[middleware])
+    subapp1 = web.Application(middlewares=[middleware])
+    subapp2 = web.Application(middlewares=[middleware])
+    app['name'] = 'app'
+    subapp1['name'] = 'subapp1'
+    subapp2['name'] = 'subapp2'
+
     subapp2.router.add_get('/to', handler)
-    with pytest.warns(DeprecationWarning):
-        subapp1.add_subapp('/b/', subapp2)
-        app.add_subapp('/a/', subapp1)
-        client = await aiohttp_client(app)
+    subapp1.add_subapp('/b/', subapp2)
+    app.add_subapp('/a/', subapp1)
+    client = await aiohttp_client(app)
 
     resp = await client.get('/a/b/to')
     assert resp.status == 200
-    assert [(1, app), (1, subapp1), (1, subapp2),
-            (2, subapp2), (2, subapp1), (2, app)] == order
+    assert [(1, 'app'), (1, 'subapp1'), (1, 'subapp2'),
+            (2, 'subapp2'), (2, 'subapp1'), (2, 'app')] == order
 
 
 async def test_subapp_on_response_prepare(aiohttp_client) -> None:
     order = []
 
     async def handler(request):
         return web.Response(text='OK')
@@ -1406,15 +1362,14 @@
     ('/', ['B: root'], ''),
 ])
 async def test_subapp_middleware_context(aiohttp_client,
                                          route, expected, middlewares):
     values = []
 
     def show_app_context(appname):
-        @web.middleware
         async def middleware(request, handler):
             values.append('{}: {}'.format(
                 appname, request.app['my_value']))
             return await handler(request)
         return middleware
 
     def make_handler(appname):
@@ -1599,28 +1554,28 @@
 
     disp = multipart.parse_content_disposition(
         resp.headers['content-disposition'])
     assert disp == ('attachment',
                     {'name': 'file', 'filename': 'file', 'filename*': 'file'})
 
 
-async def test_response_with_bodypart_named(aiohttp_client, tmpdir) -> None:
+async def test_response_with_bodypart_named(aiohttp_client, tmp_path) -> None:
 
     async def handler(request):
         reader = await request.multipart()
         part = await reader.next()
         return web.Response(body=part)
 
     app = web.Application(client_max_size=2)
     app.router.add_post('/', handler)
     client = await aiohttp_client(app)
 
-    f = tmpdir.join('foobar.txt')
+    f = tmp_path / 'foobar.txt'
     f.write_text('test', encoding='utf8')
-    data = {'file': open(str(f), 'rb')}
+    data = {'file': f.open('rb')}
     resp = await client.post('/', data=data)
 
     assert 200 == resp.status
     body = await resp.read()
     assert body == b'test'
 
     disp = multipart.parse_content_disposition(
@@ -1791,25 +1746,25 @@
     async with aiohttp.ClientSession() as session:
         async with session.post(server.make_url('/'), data=data) as resp:
             assert resp.status == 200
 
 
 async def test_request_tracing(aiohttp_server) -> None:
 
-    on_request_start = mock.Mock(side_effect=asyncio.coroutine(mock.Mock()))
-    on_request_end = mock.Mock(side_effect=asyncio.coroutine(mock.Mock()))
+    on_request_start = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))
+    on_request_end = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))
     on_dns_resolvehost_start = mock.Mock(
-        side_effect=asyncio.coroutine(mock.Mock()))
+        side_effect=make_mocked_coro(mock.Mock()))
     on_dns_resolvehost_end = mock.Mock(
-        side_effect=asyncio.coroutine(mock.Mock()))
-    on_request_redirect = mock.Mock(side_effect=asyncio.coroutine(mock.Mock()))
+        side_effect=make_mocked_coro(mock.Mock()))
+    on_request_redirect = mock.Mock(side_effect=make_mocked_coro(mock.Mock()))
     on_connection_create_start = mock.Mock(
-        side_effect=asyncio.coroutine(mock.Mock()))
+        side_effect=make_mocked_coro(mock.Mock()))
     on_connection_create_end = mock.Mock(
-        side_effect=asyncio.coroutine(mock.Mock()))
+        side_effect=make_mocked_coro(mock.Mock()))
 
     async def redirector(request):
         raise web.HTTPFound(location=URL('/redirected'))
 
     async def redirected(request):
         return web.Response()
 
@@ -1864,25 +1819,25 @@
     assert on_dns_resolvehost_end.called
     assert on_request_redirect.called
     assert on_connection_create_start.called
     assert on_connection_create_end.called
     await client.close()
 
 
-async def test_return_http_exception_deprecated(aiohttp_client) -> None:
+async def test_raise_http_exception(aiohttp_client) -> None:
 
     async def handler(request):
-        return web.HTTPForbidden()
+        raise web.HTTPForbidden()
 
     app = web.Application()
     app.router.add_route('GET', '/', handler)
     client = await aiohttp_client(app)
 
-    with pytest.warns(DeprecationWarning):
-        await client.get('/')
+    resp = await client.get('/')
+    assert resp.status == 403
 
 
 async def test_request_path(aiohttp_client) -> None:
 
     async def handler(request):
         assert request.path_qs == '/path%20to?a=1'
         assert request.path == '/path to'
```

### Comparing `aiohttp-4.0.0a0/tests/test_web_middleware.py` & `aiohttp-4.0.0a1/tests/test_web_middleware.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,20 +1,17 @@
-import re
-
 import pytest
 from yarl import URL
 
 from aiohttp import web
 
 
 async def test_middleware_modifies_response(loop, aiohttp_client) -> None:
     async def handler(request):
         return web.Response(body=b'OK')
 
-    @web.middleware
     async def middleware(request, handler):
         resp = await handler(request)
         assert 200 == resp.status
         resp.set_status(201)
         resp.text = resp.text + '[MIDDLEWARE]'
         return resp
 
@@ -28,15 +25,14 @@
     assert 'OK[MIDDLEWARE]' == txt
 
 
 async def test_middleware_handles_exception(loop, aiohttp_client) -> None:
     async def handler(request):
         raise RuntimeError('Error text')
 
-    @web.middleware
     async def middleware(request, handler):
         with pytest.raises(RuntimeError) as ctx:
             await handler(request)
         return web.Response(status=501,
                             text=str(ctx.value) + '[MIDDLEWARE]')
 
     app = web.Application()
@@ -50,15 +46,14 @@
 
 
 async def test_middleware_chain(loop, aiohttp_client) -> None:
     async def handler(request):
         return web.Response(text='OK')
 
     def make_middleware(num):
-        @web.middleware
         async def middleware(request, handler):
             resp = await handler(request)
             resp.text = resp.text + '[{}]'.format(num)
             return resp
         return middleware
 
     app = web.Application()
@@ -124,15 +119,17 @@
         ('/resource2', 404),
         ('/resource2/', 200),
         ('/resource1?p1=1&p2=2', 200),
         ('/resource1/?p1=1&p2=2', 200),
         ('/resource2?p1=1&p2=2', 404),
         ('/resource2/?p1=1&p2=2', 200),
         ('/resource2/a/b%2Fc', 404),
-        ('/resource2/a/b%2Fc/', 200)
+        ('/resource2/a/b%2Fc/', 200),
+        ('/resource12', 404),
+        ('/resource12345', 404)
     ])
     async def test_remove_trailing_when_necessary(self, path,
                                                   status, cli) -> None:
         extra_middlewares = [
             web.normalize_path_middleware(
                 append_slash=False, remove_slash=True, merge_slashes=False)]
         client = await cli(extra_middlewares)
@@ -272,137 +269,61 @@
         assert resp.url.query == URL(path).query
 
     async def test_cannot_remove_and_add_slash(self) -> None:
         with pytest.raises(AssertionError):
             web.normalize_path_middleware(append_slash=True, remove_slash=True)
 
 
+async def test_bug_3669(aiohttp_client):
+    async def paymethod(request):
+        return web.Response(text="OK")
+
+    app = web.Application()
+    app.router.add_route('GET', '/paymethod', paymethod)
+    app.middlewares.append(
+        web.normalize_path_middleware(append_slash=False, remove_slash=True)
+    )
+
+    client = await aiohttp_client(
+        app, server_kwargs={'skip_url_asserts': True}
+    )
+
+    resp = await client.get('/paymethods')
+    assert resp.status == 404
+    assert resp.url.path != '/paymethod'
+
+
 async def test_old_style_middleware(loop, aiohttp_client) -> None:
-    async def handler(request):
+    async def view_handler(request):
         return web.Response(body=b'OK')
 
-    async def middleware_factory(app, handler):
-
-        async def middleware(request):
+    with pytest.warns(
+        DeprecationWarning, match='Middleware decorator is deprecated'
+    ):
+        @web.middleware
+        async def middleware(request, handler):
             resp = await handler(request)
             assert 200 == resp.status
             resp.set_status(201)
             resp.text = resp.text + '[old style middleware]'
             return resp
-        return middleware
-
-    with pytest.warns(DeprecationWarning) as warning_checker:
-        app = web.Application()
-        app.middlewares.append(middleware_factory)
-        app.router.add_route('GET', '/', handler)
-        client = await aiohttp_client(app)
-        resp = await client.get('/')
-        assert 201 == resp.status
-        txt = await resp.text()
-        assert 'OK[old style middleware]' == txt
-
-    assert len(warning_checker) == 1
-    msg = str(warning_checker.list[0].message)
-    assert re.match('^old-style middleware '
-                    '"<function test_old_style_middleware.<locals>.'
-                    'middleware_factory at 0x[0-9a-fA-F]+>" '
-                    'deprecated, see #2252$',
-                    msg)
-
-
-async def test_mixed_middleware(loop, aiohttp_client) -> None:
-    async def handler(request):
-        return web.Response(body=b'OK')
-
-    async def m_old1(app, handler):
-        async def middleware(request):
-            resp = await handler(request)
-            resp.text += '[old style 1]'
-            return resp
-        return middleware
-
-    @web.middleware
-    async def m_new1(request, handler):
-        resp = await handler(request)
-        resp.text += '[new style 1]'
-        return resp
 
-    async def m_old2(app, handler):
-        async def middleware(request):
-            resp = await handler(request)
-            resp.text += '[old style 2]'
-            return resp
-        return middleware
-
-    @web.middleware
-    async def m_new2(request, handler):
-        resp = await handler(request)
-        resp.text += '[new style 2]'
-        return resp
-
-    middlewares = m_old1, m_new1, m_old2, m_new2
-
-    with pytest.warns(DeprecationWarning) as w:
-        app = web.Application(middlewares=middlewares)
-        app.router.add_route('GET', '/', handler)
-        client = await aiohttp_client(app)
-        resp = await client.get('/')
-        assert 200 == resp.status
-        txt = await resp.text()
-        assert 'OK[new style 2][old style 2][new style 1][old style 1]' == txt
-
-    assert len(w) == 2
-    tmpl = ('^old-style middleware '
-            '"<function test_mixed_middleware.<locals>.'
-            '{} at 0x[0-9a-fA-F]+>" '
-            'deprecated, see #2252$')
-    p1 = tmpl.format('m_old1')
-    p2 = tmpl.format('m_old2')
-
-    assert re.match(p2, str(w.list[0].message))
-    assert re.match(p1, str(w.list[1].message))
-
-
-async def test_old_style_middleware_class(loop, aiohttp_client) -> None:
-    async def handler(request):
-        return web.Response(body=b'OK')
-
-    class Middleware:
-        async def __call__(self, app, handler):
-            async def middleware(request):
-                resp = await handler(request)
-                assert 200 == resp.status
-                resp.set_status(201)
-                resp.text = resp.text + '[old style middleware]'
-                return resp
-            return middleware
-
-    with pytest.warns(DeprecationWarning) as warning_checker:
-        app = web.Application()
-        app.middlewares.append(Middleware())
-        app.router.add_route('GET', '/', handler)
-        client = await aiohttp_client(app)
-        resp = await client.get('/')
-        assert 201 == resp.status
-        txt = await resp.text()
-        assert 'OK[old style middleware]' == txt
-
-    assert len(warning_checker) == 1
-    msg = str(warning_checker.list[0].message)
-    assert re.match('^old-style middleware '
-                    '"<test_web_middleware.test_old_style_middleware_class.'
-                    '<locals>.Middleware object '
-                    'at 0x[0-9a-fA-F]+>" deprecated, see #2252$', msg)
+    app = web.Application(middlewares=[middleware])
+    app.router.add_route('GET', '/', view_handler)
+    client = await aiohttp_client(app)
+    resp = await client.get('/')
+    assert 201 == resp.status
+    txt = await resp.text()
+    assert 'OK[old style middleware]' == txt
 
 
 async def test_new_style_middleware_class(loop, aiohttp_client) -> None:
     async def handler(request):
         return web.Response(body=b'OK')
 
-    @web.middleware
     class Middleware:
         async def __call__(self, request, handler):
             resp = await handler(request)
             assert 200 == resp.status
             resp.set_status(201)
             resp.text = resp.text + '[new style middleware]'
             return resp
@@ -421,15 +342,14 @@
 
 
 async def test_new_style_middleware_method(loop, aiohttp_client) -> None:
     async def handler(request):
         return web.Response(body=b'OK')
 
     class Middleware:
-        @web.middleware
         async def call(self, request, handler):
             resp = await handler(request)
             assert 200 == resp.status
             resp.set_status(201)
             resp.text = resp.text + '[new style middleware]'
             return resp
```

### Comparing `aiohttp-4.0.0a0/tests/test_web_protocol.py` & `aiohttp-4.0.0a1/tests/test_web_protocol.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,19 +1,21 @@
 """Tests for aiohttp/server.py"""
 
 import asyncio
+import platform
 import socket
 from functools import partial
-from html import escape
 from unittest import mock
 
 import pytest
 
 from aiohttp import helpers, http, streams, web
 
+IS_MACOS = platform.system() == 'Darwin'
+
 
 @pytest.fixture
 def make_srv(loop, manager):
     srv = None
 
     def maker(*, cls=web.RequestHandler, **kwargs):
         nonlocal srv
@@ -36,17 +38,20 @@
 
 
 @pytest.fixture
 def srv(make_srv, transport):
     srv = make_srv()
     srv.connection_made(transport)
     transport.close.side_effect = partial(srv.connection_lost, None)
-    srv._drain_helper = mock.Mock()
-    srv._drain_helper.side_effect = helpers.noop
-    return srv
+    with mock.patch.object(
+        web.RequestHandler,
+        '_drain_helper',
+        side_effect=helpers.noop
+    ):
+        yield srv
 
 
 @pytest.fixture
 def buf():
     return bytearray()
 
 
@@ -278,52 +283,29 @@
         b'Host: example.com\r\n'
         b'Content-Length: sdgg\r\n\r\n')
     await asyncio.sleep(0)
 
     assert buf.startswith(b'HTTP/1.0 400 Bad Request\r\n')
 
 
-async def test_handle_error__utf(
-    make_srv, buf, transport, request_handler
-):
-    request_handler.side_effect = RuntimeError('-   ')
-
-    srv = make_srv(debug=True)
-    srv.connection_made(transport)
-    srv.keep_alive(True)
-    srv.logger = mock.Mock()
-
-    srv.data_received(
-        b'GET / HTTP/1.0\r\n'
-        b'Host: example.com\r\n'
-        b'Content-Length: 0\r\n\r\n')
-    await asyncio.sleep(0)
-
-    assert b'HTTP/1.0 500 Internal Server Error' in buf
-    assert b'Content-Type: text/plain; charset=utf-8' in buf
-    pattern = escape("RuntimeError: -   ")
-    assert pattern.encode('utf-8') in buf
-    assert not srv._keepalive
-
-    srv.logger.exception.assert_called_with(
-        "Error handling request", exc_info=mock.ANY)
-
-
 async def test_unhandled_runtime_error(
     make_srv, transport, request_handler
 ):
 
+    class MyResponse(web.Response):
+        async def write_eof(self, data=b''):
+            raise RuntimeError()
+
     async def handle(request):
-        resp = web.Response()
-        resp.write_eof = mock.Mock()
-        resp.write_eof.side_effect = RuntimeError
+        resp = MyResponse()
         return resp
 
+    loop = asyncio.get_event_loop()
+    loop.set_debug(True)
     srv = make_srv(lingering_time=0)
-    srv.debug = True
     srv.connection_made(transport)
     srv.logger.exception = mock.Mock()
     request_handler.side_effect = handle
 
     srv.data_received(
         b'GET / HTTP/1.0\r\n'
         b'Host: example.com\r\n'
@@ -358,14 +340,19 @@
     await srv._task_handler
     assert request_handler.called
     assert closed
     srv.logger.exception.assert_called_with(
         "Error handling request", exc_info=mock.ANY)
 
 
+@pytest.mark.xfail(
+    IS_MACOS,
+    raises=TypeError,
+    reason='Intermittently fails on macOS',
+)
 async def test_handle_uncompleted_pipe(
         make_srv, transport, request_handler, handle_with_error):
     closed = False
     normal_completed = False
 
     def close():
         nonlocal closed
@@ -385,26 +372,26 @@
 
     # normal
     request_handler.side_effect = handle
     srv.data_received(
         b'GET / HTTP/1.1\r\n'
         b'Host: example.com\r\n'
         b'Content-Length: 0\r\n\r\n')
-    await asyncio.sleep(0)
+    await asyncio.sleep(0.01)
 
     # with exception
     request_handler.side_effect = handle_with_error()
     srv.data_received(
         b'GET / HTTP/1.1\r\n'
         b'Host: example.com\r\n'
         b'Content-Length: 50000\r\n\r\n')
 
     assert srv._task_handler
 
-    await asyncio.sleep(0)
+    await asyncio.sleep(0.01)
 
     await srv._task_handler
     assert normal_completed
     assert request_handler.called
     assert closed
     srv.logger.exception.assert_called_with(
         "Error handling request", exc_info=mock.ANY)
@@ -412,27 +399,29 @@
 
 async def test_lingering(srv, transport) -> None:
     assert not transport.close.called
 
     async def handle(message, request, writer):
         pass
 
-    srv.handle_request = handle
-    srv.data_received(
-        b'GET / HTTP/1.0\r\n'
-        b'Host: example.com\r\n'
-        b'Content-Length: 3\r\n\r\n')
+    with mock.patch.object(
+        web.RequestHandler, 'handle_request', create=True, new=handle
+    ):
+        srv.data_received(
+            b'GET / HTTP/1.0\r\n'
+            b'Host: example.com\r\n'
+            b'Content-Length: 3\r\n\r\n')
 
-    await asyncio.sleep(0.05)
-    assert not transport.close.called
+        await asyncio.sleep(0.05)
+        assert not transport.close.called
 
-    srv.data_received(b'123')
+        srv.data_received(b'123')
 
-    await asyncio.sleep(0)
-    transport.close.assert_called_with()
+        await asyncio.sleep(0)
+        transport.close.assert_called_with()
 
 
 async def test_lingering_disabled(make_srv,
                                   transport, request_handler) -> None:
 
     async def handle_request(request):
         await asyncio.sleep(0)
@@ -493,43 +482,47 @@
     await asyncio.sleep(0.05)
 
     with pytest.raises(web.PayloadAccessError):
         await request_handler.call_args[0][0].content.read()
 
 
 async def test_handle_cancel(make_srv, transport) -> None:
+    loop = asyncio.get_event_loop()
+    loop.set_debug(True)
     log = mock.Mock()
 
-    srv = make_srv(logger=log, debug=True)
+    srv = make_srv(logger=log)
     srv.connection_made(transport)
 
     async def handle_request(message, payload, writer):
         await asyncio.sleep(10)
 
-    srv.handle_request = handle_request
-
     async def cancel():
         srv._task_handler.cancel()
 
-    srv.data_received(
-        b'GET / HTTP/1.0\r\n'
-        b'Content-Length: 10\r\n'
-        b'Host: example.com\r\n\r\n')
+    with mock.patch.object(
+        web.RequestHandler, 'handle_request', create=True, new=handle_request
+    ):
+        srv.data_received(
+            b'GET / HTTP/1.0\r\n'
+            b'Content-Length: 10\r\n'
+            b'Host: example.com\r\n\r\n')
 
-    await asyncio.gather(srv._task_handler, cancel())
-    assert log.debug.called
+        await asyncio.gather(srv._task_handler, cancel())
+        assert log.debug.called
 
 
 async def test_handle_cancelled(make_srv, transport) -> None:
+    loop = asyncio.get_event_loop()
+    loop.set_debug(True)
     log = mock.Mock()
 
-    srv = make_srv(logger=log, debug=True)
+    srv = make_srv(logger=log)
     srv.connection_made(transport)
 
-    srv.handle_request = mock.Mock()
     # start request_handler task
     await asyncio.sleep(0)
 
     srv.data_received(
         b'GET / HTTP/1.0\r\n'
         b'Host: example.com\r\n\r\n')
 
@@ -540,62 +533,42 @@
 async def test_handle_400(srv, buf, transport) -> None:
     srv.data_received(b'GET / HT/asd\r\n\r\n')
 
     await asyncio.sleep(0)
     assert b'400 Bad Request' in buf
 
 
-async def test_handle_500(srv, buf, transport, request_handler) -> None:
-    request_handler.side_effect = ValueError
-
-    srv.data_received(
-        b'GET / HTTP/1.0\r\n'
-        b'Host: example.com\r\n\r\n')
-    await srv._task_handler
-
-    assert b'500 Internal Server Error' in buf
-
-
-async def test_handle_504(srv, buf, request_handler) -> None:
-    request_handler.side_effect = asyncio.TimeoutError
-
-    srv.data_received(
-        b'GET / HTTP/1.0\r\n'
-        b'Host: example.com\r\n\r\n')
-    await srv._task_handler
-
-    assert b'504 Gateway Timeout' in buf
-
-
 async def test_keep_alive(make_srv, transport, ceil) -> None:
     loop = asyncio.get_event_loop()
     srv = make_srv(keepalive_timeout=0.05)
-    srv.KEEPALIVE_RESCHEDULE_DELAY = 0.1
-    srv.connection_made(transport)
-
-    srv.keep_alive(True)
-    srv.handle_request = mock.Mock()
-    srv.handle_request.return_value = loop.create_future()
-    srv.handle_request.return_value.set_result(1)
-
-    srv.data_received(
-        b'GET / HTTP/1.1\r\n'
-        b'Host: example.com\r\n'
-        b'Content-Length: 0\r\n\r\n')
-
-    waiter = None
-    while waiter is None:
-        await asyncio.sleep(0)
-        waiter = srv._waiter
-    assert srv._keepalive_handle is not None
-    assert not transport.close.called
+    future = loop.create_future()
+    future.set_result(1)
 
-    await asyncio.sleep(0.2)
-    assert transport.close.called
-    assert waiter.cancelled
+    with mock.patch.object(
+        web.RequestHandler, 'KEEPALIVE_RESCHEDULE_DELAY', new=0.1
+    ), mock.patch.object(
+        web.RequestHandler, 'handle_request', create=True, return_value=future
+    ):
+        srv.connection_made(transport)
+        srv.keep_alive(True)
+        srv.data_received(
+            b'GET / HTTP/1.1\r\n'
+            b'Host: example.com\r\n'
+            b'Content-Length: 0\r\n\r\n')
+
+        waiter = None
+        while waiter is None:
+            await asyncio.sleep(0)
+            waiter = srv._waiter
+        assert srv._keepalive_handle is not None
+        assert not transport.close.called
+
+        await asyncio.sleep(0.2)
+        assert transport.close.called
+        assert waiter.cancelled
 
 
 async def test_srv_process_request_without_timeout(make_srv,
                                                    transport) -> None:
     srv = make_srv()
     srv.connection_made(transport)
 
@@ -630,15 +603,15 @@
 
 
 async def test_content_length_0(srv, request_handler) -> None:
     srv.data_received(
         b'GET / HTTP/1.1\r\n'
         b'Host: example.org\r\n'
         b'Content-Length: 0\r\n\r\n')
-    await asyncio.sleep(0)
+    await asyncio.sleep(0.01)
 
     assert request_handler.called
     assert request_handler.call_args[0][0].content == streams.EMPTY_PAYLOAD
 
 
 def test_rudimentary_transport(srv) -> None:
     transport = mock.Mock()
@@ -664,37 +637,42 @@
 
 
 async def test_close(srv, transport) -> None:
     transport.close.side_effect = partial(srv.connection_lost, None)
     srv.connection_made(transport)
     await asyncio.sleep(0)
 
-    srv.handle_request = mock.Mock()
-    srv.handle_request.side_effect = helpers.noop
-
-    assert transport is srv.transport
+    handle_request = mock.Mock()
+    handle_request.side_effect = helpers.noop
+    with mock.patch.object(
+        web.RequestHandler,
+        'handle_request',
+        create=True,
+        new=handle_request
+    ):
+        assert transport is srv.transport
+
+        srv._keepalive = True
+        srv.data_received(
+            b'GET / HTTP/1.1\r\n'
+            b'Host: example.com\r\n'
+            b'Content-Length: 0\r\n\r\n'
+            b'GET / HTTP/1.1\r\n'
+            b'Host: example.com\r\n'
+            b'Content-Length: 0\r\n\r\n')
 
-    srv._keepalive = True
-    srv.data_received(
-        b'GET / HTTP/1.1\r\n'
-        b'Host: example.com\r\n'
-        b'Content-Length: 0\r\n\r\n'
-        b'GET / HTTP/1.1\r\n'
-        b'Host: example.com\r\n'
-        b'Content-Length: 0\r\n\r\n')
-
-    await asyncio.sleep(0.05)
-    assert srv._task_handler
-    assert srv._waiter
+        await asyncio.sleep(0.05)
+        assert srv._task_handler
+        assert srv._waiter
 
-    srv.close()
-    await asyncio.sleep(0)
-    assert srv._task_handler is None
-    assert srv.transport is None
-    assert transport.close.called
+        srv.close()
+        await asyncio.sleep(0)
+        assert srv._task_handler is None
+        assert srv.transport is None
+        assert transport.close.called
 
 
 async def test_pipeline_multiple_messages(
     srv, transport, request_handler
 ):
     transport.close.side_effect = partial(srv.connection_lost, None)
 
@@ -747,15 +725,15 @@
         return resp
 
     request_handler.side_effect = handle1
     srv.data_received(
         b'GET / HTTP/1.1\r\n'
         b'Host: example.com\r\n'
         b'Content-Length: 0\r\n\r\n')
-    await asyncio.sleep(0)
+    await asyncio.sleep(0.01)
 
     # second
 
     async def handle2(request):
         nonlocal processed
         resp = web.StreamResponse()
         await resp.prepare(request)
@@ -765,15 +743,15 @@
         return resp
 
     request_handler.side_effect = handle2
     srv.data_received(
         b'GET / HTTP/1.1\r\n'
         b'Host: example.com\r\n'
         b'Content-Length: 0\r\n\r\n')
-    await asyncio.sleep(0)
+    await asyncio.sleep(0.01)
 
     assert srv._task_handler is not None
 
     await asyncio.sleep(0.1)
     assert processed == [1, 2]
 
 
@@ -854,7 +832,42 @@
         b'Host: ex.com\r\n'
         b'Content-Length: 1\r\n\r\n'
         b'b')
 
     assert len(srv._messages) == 2
     assert srv._waiter.done()
     await asyncio.sleep(0.01)
+
+
+async def test_client_disconnect(aiohttp_server) -> None:
+
+    async def handler(request):
+        buf = b""
+        with pytest.raises(ConnectionError):
+            while len(buf) < 10:
+                buf += await request.content.read(10)
+        # return with closed transport means premature client disconnection
+        return web.Response()
+
+    loop = asyncio.get_event_loop()
+    loop.set_debug(True)
+    logger = mock.Mock()
+    app = web.Application()
+    app.router.add_route('POST', '/', handler)
+    server = await aiohttp_server(app, logger=logger)
+
+    if helpers.PY_38:
+        writer = await asyncio.connect('127.0.0.1', server.port)
+    else:
+        _, writer = await asyncio.open_connection('127.0.0.1', server.port)
+    writer.write("""POST / HTTP/1.1\r
+Connection: keep-alive\r
+Content-Length: 10\r
+Host: localhost:{port}\r
+\r
+""".format(port=server.port).encode("ascii"))
+    await writer.drain()
+    await asyncio.sleep(0.1)
+    writer.write(b"x")
+    writer.close()
+    await asyncio.sleep(0.1)
+    logger.debug.assert_called_with('Ignored premature client disconnection.')
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `aiohttp-4.0.0a0/tests/test_web_request.py` & `aiohttp-4.0.0a1/tests/test_web_request.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,28 +1,63 @@
 import asyncio
 import socket
 from collections.abc import MutableMapping
 from unittest import mock
 
 import pytest
-from multidict import CIMultiDict, MultiDict
+from multidict import CIMultiDict, CIMultiDictProxy, MultiDict
 from yarl import URL
 
-from aiohttp import HttpVersion
+from aiohttp import HttpVersion, web
 from aiohttp.helpers import DEBUG
+from aiohttp.http_parser import RawRequestMessage
 from aiohttp.streams import StreamReader
 from aiohttp.test_utils import make_mocked_request
-from aiohttp.web import HTTPRequestEntityTooLarge
+from aiohttp.web import HTTPRequestEntityTooLarge, HTTPUnsupportedMediaType
 
 
 @pytest.fixture
 def protocol():
     return mock.Mock(_reading_paused=False)
 
 
+def test_base_ctor() -> None:
+    message = RawRequestMessage(
+        'GET', '/path/to?a=1&b=2', HttpVersion(1, 1),
+        CIMultiDictProxy(CIMultiDict()), (),
+        False, False, False, False, URL('/path/to?a=1&b=2'))
+
+    req = web.BaseRequest(message,
+                          mock.Mock(),
+                          mock.Mock(),
+                          mock.Mock(),
+                          mock.Mock(),
+                          mock.Mock())
+
+    assert 'GET' == req.method
+    assert HttpVersion(1, 1) == req.version
+    assert req.host == socket.getfqdn()
+    assert '/path/to?a=1&b=2' == req.path_qs
+    assert '/path/to' == req.path
+    assert 'a=1&b=2' == req.query_string
+    assert CIMultiDict() == req.headers
+    assert () == req.raw_headers
+
+    get = req.query
+    assert MultiDict([('a', '1'), ('b', '2')]) == get
+    # second call should return the same object
+    assert get is req.query
+
+    assert req.keep_alive
+
+    assert '__dict__' not in dir(req)
+
+    assert req
+
+
 def test_ctor() -> None:
     req = make_mocked_request('GET', '/path/to?a=1&b=2')
 
     assert 'GET' == req.method
     assert HttpVersion(1, 1) == req.version
     assert req.host == socket.getfqdn()
     assert '/path/to?a=1&b=2' == req.path_qs
@@ -49,19 +84,15 @@
     assert req.content is payload
     assert req.protocol is protocol
     assert req.transport is protocol.transport
     assert req.headers == headers
     assert req.raw_headers == ((b'FOO', b'bar'),)
     assert req.task is req._task
 
-
-def test_deprecated_message() -> None:
-    req = make_mocked_request('GET', '/path/to?a=1&b=2')
-    with pytest.warns(DeprecationWarning):
-        assert req.message == req._message
+    assert '__dict__' not in dir(req)
 
 
 def test_doubleslashes() -> None:
     # NB: //foo/bar is an absolute URL with foo netloc and /bar path
     req = make_mocked_request('GET', '/bar//foo/')
     assert '/bar//foo/' == req.path
 
@@ -509,51 +540,63 @@
     req = make_mocked_request('GET', '/path', headers={'A': 'B'})
     req2 = req.clone(headers={'B': 'C'})
     assert req2.headers == CIMultiDict({'B': 'C'})
     assert req2.raw_headers == ((b'B', b'C'),)
 
 
 async def test_cannot_clone_after_read(protocol) -> None:
-    payload = StreamReader(protocol)
+    payload = StreamReader(protocol, loop=asyncio.get_event_loop())
     payload.feed_data(b'data')
     payload.feed_eof()
     req = make_mocked_request('GET', '/path', payload=payload)
     await req.read()
     with pytest.raises(RuntimeError):
         req.clone()
 
 
 async def test_make_too_big_request(protocol) -> None:
-    payload = StreamReader(protocol)
+    payload = StreamReader(protocol, loop=asyncio.get_event_loop())
     large_file = 1024 ** 2 * b'x'
     too_large_file = large_file + b'x'
     payload.feed_data(too_large_file)
     payload.feed_eof()
     req = make_mocked_request('POST', '/', payload=payload)
     with pytest.raises(HTTPRequestEntityTooLarge) as err:
         await req.read()
 
     assert err.value.status_code == 413
 
 
+async def test_request_with_wrong_content_type_encoding(protocol) -> None:
+    payload = StreamReader(protocol, loop=asyncio.get_event_loop())
+    payload.feed_data(b'{}')
+    payload.feed_eof()
+    headers = {'Content-Type': 'text/html; charset=test'}
+    req = make_mocked_request('POST', '/', payload=payload, headers=headers)
+
+    with pytest.raises(HTTPUnsupportedMediaType) as err:
+        await req.text()
+    assert err.value.status_code == 415
+
+
 async def test_make_too_big_request_adjust_limit(protocol) -> None:
-    payload = StreamReader(protocol)
+    payload = StreamReader(protocol, loop=asyncio.get_event_loop())
     large_file = 1024 ** 2 * b'x'
     too_large_file = large_file + b'x'
     payload.feed_data(too_large_file)
     payload.feed_eof()
     max_size = 1024**2 + 2
     req = make_mocked_request('POST', '/', payload=payload,
                               client_max_size=max_size)
     txt = await req.read()
     assert len(txt) == 1024**2 + 1
 
 
 async def test_multipart_formdata(protocol) -> None:
-    payload = StreamReader(protocol)
+    payload = StreamReader(protocol, loop=asyncio.get_event_loop())
     payload.feed_data(b"""-----------------------------326931944431359\r
 Content-Disposition: form-data; name="a"\r
 \r
 b\r
 -----------------------------326931944431359\r
 Content-Disposition: form-data; name="c"\r
 \r
@@ -566,15 +609,15 @@
                               headers={'CONTENT-TYPE': content_type},
                               payload=payload)
     result = await req.post()
     assert dict(result) == {'a': 'b', 'c': 'd'}
 
 
 async def test_make_too_big_request_limit_None(protocol) -> None:
-    payload = StreamReader(protocol)
+    payload = StreamReader(protocol, loop=asyncio.get_event_loop())
     large_file = 1024 ** 2 * b'x'
     too_large_file = large_file + b'x'
     payload.feed_data(too_large_file)
     payload.feed_eof()
     max_size = None
     req = make_mocked_request('POST', '/', payload=payload,
                               client_max_size=max_size)
@@ -654,12 +697,44 @@
 def test_eq() -> None:
     req1 = make_mocked_request('GET', '/path/to?a=1&b=2')
     req2 = make_mocked_request('GET', '/path/to?a=1&b=2')
     assert req1 != req2
     assert req1 == req1
 
 
-async def test_loop_prop() -> None:
-    loop = asyncio.get_event_loop()
-    req = make_mocked_request('GET', '/path', loop=loop)
-    with pytest.warns(DeprecationWarning):
-        assert req.loop is loop
+async def test_json(aiohttp_client) -> None:
+    async def handler(request):
+        body_text = await request.text()
+        assert body_text == '{"some": "data"}'
+        assert request.headers['Content-Type'] == 'application/json'
+        body_json = await request.json()
+        assert body_json == {'some': 'data'}
+        return web.Response()
+
+    app = web.Application()
+    app.router.add_post('/', handler)
+    client = await aiohttp_client(app)
+
+    json_data = {'some': 'data'}
+    async with client.post('/', json=json_data) as resp:
+        assert 200 == resp.status
+
+
+async def test_json_invalid_content_type(aiohttp_client) -> None:
+    async def handler(request):
+        body_text = await request.text()
+        assert body_text == '{"some": "data"}'
+        assert request.headers['Content-Type'] == 'text/plain'
+        await request.json()  # raises HTTP 400
+        return web.Response()
+
+    app = web.Application()
+    app.router.add_post('/', handler)
+    client = await aiohttp_client(app)
+
+    json_data = {'some': 'data'}
+    headers = {'Content-Type': 'text/plain'}
+    async with client.post('/', json=json_data, headers=headers) as resp:
+        assert 400 == resp.status
+        resp_text = await resp.text()
+        assert resp_text == ('Attempt to decode JSON with '
+                             'unexpected mimetype: text/plain')
```

### Comparing `aiohttp-4.0.0a0/tests/test_web_request_handler.py` & `aiohttp-4.0.0a1/tests/test_web_request_handler.py`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/tests/test_web_response.py` & `aiohttp-4.0.0a1/tests/test_web_response.py`

 * *Files 5% similar despite different names*

```diff
@@ -279,29 +279,14 @@
     resp = StreamResponse()
 
     resp.content_length = 234
     with pytest.raises(RuntimeError):
         resp.enable_chunked_encoding()
 
 
-async def test_chunk_size() -> None:
-    req = make_request('GET', '/')
-    resp = StreamResponse()
-    assert not resp.chunked
-
-    with pytest.warns(DeprecationWarning):
-        resp.enable_chunked_encoding(chunk_size=8192)
-    assert resp.chunked
-
-    msg = await resp.prepare(req)
-    assert msg.chunked
-    assert msg.enable_chunking.called
-    assert msg.filter is not None
-
-
 async def test_chunked_encoding_forbidden_for_http_10() -> None:
     req = make_request('GET', '/', version=HttpVersion10)
     resp = StreamResponse()
     resp.enable_chunked_encoding()
 
     with pytest.raises(RuntimeError) as ctx:
         await resp.prepare(req)
@@ -318,42 +303,14 @@
     resp.enable_compression()
     assert resp.compression
 
     msg = await resp.prepare(req)
     assert not msg.enable_compression.called
 
 
-async def test_force_compression_no_accept_backwards_compat() -> None:
-    req = make_request('GET', '/')
-    resp = StreamResponse()
-    assert not resp.chunked
-
-    assert not resp.compression
-    with pytest.warns(DeprecationWarning):
-        resp.enable_compression(force=True)
-    assert resp.compression
-
-    msg = await resp.prepare(req)
-    assert msg.enable_compression.called
-    assert msg.filter is not None
-
-
-async def test_force_compression_false_backwards_compat() -> None:
-    req = make_request('GET', '/')
-    resp = StreamResponse()
-
-    assert not resp.compression
-    with pytest.warns(DeprecationWarning):
-        resp.enable_compression(force=False)
-    assert resp.compression
-
-    msg = await resp.prepare(req)
-    assert not msg.enable_compression.called
-
-
 async def test_compression_default_coding() -> None:
     req = make_request(
         'GET', '/',
         headers=CIMultiDict({hdrs.ACCEPT_ENCODING: 'gzip, deflate'}))
     resp = StreamResponse()
     assert not resp.chunked
 
@@ -654,21 +611,14 @@
     resp = StreamResponse()
 
     assert resp.keep_alive is None
     resp.force_close()
     assert resp.keep_alive is False
 
 
-async def test_response_output_length() -> None:
-    resp = StreamResponse()
-    await resp.prepare(make_request('GET', '/'))
-    with pytest.warns(DeprecationWarning):
-        assert resp.output_length
-
-
 def test_response_cookies() -> None:
     resp = StreamResponse()
 
     assert resp.cookies == {}
     assert str(resp.cookies) == ''
 
     resp.set_cookie('name', 'value')
```

### Comparing `aiohttp-4.0.0a0/tests/test_web_sendfile.py` & `aiohttp-4.0.0a1/tests/test_web_sendfile.py`

 * *Files 2% similar despite different names*

```diff
@@ -105,7 +105,27 @@
     file_sender = FileResponse(filepath)
     file_sender._sendfile = make_mocked_coro(None)
 
     loop.run_until_complete(file_sender.prepare(request))
 
     assert filepath.open.called
     assert not gz_filepath.open.called
+
+
+def test_status_controlled_by_user(loop) -> None:
+    request = make_mocked_request(
+        'GET', 'http://python.org/logo.png', headers={
+        }
+    )
+
+    filepath = mock.Mock()
+    filepath.name = 'logo.png'
+    filepath.open = mock.mock_open()
+    filepath.stat.return_value = mock.MagicMock()
+    filepath.stat.st_size = 1024
+
+    file_sender = FileResponse(filepath, status=203)
+    file_sender._sendfile = make_mocked_coro(None)
+
+    loop.run_until_complete(file_sender.prepare(request))
+
+    assert file_sender._status == 203
```

### Comparing `aiohttp-4.0.0a0/tests/test_web_sendfile_functional.py` & `aiohttp-4.0.0a1/tests/test_web_sendfile_functional.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 import asyncio
-import os
 import pathlib
 import socket
 import zlib
 
 import pytest
 
 import aiohttp
@@ -267,15 +266,15 @@
 
 
 @pytest.mark.skipif(not ssl, reason="ssl not supported")
 async def test_static_file_ssl(
         aiohttp_server, ssl_ctx,
         aiohttp_client, client_ssl_ctx,
 ) -> None:
-    dirname = os.path.dirname(__file__)
+    dirname = pathlib.Path(__file__).parent
     filename = 'data.unknown_mime_type'
     app = web.Application()
     app.router.add_static('/static', dirname)
     server = await aiohttp_server(app, ssl=ssl_ctx)
     conn = aiohttp.TCPConnector(ssl=client_ssl_ctx)
     client = await aiohttp_client(server, connector=conn)
 
@@ -285,66 +284,66 @@
     assert 'file content' == txt.rstrip()
     ct = resp.headers['CONTENT-TYPE']
     assert 'application/octet-stream' == ct
     assert resp.headers.get('CONTENT-ENCODING') is None
 
 
 async def test_static_file_directory_traversal_attack(aiohttp_client) -> None:
-    dirname = os.path.dirname(__file__)
+    dirname = pathlib.Path(__file__).parent
     relpath = '../README.rst'
-    assert os.path.isfile(os.path.join(dirname, relpath))
+    full_path = dirname / relpath
+    assert full_path.is_file()
 
     app = web.Application()
     app.router.add_static('/static', dirname)
     client = await aiohttp_client(app)
 
     resp = await client.get('/static/'+relpath)
     assert 404 == resp.status
 
     url_relpath2 = '/static/dir/../' + relpath
     resp = await client.get(url_relpath2)
     assert 404 == resp.status
 
-    url_abspath = \
-        '/static/' + os.path.abspath(os.path.join(dirname, relpath))
+    url_abspath = '/static/' + str(full_path.resolve())
     resp = await client.get(url_abspath)
     assert 403 == resp.status
 
 
 def test_static_route_path_existence_check() -> None:
-    directory = os.path.dirname(__file__)
+    directory = pathlib.Path(__file__).parent
     web.StaticResource("/", directory)
 
-    nodirectory = os.path.join(directory, "nonexistent-uPNiOEAg5d")
+    nodirectory = directory / "nonexistent-uPNiOEAg5d"
     with pytest.raises(ValueError):
         web.StaticResource("/", nodirectory)
 
 
-async def test_static_file_huge(aiohttp_client, tmpdir) -> None:
-    filename = 'huge_data.unknown_mime_type'
+async def test_static_file_huge(aiohttp_client, tmp_path) -> None:
+    file_path = tmp_path / 'huge_data.unknown_mime_type'
 
     # fill 20MB file
-    with tmpdir.join(filename).open('w') as f:
+    with file_path.open('w') as f:
         for i in range(1024*20):
             f.write(chr(i % 64 + 0x20) * 1024)
 
-    file_st = os.stat(str(tmpdir.join(filename)))
+    file_st = file_path.stat()
 
     app = web.Application()
-    app.router.add_static('/static', str(tmpdir))
+    app.router.add_static('/static', str(tmp_path))
     client = await aiohttp_client(app)
 
-    resp = await client.get('/static/'+filename)
+    resp = await client.get('/static/'+file_path.name)
     assert 200 == resp.status
     ct = resp.headers['CONTENT-TYPE']
     assert 'application/octet-stream' == ct
     assert resp.headers.get('CONTENT-ENCODING') is None
     assert int(resp.headers.get('CONTENT-LENGTH')) == file_st.st_size
 
-    f = tmpdir.join(filename).open('rb')
+    f = file_path.open('rb')
     off = 0
     cnt = 0
     while off < file_st.st_size:
         chunk = await resp.content.readany()
         expected = f.read(len(chunk))
         assert chunk == expected
         off += len(chunk)
@@ -747,32 +746,32 @@
     expected_body = zcomp.compress(b'file content\n') + zcomp.flush()
     assert expected_body == await resp.read()
     assert 'application/octet-stream' == resp.headers['Content-Type']
     assert resp.headers.get('Content-Encoding') == 'deflate'
     await resp.release()
 
 
-async def test_static_file_huge_cancel(aiohttp_client, tmpdir) -> None:
-    filename = 'huge_data.unknown_mime_type'
+async def test_static_file_huge_cancel(aiohttp_client, tmp_path) -> None:
+    file_path = tmp_path / 'huge_data.unknown_mime_type'
 
     # fill 100MB file
-    with tmpdir.join(filename).open('w') as f:
+    with file_path.open('w') as f:
         for i in range(1024*20):
             f.write(chr(i % 64 + 0x20) * 1024)
 
     task = None
 
     async def handler(request):
         nonlocal task
         task = request.task
         # reduce send buffer size
         tr = request.transport
         sock = tr.get_extra_info('socket')
         sock.setsockopt(socket.SOL_SOCKET, socket.SO_SNDBUF, 1024)
-        ret = web.FileResponse(pathlib.Path(str(tmpdir.join(filename))))
+        ret = web.FileResponse(file_path)
         return ret
 
     app = web.Application()
 
     app.router.add_get('/', handler)
     client = await aiohttp_client(app)
 
@@ -785,28 +784,28 @@
         try:
             data += await resp.content.read(1024)
         except aiohttp.ClientPayloadError:
             break
     assert len(data) < 1024 * 1024 * 20
 
 
-async def test_static_file_huge_error(aiohttp_client, tmpdir) -> None:
-    filename = 'huge_data.unknown_mime_type'
+async def test_static_file_huge_error(aiohttp_client, tmp_path) -> None:
+    file_path = tmp_path / 'huge_data.unknown_mime_type'
 
     # fill 20MB file
-    with tmpdir.join(filename).open('wb') as f:
+    with file_path.open('wb') as f:
         f.seek(20*1024*1024)
         f.write(b'1')
 
     async def handler(request):
         # reduce send buffer size
         tr = request.transport
         sock = tr.get_extra_info('socket')
         sock.setsockopt(socket.SOL_SOCKET, socket.SO_SNDBUF, 1024)
-        ret = web.FileResponse(pathlib.Path(str(tmpdir.join(filename))))
+        ret = web.FileResponse(file_path)
         return ret
 
     app = web.Application()
 
     app.router.add_get('/', handler)
     client = await aiohttp_client(app)
```

### Comparing `aiohttp-4.0.0a0/tests/test_web_server.py` & `aiohttp-4.0.0a1/tests/test_web_server.py`

 * *Files 14% similar despite different names*

```diff
@@ -15,22 +15,26 @@
     resp = await cli.get('/path/to')
     assert resp.status == 200
     txt = await resp.text()
     assert txt == '/path/to'
 
 
 async def test_raw_server_not_http_exception(aiohttp_raw_server,
-                                             aiohttp_client):
+                                             aiohttp_client,
+                                             loop):
+    # disable debug mode not to print traceback
+    loop.set_debug(False)
+
     exc = RuntimeError("custom runtime error")
 
     async def handler(request):
         raise exc
 
     logger = mock.Mock()
-    server = await aiohttp_raw_server(handler, logger=logger, debug=False)
+    server = await aiohttp_raw_server(handler, logger=logger)
     cli = await aiohttp_client(server)
     resp = await cli.get('/path/to')
     assert resp.status == 500
     assert resp.headers['Content-Type'].startswith('text/plain')
 
     txt = await resp.text()
     assert txt.startswith('500 Internal Server Error')
@@ -39,14 +43,16 @@
     logger.exception.assert_called_with(
         "Error handling request",
         exc_info=exc)
 
 
 async def test_raw_server_handler_timeout(aiohttp_raw_server,
                                           aiohttp_client) -> None:
+    loop = asyncio.get_event_loop()
+    loop.set_debug(True)
     exc = asyncio.TimeoutError("error")
 
     async def handler(request):
         raise exc
 
     logger = mock.Mock()
     server = await aiohttp_raw_server(handler, logger=logger)
@@ -59,73 +65,87 @@
 
 
 async def test_raw_server_do_not_swallow_exceptions(aiohttp_raw_server,
                                                     aiohttp_client):
     async def handler(request):
         raise asyncio.CancelledError()
 
+    loop = asyncio.get_event_loop()
+    loop.set_debug(True)
     logger = mock.Mock()
     server = await aiohttp_raw_server(handler, logger=logger)
     cli = await aiohttp_client(server)
 
     with pytest.raises(client.ServerDisconnectedError):
         await cli.get('/path/to')
 
     logger.debug.assert_called_with('Ignored premature client disconnection')
 
 
 async def test_raw_server_cancelled_in_write_eof(aiohttp_raw_server,
                                                  aiohttp_client):
 
+    class MyResponse(web.Response):
+        async def write_eof(self, data=b''):
+            raise asyncio.CancelledError("error")
+
     async def handler(request):
-        resp = web.Response(text=str(request.rel_url))
-        resp.write_eof = mock.Mock(side_effect=asyncio.CancelledError("error"))
+        resp = MyResponse(text=str(request.rel_url))
         return resp
 
+    loop = asyncio.get_event_loop()
+    loop.set_debug(True)
     logger = mock.Mock()
     server = await aiohttp_raw_server(handler, logger=logger)
     cli = await aiohttp_client(server)
 
     resp = await cli.get('/path/to')
     with pytest.raises(client.ClientPayloadError):
         await resp.read()
 
-    logger.debug.assert_called_with('Ignored premature client disconnection ')
+    logger.debug.assert_called_with('Ignored premature client disconnection')
 
 
 async def test_raw_server_not_http_exception_debug(aiohttp_raw_server,
                                                    aiohttp_client):
     exc = RuntimeError("custom runtime error")
 
     async def handler(request):
         raise exc
 
+    loop = asyncio.get_event_loop()
+    loop.set_debug(True)
     logger = mock.Mock()
-    server = await aiohttp_raw_server(handler, logger=logger, debug=True)
+    server = await aiohttp_raw_server(handler, logger=logger)
     cli = await aiohttp_client(server)
     resp = await cli.get('/path/to')
     assert resp.status == 500
     assert resp.headers['Content-Type'].startswith('text/plain')
 
     txt = await resp.text()
     assert 'Traceback (most recent call last):\n' in txt
 
     logger.exception.assert_called_with(
         "Error handling request",
         exc_info=exc)
 
 
-async def test_raw_server_html_exception(aiohttp_raw_server, aiohttp_client):
+async def test_raw_server_html_exception(aiohttp_raw_server,
+                                         aiohttp_client,
+                                         loop):
+    # disable debug mode not to print traceback
+    loop.set_debug(False)
+
     exc = RuntimeError("custom runtime error")
 
     async def handler(request):
         raise exc
 
     logger = mock.Mock()
-    server = await aiohttp_raw_server(handler, logger=logger, debug=False)
+    server = await aiohttp_raw_server(handler, logger=logger)
     cli = await aiohttp_client(server)
     resp = await cli.get('/path/to', headers={'Accept': 'text/html'})
     assert resp.status == 500
     assert resp.headers['Content-Type'].startswith('text/html')
 
     txt = await resp.text()
     assert txt == (
@@ -142,16 +162,18 @@
 async def test_raw_server_html_exception_debug(aiohttp_raw_server,
                                                aiohttp_client):
     exc = RuntimeError("custom runtime error")
 
     async def handler(request):
         raise exc
 
+    loop = asyncio.get_event_loop()
+    loop.set_debug(True)
     logger = mock.Mock()
-    server = await aiohttp_raw_server(handler, logger=logger, debug=True)
+    server = await aiohttp_raw_server(handler, logger=logger)
     cli = await aiohttp_client(server)
     resp = await cli.get('/path/to', headers={'Accept': 'text/html'})
     assert resp.status == 500
     assert resp.headers['Content-Type'].startswith('text/html')
 
     txt = await resp.text()
     assert txt.startswith(
```

### Comparing `aiohttp-4.0.0a0/tests/test_web_urldispatcher.py` & `aiohttp-4.0.0a1/tests/test_web_urldispatcher.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,38 +1,17 @@
-import functools
-import os
 import pathlib
-import shutil
-import tempfile
 from unittest import mock
 from unittest.mock import MagicMock
 
 import pytest
 
-from aiohttp import abc, web
+from aiohttp import web
 from aiohttp.web_urldispatcher import SystemRoute
 
 
-@pytest.fixture(scope='function')
-def tmp_dir_path(request):
-    """
-    Give a path for a temporary directory
-    The directory is destroyed at the end of the test.
-    """
-    # Temporary directory.
-    tmp_dir = tempfile.mkdtemp()
-
-    def teardown():
-        # Delete the whole directory:
-        shutil.rmtree(tmp_dir)
-
-    request.addfinalizer(teardown)
-    return tmp_dir
-
-
 @pytest.mark.parametrize(
     "show_index,status,prefix,data",
     [pytest.param(False, 403, '/', None, id="index_forbidden"),
      pytest.param(True, 200, '/',
                   b'<html>\n<head>\n<title>Index of /.</title>\n'
                   b'</head>\n<body>\n<h1>Index of /.</h1>\n<ul>\n'
                   b'<li><a href="/my_dir">my_dir/</a></li>\n'
@@ -42,125 +21,122 @@
      pytest.param(True, 200, '/static',
                   b'<html>\n<head>\n<title>Index of /.</title>\n'
                   b'</head>\n<body>\n<h1>Index of /.</h1>\n<ul>\n'
                   b'<li><a href="/static/my_dir">my_dir/</a></li>\n'
                   b'<li><a href="/static/my_file">my_file</a></li>\n'
                   b'</ul>\n</body>\n</html>',
                   id="index_static")])
-async def test_access_root_of_static_handler(tmp_dir_path,
+async def test_access_root_of_static_handler(tmp_path,
                                              aiohttp_client,
                                              show_index,
                                              status,
                                              prefix,
                                              data) -> None:
     """
     Tests the operation of static file server.
     Try to access the root of static file server, and make
     sure that correct HTTP statuses are returned depending if we directory
     index should be shown or not.
     """
-    # Put a file inside tmp_dir_path:
-    my_file_path = os.path.join(tmp_dir_path, 'my_file')
-    with open(my_file_path, 'w') as fw:
-        fw.write('hello')
+    my_file = tmp_path / 'my_file'
+    my_dir = tmp_path / 'my_dir'
+    my_dir.mkdir()
+    my_file_in_dir = my_dir / 'my_file_in_dir'
 
-    my_dir_path = os.path.join(tmp_dir_path, 'my_dir')
-    os.mkdir(my_dir_path)
+    with my_file.open('w') as fw:
+        fw.write('hello')
 
-    my_file_path = os.path.join(my_dir_path, 'my_file_in_dir')
-    with open(my_file_path, 'w') as fw:
+    with my_file_in_dir.open('w') as fw:
         fw.write('world')
 
     app = web.Application()
 
     # Register global static route:
-    app.router.add_static(prefix, tmp_dir_path, show_index=show_index)
+    app.router.add_static(prefix, str(tmp_path), show_index=show_index)
     client = await aiohttp_client(app)
 
     # Request the root of the static directory.
     r = await client.get(prefix)
     assert r.status == status
 
     if data:
         assert r.headers['Content-Type'] == "text/html; charset=utf-8"
         read_ = (await r.read())
         assert read_ == data
 
 
-async def test_follow_symlink(tmp_dir_path, aiohttp_client) -> None:
+async def test_follow_symlink(tmp_path, aiohttp_client) -> None:
     """
     Tests the access to a symlink, in static folder
     """
     data = 'hello world'
 
-    my_dir_path = os.path.join(tmp_dir_path, 'my_dir')
-    os.mkdir(my_dir_path)
+    my_dir_path = tmp_path / 'my_dir'
+    my_dir_path.mkdir()
 
-    my_file_path = os.path.join(my_dir_path, 'my_file_in_dir')
-    with open(my_file_path, 'w') as fw:
+    my_file_path = my_dir_path / 'my_file_in_dir'
+    with my_file_path.open('w') as fw:
         fw.write(data)
 
-    my_symlink_path = os.path.join(tmp_dir_path, 'my_symlink')
-    os.symlink(my_dir_path, my_symlink_path)
+    my_symlink_path = tmp_path / 'my_symlink'
+    pathlib.Path(str(my_symlink_path)).symlink_to(str(my_dir_path), True)
 
     app = web.Application()
 
     # Register global static route:
-    app.router.add_static('/', tmp_dir_path, follow_symlinks=True)
+    app.router.add_static('/', str(tmp_path), follow_symlinks=True)
     client = await aiohttp_client(app)
 
     # Request the root of the static directory.
     r = await client.get('/my_symlink/my_file_in_dir')
     assert r.status == 200
     assert (await r.text()) == data
 
 
 @pytest.mark.parametrize('dir_name,filename,data', [
     ('', 'test file.txt', 'test text'),
     ('test dir name', 'test dir file .txt', 'test text file folder')
 ])
-async def test_access_to_the_file_with_spaces(tmp_dir_path, aiohttp_client,
+async def test_access_to_the_file_with_spaces(tmp_path, aiohttp_client,
                                               dir_name, filename, data):
     """
     Checks operation of static files with spaces
     """
 
-    my_dir_path = os.path.join(tmp_dir_path, dir_name)
+    my_dir_path = tmp_path / dir_name
+    if my_dir_path != tmp_path:
+        my_dir_path.mkdir()
 
-    if dir_name:
-        os.mkdir(my_dir_path)
-
-    my_file_path = os.path.join(my_dir_path, filename)
-
-    with open(my_file_path, 'w') as fw:
+    my_file_path = my_dir_path / filename
+    with my_file_path.open('w') as fw:
         fw.write(data)
 
     app = web.Application()
 
-    url = os.path.join('/', dir_name, filename)
+    url = '/' + str(pathlib.Path(dir_name, filename))
 
-    app.router.add_static('/', tmp_dir_path)
+    app.router.add_static('/', str(tmp_path))
     client = await aiohttp_client(app)
 
     r = await client.get(url)
     assert r.status == 200
     assert (await r.text()) == data
 
 
-async def test_access_non_existing_resource(tmp_dir_path,
+async def test_access_non_existing_resource(tmp_path,
                                             aiohttp_client) -> None:
     """
     Tests accessing non-existing resource
     Try to access a non-exiting resource and make sure that 404 HTTP status
     returned.
     """
     app = web.Application()
 
     # Register global static route:
-    app.router.add_static('/', tmp_dir_path, show_index=True)
+    app.router.add_static('/', str(tmp_path), show_index=True)
     client = await aiohttp_client(app)
 
     # Request the root of the static directory.
     r = await client.get('/non_existing_resource')
     assert r.status == 404
 
 
@@ -183,84 +159,76 @@
     client = await aiohttp_client(app)
 
     r = await client.get(request_url)
     assert r.status == 200
 
 
 async def test_handler_metadata_persistence() -> None:
-    """
-    Tests accessing metadata of a handler after registering it on the app
-    router.
-    """
+    # Tests accessing metadata of a handler after registering it on the app
+    # router.
     app = web.Application()
 
     async def async_handler(request):
         """Doc"""
         return web.Response()
 
-    def sync_handler(request):
-        """Doc"""
-        return web.Response()
-
     app.router.add_get('/async', async_handler)
-    with pytest.warns(DeprecationWarning):
-        app.router.add_get('/sync', sync_handler)
 
     for resource in app.router.resources():
         for route in resource:
             assert route.handler.__doc__ == 'Doc'
 
 
-async def test_unauthorized_folder_access(tmp_dir_path,
+async def test_unauthorized_folder_access(tmp_path,
                                           aiohttp_client) -> None:
     """
     Tests the unauthorized access to a folder of static file server.
     Try to list a folder content of static file server when server does not
     have permissions to do so for the folder.
     """
-    my_dir_path = os.path.join(tmp_dir_path, 'my_dir')
-    os.mkdir(my_dir_path)
+    my_dir = tmp_path / 'my_dir'
+    my_dir.mkdir()
 
     app = web.Application()
 
     with mock.patch('pathlib.Path.__new__') as path_constructor:
         path = MagicMock()
         path.joinpath.return_value = path
         path.resolve.return_value = path
         path.iterdir.return_value.__iter__.side_effect = PermissionError()
         path_constructor.return_value = path
 
         # Register global static route:
-        app.router.add_static('/', tmp_dir_path, show_index=True)
+        app.router.add_static('/', str(tmp_path), show_index=True)
         client = await aiohttp_client(app)
 
         # Request the root of the static directory.
-        r = await client.get('/my_dir')
+        r = await client.get('/' + my_dir.name)
         assert r.status == 403
 
 
-async def test_access_symlink_loop(tmp_dir_path, aiohttp_client) -> None:
+async def test_access_symlink_loop(tmp_path, aiohttp_client) -> None:
     """
     Tests the access to a looped symlink, which could not be resolved.
     """
-    my_dir_path = os.path.join(tmp_dir_path, 'my_symlink')
-    os.symlink(my_dir_path, my_dir_path)
+    my_dir_path = tmp_path / 'my_symlink'
+    pathlib.Path(str(my_dir_path)).symlink_to(str(my_dir_path), True)
 
     app = web.Application()
 
     # Register global static route:
-    app.router.add_static('/', tmp_dir_path, show_index=True)
+    app.router.add_static('/', str(tmp_path), show_index=True)
     client = await aiohttp_client(app)
 
     # Request the root of the static directory.
-    r = await client.get('/my_symlink')
+    r = await client.get('/' + my_dir_path.name)
     assert r.status == 404
 
 
-async def test_access_special_resource(tmp_dir_path, aiohttp_client) -> None:
+async def test_access_special_resource(tmp_path, aiohttp_client) -> None:
     """
     Tests the access to a resource that is neither a file nor a directory.
     Checks that if a special resource is accessed (f.e. named pipe or UNIX
     domain socket) then 404 HTTP status returned.
     """
     app = web.Application()
 
@@ -274,65 +242,33 @@
                                                else path)
         path.resolve.return_value = path
         special.resolve.return_value = special
 
         path_constructor.return_value = path
 
         # Register global static route:
-        app.router.add_static('/', tmp_dir_path, show_index=True)
+        app.router.add_static('/', str(tmp_path), show_index=True)
         client = await aiohttp_client(app)
 
         # Request the root of the static directory.
         r = await client.get('/special')
         assert r.status == 403
 
 
-async def test_partially_applied_handler(aiohttp_client) -> None:
-    app = web.Application()
-
-    async def handler(data, request):
-        return web.Response(body=data)
-
-    with pytest.warns(DeprecationWarning):
-        app.router.add_route('GET', '/', functools.partial(handler, b'hello'))
-    client = await aiohttp_client(app)
-
-    r = await client.get('/')
-    data = (await r.read())
-    assert data == b'hello'
-
-
 def test_system_route() -> None:
     route = SystemRoute(web.HTTPCreated(reason='test'))
     with pytest.raises(RuntimeError):
         route.url_for()
     assert route.name is None
     assert route.resource is None
     assert "<SystemRoute 201: test>" == repr(route)
     assert 201 == route.status
     assert 'test' == route.reason
 
 
-async def test_412_is_returned(aiohttp_client) -> None:
-
-    class MyRouter(abc.AbstractRouter):
-
-        async def resolve(self, request):
-            raise web.HTTPPreconditionFailed()
-
-    with pytest.warns(DeprecationWarning):
-        app = web.Application(router=MyRouter())
-
-    client = await aiohttp_client(app)
-
-    resp = await client.get('/')
-
-    assert resp.status == 412
-
-
 async def test_allow_head(aiohttp_client) -> None:
     """
     Test allow_head on routes.
     """
     app = web.Application()
 
     async def handler(_):
@@ -475,19 +411,19 @@
     await r.release()
 
     r = await client.put("/a")
     assert r.status == 405
     await r.release()
 
 
-async def test_static_absolute_url(aiohttp_client, tmpdir) -> None:
+async def test_static_absolute_url(aiohttp_client, tmp_path) -> None:
     # requested url is an absolute name like
     # /static/\\machine_name\c$ or /static/D:\path
     # where the static dir is totally different
     app = web.Application()
-    fname = tmpdir / 'file.txt'
-    fname.write_text('sample text', 'ascii')
+    file_path = tmp_path / 'file.txt'
+    file_path.write_text('sample text', 'ascii')
     here = pathlib.Path(__file__).parent
     app.router.add_static('/static', here)
     client = await aiohttp_client(app)
-    resp = await client.get('/static/' + str(fname))
+    resp = await client.get('/static/' + str(file_path.resolve()))
     assert resp.status == 403
```

### Comparing `aiohttp-4.0.0a0/tests/test_web_websocket.py` & `aiohttp-4.0.0a1/tests/test_web_websocket.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,18 +1,17 @@
 import asyncio
 from unittest import mock
 
 import pytest
 from multidict import CIMultiDict
 
-from aiohttp import WSMessage, WSMsgType, signals
-from aiohttp.log import ws_logger
+from aiohttp import WSMsgType, signals
 from aiohttp.streams import EofStream
 from aiohttp.test_utils import make_mocked_coro, make_mocked_request
-from aiohttp.web import HTTPBadRequest, HTTPMethodNotAllowed, WebSocketResponse
+from aiohttp.web import HTTPBadRequest, WebSocketResponse
 from aiohttp.web_ws import WS_CLOSED_MESSAGE, WebSocketReady
 
 
 @pytest.fixture
 def app(loop):
     ret = mock.Mock()
     ret.loop = loop
@@ -101,42 +100,14 @@
 
 async def test_nonstarted_receive_json() -> None:
     ws = WebSocketResponse()
     with pytest.raises(RuntimeError):
         await ws.receive_json()
 
 
-async def test_receive_str_nonstring(make_request) -> None:
-    req = make_request('GET', '/')
-    ws = WebSocketResponse()
-    await ws.prepare(req)
-
-    async def receive():
-        return WSMessage(WSMsgType.BINARY, b'data', b'')
-
-    ws.receive = receive
-
-    with pytest.raises(TypeError):
-        await ws.receive_str()
-
-
-async def test_receive_bytes_nonsbytes(make_request) -> None:
-    req = make_request('GET', '/')
-    ws = WebSocketResponse()
-    await ws.prepare(req)
-
-    async def receive():
-        return WSMessage(WSMsgType.TEXT, 'data', b'')
-
-    ws.receive = receive
-
-    with pytest.raises(TypeError):
-        await ws.receive_bytes()
-
-
 async def test_send_str_nonstring(make_request) -> None:
     req = make_request('GET', '/')
     ws = WebSocketResponse()
     await ws.prepare(req)
     with pytest.raises(TypeError):
         await ws.send_str(b'bytes')
 
@@ -199,20 +170,14 @@
 
 def test_can_prepare_unknown_protocol(make_request) -> None:
     req = make_request('GET', '/')
     ws = WebSocketResponse()
     assert WebSocketReady(True, None) == ws.can_prepare(req)
 
 
-def test_can_prepare_invalid_method(make_request) -> None:
-    req = make_request('POST', '/')
-    ws = WebSocketResponse()
-    assert WebSocketReady(False, None) == ws.can_prepare(req)
-
-
 def test_can_prepare_without_upgrade(make_request) -> None:
     req = make_request('GET', '/',
                        headers=CIMultiDict({}))
     ws = WebSocketResponse()
     assert WebSocketReady(False, None) == ws.can_prepare(req)
 
 
@@ -228,89 +193,84 @@
 
 def test_closed_after_ctor() -> None:
     ws = WebSocketResponse()
     assert not ws.closed
     assert ws.close_code is None
 
 
-async def test_send_str_closed(make_request, mocker) -> None:
+async def test_send_str_closed(make_request) -> None:
     req = make_request('GET', '/')
     ws = WebSocketResponse()
     await ws.prepare(req)
     ws._reader.feed_data(WS_CLOSED_MESSAGE, 0)
     await ws.close()
 
-    mocker.spy(ws_logger, 'warning')
-    await ws.send_str('string')
-    assert ws_logger.warning.called
+    with pytest.raises(ConnectionError):
+        await ws.send_str('string')
 
 
-async def test_send_bytes_closed(make_request, mocker) -> None:
+async def test_send_bytes_closed(make_request) -> None:
     req = make_request('GET', '/')
     ws = WebSocketResponse()
     await ws.prepare(req)
     ws._reader.feed_data(WS_CLOSED_MESSAGE, 0)
     await ws.close()
 
-    mocker.spy(ws_logger, 'warning')
-    await ws.send_bytes(b'bytes')
-    assert ws_logger.warning.called
+    with pytest.raises(ConnectionError):
+        await ws.send_bytes(b'bytes')
 
 
-async def test_send_json_closed(make_request, mocker) -> None:
+async def test_send_json_closed(make_request) -> None:
     req = make_request('GET', '/')
     ws = WebSocketResponse()
     await ws.prepare(req)
     ws._reader.feed_data(WS_CLOSED_MESSAGE, 0)
     await ws.close()
 
-    mocker.spy(ws_logger, 'warning')
-    await ws.send_json({'type': 'json'})
-    assert ws_logger.warning.called
+    with pytest.raises(ConnectionError):
+        await ws.send_json({'type': 'json'})
 
 
-async def test_ping_closed(make_request, mocker) -> None:
+async def test_ping_closed(make_request) -> None:
     req = make_request('GET', '/')
     ws = WebSocketResponse()
     await ws.prepare(req)
     ws._reader.feed_data(WS_CLOSED_MESSAGE, 0)
     await ws.close()
 
-    mocker.spy(ws_logger, 'warning')
-    await ws.ping()
-    assert ws_logger.warning.called
+    with pytest.raises(ConnectionError):
+        await ws.ping()
 
 
 async def test_pong_closed(make_request, mocker) -> None:
     req = make_request('GET', '/')
     ws = WebSocketResponse()
     await ws.prepare(req)
     ws._reader.feed_data(WS_CLOSED_MESSAGE, 0)
     await ws.close()
 
-    mocker.spy(ws_logger, 'warning')
-    await ws.pong()
-    assert ws_logger.warning.called
+    with pytest.raises(ConnectionError):
+        await ws.pong()
 
 
 async def test_close_idempotent(make_request) -> None:
     req = make_request('GET', '/')
     ws = WebSocketResponse()
     await ws.prepare(req)
     ws._reader.feed_data(WS_CLOSED_MESSAGE, 0)
     assert (await ws.close(code=1, message='message1'))
     assert ws.closed
     assert not (await ws.close(code=2, message='message2'))
 
 
-async def test_prepare_invalid_method(make_request) -> None:
+async def test_prepare_post_method_ok(make_request) -> None:
     req = make_request('POST', '/')
     ws = WebSocketResponse()
-    with pytest.raises(HTTPMethodNotAllowed):
-        await ws.prepare(req)
+    await ws.prepare(req)
+    assert ws.prepared
 
 
 async def test_prepare_without_upgrade(make_request) -> None:
     req = make_request('GET', '/',
                        headers=CIMultiDict({}))
     ws = WebSocketResponse()
     with pytest.raises(HTTPBadRequest):
@@ -356,48 +316,14 @@
     ws._payload_writer.drain.return_value.set_result(True)
 
     msg = await ws.receive()
     assert msg.type == WSMsgType.CLOSED
     assert ws.closed
 
 
-async def test_receive_exc_in_reader(make_request, loop) -> None:
-    req = make_request('GET', '/')
-    ws = WebSocketResponse()
-    await ws.prepare(req)
-
-    ws._reader = mock.Mock()
-    exc = ValueError()
-    res = loop.create_future()
-    res.set_exception(exc)
-    ws._reader.read = make_mocked_coro(res)
-    ws._payload_writer.drain = mock.Mock()
-    ws._payload_writer.drain.return_value = loop.create_future()
-    ws._payload_writer.drain.return_value.set_result(True)
-
-    msg = await ws.receive()
-    assert msg.type == WSMsgType.ERROR
-    assert msg.data is exc
-    assert ws.exception() is exc
-
-
-async def test_receive_cancelled(make_request, loop) -> None:
-    req = make_request('GET', '/')
-    ws = WebSocketResponse()
-    await ws.prepare(req)
-
-    ws._reader = mock.Mock()
-    res = loop.create_future()
-    res.set_exception(asyncio.CancelledError())
-    ws._reader.read = make_mocked_coro(res)
-
-    with pytest.raises(asyncio.CancelledError):
-        await ws.receive()
-
-
 async def test_receive_timeouterror(make_request, loop) -> None:
     req = make_request('GET', '/')
     ws = WebSocketResponse()
     await ws.prepare(req)
 
     ws._reader = mock.Mock()
     res = loop.create_future()
@@ -430,41 +356,15 @@
     await ws.prepare(req)
     ws._waiting = True
 
     with pytest.raises(RuntimeError):
         await ws.receive()
 
 
-async def test_close_exc(make_request, loop, mocker) -> None:
-    req = make_request('GET', '/')
-
-    ws = WebSocketResponse()
-    await ws.prepare(req)
-
-    ws._reader = mock.Mock()
-    exc = ValueError()
-    ws._reader.read.return_value = loop.create_future()
-    ws._reader.read.return_value.set_exception(exc)
-    ws._payload_writer.drain = mock.Mock()
-    ws._payload_writer.drain.return_value = loop.create_future()
-    ws._payload_writer.drain.return_value.set_result(True)
-
-    await ws.close()
-    assert ws.closed
-    assert ws.exception() is exc
-
-    ws._closed = False
-    ws._reader.read.return_value = loop.create_future()
-    ws._reader.read.return_value.set_exception(asyncio.CancelledError())
-    with pytest.raises(asyncio.CancelledError):
-        await ws.close()
-    assert ws.close_code == 1006
-
-
-async def test_close_exc2(make_request) -> None:
+async def test_close_exc(make_request) -> None:
 
     req = make_request('GET', '/')
     ws = WebSocketResponse()
     await ws.prepare(req)
 
     exc = ValueError()
     ws._writer = mock.Mock()
@@ -498,7 +398,15 @@
     writer_send.assert_called_with('string', binary=False, compress=15)
 
     await ws.send_bytes(b'bytes', compress=0)
     writer_send.assert_called_with(b'bytes', binary=True, compress=0)
 
     await ws.send_json('[{}]', compress=9)
     writer_send.assert_called_with('"[{}]"', binary=False, compress=9)
+
+
+async def test_no_transfer_encoding_header(make_request, mocker) -> None:
+    req = make_request('GET', '/')
+    ws = WebSocketResponse()
+    await ws._start(req)
+
+    assert 'Transfer-Encoding' not in ws.headers
```

### Comparing `aiohttp-4.0.0a0/tests/test_web_websocket_functional.py` & `aiohttp-4.0.0a1/tests/test_web_websocket_functional.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """HTTP websocket server functional tests"""
 
 import asyncio
 
 import pytest
 
 import aiohttp
-from aiohttp import web
+from aiohttp import WSServerHandshakeError, web
 from aiohttp.http import WSMsgType
 
 
 @pytest.fixture
 def ceil(mocker):
     def ceil(val):
         return val
@@ -270,32 +270,19 @@
     ws = await client.ws_connect('/')
     await ws.send_str('request')
     assert 'reply' == (await ws.receive_str())
 
     # The server closes here.  Then the client sends bogus messages with an
     # internval shorter than server-side close timeout, to make the server
     # hanging indefinitely.
-    await asyncio.sleep(0.08, loop=loop)
+    await asyncio.sleep(0.08)
     msg = await ws._reader.read()
     assert msg.type == WSMsgType.CLOSE
-    await ws.send_str('hang')
 
-    # i am not sure what do we test here
-    # under uvloop this code raises RuntimeError
-    try:
-        await asyncio.sleep(0.08, loop=loop)
-        await ws.send_str('hang')
-        await asyncio.sleep(0.08, loop=loop)
-        await ws.send_str('hang')
-        await asyncio.sleep(0.08, loop=loop)
-        await ws.send_str('hang')
-    except RuntimeError:
-        pass
-
-    await asyncio.sleep(0.08, loop=loop)
+    await asyncio.sleep(0.08)
     assert (await aborted)
 
     await ws.close()
 
 
 async def test_concurrent_close(loop, aiohttp_client) -> None:
 
@@ -309,15 +296,15 @@
 
         msg = await ws.receive()
         assert msg.type == WSMsgType.CLOSING
 
         msg = await ws.receive()
         assert msg.type == WSMsgType.CLOSING
 
-        await asyncio.sleep(0, loop=loop)
+        await asyncio.sleep(0)
 
         msg = await ws.receive()
         assert msg.type == WSMsgType.CLOSED
 
         return ws
 
     app = web.Application()
@@ -328,15 +315,15 @@
                                  protocols=('eggs', 'bar'))
 
     await srv_ws.close(code=1007)
 
     msg = await ws.receive()
     assert msg.type == WSMsgType.CLOSE
 
-    await asyncio.sleep(0, loop=loop)
+    await asyncio.sleep(0)
     msg = await ws.receive()
     assert msg.type == WSMsgType.CLOSED
 
 
 async def test_auto_pong_with_closing_by_peer(loop, aiohttp_client) -> None:
 
     closed = loop.create_future()
@@ -655,45 +642,36 @@
     app = web.Application()
     app.router.add_get('/', handler)
 
     client = await aiohttp_client(app)
     ws = await client.ws_connect('/', autoping=False)
     msg = await ws.receive()
 
-    assert msg.type == aiohttp.WSMsgType.ping
+    assert msg.type == aiohttp.WSMsgType.PING
 
     await ws.close()
 
 
 async def test_heartbeat_no_pong(loop, aiohttp_client, ceil) -> None:
-    cancelled = False
 
     async def handler(request):
-        nonlocal cancelled
-
         ws = web.WebSocketResponse(heartbeat=0.05)
         await ws.prepare(request)
 
-        try:
-            await ws.receive()
-        except asyncio.CancelledError:
-            cancelled = True
-
+        await ws.receive()
         return ws
 
     app = web.Application()
     app.router.add_get('/', handler)
 
     client = await aiohttp_client(app)
     ws = await client.ws_connect('/', autoping=False)
     msg = await ws.receive()
-    assert msg.type == aiohttp.WSMsgType.ping
-    await ws.receive()
-
-    assert cancelled
+    assert msg.type == aiohttp.WSMsgType.PING
+    await ws.close()
 
 
 async def test_server_ws_async_for(loop, aiohttp_server) -> None:
     closed = loop.create_future()
 
     async def handler(request):
         ws = web.WebSocketResponse()
@@ -706,15 +684,15 @@
         closed.set_result(1)
         return ws
 
     app = web.Application()
     app.router.add_route('GET', '/', handler)
     server = await aiohttp_server(app)
 
-    async with aiohttp.ClientSession(loop=loop) as sm:
+    async with aiohttp.ClientSession() as sm:
         async with sm.ws_connect(server.make_url('/')) as resp:
 
             items = ['q1', 'q2', 'q3']
             for item in items:
                 await resp.send_str(item)
                 msg = await resp.receive()
                 assert msg.type == aiohttp.WSMsgType.TEXT
@@ -781,7 +759,75 @@
     resp = await client.get('/')
     txt = await resp.text()
     assert txt == 'OK'
 
     ws = await client.ws_connect('/')
     data = await ws.receive_str()
     assert data == 'OK'
+
+
+async def test_receive_str_nonstring(loop, aiohttp_client) -> None:
+
+    async def handler(request):
+        ws = web.WebSocketResponse()
+        if not ws.can_prepare(request):
+            return web.HTTPUpgradeRequired()
+
+        await ws.prepare(request)
+        await ws.send_bytes(b'answer')
+        await ws.close()
+        return ws
+
+    app = web.Application()
+    app.router.add_route('GET', '/', handler)
+    client = await aiohttp_client(app)
+
+    ws = await client.ws_connect('/')
+    with pytest.raises(TypeError):
+        await ws.receive_str()
+
+
+async def test_receive_bytes_nonbytes(loop, aiohttp_client) -> None:
+
+    async def handler(request):
+        ws = web.WebSocketResponse()
+        if not ws.can_prepare(request):
+            return web.HTTPUpgradeRequired()
+
+        await ws.prepare(request)
+        await ws.send_bytes('answer')
+        await ws.close()
+        return ws
+
+    app = web.Application()
+    app.router.add_route('GET', '/', handler)
+    client = await aiohttp_client(app)
+
+    ws = await client.ws_connect('/')
+    with pytest.raises(TypeError):
+        await ws.receive_bytes()
+
+
+async def test_bug3380(loop, aiohttp_client) -> None:
+
+    async def handle_null(request):
+        return aiohttp.web.json_response({'err': None})
+
+    async def ws_handler(request):
+        return web.Response(status=401)
+
+    app = web.Application()
+    app.router.add_route('GET', '/ws', ws_handler)
+    app.router.add_route('GET', '/api/null', handle_null)
+
+    client = await aiohttp_client(app)
+
+    resp = await client.get('/api/null')
+    assert (await resp.json()) == {'err': None}
+    resp.close()
+
+    with pytest.raises(WSServerHandshakeError):
+        await client.ws_connect('/ws')
+
+    resp = await client.get('/api/null', timeout=1)
+    assert (await resp.json()) == {'err': None}
+    resp.close()
```

### Comparing `aiohttp-4.0.0a0/tests/test_worker.py` & `aiohttp-4.0.0a1/tests/test_worker.py`

 * *Files 0% similar despite different names*

```diff
@@ -65,15 +65,14 @@
 def test_init_process(worker) -> None:
     with mock.patch('aiohttp.worker.asyncio') as m_asyncio:
         try:
             worker.init_process()
         except TypeError:
             pass
 
-        assert m_asyncio.get_event_loop.return_value.close.called
         assert m_asyncio.new_event_loop.called
         assert m_asyncio.set_event_loop.called
 
 
 def test_run(worker, loop) -> None:
     worker.log = mock.Mock()
     worker.cfg = mock.Mock()
@@ -191,15 +190,15 @@
 def test__get_valid_log_format_ok(worker, source, result) -> None:
     assert result == worker._get_valid_log_format(source)
 
 
 def test__get_valid_log_format_exc(worker) -> None:
     with pytest.raises(ValueError) as exc:
         worker._get_valid_log_format(WRONG_LOG_FORMAT)
-    assert '%(name)s' in str(exc)
+    assert '%(name)s' in str(exc.value)
 
 
 async def test__run_ok_parent_changed(worker, loop,
                                       aiohttp_unused_port) -> None:
     skip_if_no_dict(loop)
 
     worker.ppid = 0
@@ -266,15 +265,15 @@
         tls_certificate_pem_path,
 ) -> None:
     worker.cfg.ssl_version = ssl.PROTOCOL_SSLv23
     worker.cfg.cert_reqs = ssl.CERT_OPTIONAL
     worker.cfg.certfile = tls_certificate_pem_path
     worker.cfg.keyfile = tls_certificate_pem_path
     worker.cfg.ca_certs = None
-    worker.cfg.ciphers = 'PSK'
+    worker.cfg.ciphers = '3DES PSK'
     ctx = worker._create_ssl_context(worker.cfg)
     assert isinstance(ctx, ssl.SSLContext)
 
 
 def test__create_ssl_context_with_ca_certs(
         worker,
         tls_ca_certificate_pem_path, tls_certificate_pem_path,
```

### Comparing `aiohttp-4.0.0a0/vendor/http-parser/AUTHORS` & `aiohttp-4.0.0a1/vendor/http-parser/AUTHORS`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/vendor/http-parser/bench.c` & `aiohttp-4.0.0a1/vendor/http-parser/bench.c`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/vendor/http-parser/contrib/parsertrace.c` & `aiohttp-4.0.0a1/vendor/http-parser/contrib/parsertrace.c`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/vendor/http-parser/contrib/url_parser.c` & `aiohttp-4.0.0a1/vendor/http-parser/contrib/url_parser.c`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/vendor/http-parser/http_parser.c` & `aiohttp-4.0.0a1/vendor/http-parser/http_parser.c`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/vendor/http-parser/http_parser.gyp` & `aiohttp-4.0.0a1/vendor/http-parser/http_parser.gyp`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/vendor/http-parser/http_parser.h` & `aiohttp-4.0.0a1/vendor/http-parser/http_parser.h`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/vendor/http-parser/LICENSE-MIT` & `aiohttp-4.0.0a1/vendor/http-parser/LICENSE-MIT`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/vendor/http-parser/Makefile` & `aiohttp-4.0.0a1/vendor/http-parser/Makefile`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/vendor/http-parser/README.md` & `aiohttp-4.0.0a1/vendor/http-parser/README.md`

 * *Files identical despite different names*

### Comparing `aiohttp-4.0.0a0/vendor/http-parser/test.c` & `aiohttp-4.0.0a1/vendor/http-parser/test.c`

 * *Files identical despite different names*

