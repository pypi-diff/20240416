# Comparing `tmp/onnxsharp-0.0.1-py2.py3-none-any.whl.zip` & `tmp/onnxsharp-0.0.2-py2.py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,20 +1,25 @@
-Zip file size: 22879 bytes, number of entries: 18
--rw-rw-rw-  2.0 fat      149 b- defN 22-Jun-15 16:41 onnx-sharp/__init__.py
--rw-rw-rw-  2.0 fat      199 b- defN 22-Jun-13 14:35 onnx-sharp/basics.py
--rw-rw-rw-  2.0 fat    24080 b- defN 22-Jun-15 15:55 onnx-sharp/graph.py
--rw-rw-rw-  2.0 fat     3370 b- defN 22-Jun-13 14:39 onnx-sharp/model.py
--rw-rw-rw-  2.0 fat     9554 b- defN 22-Jun-15 16:43 onnx-sharp/node.py
--rw-rw-rw-  2.0 fat     1718 b- defN 22-Jun-13 14:36 onnx-sharp/tensor.py
--rw-rw-rw-  2.0 fat      299 b- defN 22-Jun-21 11:07 onnxsharp/__init__.py
--rw-rw-rw-  2.0 fat      199 b- defN 22-Jun-13 14:35 onnxsharp/basics.py
--rw-rw-rw-  2.0 fat    17073 b- defN 22-Jun-21 11:02 onnxsharp/graph.py
--rw-rw-rw-  2.0 fat    20266 b- defN 22-Jun-21 11:28 onnxsharp/graph_utils.py
--rw-rw-rw-  2.0 fat     3332 b- defN 22-Jun-15 16:49 onnxsharp/model.py
--rw-rw-rw-  2.0 fat     9891 b- defN 22-Jun-21 11:28 onnxsharp/node.py
--rw-rw-rw-  2.0 fat     2202 b- defN 22-Jun-21 07:57 onnxsharp/tensor.py
--rw-rw-rw-  2.0 fat     1038 b- defN 22-Jun-21 12:22 onnxsharp-0.0.1.dist-info/LICENSE
--rw-rw-rw-  2.0 fat     1112 b- defN 22-Jun-21 12:22 onnxsharp-0.0.1.dist-info/METADATA
--rw-rw-rw-  2.0 fat      110 b- defN 22-Jun-21 12:22 onnxsharp-0.0.1.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       10 b- defN 22-Jun-21 12:22 onnxsharp-0.0.1.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     1391 b- defN 22-Jun-21 12:22 onnxsharp-0.0.1.dist-info/RECORD
-18 files, 95993 bytes uncompressed, 20643 bytes compressed:  78.5%
+Zip file size: 30939 bytes, number of entries: 23
+-rw-rw-rw-  2.0 fat      713 b- defN 23-Mar-09 10:06 onnxsharp/__init__.py
+-rw-rw-rw-  2.0 fat     1318 b- defN 23-Mar-09 09:40 onnxsharp/basics.py
+-rw-rw-rw-  2.0 fat    23928 b- defN 24-Mar-05 08:15 onnxsharp/graph.py
+-rw-rw-rw-  2.0 fat    27581 b- defN 23-Mar-09 10:06 onnxsharp/graph_utils.py
+-rw-rw-rw-  2.0 fat     4216 b- defN 24-Jan-11 09:08 onnxsharp/model.py
+-rw-rw-rw-  2.0 fat     8982 b- defN 24-Jan-12 01:33 onnxsharp/node.py
+-rw-rw-rw-  2.0 fat     1445 b- defN 23-Mar-09 07:19 onnxsharp/npy_utils.py
+-rw-rw-rw-  2.0 fat     1081 b- defN 22-Nov-17 11:36 onnxsharp/ort_utils.py
+-rw-rw-rw-  2.0 fat     8659 b- defN 22-Nov-09 05:54 onnxsharp/tensor.py
+-rw-rw-rw-  2.0 fat     2443 b- defN 23-Aug-25 02:11 onnxsharp/topy_sample.py
+-rw-rw-rw-  2.0 fat     3818 b- defN 23-Mar-09 07:19 onnxsharp/torch_utils.py
+-rw-rw-rw-  2.0 fat      462 b- defN 22-Nov-02 12:35 onnxsharp-0.0.2.data/scripts/ort_get_peak_details
+-rw-rw-rw-  2.0 fat     5491 b- defN 23-Mar-09 10:06 onnxsharp-0.0.2.data/scripts/ort_get_peak_op_summary
+-rw-rw-rw-  2.0 fat      237 b- defN 22-Nov-02 12:35 onnxsharp-0.0.2.data/scripts/ort_get_peak_step
+-rw-rw-rw-  2.0 fat      269 b- defN 22-Nov-02 12:35 onnxsharp-0.0.2.data/scripts/ort_get_peak_summary
+-rw-rw-rw-  2.0 fat     1911 b- defN 22-Nov-17 11:36 onnxsharp-0.0.2.data/scripts/ort_parse_output_name
+-rw-rw-rw-  2.0 fat     2436 b- defN 22-Nov-02 12:35 onnxsharp-0.0.2.data/scripts/ort_parse_peak_summary
+-rw-rw-rw-  2.0 fat      256 b- defN 22-Nov-17 11:36 onnxsharp-0.0.2.data/scripts/ort_scan_output_in_order
+-rw-rw-rw-  2.0 fat    11558 b- defN 24-Apr-16 04:55 onnxsharp-0.0.2.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat     1118 b- defN 24-Apr-16 04:55 onnxsharp-0.0.2.dist-info/METADATA
+-rw-rw-rw-  2.0 fat      110 b- defN 24-Apr-16 04:55 onnxsharp-0.0.2.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       10 b- defN 24-Apr-16 04:55 onnxsharp-0.0.2.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat     1999 b- defN 24-Apr-16 04:55 onnxsharp-0.0.2.dist-info/RECORD
+23 files, 110041 bytes uncompressed, 27675 bytes compressed:  74.9%
```

## zipnote {}

```diff
@@ -1,55 +1,70 @@
-Filename: onnx-sharp/__init__.py
+Filename: onnxsharp/__init__.py
 Comment: 
 
-Filename: onnx-sharp/basics.py
+Filename: onnxsharp/basics.py
 Comment: 
 
-Filename: onnx-sharp/graph.py
+Filename: onnxsharp/graph.py
 Comment: 
 
-Filename: onnx-sharp/model.py
+Filename: onnxsharp/graph_utils.py
 Comment: 
 
-Filename: onnx-sharp/node.py
+Filename: onnxsharp/model.py
 Comment: 
 
-Filename: onnx-sharp/tensor.py
+Filename: onnxsharp/node.py
 Comment: 
 
-Filename: onnxsharp/__init__.py
+Filename: onnxsharp/npy_utils.py
 Comment: 
 
-Filename: onnxsharp/basics.py
+Filename: onnxsharp/ort_utils.py
 Comment: 
 
-Filename: onnxsharp/graph.py
+Filename: onnxsharp/tensor.py
 Comment: 
 
-Filename: onnxsharp/graph_utils.py
+Filename: onnxsharp/topy_sample.py
 Comment: 
 
-Filename: onnxsharp/model.py
+Filename: onnxsharp/torch_utils.py
 Comment: 
 
-Filename: onnxsharp/node.py
+Filename: onnxsharp-0.0.2.data/scripts/ort_get_peak_details
 Comment: 
 
-Filename: onnxsharp/tensor.py
+Filename: onnxsharp-0.0.2.data/scripts/ort_get_peak_op_summary
+Comment: 
+
+Filename: onnxsharp-0.0.2.data/scripts/ort_get_peak_step
+Comment: 
+
+Filename: onnxsharp-0.0.2.data/scripts/ort_get_peak_summary
+Comment: 
+
+Filename: onnxsharp-0.0.2.data/scripts/ort_parse_output_name
+Comment: 
+
+Filename: onnxsharp-0.0.2.data/scripts/ort_parse_peak_summary
+Comment: 
+
+Filename: onnxsharp-0.0.2.data/scripts/ort_scan_output_in_order
 Comment: 
 
-Filename: onnxsharp-0.0.1.dist-info/LICENSE
+Filename: onnxsharp-0.0.2.dist-info/LICENSE
 Comment: 
 
-Filename: onnxsharp-0.0.1.dist-info/METADATA
+Filename: onnxsharp-0.0.2.dist-info/METADATA
 Comment: 
 
-Filename: onnxsharp-0.0.1.dist-info/WHEEL
+Filename: onnxsharp-0.0.2.dist-info/WHEEL
 Comment: 
 
-Filename: onnxsharp-0.0.1.dist-info/top_level.txt
+Filename: onnxsharp-0.0.2.dist-info/top_level.txt
 Comment: 
 
-Filename: onnxsharp-0.0.1.dist-info/RECORD
+Filename: onnxsharp-0.0.2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## onnxsharp/__init__.py

```diff
@@ -1,11 +1,25 @@
 from .graph import Graph
 from .node import NodeArg, Node, ValueInfo
 from .model import Model
 from .tensor import Tensor, TensorShape, TensorType
 
+from .basics import save_onnx_model_to_string, save_onnx_model
+
 from .graph_utils import (
     clip_subgraph_around,
     topological_sort,
     LogicalSubgraphInfo,
     create_graph_from_logical_subgraph,
+    fill_with_execution_plan,
+    bfs_from_output,
+    auto_cluster_pointwise_graphs,
+)
+
+
+from .npy_utils import npy_summurize_array
+from .torch_utils import (
+    dump_parameters_and_grads_before_step_start,
+    compare_parameters_and_grads,
+    DataObserver,
 )
+from .ort_utils import ort_scan_tensor_from_dump, ort_get_tensor_from_dump
```

## onnxsharp/basics.py

```diff
@@ -1,8 +1,52 @@
+import onnx, os
+
+
 def enforce(status, msg):
     if status is not True:
         raise RuntimeError("exception raised during execution: ", msg)
 
 
 class Type(object):
     def __init__(self) -> None:
         pass
+
+
+def save_onnx_model_to_string(model_proto, path):
+    if os.path.exists(path):
+        print(f"WARNING: File {path} already exists, will be overwritten.")
+
+    text_file = open(path, "w")
+    text_file.write(str(model_proto))
+    text_file.close()
+    print(f"Saved model serialized string to {path} successfully.")
+
+
+def save_onnx_model(
+    model_proto,
+    path,
+    save_as_external_data=True,
+    all_tensors_to_one_file=True,
+    location="filename",
+    size_threshold=1024,
+    convert_attribute=False,
+):
+
+    if os.path.exists(path):
+        print(
+            f"WARNING: {path} already exists, to make sure the written file is 100% usable,"
+            " suggest you to remove it manually."
+        )
+
+    onnx.save_model(
+        model_proto,
+        path,
+        save_as_external_data,
+        all_tensors_to_one_file,
+        location,
+        size_threshold,
+        convert_attribute,
+    )
+    print(
+        f"Saved model to {path} successfully."
+        + (f"External data location: {location}" if save_as_external_data else "")
+    )
```

## onnxsharp/graph.py

```diff
@@ -1,14 +1,17 @@
 from collections import OrderedDict
+from typing import List, Tuple
 from black import validate_cell
 import onnx
 from onnx import helper, defs, numpy_helper, checker
 import copy
+import numpy as np
+
+from .node import enforce, Node, NodeArg, ValueInfo, Attribute, AttributeType
 
-from .node import enforce, Node, NodeArg, ValueInfo
 from .tensor import TensorType, Tensor, TensorShape
 
 
 class Graph(object):
     def __init__(self) -> None:
         self._output_arg_name_to_node_mapping: OrderedDict[str, Node] = OrderedDict()
         self._node_name_mapping: OrderedDict[str, Node] = OrderedDict()
@@ -29,32 +32,32 @@
             g.update_node_mapping(n)
 
         # string name = 2;
         g._name = graph_proto.name
 
         # repeated TensorProto initializer = 5;
         for initializer in graph_proto.initializer:
-            g._initializer_map[initializer.name] = Tensor(initializer)
+            g._initializer_map[initializer.name] = Tensor.from_proto(initializer)
 
         # string doc_string = 10;
         g._doc_string = graph_proto.doc_string
 
-        # // The inputs and outputs of the graph.
+        # The inputs and outputs of the graph.
         # repeated ValueInfoProto input = 11;
         for value_info_proto in graph_proto.input:
             g._input_map[value_info_proto.name] = ValueInfo.from_proto(value_info_proto)
 
         # repeated ValueInfoProto output = 12;
         for value_info_proto in graph_proto.output:
             g._output_map[value_info_proto.name] = ValueInfo.from_proto(
                 value_info_proto
             )
 
-        # // Information for the values in the graph. The ValueInfoProto.name's
-        # // must be distinct. It is optional for a value to appear in value_info list.
+        # Information for the values in the graph. The ValueInfoProto.name's
+        # must be distinct. It is optional for a value to appear in value_info list.
         # repeated ValueInfoProto value_info = 13;
         value_info_map = OrderedDict()
         for value_info_proto in graph_proto.value_info:
             value_info_name = value_info_proto.name
             value_info_map[value_info_name] = ValueInfo.from_proto(value_info_proto)
 
         # Update input/output args according to available ValueInfos.
@@ -83,25 +86,28 @@
             # g.update_node_mapping(node)
 
         return g
 
     def update_node_mapping(self, new_node: Node):
         self._node_name_mapping[new_node.name] = new_node
         for index, o in enumerate(new_node.output_arg_names):
+            # Skip if the output arg is null.
+            if self.is_null(o):
+                continue
             self._output_arg_name_to_node_mapping[o] = (new_node, index)
 
     def get_tensor(self, output_arg_name: str) -> Tensor:
         enforce(output_arg_name is not None, "output_arg_name should not be None")
         enforce(
             output_arg_name in self._initializer_map,
             f"output_arg_name {output_arg_name} not exists",
         )
         return self._initializer_map[output_arg_name]
 
-    def get_node_with_output_arg_name(self, output_arg_name: str) -> tuple[Node, int]:
+    def get_node_with_output_arg_name(self, output_arg_name: str) -> Tuple[Node, int]:
         enforce(output_arg_name is not None, "output_arg_name should not be None")
         enforce(
             output_arg_name in self._output_arg_name_to_node_mapping,
             f"output_arg_name {output_arg_name} not exists",
         )
         return self._output_arg_name_to_node_mapping[output_arg_name]
 
@@ -234,15 +240,18 @@
 
         self._initializer_map[input_arg_name] = tensor
 
     # output_arg_name MUST be an activation before we make it a graph outputs.
     # Correspondingly, removing from graph outputs, it is still an activation.
     def add_output(self, output_arg_name, value_info: ValueInfo):
         enforce(value_info is not None, "value_info should not be None")
-        enforce(not self.is_null(output_arg_name), f"{output_arg_name} is null")
+        enforce(
+            not self.is_null(output_arg_name),
+            f"output arg name [{output_arg_name}] is null",
+        )
         enforce(
             not self.is_input(output_arg_name),
             f"{output_arg_name} already exists as input.",
         )
         enforce(
             not self.is_output(output_arg_name),
             f"{output_arg_name} already exists as output.",
@@ -303,16 +312,16 @@
         self.update_node_mapping(n)
         print(f"add_node_copy_from>>>exiting for node {n}.")
 
     def add_node(
         self,
         type: str,
         name: str,
-        input_arg_names: list[str],
-        output_arg_names: list[str],
+        input_arg_names: List[str],
+        output_arg_names: List[str],
         domain: str,
         doc_string: str,
         **kwargs,
     ):
         for input_arg_name in input_arg_names:
             enforce(
                 not self.is_output(input_arg_name),
@@ -393,16 +402,18 @@
         graph_proto = onnx.GraphProto()
 
         node_protos = []
         value_info_protos = []
         for name, node in self._node_name_mapping.items():
             node_protos.append(node.to_proto())
             for output_arg in node._output_args:
-                # todo: clean up this if
-                if output_arg._value_info is not None:
+                if (
+                    output_arg._value_info is not None
+                    and output_arg._value_info.has_type()
+                ):
                     value_info_protos.append(output_arg.to_proto())
         graph_proto.node.extend(node_protos)
 
         graph_proto.name = self._name
 
         initializer_protos = []
         for name, tensor in self._initializer_map.items():
@@ -432,7 +443,175 @@
             if c not in subgraph_nodes:
                 print(
                     f"found external node [{c.name}({c.type})], consuming output_arg {arg_name}"
                 )
                 return False
 
         return True
+
+    def summarize_inputs(self):
+        import pprint
+
+        pp = pprint.PrettyPrinter(indent=4)
+        pp.pprint(self._input_map)
+
+    def summarize_tensors(self):
+        import pprint
+
+        # https://en.wikipedia.org/wiki/Half-precision_floating-point_format
+
+        smallest_subnormal_number = 5.96e-8
+        smallest_normal_number = 6.10e-5
+        largest_norm_number = 65504
+
+        pp = pprint.PrettyPrinter(indent=4)
+        nan_tensor_names: OrderedDict[str, Tensor] = OrderedDict()
+        inf_tensor_names: OrderedDict[str, Tensor] = OrderedDict()
+
+        def _summarize_tensors(tensors_map):
+            for initializer_name, tensor in tensors_map:
+                if np.isnan(tensor.value).any():
+                    if initializer_name not in nan_tensor_names:
+                        nan_tensor_names[initializer_name] = tensor
+                    continue
+
+                if np.isinf(tensor.value).any():
+                    if initializer_name not in nan_tensor_names:
+                        inf_tensor_names[initializer_name] = tensor
+                    continue
+
+                subnormal_candidiates = np.logical_and(
+                    np.abs(tensor.value) > 0,
+                    np.abs(tensor.value) <= smallest_subnormal_number,
+                )
+                if subnormal_candidiates.any():
+                    to_print = tensor.value
+                    if tensor.value.ndim > 0:
+                        indices = np.where(subnormal_candidiates)
+                        to_print = tensor.value[indices]
+
+                    print(
+                        f"Warning: find a tensor {initializer_name} having subnormal number {to_print} around fp16 lower boundary."
+                    )
+
+                around_fp16_boundary = np.abs(tensor.value) >= largest_norm_number
+                if around_fp16_boundary.any():
+                    to_print = tensor.value
+                    if tensor.value.ndim > 0:
+                        indices = np.where(around_fp16_boundary)
+                        to_print = tensor.value[indices]
+
+                    print(
+                        f"Warning: find a tensor {initializer_name} having number {to_print} around fp16 upper boundary."
+                    )
+
+        _summarize_tensors(self._initializer_map.items())
+
+        constant_tensors: OrderedDict[str, Tensor] = OrderedDict()
+        for _, n in self._node_name_mapping.items():
+            if n.type == "Constant":
+                constant_tensors[n.output_arg_names[0]] = Tensor.from_proto(
+                    n._attr["value"].value
+                )
+
+        _summarize_tensors(constant_tensors.items())
+
+        if len(nan_tensor_names) == 0 and len(inf_tensor_names) == 0:
+            print("NaN or inf not found for all initializers.")
+        else:
+            print(
+                f"Found {len(nan_tensor_names)} initializers contains Nan. Be cautious used for training."
+            )
+
+            print(
+                f"Found {len(inf_tensor_names)} initializers contains Inf. Be cautious used for training."
+            )
+        # pp.pprint(self._initializer_map.items())
+
+    def summarize_nodes(
+        self, level=0, with_execution_plan=False, include_shape=False, op_type=None
+    ):
+        import pprint
+
+        pp = pprint.PrettyPrinter(indent=4)
+
+        def _get_primitive_attr_pattern(a: Attribute):
+            if a._type == AttributeType.FLOAT:
+                return f"{a._name}_F_{a._value}"
+            elif a._type == AttributeType.INT:
+                return f"{a._name}_I_{a._value}"
+            elif a._type == AttributeType.STRING:
+                return f"{a._name}_S_{a._value}"
+            elif a._type == AttributeType.FLOATS:
+                return f"{a._name}_FS_{a._value}"
+            elif a._type == AttributeType.INTS:
+                return f"{a._name}_IS_{a._value}"
+            elif a._type == AttributeType.STRINGS:
+                return f"{a._name}_SS_{a._value}"
+            else:
+                return ""
+
+        def _get_node_pattern(n: Node, cur_level):
+            optypestr_list = []
+            if cur_level < level:
+                for i in n.input_arg_names:
+                    if not self.is_activation(i):
+                        continue
+
+                    p_node, _ = self.get_node_with_output_arg_name(i)
+                    node_str = _get_node_pattern(p_node, cur_level + 1)
+                    optypestr_list.append(node_str)
+
+            types_str = "(" + ",".join(optypestr_list) + ")" if optypestr_list else ""
+            execution_str = (
+                "@" + str(n._ort_program_counter)
+                if with_execution_plan is True and n._ort_program_counter is not None
+                else ""
+            )
+            bw_str = ""  # attribute contains backward pass information
+
+            shape_str = ""
+            if include_shape is True:
+                all_input_shape_str = ",".join(
+                    [
+                        (
+                            "(" + ",".join([str(s) for s in node_input_arg.shape]) + ")"
+                            if node_input_arg.shape
+                            else "None"
+                        )
+                        for node_input_arg in n._input_args
+                    ]
+                )
+                shape_str = f"<-[{all_input_shape_str}]"
+
+            attribute_str = "_" + ",".join(
+                [
+                    _get_primitive_attr_pattern(attr)
+                    for _, attr in n._attr.items()
+                    if n._type not in ["PythonOp", "PythonOpGrad"]
+                ]
+            )
+
+            return (
+                f"{n.type}{attribute_str}{bw_str}{execution_str}{types_str}{shape_str}"
+            )
+
+        op_type_str_summary: OrderedDict[str, int] = OrderedDict()
+        for name, node in self._node_name_mapping.items():
+            if op_type is not None and op_type != node.type:
+                continue
+
+            pattern_str = _get_node_pattern(node, 0)
+
+            if pattern_str not in op_type_str_summary:
+                op_type_str_summary[pattern_str] = 0
+
+            op_type_str_summary[pattern_str] += 1
+
+        sorted_tuples = sorted(
+            op_type_str_summary.items(), key=lambda item: item[1], reverse=True
+        )
+
+        print(f"## {level} levels of node summary:")
+        pp.pprint(sorted_tuples)
+
+        return
```

## onnxsharp/graph_utils.py

```diff
@@ -1,14 +1,15 @@
-from typing import OrderedDict
+from typing import List, OrderedDict
 from onnxsharp import Model, Graph, Node, ValueInfo, NodeArg
 from .basics import enforce
 import copy
+import re
 
 
-def topological_sort(graph, ops: list[Node]) -> list[Node]:
+def topological_sort(graph, ops: List[Node]) -> List[Node]:
     """Topological sort of graph."""
     # sort by name, the result will be reversed alphabeta
     ops.sort(key=lambda op: op.name)
 
     def _push_stack(stack, node, in_stack):
         stack.append(node)
         if node in in_stack:
@@ -487,39 +488,29 @@
 
     for subgraph_initializer in updated_removable_subgraph_initializers:
         g.remove_initializer(subgraph_initializer)
 
     print("safe_remove_subgraph - successfully remove the subgraph.")
 
 
-def clip_subgraph_around(g: Graph, output_arg_name):
-    print(f"clip_subgraph_around>> output_arg_name: {output_arg_name}")
-    g_nodes = []
-    n, index = g.get_node_with_output_arg_name(output_arg_name)
-    print(f"{n.output_arg(index)}")
-    for index, input_arg_name in enumerate(n.input_arg_names):
-        if g.is_activation(input_arg_name):
-            n_, index_ = g.get_node_with_output_arg_name(input_arg_name)
-            g_nodes.append(n_)
-
-    g_nodes.append(n)
-    n_consumers = g.get_consumer_nodes(output_arg_name)
-    g_nodes.extend(n_consumers)
-
+def _create_graph_from_nodes(g: Graph, g_nodes: List[Node]):
+    # remove duplications
+    g_nodes = list(set(g_nodes))
     updated_node_list = topological_sort(g, g_nodes)
 
     print("updated_node_list: ", updated_node_list)
 
     # so far, g_nodes contains 3 level of nodes.
 
     # Collect all graph-level inputs and initializers.
     new_g = Graph()
     new_g._name = g._name
     new_g._doc_string = g._doc_string
 
+    activation_outs = []
     for n in updated_node_list:
         for index, input_arg_name in enumerate(n.input_arg_names):
             if g.is_input(input_arg_name) and not new_g.is_input(input_arg_name):
                 new_g.add_input(
                     input_arg_name, copy.deepcopy(n.input_arg(index)._value_info)
                 )
 
@@ -535,8 +526,245 @@
 
         for index, output_arg_name in enumerate(n.output_arg_names):
             if g.is_output(output_arg_name) and not new_g.is_output(output_arg_name):
                 new_g.add_output(
                     output_arg_name, copy.deepcopy(n.output_arg(index)._value_info)
                 )
 
+            if g.is_activation(output_arg_name):
+                activation_outs.append([output_arg_name, n.output_arg(index)])
+
+    for output_arg_name, output_arg in activation_outs:
+        if new_g.is_output(output_arg_name):
+            continue
+
+        new_g.add_output(
+            f"{output_arg_name}",
+            copy.deepcopy(output_arg._value_info),
+        )
+
     return new_g
+
+
+def clip_subgraph_around(g: Graph, output_arg_name):
+    print(f"clip_subgraph_around>> output_arg_name: {output_arg_name}")
+    g_nodes = []
+
+    if g.is_null(output_arg_name):
+        raise RuntimeError("output_arg_name is null.")
+
+    if g.is_initializer(output_arg_name):
+        raise RuntimeError("output_arg_name is an initializer, stop searching.")
+
+    if g.is_input(output_arg_name):
+        raise RuntimeError("output_arg_name is an input, stop searching.")
+
+    n, index = g.get_node_with_output_arg_name(output_arg_name)
+    print(f"{n.output_arg(index)}")
+
+    input_level = 3
+    cur_level_nodes = [n]
+    for i in range(input_level):
+        next_level_nodes = []
+        for cur_n in set(cur_level_nodes):
+            for index, input_arg_name in enumerate(cur_n.input_arg_names):
+                if g.is_activation(input_arg_name):
+                    n_, index_ = g.get_node_with_output_arg_name(input_arg_name)
+                    g_nodes.append(n_)
+                    next_level_nodes.append(n_)
+
+        cur_level_nodes = next_level_nodes
+
+    g_nodes.append(n)
+
+    n_consumers = g.get_consumer_nodes(output_arg_name)
+    output_level = 3
+    cur_level_nodes = [n]
+    for i in range(output_level):
+        next_level_nodes = []
+        for cur_n in set(cur_level_nodes):
+            for index, output_arg_name in enumerate(cur_n.output_arg_names):
+                if g.is_activation(output_arg_name):
+                    n_consumers = g.get_consumer_nodes(output_arg_name)
+                    next_level_nodes.extend(n_consumers)
+                    g_nodes.extend(n_consumers)
+
+        cur_level_nodes = next_level_nodes
+
+    return _create_graph_from_nodes(g, g_nodes)
+
+
+def fill_with_execution_plan(g: Graph, file_name):
+    # [6] Mul (Mul_17)
+    # Free ml-values: (550) onnx::Mul_564
+    # Free ml-values: (4971) onnx::Unsqueeze_8287, (4974) onnx::Unsqueeze_8290, (4978) per_input_length_token_715
+
+    # \S: non whiltespace character
+    execution_regex = "\[([0-9]+)\] ([\S]+) \(([\S]+)\)"
+    free_regex = "Free ml-values: \(([\S]+)\) ([\S]+)"
+
+    with open(file_name) as f:
+        for line in f:
+            match = re.match(execution_regex, line)
+            if match:
+                program_counter = int(match.group(1))
+                node_type = str(match.group(2))
+                node_name = str(match.group(3))
+                node = g.get_node_with_name(node_name)
+
+                enforce(node_type == node.type, f"Op type should match for node {node}")
+                node._ort_program_counter = program_counter
+
+                continue
+            else:
+                match = re.match(free_regex, line)
+                if match:
+                    ortvalue_idx = int(match.group(1))
+                    output_arg_name = str(match.group(2))
+                    # So far, looks this is not useful
+                    continue
+                else:
+                    print("warning: the line is not parsed correctly ", line)
+
+
+tag = 0
+has_update = False
+
+
+def auto_cluster_pointwise_graphs(g: Graph):
+    global tag
+    global has_update
+    elementwise_operators = [
+        "Abs",
+        "Acos",
+        "Acosh",
+        "Add",
+        "And",
+        "BiasGelu",
+        "Cast",
+        "Clip",
+        "ConstantOfShape",
+        "Div",
+        "Equal",
+        "Erf",
+        "Exp",
+        "Greater",
+        "Gelu",
+        "GeluGrad",
+        "Less",
+        "Log",
+        "MemcpyFromHost",
+        "MemcpyToHost",
+        "Max",
+        "Min",
+        "Mul",
+        "Neg",
+        "Not",
+        "Pow",
+        "Range",
+        "Reshape",
+        "Scale",
+        "Shape",
+        "Sigmoid",
+        "SigmoidGrad",
+        "Sqrt",
+        "Squeeze",
+        "Sub",
+        "Unsqueeze",
+        "Where",
+    ]
+
+    node_name_to_tag = {}
+
+    def initialize_node_tag(node: Node):
+        global tag
+        node_name_to_tag[node.name] = tag
+        tag += 1
+
+    def update_flag(old_flag, new_flag):
+        has_update = False
+        for node_name in node_name_to_tag:
+            if node_name_to_tag[node_name] == old_flag:
+                node_name_to_tag[node_name] = new_flag
+                has_update = True
+        return has_update
+
+    g.iterate_node(initialize_node_tag)
+
+    has_update = True
+    while has_update:
+        has_update = False
+
+        def initialize_node_tag(node: Node):
+            global has_update
+            if node.type in elementwise_operators:
+                # update self's other parents use the same tag.
+                # while idx < len(extensible_input_idxs):
+                for idx in range(len(node.input_arg_names)):
+                    input_arg_name = node.input_arg_names[idx]
+                    if g.is_activation(input_arg_name):
+                        p_node, _ = g.get_node_with_output_arg_name(
+                            node.input_arg_names[idx]
+                        )
+                        if (
+                            p_node.type in elementwise_operators
+                            and node_name_to_tag[p_node.name]
+                            != node_name_to_tag[node.name]
+                        ):
+                            has_update = update_flag(
+                                node_name_to_tag[p_node.name],
+                                node_name_to_tag[node.name],
+                            )
+
+        g.iterate_node(initialize_node_tag)
+
+    inversed_map = OrderedDict()
+    for name, tag in node_name_to_tag.items():
+        if tag not in inversed_map:
+            inversed_map[tag] = []
+
+        inversed_map[tag].append(g.get_node_with_name(name))
+        print(
+            f"append node name {name} into tag {tag}, count become: {len(inversed_map[tag])}"
+        )
+
+    g_to_return = OrderedDict()
+    for k, v in inversed_map.items():
+        if len(v) >= 2:
+            print(f"find candidate subgraph with tag: {k}, node count: {len(v)}")
+            # subgraphs.append(_create_graph_from_nodes(g, v))
+
+            subgraph_unique_id = unique_id_str(g, v)
+            if subgraph_unique_id not in g_to_return:
+                g_to_return[subgraph_unique_id] = [
+                    _create_graph_from_nodes(g, v),
+                    len(v),
+                    1,
+                ]
+            else:
+                g_to_return[subgraph_unique_id][2] += 1
+
+    print(f"Find {len(g_to_return)} unique sub graphs.")
+    return g_to_return
+
+
+def unique_id_str(g: Graph, g_nodes: List[Node]):
+    g_nodes = list(set(g_nodes))
+    sorted_nodes = topological_sort(g, g_nodes)
+
+    unique_id_str = ""
+    for n in sorted_nodes:
+        input_shapes = []
+        for i in range(len(n.input_arg_names)):
+            input_shapes.append(str(n.input_arg(i).shape))
+
+        input_shapes_str = ",".join(input_shapes)
+
+        output_shapes = []
+        for i in range(len(n.output_arg_names)):
+            output_shapes.append(str(n.output_arg(i).shape))
+
+        output_shapes_str = ",".join(output_shapes)
+
+        unique_id_str += f"{len(n.input_arg_names)}.[{input_shapes_str}].{n.type}.{len(n.output_arg_names)}.[{output_shapes_str}]"
+
+    return unique_id_str
```

## onnxsharp/model.py

```diff
@@ -100,7 +100,38 @@
 
         if self._doc_string:
             kwargs["doc_string"] = self._doc_string
 
         model_proto = helper.make_model(self._graph.to_proto(), **kwargs)
         model_proto.metadata_props.extend(self._metadata_props)
         return model_proto
+
+    @classmethod
+    def load_model(cls, path, load_external_data=True):
+        model_proto = onnx.load(path, load_external_data=load_external_data)
+        return Model.from_proto(model_proto)
+
+    def save_model(
+        self,
+        path,
+        save_as_external_data=False,
+        all_tensors_to_one_file=True,
+        location="filename",
+        size_threshold=1024,
+        convert_attribute=False,
+    ):
+        from .basics import save_onnx_model
+
+        save_onnx_model(
+            self.to_proto(),
+            path,
+            save_as_external_data,
+            all_tensors_to_one_file,
+            location,
+            size_threshold,
+            convert_attribute,
+        )
+
+    def save_model_to_string(self, path):
+        from .basics import save_onnx_model_to_string
+
+        save_onnx_model_to_string(self.to_proto(), path)
```

## onnxsharp/node.py

```diff
@@ -1,14 +1,15 @@
 from collections import OrderedDict
+from typing import List
 from black import validate_cell
 import onnx
 from onnx import helper, defs, numpy_helper, checker
 import copy
 
-from .tensor import TensorType, enforce
+from .tensor import TensorType, enforce, Tensor
 
 
 class ValueInfo(object):
     def __init__(self) -> None:
         self._name = None
         self._type = None
         self._doc_string = None
@@ -23,22 +24,26 @@
         type_proto = value_info_proto.type
         if type_proto.HasField("tensor_type"):
             v._type = TensorType(type_proto.tensor_type)
         else:
             raise NotImplementedError("unsupported type")
 
         # string doc_string = 3;
-        v._doc_string = value_info_proto.doc_string
+        if value_info_proto.HasField("doc_string"):
+            v._doc_string = value_info_proto.doc_string
 
         return v
 
     @property
     def name(self):
         return self._name
 
+    def has_type(self):
+        return self._type is not None
+
     def set_name(self, new_name):
         self._name = new_name
 
     def to_proto(self):
         value_info_proto = onnx.ValueInfoProto()
         value_info_proto.name = self._name
         if self._type is not None:
@@ -97,15 +102,16 @@
         if a._type == AttributeType.FLOAT:
             a._value = attribute_proto.f
         elif a._type == AttributeType.INT:
             a._value = attribute_proto.i
         elif a._type == AttributeType.STRING:
             a._value = attribute_proto.s
         elif a._type == AttributeType.TENSOR:
-            a._value = attribute_proto.t
+            tensor_proto_val = attribute_proto.t
+            a._value = Tensor.from_proto(tensor_proto_val)
         elif a._type == AttributeType.GRAPH:
             a._value = attribute_proto.g
         elif a._type == AttributeType.SPARSE_TENSOR:
             a._value = attribute_proto.sparse_tensor
         elif a._type == AttributeType.TYPE_PROTO:
             a._value = attribute_proto.tp
         elif a._type == AttributeType.FLOATS:
@@ -122,43 +128,19 @@
             a._value = attribute_proto.sparse_tensors
         elif a._type == AttributeType.TYPE_PROTO:
             a._value = attribute_proto.type_protos
 
         return a
 
     def to_proto(self):
-        attr_proto = onnx.AttributeProto()
-        if self._type == AttributeType.FLOAT:
-            attr_proto.f = self._value
-        elif self._type == AttributeType.INT:
-            attr_proto.i = self._value
-        elif self._type == AttributeType.STRING:
-            attr_proto.s = self._value
-        elif self._type == AttributeType.TENSOR:
-            attr_proto.t = self._value.to_proto()
-        elif self._type == AttributeType.GRAPH:
-            attr_proto.g = self._value.to_proto()
-        elif self._type == AttributeType.SPARSE_TENSOR:
-            attr_proto.sparse_tensor = self._value.to_proto()
-        elif self._type == AttributeType.TYPE_PROTO:
-            attr_proto.tp = self._value.to_proto()
-        elif self._type == AttributeType.FLOATS:
-            attr_proto.floats.extend(v for v in self._value)
-        elif self._type == AttributeType.INTS:
-            attr_proto.ints.extend(v for v in self._value)
-        elif self._type == AttributeType.STRINGS:
-            attr_proto.strings.extend(v for v in self._value)
-        elif self._type == AttributeType.TENSORS:
-            attr_proto.tensors.extend(v.to_proto() for v in self._value)
-        elif self._type == AttributeType.GRAPHS:
-            attr_proto.graphs.extend(v.to_proto() for v in self._value)
-        elif self._type == AttributeType.SPARSE_TENSORS:
-            attr_proto.sparse_tensors.extend(v.to_proto() for v in self._value)
-        elif self._type == AttributeType.TYPE_PROTO:
-            attr_proto.type_protos.extend(v.to_proto() for v in self._value)
+        value = self._value
+        if self._type == AttributeType.TENSOR:
+            value = self._value.to_proto()
+
+        return helper.make_attribute(self._name, value)
 
 
 class NodeArg(object):
     def __init__(self, name) -> None:
         self._name = name
 
         v = ValueInfo()
@@ -172,14 +154,20 @@
         instance._value_info = value_info
         return instance
 
     @property
     def name(self):
         return self._name
 
+    @property
+    def shape(self):
+        if not hasattr(self._value_info, "_type") or self._value_info._type is None:
+            return None
+        return self._value_info._type._shape._dim
+
     def update(self, value_info):
         self._value_info = value_info
 
     def to_proto(self):
         return self._value_info.to_proto()
 
     def __str__(self) -> str:
@@ -188,14 +176,17 @@
     def __repr__(self) -> str:
         return str(self)
 
 
 class Node(object):
     def __init__(self) -> None:
         self._g = None
+
+        ## ONNX Proto
+
         # self._node_proto = None
 
         # string name = 3;
         self._name = None
 
         # string op_type = 4;
         self._type = None
@@ -206,19 +197,23 @@
         # repeated string output = 2;
         self._output_args: list[NodeArg] = []
 
         # string domain = 7;
         self._domain = None
 
         # repeated AttributeProto attribute = 5;
-        self._attr = OrderedDict()
+        self._attr: OrderedDict[str, Attribute] = OrderedDict()
 
         # string doc_string = 6;
         self._doc_string = None
 
+        ## ONNXRuntime specific.
+
+        self._ort_program_counter = None
+
     @classmethod
     def from_proto(self, graph, node_proto):
         n = Node()
 
         n._g = graph
         # n._node_proto = node_proto
         n._name = node_proto.name if node_proto.HasField("name") else None
@@ -266,49 +261,46 @@
         return self._name
 
     @property
     def type(self):
         return self._type
 
     @property
-    def output_arg_names(self) -> list[str]:
+    def output_arg_names(self) -> List[str]:
         return [arg.name for arg in self._output_args]
 
     def output_arg(self, index):
         enforce(
             index is not None and index >= 0 and index < len(self._output_args),
             "index out of range",
         )
         return self._output_args[index]
 
     @property
-    def input_arg_names(self) -> list[str]:
+    def input_arg_names(self) -> List[str]:
         return [arg.name for arg in self._input_args]
 
     def input_arg(self, index):
         enforce(
             index is not None and index >= 0 and index < len(self._input_args),
             "index out of range",
         )
         return self._input_args[index]
 
     def to_proto(self):
-        attribute_protos = {
-            attr_name: a.to_proto()
-            for attr_name, a in self._attr.items()
-            if attr_name != "name"
-        }
         node_proto = helper.make_node(
             self._type,
             self.input_arg_names,
             self.output_arg_names,
             name=self._name,
             doc_string=self._doc_string,
             domain=self._domain,
-            **attribute_protos,
+        )
+        node_proto.attribute.extend(
+            a.to_proto() for attr_name, a in self._attr.items() if attr_name != "name"
         )
         return node_proto
 
     def __str__(self):
         return f"Node: name - {self._name}, type - {self.type}, inputs - {self.input_arg_names}, outputs - {self.output_arg_names}"
 
     def __repr__(self):
```

## onnxsharp/tensor.py

```diff
@@ -1,14 +1,15 @@
 from collections import OrderedDict
 from black import validate_cell
 import onnx
-from onnx import helper, defs, numpy_helper, checker
+from onnx import helper, defs, numpy_helper, checker, onnx_pb
 import copy
 from .basics import enforce, Type
-
+from onnx.numpy_helper import to_array, from_array
+import numpy as np
 
 class TensorShape(object):
     def __init__(self, tensor_shape_proto) -> None:
         self._dim = []
         for dim_proto in tensor_shape_proto.dim:
             if dim_proto.HasField("dim_param"):
                 self._dim.append(dim_proto.dim_param)
@@ -59,12 +60,201 @@
     def __repr__(self) -> str:
         return str(self)
 
 
 class Tensor(object):
     """// A serialized tensor value."""
 
-    def __init__(self, tensor_proto) -> None:
-        self._tensor_proto = tensor_proto
+    def __init__(self):
+        self._dims = None
+        self._data_type = None
+        self._name = None
+
+        self._raw_value = None
+        self._float_data = None
+        self._int32_data = None
+        self._int64_data = None
+        self._uint64_data = None
+        self._double_data = None
+        self._string_data = None
+
+    @classmethod
+    def from_proto(self, tensor_proto):
+        t = Tensor()
+
+        ## The shape of the tensor.
+        # repeated int64 dims = 1;
+        # if tensor_proto.HasField("dim"):
+        t._dims = [int(dim_value) for dim_value in tensor_proto.dims]
+
+        # optional int32 data_type = 2;
+        t._data_type = tensor_proto.data_type
+
+        # onnx_pb.TensorProto.FLOAT: np.float32,
+        # onnx_pb.TensorProto.FLOAT16: np.float16,
+        # onnx_pb.TensorProto.DOUBLE: np.float64,
+        # onnx_pb.TensorProto.INT32: np.int32,
+        # onnx_pb.TensorProto.INT16: np.int16,
+        # onnx_pb.TensorProto.INT8: np.int8,
+        # onnx_pb.TensorProto.UINT8: np.uint8,
+        # onnx_pb.TensorProto.UINT16: np.uint16,
+        # onnx_pb.TensorProto.UINT32: np.uint32,
+        # onnx_pb.TensorProto.UINT64: np.uint64,
+        # onnx_pb.TensorProto.INT64: np.int64,
+        # onnx_pb.TensorProto.UINT64: np.uint64,
+        # onnx_pb.TensorProto.BOOL: np.bool,
+        # onnx_pb.TensorProto.COMPLEX64: np.complex64,
+        # onnx_pb.TensorProto.COMPLEX128: np.complex128,
+        # onnx_pb.TensorProto.STRING: np.object,
+
+        # repeated float float_data = 4 [packed = true];
+
+        # repeated int32 int32_data = 5 [packed = true];
+
+        # repeated bytes string_data = 6;
+
+        # repeated int64 int64_data = 7 [packed = true];
+
+        # optional string name = 8; // namespace Value
+        t._name = tensor_proto.name if tensor_proto.HasField("name") else None
+
+        # optional string doc_string = 12;
+
+        # optional bytes raw_data = 9;
+
+        # repeated StringStringEntryProto external_data = 13;
+
+        # optional DataLocation data_location = 14;
+
+        # repeated double double_data = 10 [packed = true];
+
+        # repeated uint64 uint64_data = 11 [packed = true];
+
+        if tensor_proto.HasField("raw_data"):
+            # print("raw_data found for tensorproto.name", tensor_proto.name)
+            t._raw_value = numpy_helper.to_array(tensor_proto)
+            return t
+
+        if tensor_proto.data_type in [
+            onnx_pb.TensorProto.FLOAT,
+            onnx_pb.TensorProto.COMPLEX64,
+        ]:
+            t._float_data = np.array([f for f in tensor_proto.float_data], dtype=np.float32)
+
+        if tensor_proto.data_type in [
+            onnx_pb.TensorProto.FLOAT16,
+            onnx_pb.TensorProto.BFLOAT16,
+            onnx_pb.TensorProto.BOOL,
+            onnx_pb.TensorProto.INT8,
+            onnx_pb.TensorProto.INT16,
+            onnx_pb.TensorProto.INT32,
+            onnx_pb.TensorProto.UINT8,
+            onnx_pb.TensorProto.UINT16,
+        ]:
+            t._int32_data = np.array([i for i in tensor_proto.int32_data], dtype=np.int32)
+
+        if tensor_proto.data_type in [
+            onnx_pb.TensorProto.INT64,
+        ]:
+            t._int64_data = np.array([i for i in tensor_proto.int64_data], dtype=np.int64)
+
+        if tensor_proto.data_type in [
+            onnx_pb.TensorProto.UINT32,
+            onnx_pb.TensorProto.UINT64,
+        ]:
+            t._uint64_data = np.array([i for i in tensor_proto.uint64_data], dtype=np.uint64)
+
+        if tensor_proto.data_type in [
+            onnx_pb.TensorProto.DOUBLE,
+            onnx_pb.TensorProto.COMPLEX128,
+        ]:
+            t._double_data = np.array([i for i in tensor_proto.double_data], dtype=np.float64)
+
+        if tensor_proto.data_type in [
+            onnx_pb.TensorProto.STRING,
+        ]:
+            t._string_data = np.array([i for i in tensor_proto.string_data], dtype=np.object)
+
+        return t
+
+    @property
+    def value(self):
+
+        if self._float_data is not None:
+            return self._float_data
+
+        if self._int32_data is not None:
+            return self._int32_data
+
+        if self._int64_data is not None:
+            return self._int64_data
+
+        if self._uint64_data is not None:
+            return self._uint64_data
+
+        if self._double_data is not None:
+            return self._double_data
+
+        if self._string_data is not None:
+            return self._string_data
+
+        if self._raw_value is not None:
+            return self._raw_value
 
     def to_proto(self):
-        return self._tensor_proto
+        if self._raw_value is not None:
+            return numpy_helper.from_array(self._raw_value, name=self._name)
+
+        tensor_proto = onnx.TensorProto()
+        if self._data_type in [
+            onnx_pb.TensorProto.FLOAT,
+            onnx_pb.TensorProto.COMPLEX64,
+        ]:
+            tensor_proto.float_data.extend(self._float_data.tolist())
+
+        if self._data_type in [
+            onnx_pb.TensorProto.FLOAT16,
+            onnx_pb.TensorProto.BFLOAT16,
+            onnx_pb.TensorProto.BOOL,
+            onnx_pb.TensorProto.INT8,
+            onnx_pb.TensorProto.INT16,
+            onnx_pb.TensorProto.INT32,
+            onnx_pb.TensorProto.UINT8,
+            onnx_pb.TensorProto.UINT16,
+        ]:
+            tensor_proto.int32_data.extend(self._int32_data.tolist())
+
+        if self._data_type in [
+            onnx_pb.TensorProto.INT64,
+        ]:
+            tensor_proto.int64_data.extend(self._int64_data.tolist())
+
+        if self._data_type in [
+            onnx_pb.TensorProto.UINT32,
+            onnx_pb.TensorProto.UINT64,
+        ]:
+            tensor_proto.uint64_data.extend(self._uint64_data.tolist())
+
+        if self._data_type in [
+            onnx_pb.TensorProto.DOUBLE,
+            onnx_pb.TensorProto.COMPLEX128,
+        ]:
+            tensor_proto.double_data.extend(self._double_data.tolist())
+
+        if self._data_type in [
+            onnx_pb.TensorProto.STRING,
+        ]:
+            tensor_proto.string_data.extend(self._string_data.tolist())
+
+        tensor_proto.dims.extend(self._dims)
+        tensor_proto.data_type = self._data_type
+
+        if self._name:
+            tensor_proto.name = self._name
+
+        return tensor_proto
+
+    def __str__(self):
+        return f"Tensor: name - {self._name}, type - {self._data_type}, dims - {self._dims}"
+
+    def __repr__(self):
+        return str(self)
```

## Comparing `onnxsharp-0.0.1.dist-info/METADATA` & `onnxsharp-0.0.2.dist-info/METADATA`

 * *Files 10% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 Metadata-Version: 2.1
 Name: onnxsharp
-Version: 0.0.1
+Version: 0.0.2
 Summary: ONNX Sharp
 Home-page: https://github.com/xuyus/onnx-sharp
 Author: xuyus
-Author-email: teams@xuyus.com
+Author-email: 
 License: Apache License v2.0
 Platform: UNKNOWN
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Intended Audience :: Developers
 Classifier: Intended Audience :: Education
 Classifier: Intended Audience :: Science/Research
 Classifier: Topic :: Scientific/Engineering
@@ -22,10 +22,11 @@
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 License-File: LICENSE
 Requires-Dist: numpy (>=1.14.1)
 Requires-Dist: onnx (>=1.4.1)
 Requires-Dist: pytest
+Requires-Dist: black
 
 UNKNOWN
```

