# Comparing `tmp/datarobot_model_metrics-0.5.4-py2.py3-none-any.whl.zip` & `tmp/datarobot_model_metrics-0.5.5-py2.py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,34 +1,34 @@
-Zip file size: 56045 bytes, number of entries: 32
--rw-r--r--  2.0 unx      637 b- defN 24-Apr-04 06:39 dmm/__init__.py
--rw-r--r--  2.0 unx    10115 b- defN 24-Apr-04 06:39 dmm/batch_metric_evaluator.py
--rw-r--r--  2.0 unx     2123 b- defN 24-Apr-04 06:39 dmm/constants.py
--rw-r--r--  2.0 unx     8062 b- defN 24-Apr-04 06:39 dmm/custom_metric.py
--rw-r--r--  2.0 unx    16633 b- defN 24-Apr-04 06:39 dmm/datarobot_api_client.py
--rw-r--r--  2.0 unx     7206 b- defN 24-Apr-04 06:52 dmm/example_data_helper.py
--rw-r--r--  2.0 unx      545 b- defN 24-Apr-04 06:39 dmm/exceptions.py
--rw-r--r--  2.0 unx    18191 b- defN 24-Apr-04 06:39 dmm/metric_evaluator.py
--rw-r--r--  2.0 unx     3680 b- defN 24-Apr-04 06:39 dmm/time_bucket.py
--rw-r--r--  2.0 unx     4016 b- defN 24-Apr-04 06:39 dmm/utils.py
--rw-r--r--  2.0 unx      980 b- defN 24-Apr-04 06:39 dmm/data_source/__init__.py
--rw-r--r--  2.0 unx     2348 b- defN 24-Apr-04 06:39 dmm/data_source/data_source_base.py
--rw-r--r--  2.0 unx     3161 b- defN 24-Apr-04 06:52 dmm/data_source/dataframe_source.py
--rw-r--r--  2.0 unx    59608 b- defN 24-Apr-04 06:39 dmm/data_source/datarobot_source.py
--rw-r--r--  2.0 unx     3255 b- defN 24-Apr-04 06:39 dmm/data_source/generator_source.py
--rw-r--r--  2.0 unx     1515 b- defN 24-Apr-04 06:39 dmm/data_source/runtime_parameters_source.py
--rw-r--r--  2.0 unx      252 b- defN 24-Apr-04 06:39 dmm/data_source/datarobot/__init__.py
--rw-r--r--  2.0 unx     5434 b- defN 24-Apr-04 06:39 dmm/data_source/datarobot/deployment.py
--rw-r--r--  2.0 unx     5495 b- defN 24-Apr-04 06:39 dmm/data_source/datarobot/export_provider.py
--rw-r--r--  2.0 unx      428 b- defN 24-Apr-04 06:39 dmm/dr_custom_metrics/__init__.py
--rw-r--r--  2.0 unx     1667 b- defN 24-Apr-04 06:39 dmm/dr_custom_metrics/deployment_event_reporter.py
--rw-r--r--  2.0 unx     8764 b- defN 24-Apr-04 06:39 dmm/dr_custom_metrics/dr_custom_metric.py
--rw-r--r--  2.0 unx      711 b- defN 24-Apr-04 06:39 dmm/metric/__init__.py
--rw-r--r--  2.0 unx     1872 b- defN 24-Apr-04 06:39 dmm/metric/asymmetric_error.py
--rw-r--r--  2.0 unx      572 b- defN 24-Apr-04 06:39 dmm/metric/median_absolute_error.py
--rw-r--r--  2.0 unx     4424 b- defN 24-Apr-04 06:39 dmm/metric/metric_base.py
--rw-r--r--  2.0 unx     1209 b- defN 24-Apr-04 06:39 dmm/metric/missing_values.py
--rw-r--r--  2.0 unx     2302 b- defN 24-Apr-04 06:39 dmm/metric/sklearn_metric.py
--rw-r--r--  2.0 unx    40827 b- defN 24-Apr-04 06:54 datarobot_model_metrics-0.5.4.dist-info/METADATA
--rw-r--r--  2.0 unx      110 b- defN 24-Apr-04 06:54 datarobot_model_metrics-0.5.4.dist-info/WHEEL
--rw-r--r--  2.0 unx        4 b- defN 24-Apr-04 06:54 datarobot_model_metrics-0.5.4.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     2782 b- defN 24-Apr-04 06:54 datarobot_model_metrics-0.5.4.dist-info/RECORD
-32 files, 218928 bytes uncompressed, 51555 bytes compressed:  76.5%
+Zip file size: 56765 bytes, number of entries: 32
+-rw-r--r--  2.0 unx      637 b- defN 24-Apr-16 06:41 dmm/__init__.py
+-rw-r--r--  2.0 unx    10115 b- defN 24-Apr-16 06:41 dmm/batch_metric_evaluator.py
+-rw-r--r--  2.0 unx     2123 b- defN 24-Apr-16 06:41 dmm/constants.py
+-rw-r--r--  2.0 unx    10806 b- defN 24-Apr-16 06:41 dmm/custom_metric.py
+-rw-r--r--  2.0 unx    16633 b- defN 24-Apr-16 06:41 dmm/datarobot_api_client.py
+-rw-r--r--  2.0 unx     7206 b- defN 24-Apr-16 06:41 dmm/example_data_helper.py
+-rw-r--r--  2.0 unx      545 b- defN 24-Apr-16 06:41 dmm/exceptions.py
+-rw-r--r--  2.0 unx    18191 b- defN 24-Apr-16 06:41 dmm/metric_evaluator.py
+-rw-r--r--  2.0 unx     3680 b- defN 24-Apr-16 06:41 dmm/time_bucket.py
+-rw-r--r--  2.0 unx     4201 b- defN 24-Apr-16 06:41 dmm/utils.py
+-rw-r--r--  2.0 unx      980 b- defN 24-Apr-16 06:41 dmm/data_source/__init__.py
+-rw-r--r--  2.0 unx     2348 b- defN 24-Apr-16 06:41 dmm/data_source/data_source_base.py
+-rw-r--r--  2.0 unx     3161 b- defN 24-Apr-16 06:41 dmm/data_source/dataframe_source.py
+-rw-r--r--  2.0 unx    59608 b- defN 24-Apr-16 06:41 dmm/data_source/datarobot_source.py
+-rw-r--r--  2.0 unx     3255 b- defN 24-Apr-16 06:41 dmm/data_source/generator_source.py
+-rw-r--r--  2.0 unx     1515 b- defN 24-Apr-16 06:41 dmm/data_source/runtime_parameters_source.py
+-rw-r--r--  2.0 unx      252 b- defN 24-Apr-16 06:41 dmm/data_source/datarobot/__init__.py
+-rw-r--r--  2.0 unx     5434 b- defN 24-Apr-16 06:41 dmm/data_source/datarobot/deployment.py
+-rw-r--r--  2.0 unx     5495 b- defN 24-Apr-16 06:41 dmm/data_source/datarobot/export_provider.py
+-rw-r--r--  2.0 unx      428 b- defN 24-Apr-16 06:41 dmm/dr_custom_metrics/__init__.py
+-rw-r--r--  2.0 unx     1667 b- defN 24-Apr-16 06:41 dmm/dr_custom_metrics/deployment_event_reporter.py
+-rw-r--r--  2.0 unx     8764 b- defN 24-Apr-16 06:41 dmm/dr_custom_metrics/dr_custom_metric.py
+-rw-r--r--  2.0 unx      711 b- defN 24-Apr-16 06:41 dmm/metric/__init__.py
+-rw-r--r--  2.0 unx     1872 b- defN 24-Apr-16 06:41 dmm/metric/asymmetric_error.py
+-rw-r--r--  2.0 unx      572 b- defN 24-Apr-16 06:41 dmm/metric/median_absolute_error.py
+-rw-r--r--  2.0 unx     4424 b- defN 24-Apr-16 06:41 dmm/metric/metric_base.py
+-rw-r--r--  2.0 unx     1209 b- defN 24-Apr-16 06:41 dmm/metric/missing_values.py
+-rw-r--r--  2.0 unx     2302 b- defN 24-Apr-16 06:41 dmm/metric/sklearn_metric.py
+-rw-r--r--  2.0 unx    40827 b- defN 24-Apr-16 06:43 datarobot_model_metrics-0.5.5.dist-info/METADATA
+-rw-r--r--  2.0 unx      110 b- defN 24-Apr-16 06:43 datarobot_model_metrics-0.5.5.dist-info/WHEEL
+-rw-r--r--  2.0 unx        4 b- defN 24-Apr-16 06:43 datarobot_model_metrics-0.5.5.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     2783 b- defN 24-Apr-16 06:43 datarobot_model_metrics-0.5.5.dist-info/RECORD
+32 files, 221858 bytes uncompressed, 52275 bytes compressed:  76.4%
```

## zipnote {}

```diff
@@ -78,20 +78,20 @@
 
 Filename: dmm/metric/missing_values.py
 Comment: 
 
 Filename: dmm/metric/sklearn_metric.py
 Comment: 
 
-Filename: datarobot_model_metrics-0.5.4.dist-info/METADATA
+Filename: datarobot_model_metrics-0.5.5.dist-info/METADATA
 Comment: 
 
-Filename: datarobot_model_metrics-0.5.4.dist-info/WHEEL
+Filename: datarobot_model_metrics-0.5.5.dist-info/WHEEL
 Comment: 
 
-Filename: datarobot_model_metrics-0.5.4.dist-info/top_level.txt
+Filename: datarobot_model_metrics-0.5.5.dist-info/top_level.txt
 Comment: 
 
-Filename: datarobot_model_metrics-0.5.4.dist-info/RECORD
+Filename: datarobot_model_metrics-0.5.5.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## dmm/custom_metric.py

```diff
@@ -8,34 +8,52 @@
 # This is proprietary source code of DataRobot, Inc. and its
 # affiliates.
 #
 # Released under the terms of DataRobot Tool and Utility Agreement.
 from __future__ import annotations
 
 import os
+from dataclasses import dataclass
 from datetime import datetime
+from typing import List, Optional, Union
 
 import datarobot as dr
+import dateutil
 import pandas as pd
 import requests
 from dateutil.parser import parse
 
 from dmm.constants import CustomMetricAggregationType, CustomMetricDirectionality
 from dmm.datarobot_api_client import DataRobotApiClient
+from dmm.utils import chunk_list
 
+MAX_BUCKETS_NUMBER_PER_REQUEST = 10000
 _global_client = None
 
 
 def get_global_client():
     global _global_client
     if not _global_client:
         _global_client = dr.Client()
     return _global_client
 
 
+@dataclass
+class SingleMetricResult:
+    """
+    Helper data class that contains fields required for individual metric results.
+    Used to report metric values per prediction row.
+    """
+
+    value: float
+    timestamp: Optional[Union[datetime, str]] = None
+    batch_id: Optional[str] = None
+    association_id: Optional[str] = None
+
+
 class CustomMetric:
     def __init__(
         self,
         custom_metric_id: str,
         deployment_id: str,
         model_id: str,
         name: str,
@@ -125,14 +143,18 @@
             time_format=cm_metadata["timestamp"]["timeFormat"],
             client=client,
             is_batch=is_batch,
         )
         return custom_metric
 
     def report(self, df: pd.DataFrame, dry_run: bool = False) -> requests.Response:
+        """
+        Method used to report aggregated custom metrics values in form of pandas DataFrame.
+        This is motivated by the fact that the MetricEvaluator returns such a data format at the output.
+        """
         buckets = []
         for _, row in df.iterrows():
             bucket = {"sampleSize": row["samples"]}
 
             # if the metric aggregation type is sum and values aggregated over time are passed,
             # the reverse operation is performed before the values are sent to DR to avoid double aggregation
             if self.aggregation_type == CustomMetricAggregationType.SUM:
@@ -184,14 +206,70 @@
             custom_metric_id=self.custom_metric_id,
             model_id=self.model_id,
             buckets=[bucket],
             dry_run=dry_run,
         )
         return response
 
+    def report_single_results(
+        self, results: List[SingleMetricResult], dry_run: bool = False
+    ) -> None:
+        """
+        Method that is used to report non-aggregated custom metric values.
+        In this case, each bucket corresponds to one custom metric result.
+        """
+        buckets = []
+        for result in results:
+            bucket = {"sampleSize": 1, "value": result.value}
+
+            if not result.timestamp and not result.batch_id:
+                raise ValueError(
+                    "Each metric result must have either timestamp or batch defined."
+                )
+
+            if result.timestamp and self.is_batch:
+                raise ValueError(
+                    f"Custom metric: {self.name} values should contain only batch IDs"
+                )
+
+            if result.batch_id and not self.is_batch:
+                raise ValueError(
+                    f"Custom metric: {self.name} values should contain only timestamps"
+                )
+
+            if result.timestamp:
+                if isinstance(result.timestamp, datetime):
+                    bucket["timestamp"] = result.timestamp.isoformat()
+                else:
+                    bucket["timestamp"] = dateutil.parser.parse(
+                        result.timestamp
+                    ).isoformat()
+
+            if result.batch_id:
+                bucket["batch"] = result.batch_id
+
+            if result.association_id:
+                bucket["associationId"] = result.association_id
+
+            buckets.append(bucket)
+
+        if len(buckets) > MAX_BUCKETS_NUMBER_PER_REQUEST:
+            chunks = chunk_list(buckets, MAX_BUCKETS_NUMBER_PER_REQUEST)
+        else:
+            chunks = [buckets]
+
+        for chunk in chunks:
+            self._api.submit_custom_metric_values(
+                deployment_id=self.deployment_id,
+                custom_metric_id=self.custom_metric_id,
+                model_id=self.model_id,
+                buckets=chunk,
+                dry_run=dry_run,
+            )
+
 
 class CustomLLMMetric:
     """Used for custom metrics that are generated for a single prompt-response pair from
     the LLM Playground.  Custom LLM metrics that are associated with a deployed LLM will
     use CustomMetric to report results."""
 
     def __init__(
```

## dmm/utils.py

```diff
@@ -7,14 +7,16 @@
 #
 # This is proprietary source code of DataRobot, Inc. and its
 # affiliates.
 #
 # Released under the terms of DataRobot Tool and Utility Agreement.
 import os
 from datetime import datetime, timedelta, timezone
+from itertools import islice
+from typing import Iterator, List
 
 from datarobot import Client
 from datarobot.utils.waiters import wait_for_async_resolution
 from dateutil.parser import parse
 from requests import Response
 
 
@@ -55,14 +57,19 @@
     return datetime_to_round.replace(second=0, microsecond=0, minute=0)
 
 
 def hour_rounder_down(datetime_to_round: datetime) -> datetime:
     return datetime_to_round.replace(microsecond=0, second=0, minute=0)
 
 
+def chunk_list(it: List, size: int) -> Iterator:
+    it = iter(it)
+    return iter(lambda: tuple(islice(it, size)), ())
+
+
 class RunTimeParameterHandler:
     """"""
 
     def __init__(self):
         self.deployment_id = os.environ.get("DEPLOYMENT_ID")
         self.playground_id = os.environ.get("PLAYGROUND_ID")
         if self.deployment_id and self.playground_id:
```

## Comparing `datarobot_model_metrics-0.5.4.dist-info/METADATA` & `datarobot_model_metrics-0.5.5.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: datarobot-model-metrics
-Version: 0.5.4
+Version: 0.5.5
 Summary: datarobot-model-metrics provides a framework to compute model ML metrics over time and produce aggregated metrics.
 Home-page: https://github.com/datarobot/datarobot-model-metrics
 Author: DataRobot
 Author-email: info@datarobot.com
 License: DataRobot
 Platform: UNKNOWN
 Classifier: Programming Language :: Python :: 3
```

## Comparing `datarobot_model_metrics-0.5.4.dist-info/RECORD` & `datarobot_model_metrics-0.5.5.dist-info/RECORD`

 * *Files 18% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 dmm/__init__.py,sha256=aOh7b_vX80N1OpYTBK6iDhHd-dLPBQhuMmC74VMYwwI,637
 dmm/batch_metric_evaluator.py,sha256=1B_r6wuiclaYsG9ku9lmralnL944M9P_pi2lj4wLPEo,10115
 dmm/constants.py,sha256=kA7PLpdv4p63Ks4qa-pqI9-qKQG1E7RRcRzYC3QY9Vw,2123
-dmm/custom_metric.py,sha256=KL0jQIlW2515R9WH0a3ryhXYQ0bZyy97_eSIqB-Fh-4,8062
+dmm/custom_metric.py,sha256=NxvWxJuKUONUAIjDIxE7j6DcYfdj4dqn3O80MVOFx_g,10806
 dmm/datarobot_api_client.py,sha256=cMloeC4kcv3_9vxJNWmimJfYGiASZUC5s-_BrzUukyU,16633
 dmm/example_data_helper.py,sha256=ar8_YARtH-_W078lRrNrDNxTNm5q9rAPjvOWfL7mNyU,7206
 dmm/exceptions.py,sha256=0IgGfrXQ_PPry9O6ctZSBFrmU_l4MaKjRwjhG0EVweQ,545
 dmm/metric_evaluator.py,sha256=zeTAyyuBfxo35U9yBxEtyMx5KIIu7LO6Bz8b2yYQXY0,18191
 dmm/time_bucket.py,sha256=Q5TDguUfQJld6kvZkgBfvM2-9UMRxKB-8XER5x-Cvbw,3680
-dmm/utils.py,sha256=6xl-pI6enGgQUjvpzCEMkPvD1YsW1zlygfw6YYFMhkY,4016
+dmm/utils.py,sha256=rXnJLqLjv34KeFoikN0FDF9A0TfBERPgvY7qpJhAOVw,4201
 dmm/data_source/__init__.py,sha256=kHvEX3_rIuhNdvYYcxAqFQcHJTIJBDYtY7ah_Oa8K58,980
 dmm/data_source/data_source_base.py,sha256=erZ3ieqOiQC9ebrS_MmBAxsxxoKqeK9jH7rwrruECFQ,2348
 dmm/data_source/dataframe_source.py,sha256=hQiBwZI0-eKCyqBlMvENa6XGSnPXV9rElqqiLjU8WMk,3161
 dmm/data_source/datarobot_source.py,sha256=JFnDhpUipdYuU55XS_DAyDkJMiAzYOqivTZRvCUH93U,59608
 dmm/data_source/generator_source.py,sha256=Tqn-cDeeHoPBLVqseao2nftqgUwvLGYyatVIkXCAcAs,3255
 dmm/data_source/runtime_parameters_source.py,sha256=LBbBqRpi1pEKvMXzOBuvklViyRSVq1czniNqX7-8Wg4,1515
 dmm/data_source/datarobot/__init__.py,sha256=T6qXyJ8_GGn6SYg3J6JZgYMajJ9WH_nBZefjdy3d09k,252
@@ -22,11 +22,11 @@
 dmm/dr_custom_metrics/dr_custom_metric.py,sha256=c1HormGR7eiQz3UlEPv-xru6G4DeLT-BtUAcIREX-Bo,8764
 dmm/metric/__init__.py,sha256=q0HfjwoQf22jyhja1Z-Vl0kBLQcl1pjn5VrCz1Qhq2Q,711
 dmm/metric/asymmetric_error.py,sha256=uJVfUx1T0dIcg419Y6XW-qA3qTUVMbG4hzyTXXPaGeY,1872
 dmm/metric/median_absolute_error.py,sha256=OYnw12uBLQH6ldBEUaZqvClGnmjV6t8kSYjo-ddy69M,572
 dmm/metric/metric_base.py,sha256=1pjyA-Cz1PRxTLknuJvWANam_XCsU7734zn5xUBjjXs,4424
 dmm/metric/missing_values.py,sha256=KAj2GDVKaYk3yT_VuLPs09qTCu64tYAmfts9ehhp8Xs,1209
 dmm/metric/sklearn_metric.py,sha256=mxHimJhkPCJrWbKbBFKgZ_DY0F0uip5ehEDYr6aZgbk,2302
-datarobot_model_metrics-0.5.4.dist-info/METADATA,sha256=gckAeJmfUwfZ5-jJBD9i3vQVnJy41HjCcy9HE1G6B8A,40827
-datarobot_model_metrics-0.5.4.dist-info/WHEEL,sha256=iYlv5fX357PQyRT2o6tw1bN-YcKFFHKqB_LwHO5wP-g,110
-datarobot_model_metrics-0.5.4.dist-info/top_level.txt,sha256=69FbTyYFh17OyfaIppCUhlu4QG-prAaQ6ovJ_X0SNG8,4
-datarobot_model_metrics-0.5.4.dist-info/RECORD,,
+datarobot_model_metrics-0.5.5.dist-info/METADATA,sha256=t0aFrz_Tdm3J9mn6o-eNVH-jNdnJWEovI7L4ChkKmpg,40827
+datarobot_model_metrics-0.5.5.dist-info/WHEEL,sha256=iYlv5fX357PQyRT2o6tw1bN-YcKFFHKqB_LwHO5wP-g,110
+datarobot_model_metrics-0.5.5.dist-info/top_level.txt,sha256=69FbTyYFh17OyfaIppCUhlu4QG-prAaQ6ovJ_X0SNG8,4
+datarobot_model_metrics-0.5.5.dist-info/RECORD,,
```

